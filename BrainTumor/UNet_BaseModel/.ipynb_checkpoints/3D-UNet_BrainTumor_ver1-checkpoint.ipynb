{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "560838ee-203a-4968-adef-6444de37a2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jaber\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jaber\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor']. Received: the structure of inputs=*\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1/387 ━━━━━━━━━━━━━━━━━━━━ 10:23:18\n",
      "Accuracy: 0.6511 - Precision: 0.0389 - Recall: 0.7928 - Specificity: 0.6486 - F1: 0.0742 - Loss: 1.5864\n",
      "\n",
      "Batch 2/387 ━━━━━━━━━━━━━━━━━━━━ 10:25:17\n",
      "Accuracy: 0.7611 - Precision: 0.0750 - Recall: 0.8652 - Specificity: 0.7593 - F1: 0.1363 - Loss: 1.4791\n",
      "\n",
      "Batch 3/387 ━━━━━━━━━━━━━━━━━━━━ 10:27:26\n",
      "Accuracy: 0.8369 - Precision: 0.2427 - Recall: 0.7513 - Specificity: 0.8378 - F1: 0.2740 - Loss: 1.4046\n",
      "\n",
      "Batch 4/387 ━━━━━━━━━━━━━━━━━━━━ 10:29:10\n",
      "Accuracy: 0.8678 - Precision: 0.2587 - Recall: 0.7635 - Specificity: 0.8693 - F1: 0.3163 - Loss: 1.3447\n",
      "\n",
      "Batch 5/387 ━━━━━━━━━━━━━━━━━━━━ 10:31:09\n",
      "Accuracy: 0.8904 - Precision: 0.2476 - Recall: 0.8108 - Specificity: 0.8915 - F1: 0.3207 - Loss: 1.3105\n",
      "\n",
      "Batch 6/387 ━━━━━━━━━━━━━━━━━━━━ 10:32:45\n",
      "Accuracy: 0.9070 - Precision: 0.2567 - Recall: 0.8267 - Specificity: 0.9080 - F1: 0.3428 - Loss: 1.2820\n",
      "\n",
      "Batch 7/387 ━━━━━━━━━━━━━━━━━━━━ 10:34:34\n",
      "Accuracy: 0.9193 - Precision: 0.3556 - Recall: 0.7869 - Specificity: 0.9211 - F1: 0.3931 - Loss: 1.2553\n",
      "\n",
      "Batch 8/387 ━━━━━━━━━━━━━━━━━━━━ 10:36:17\n",
      "Accuracy: 0.9280 - Precision: 0.3476 - Recall: 0.7713 - Specificity: 0.9298 - F1: 0.3946 - Loss: 1.2377\n",
      "\n",
      "Batch 9/387 ━━━━━━━━━━━━━━━━━━━━ 10:37:53\n",
      "Accuracy: 0.9350 - Precision: 0.3628 - Recall: 0.7623 - Specificity: 0.9369 - F1: 0.4140 - Loss: 1.2205\n",
      "\n",
      "Batch 10/387 ━━━━━━━━━━━━━━━━━━━━ 10:39:30\n",
      "Accuracy: 0.9401 - Precision: 0.3554 - Recall: 0.7618 - Specificity: 0.9420 - F1: 0.4144 - Loss: 1.2068\n",
      "\n",
      "Batch 11/387 ━━━━━━━━━━━━━━━━━━━━ 10:41:09\n",
      "Accuracy: 0.9443 - Precision: 0.3581 - Recall: 0.7778 - Specificity: 0.9460 - F1: 0.4264 - Loss: 1.1882\n",
      "\n",
      "Batch 12/387 ━━━━━━━━━━━━━━━━━━━━ 10:42:42\n",
      "Accuracy: 0.9487 - Precision: 0.4084 - Recall: 0.7908 - Specificity: 0.9504 - F1: 0.4699 - Loss: 1.1598\n",
      "\n",
      "Batch 13/387 ━━━━━━━━━━━━━━━━━━━━ 10:44:09\n",
      "Accuracy: 0.9523 - Precision: 0.4466 - Recall: 0.7989 - Specificity: 0.9541 - F1: 0.5030 - Loss: 1.1306\n",
      "\n",
      "Batch 14/387 ━━━━━━━━━━━━━━━━━━━━ 10:45:29\n",
      "Accuracy: 0.9539 - Precision: 0.4342 - Recall: 0.8049 - Specificity: 0.9556 - F1: 0.4968 - Loss: 1.1182\n",
      "\n",
      "Batch 15/387 ━━━━━━━━━━━━━━━━━━━━ 10:46:59\n",
      "Accuracy: 0.9567 - Precision: 0.4586 - Recall: 0.8128 - Specificity: 0.9584 - F1: 0.5209 - Loss: 1.0991\n",
      "\n",
      "Batch 16/387 ━━━━━━━━━━━━━━━━━━━━ 10:48:31\n",
      "Accuracy: 0.9586 - Precision: 0.4393 - Recall: 0.8202 - Specificity: 0.9602 - F1: 0.5044 - Loss: 1.0954\n",
      "\n",
      "Batch 17/387 ━━━━━━━━━━━━━━━━━━━━ 10:49:55\n",
      "Accuracy: 0.9607 - Precision: 0.4369 - Recall: 0.8189 - Specificity: 0.9622 - F1: 0.5060 - Loss: 1.0892\n",
      "\n",
      "Batch 18/387 ━━━━━━━━━━━━━━━━━━━━ 10:51:29\n",
      "Accuracy: 0.9628 - Precision: 0.4636 - Recall: 0.8170 - Specificity: 0.9643 - F1: 0.5248 - Loss: 1.0806\n",
      "\n",
      "Batch 19/387 ━━━━━━━━━━━━━━━━━━━━ 10:52:57\n",
      "Accuracy: 0.9646 - Precision: 0.4846 - Recall: 0.8215 - Specificity: 0.9661 - F1: 0.5437 - Loss: 1.0608\n",
      "\n",
      "Batch 20/387 ━━━━━━━━━━━━━━━━━━━━ 10:54:16\n",
      "Accuracy: 0.9661 - Precision: 0.4965 - Recall: 0.8296 - Specificity: 0.9676 - F1: 0.5581 - Loss: 1.0472\n",
      "\n",
      "Batch 21/387 ━━━━━━━━━━━━━━━━━━━━ 10:55:47\n",
      "Accuracy: 0.9674 - Precision: 0.5112 - Recall: 0.8319 - Specificity: 0.9689 - F1: 0.5716 - Loss: 1.0273\n",
      "\n",
      "Batch 22/387 ━━━━━━━━━━━━━━━━━━━━ 10:57:32\n",
      "Accuracy: 0.9682 - Precision: 0.5062 - Recall: 0.8388 - Specificity: 0.9696 - F1: 0.5715 - Loss: 1.0170\n",
      "\n",
      "Batch 23/387 ━━━━━━━━━━━━━━━━━━━━ 10:59:17\n",
      "Accuracy: 0.9687 - Precision: 0.4893 - Recall: 0.8453 - Specificity: 0.9700 - F1: 0.5557 - Loss: 1.0163\n",
      "\n",
      "Batch 24/387 ━━━━━━━━━━━━━━━━━━━━ 11:00:46\n",
      "Accuracy: 0.9699 - Precision: 0.5100 - Recall: 0.8456 - Specificity: 0.9713 - F1: 0.5706 - Loss: 1.0034\n",
      "\n",
      "Batch 25/387 ━━━━━━━━━━━━━━━━━━━━ 11:02:05\n",
      "Accuracy: 0.9708 - Precision: 0.5268 - Recall: 0.8376 - Specificity: 0.9724 - F1: 0.5783 - Loss: 0.9900\n",
      "\n",
      "Batch 26/387 ━━━━━━━━━━━━━━━━━━━━ 11:03:33\n",
      "Accuracy: 0.9718 - Precision: 0.5422 - Recall: 0.8393 - Specificity: 0.9734 - F1: 0.5908 - Loss: 0.9769\n",
      "\n",
      "Batch 27/387 ━━━━━━━━━━━━━━━━━━━━ 11:04:56\n",
      "Accuracy: 0.9723 - Precision: 0.5308 - Recall: 0.8404 - Specificity: 0.9739 - F1: 0.5827 - Loss: 0.9741\n",
      "\n",
      "Batch 28/387 ━━━━━━━━━━━━━━━━━━━━ 11:06:15\n",
      "Accuracy: 0.9731 - Precision: 0.5329 - Recall: 0.8434 - Specificity: 0.9746 - F1: 0.5876 - Loss: 0.9657\n",
      "\n",
      "Batch 29/387 ━━━━━━━━━━━━━━━━━━━━ 11:07:45\n",
      "Accuracy: 0.9739 - Precision: 0.5321 - Recall: 0.8473 - Specificity: 0.9753 - F1: 0.5902 - Loss: 0.9617\n",
      "\n",
      "Batch 30/387 ━━━━━━━━━━━━━━━━━━━━ 11:09:13\n",
      "Accuracy: 0.9745 - Precision: 0.5418 - Recall: 0.8462 - Specificity: 0.9761 - F1: 0.5978 - Loss: 0.9496\n",
      "\n",
      "Batch 31/387 ━━━━━━━━━━━━━━━━━━━━ 11:10:44\n",
      "Accuracy: 0.9751 - Precision: 0.5291 - Recall: 0.8493 - Specificity: 0.9766 - F1: 0.5869 - Loss: 0.9504\n",
      "\n",
      "Batch 32/387 ━━━━━━━━━━━━━━━━━━━━ 11:12:12\n",
      "Accuracy: 0.9758 - Precision: 0.5427 - Recall: 0.8503 - Specificity: 0.9773 - F1: 0.5973 - Loss: 0.9345\n",
      "\n",
      "Batch 33/387 ━━━━━━━━━━━━━━━━━━━━ 11:13:35\n",
      "Accuracy: 0.9763 - Precision: 0.5507 - Recall: 0.8506 - Specificity: 0.9778 - F1: 0.6044 - Loss: 0.9214\n",
      "\n",
      "Batch 34/387 ━━━━━━━━━━━━━━━━━━━━ 11:14:53\n",
      "Accuracy: 0.9767 - Precision: 0.5507 - Recall: 0.8511 - Specificity: 0.9783 - F1: 0.6065 - Loss: 0.9149\n",
      "\n",
      "Batch 35/387 ━━━━━━━━━━━━━━━━━━━━ 11:16:17\n",
      "Accuracy: 0.9766 - Precision: 0.5375 - Recall: 0.8490 - Specificity: 0.9781 - F1: 0.5938 - Loss: 0.9177\n",
      "\n",
      "Batch 36/387 ━━━━━━━━━━━━━━━━━━━━ 11:17:44\n",
      "Accuracy: 0.9771 - Precision: 0.5383 - Recall: 0.8511 - Specificity: 0.9786 - F1: 0.5967 - Loss: 0.9105\n",
      "\n",
      "Batch 37/387 ━━━━━━━━━━━━━━━━━━━━ 11:19:06\n",
      "Accuracy: 0.9776 - Precision: 0.5504 - Recall: 0.8498 - Specificity: 0.9791 - F1: 0.6045 - Loss: 0.9035\n",
      "\n",
      "Batch 38/387 ━━━━━━━━━━━━━━━━━━━━ 11:20:40\n",
      "Accuracy: 0.9781 - Precision: 0.5490 - Recall: 0.8512 - Specificity: 0.9796 - F1: 0.6055 - Loss: 0.9019\n",
      "\n",
      "Batch 39/387 ━━━━━━━━━━━━━━━━━━━━ 11:22:02\n",
      "Accuracy: 0.9786 - Precision: 0.5567 - Recall: 0.8547 - Specificity: 0.9801 - F1: 0.6134 - Loss: 0.8926\n",
      "\n",
      "Batch 40/387 ━━━━━━━━━━━━━━━━━━━━ 11:23:25\n",
      "Accuracy: 0.9791 - Precision: 0.5620 - Recall: 0.8573 - Specificity: 0.9805 - F1: 0.6194 - Loss: 0.8847\n",
      "\n",
      "Batch 41/387 ━━━━━━━━━━━━━━━━━━━━ 11:25:03\n",
      "Accuracy: 0.9795 - Precision: 0.5699 - Recall: 0.8598 - Specificity: 0.9809 - F1: 0.6268 - Loss: 0.8738\n",
      "\n",
      "Batch 42/387 ━━━━━━━━━━━━━━━━━━━━ 11:26:24\n",
      "Accuracy: 0.9800 - Precision: 0.5778 - Recall: 0.8608 - Specificity: 0.9814 - F1: 0.6333 - Loss: 0.8634\n",
      "\n",
      "Batch 43/387 ━━━━━━━━━━━━━━━━━━━━ 11:28:08\n",
      "Accuracy: 0.9803 - Precision: 0.5858 - Recall: 0.8605 - Specificity: 0.9818 - F1: 0.6391 - Loss: 0.8539\n",
      "\n",
      "Batch 44/387 ━━━━━━━━━━━━━━━━━━━━ 11:29:43\n",
      "Accuracy: 0.9807 - Precision: 0.5935 - Recall: 0.8618 - Specificity: 0.9821 - F1: 0.6455 - Loss: 0.8428\n",
      "\n",
      "Batch 45/387 ━━━━━━━━━━━━━━━━━━━━ 11:31:12\n",
      "Accuracy: 0.9806 - Precision: 0.5815 - Recall: 0.8647 - Specificity: 0.9819 - F1: 0.6334 - Loss: 0.8472\n",
      "\n",
      "Batch 46/387 ━━━━━━━━━━━━━━━━━━━━ 11:32:46\n",
      "Accuracy: 0.9809 - Precision: 0.5900 - Recall: 0.8641 - Specificity: 0.9823 - F1: 0.6391 - Loss: 0.8371\n",
      "\n",
      "Batch 47/387 ━━━━━━━━━━━━━━━━━━━━ 11:34:20\n",
      "Accuracy: 0.9812 - Precision: 0.5959 - Recall: 0.8665 - Specificity: 0.9826 - F1: 0.6451 - Loss: 0.8256\n",
      "\n",
      "Batch 48/387 ━━━━━━━━━━━━━━━━━━━━ 11:35:45\n",
      "Accuracy: 0.9812 - Precision: 0.5857 - Recall: 0.8689 - Specificity: 0.9826 - F1: 0.6356 - Loss: 0.8282\n",
      "\n",
      "Batch 49/387 ━━━━━━━━━━━━━━━━━━━━ 11:37:13\n",
      "Accuracy: 0.9815 - Precision: 0.5879 - Recall: 0.8694 - Specificity: 0.9828 - F1: 0.6385 - Loss: 0.8220\n",
      "\n",
      "Batch 50/387 ━━━━━━━━━━━━━━━━━━━━ 11:38:44\n",
      "Accuracy: 0.9817 - Precision: 0.5960 - Recall: 0.8683 - Specificity: 0.9832 - F1: 0.6437 - Loss: 0.8122\n",
      "\n",
      "Batch 51/387 ━━━━━━━━━━━━━━━━━━━━ 11:40:24\n",
      "Accuracy: 0.9820 - Precision: 0.6000 - Recall: 0.8690 - Specificity: 0.9834 - F1: 0.6477 - Loss: 0.8050\n",
      "\n",
      "Batch 52/387 ━━━━━━━━━━━━━━━━━━━━ 11:41:53\n",
      "Accuracy: 0.9823 - Precision: 0.6000 - Recall: 0.8687 - Specificity: 0.9837 - F1: 0.6488 - Loss: 0.8034\n",
      "\n",
      "Batch 53/387 ━━━━━━━━━━━━━━━━━━━━ 11:43:35\n",
      "Accuracy: 0.9825 - Precision: 0.6071 - Recall: 0.8646 - Specificity: 0.9840 - F1: 0.6513 - Loss: 0.7974\n",
      "\n",
      "Batch 54/387 ━━━━━━━━━━━━━━━━━━━━ 11:45:20\n",
      "Accuracy: 0.9828 - Precision: 0.6133 - Recall: 0.8650 - Specificity: 0.9843 - F1: 0.6561 - Loss: 0.7886\n",
      "\n",
      "Batch 55/387 ━━━━━━━━━━━━━━━━━━━━ 11:46:59\n",
      "Accuracy: 0.9830 - Precision: 0.6178 - Recall: 0.8668 - Specificity: 0.9845 - F1: 0.6608 - Loss: 0.7797\n",
      "\n",
      "Batch 56/387 ━━━━━━━━━━━━━━━━━━━━ 11:48:32\n",
      "Accuracy: 0.9832 - Precision: 0.6181 - Recall: 0.8689 - Specificity: 0.9846 - F1: 0.6627 - Loss: 0.7733\n",
      "\n",
      "Batch 57/387 ━━━━━━━━━━━━━━━━━━━━ 11:49:52\n",
      "Accuracy: 0.9829 - Precision: 0.6099 - Recall: 0.8708 - Specificity: 0.9844 - F1: 0.6557 - Loss: 0.7752\n",
      "\n",
      "Batch 58/387 ━━━━━━━━━━━━━━━━━━━━ 11:51:21\n",
      "Accuracy: 0.9831 - Precision: 0.6096 - Recall: 0.8728 - Specificity: 0.9845 - F1: 0.6572 - Loss: 0.7711\n",
      "\n",
      "Batch 59/387 ━━━━━━━━━━━━━━━━━━━━ 11:52:44\n",
      "Accuracy: 0.9833 - Precision: 0.6152 - Recall: 0.8726 - Specificity: 0.9848 - F1: 0.6613 - Loss: 0.7630\n",
      "\n",
      "Batch 60/387 ━━━━━━━━━━━━━━━━━━━━ 11:54:05\n",
      "Accuracy: 0.9835 - Precision: 0.6209 - Recall: 0.8675 - Specificity: 0.9850 - F1: 0.6622 - Loss: 0.7585\n",
      "\n",
      "Batch 61/387 ━━━━━━━━━━━━━━━━━━━━ 11:55:34\n",
      "Accuracy: 0.9837 - Precision: 0.6267 - Recall: 0.8668 - Specificity: 0.9853 - F1: 0.6659 - Loss: 0.7507\n",
      "\n",
      "Batch 62/387 ━━━━━━━━━━━━━━━━━━━━ 11:57:02\n",
      "Accuracy: 0.9839 - Precision: 0.6317 - Recall: 0.8662 - Specificity: 0.9855 - F1: 0.6694 - Loss: 0.7441\n",
      "\n",
      "Batch 63/387 ━━━━━━━━━━━━━━━━━━━━ 11:58:23\n",
      "Accuracy: 0.9841 - Precision: 0.6331 - Recall: 0.8666 - Specificity: 0.9857 - F1: 0.6714 - Loss: 0.7395\n",
      "\n",
      "Batch 64/387 ━━━━━━━━━━━━━━━━━━━━ 11:59:57\n",
      "Accuracy: 0.9843 - Precision: 0.6362 - Recall: 0.8685 - Specificity: 0.9858 - F1: 0.6750 - Loss: 0.7335\n",
      "\n",
      "Batch 65/387 ━━━━━━━━━━━━━━━━━━━━ 12:01:18\n",
      "Accuracy: 0.9845 - Precision: 0.6408 - Recall: 0.8690 - Specificity: 0.9860 - F1: 0.6787 - Loss: 0.7263\n",
      "\n",
      "Batch 66/387 ━━━━━━━━━━━━━━━━━━━━ 12:02:57\n",
      "Accuracy: 0.9846 - Precision: 0.6387 - Recall: 0.8705 - Specificity: 0.9861 - F1: 0.6785 - Loss: 0.7236\n",
      "\n",
      "Batch 67/387 ━━━━━━━━━━━━━━━━━━━━ 12:04:38\n",
      "Accuracy: 0.9848 - Precision: 0.6407 - Recall: 0.8723 - Specificity: 0.9863 - F1: 0.6813 - Loss: 0.7183\n",
      "\n",
      "Batch 68/387 ━━━━━━━━━━━━━━━━━━━━ 12:06:10\n",
      "Accuracy: 0.9849 - Precision: 0.6419 - Recall: 0.8738 - Specificity: 0.9865 - F1: 0.6835 - Loss: 0.7141\n",
      "\n",
      "Batch 69/387 ━━━━━━━━━━━━━━━━━━━━ 12:07:34\n",
      "Accuracy: 0.9851 - Precision: 0.6450 - Recall: 0.8726 - Specificity: 0.9866 - F1: 0.6855 - Loss: 0.7109\n",
      "\n",
      "Batch 70/387 ━━━━━━━━━━━━━━━━━━━━ 12:08:51\n",
      "Accuracy: 0.9852 - Precision: 0.6433 - Recall: 0.8681 - Specificity: 0.9868 - F1: 0.6834 - Loss: 0.7105\n",
      "\n",
      "Batch 71/387 ━━━━━━━━━━━━━━━━━━━━ 12:10:13\n",
      "Accuracy: 0.9853 - Precision: 0.6407 - Recall: 0.8638 - Specificity: 0.9869 - F1: 0.6809 - Loss: 0.7104\n",
      "\n",
      "Batch 72/387 ━━━━━━━━━━━━━━━━━━━━ 12:11:49\n",
      "Accuracy: 0.9855 - Precision: 0.6456 - Recall: 0.8597 - Specificity: 0.9871 - F1: 0.6815 - Loss: 0.7076\n",
      "\n",
      "Batch 73/387 ━━━━━━━━━━━━━━━━━━━━ 12:13:18\n",
      "Accuracy: 0.9856 - Precision: 0.6504 - Recall: 0.8563 - Specificity: 0.9873 - F1: 0.6825 - Loss: 0.7039\n",
      "\n",
      "Batch 74/387 ━━━━━━━━━━━━━━━━━━━━ 12:14:42\n",
      "Accuracy: 0.9858 - Precision: 0.6511 - Recall: 0.8571 - Specificity: 0.9874 - F1: 0.6841 - Loss: 0.7015\n",
      "\n",
      "Batch 75/387 ━━━━━━━━━━━━━━━━━━━━ 12:16:08\n",
      "Accuracy: 0.9859 - Precision: 0.6546 - Recall: 0.8582 - Specificity: 0.9876 - F1: 0.6873 - Loss: 0.6957\n",
      "\n",
      "Batch 76/387 ━━━━━━━━━━━━━━━━━━━━ 12:17:26\n",
      "Accuracy: 0.9860 - Precision: 0.6581 - Recall: 0.8578 - Specificity: 0.9877 - F1: 0.6897 - Loss: 0.6899\n",
      "\n",
      "Batch 77/387 ━━━━━━━━━━━━━━━━━━━━ 12:19:00\n",
      "Accuracy: 0.9862 - Precision: 0.6588 - Recall: 0.8596 - Specificity: 0.9878 - F1: 0.6915 - Loss: 0.6859\n",
      "\n",
      "Batch 78/387 ━━━━━━━━━━━━━━━━━━━━ 12:20:29\n",
      "Accuracy: 0.9863 - Precision: 0.6594 - Recall: 0.8610 - Specificity: 0.9879 - F1: 0.6932 - Loss: 0.6830\n",
      "\n",
      "Batch 79/387 ━━━━━━━━━━━━━━━━━━━━ 12:21:55\n",
      "Accuracy: 0.9864 - Precision: 0.6595 - Recall: 0.8624 - Specificity: 0.9880 - F1: 0.6944 - Loss: 0.6795\n",
      "\n",
      "Batch 80/387 ━━━━━━━━━━━━━━━━━━━━ 12:23:20\n",
      "Accuracy: 0.9865 - Precision: 0.6612 - Recall: 0.8634 - Specificity: 0.9881 - F1: 0.6965 - Loss: 0.6744\n",
      "\n",
      "Batch 81/387 ━━━━━━━━━━━━━━━━━━━━ 12:24:40\n",
      "Accuracy: 0.9867 - Precision: 0.6648 - Recall: 0.8639 - Specificity: 0.9883 - F1: 0.6994 - Loss: 0.6683\n",
      "\n",
      "Batch 82/387 ━━━━━━━━━━━━━━━━━━━━ 12:26:12\n",
      "Accuracy: 0.9868 - Precision: 0.6680 - Recall: 0.8646 - Specificity: 0.9884 - F1: 0.7021 - Loss: 0.6631\n",
      "\n",
      "Batch 83/387 ━━━━━━━━━━━━━━━━━━━━ 12:27:32\n",
      "Accuracy: 0.9869 - Precision: 0.6691 - Recall: 0.8636 - Specificity: 0.9885 - F1: 0.7030 - Loss: 0.6602\n",
      "\n",
      "Batch 84/387 ━━━━━━━━━━━━━━━━━━━━ 12:29:05\n",
      "Accuracy: 0.9870 - Precision: 0.6698 - Recall: 0.8637 - Specificity: 0.9886 - F1: 0.7040 - Loss: 0.6577\n",
      "\n",
      "Batch 85/387 ━━━━━━━━━━━━━━━━━━━━ 12:30:23\n",
      "Accuracy: 0.9872 - Precision: 0.6706 - Recall: 0.8637 - Specificity: 0.9887 - F1: 0.7051 - Loss: 0.6574\n",
      "\n",
      "Batch 86/387 ━━━━━━━━━━━━━━━━━━━━ 12:31:41\n",
      "Accuracy: 0.9872 - Precision: 0.6743 - Recall: 0.8607 - Specificity: 0.9889 - F1: 0.7056 - Loss: 0.6540\n",
      "\n",
      "Batch 87/387 ━━━━━━━━━━━━━━━━━━━━ 12:33:03\n",
      "Accuracy: 0.9873 - Precision: 0.6771 - Recall: 0.8601 - Specificity: 0.9890 - F1: 0.7073 - Loss: 0.6494\n",
      "\n",
      "Batch 88/387 ━━━━━━━━━━━━━━━━━━━━ 12:34:30\n",
      "Accuracy: 0.9874 - Precision: 0.6804 - Recall: 0.8599 - Specificity: 0.9891 - F1: 0.7095 - Loss: 0.6442\n",
      "\n",
      "Batch 89/387 ━━━━━━━━━━━━━━━━━━━━ 12:35:50\n",
      "Accuracy: 0.9874 - Precision: 0.6753 - Recall: 0.8610 - Specificity: 0.9891 - F1: 0.7057 - Loss: 0.6453\n",
      "\n",
      "Batch 90/387 ━━━━━━━━━━━━━━━━━━━━ 12:37:10\n",
      "Accuracy: 0.9875 - Precision: 0.6746 - Recall: 0.8622 - Specificity: 0.9892 - F1: 0.7062 - Loss: 0.6425\n",
      "\n",
      "Batch 91/387 ━━━━━━━━━━━━━━━━━━━━ 12:38:29\n",
      "Accuracy: 0.9875 - Precision: 0.6691 - Recall: 0.8637 - Specificity: 0.9891 - F1: 0.7017 - Loss: 0.6444\n",
      "\n",
      "Batch 92/387 ━━━━━━━━━━━━━━━━━━━━ 12:40:00\n",
      "Accuracy: 0.9876 - Precision: 0.6695 - Recall: 0.8643 - Specificity: 0.9892 - F1: 0.7028 - Loss: 0.6413\n",
      "\n",
      "Batch 93/387 ━━━━━━━━━━━━━━━━━━━━ 12:41:36\n",
      "Accuracy: 0.9876 - Precision: 0.6649 - Recall: 0.8615 - Specificity: 0.9893 - F1: 0.6990 - Loss: 0.6429\n",
      "\n",
      "Batch 94/387 ━━━━━━━━━━━━━━━━━━━━ 12:43:23\n",
      "Accuracy: 0.9877 - Precision: 0.6683 - Recall: 0.8575 - Specificity: 0.9894 - F1: 0.6985 - Loss: 0.6411\n",
      "\n",
      "Batch 95/387 ━━━━━━━━━━━━━━━━━━━━ 12:44:51\n",
      "Accuracy: 0.9877 - Precision: 0.6718 - Recall: 0.8523 - Specificity: 0.9895 - F1: 0.6967 - Loss: 0.6405\n",
      "\n",
      "Batch 96/387 ━━━━━━━━━━━━━━━━━━━━ 12:46:25\n",
      "Accuracy: 0.9878 - Precision: 0.6739 - Recall: 0.8525 - Specificity: 0.9896 - F1: 0.6985 - Loss: 0.6371\n",
      "\n",
      "Batch 97/387 ━━━━━━━━━━━━━━━━━━━━ 12:47:47\n",
      "Accuracy: 0.9879 - Precision: 0.6752 - Recall: 0.8536 - Specificity: 0.9897 - F1: 0.7003 - Loss: 0.6338\n",
      "\n",
      "Batch 98/387 ━━━━━━━━━━━━━━━━━━━━ 12:49:17\n",
      "Accuracy: 0.9879 - Precision: 0.6785 - Recall: 0.8523 - Specificity: 0.9898 - F1: 0.7017 - Loss: 0.6298\n",
      "\n",
      "Batch 99/387 ━━━━━━━━━━━━━━━━━━━━ 12:50:45\n",
      "Accuracy: 0.9880 - Precision: 0.6792 - Recall: 0.8532 - Specificity: 0.9899 - F1: 0.7030 - Loss: 0.6264\n",
      "\n",
      "Batch 100/387 ━━━━━━━━━━━━━━━━━━━━ 12:52:05\n",
      "Accuracy: 0.9879 - Precision: 0.6739 - Recall: 0.8543 - Specificity: 0.9898 - F1: 0.6987 - Loss: 0.6286\n",
      "\n",
      "Batch 101/387 ━━━━━━━━━━━━━━━━━━━━ 12:53:31\n",
      "Accuracy: 0.9880 - Precision: 0.6759 - Recall: 0.8551 - Specificity: 0.9899 - F1: 0.7007 - Loss: 0.6242\n",
      "\n",
      "Batch 102/387 ━━━━━━━━━━━━━━━━━━━━ 12:54:47\n",
      "Accuracy: 0.9881 - Precision: 0.6777 - Recall: 0.8548 - Specificity: 0.9900 - F1: 0.7021 - Loss: 0.6212\n",
      "\n",
      "Batch 103/387 ━━━━━━━━━━━━━━━━━━━━ 12:56:13\n",
      "Accuracy: 0.9882 - Precision: 0.6791 - Recall: 0.8555 - Specificity: 0.9900 - F1: 0.7038 - Loss: 0.6178\n",
      "\n",
      "Batch 104/387 ━━━━━━━━━━━━━━━━━━━━ 12:57:38\n",
      "Accuracy: 0.9883 - Precision: 0.6813 - Recall: 0.8554 - Specificity: 0.9901 - F1: 0.7054 - Loss: 0.6140\n",
      "\n",
      "Batch 105/387 ━━━━━━━━━━━━━━━━━━━━ 12:59:14\n",
      "Accuracy: 0.9883 - Precision: 0.6767 - Recall: 0.8554 - Specificity: 0.9901 - F1: 0.7017 - Loss: 0.6154\n",
      "\n",
      "Batch 106/387 ━━━━━━━━━━━━━━━━━━━━ 13:00:43\n",
      "Accuracy: 0.9883 - Precision: 0.6777 - Recall: 0.8525 - Specificity: 0.9902 - F1: 0.7011 - Loss: 0.6143\n",
      "\n",
      "Batch 107/387 ━━━━━━━━━━━━━━━━━━━━ 13:02:11\n",
      "Accuracy: 0.9884 - Precision: 0.6806 - Recall: 0.8513 - Specificity: 0.9903 - F1: 0.7024 - Loss: 0.6108\n",
      "\n",
      "Batch 108/387 ━━━━━━━━━━━━━━━━━━━━ 13:03:31\n",
      "Accuracy: 0.9885 - Precision: 0.6834 - Recall: 0.8512 - Specificity: 0.9904 - F1: 0.7044 - Loss: 0.6066\n",
      "\n",
      "Batch 109/387 ━━━━━━━━━━━━━━━━━━━━ 13:05:00\n",
      "Accuracy: 0.9886 - Precision: 0.6844 - Recall: 0.8523 - Specificity: 0.9904 - F1: 0.7059 - Loss: 0.6041\n",
      "\n",
      "Batch 110/387 ━━━━━━━━━━━━━━━━━━━━ 13:06:34\n",
      "Accuracy: 0.9886 - Precision: 0.6863 - Recall: 0.8527 - Specificity: 0.9905 - F1: 0.7076 - Loss: 0.6008\n",
      "\n",
      "Batch 111/387 ━━━━━━━━━━━━━━━━━━━━ 13:08:02\n",
      "Accuracy: 0.9887 - Precision: 0.6875 - Recall: 0.8533 - Specificity: 0.9906 - F1: 0.7090 - Loss: 0.5977\n",
      "\n",
      "Batch 112/387 ━━━━━━━━━━━━━━━━━━━━ 13:09:33\n",
      "Accuracy: 0.9888 - Precision: 0.6894 - Recall: 0.8538 - Specificity: 0.9907 - F1: 0.7108 - Loss: 0.5945\n",
      "\n",
      "Batch 113/387 ━━━━━━━━━━━━━━━━━━━━ 13:11:04\n",
      "Accuracy: 0.9889 - Precision: 0.6901 - Recall: 0.8540 - Specificity: 0.9907 - F1: 0.7117 - Loss: 0.5918\n",
      "\n",
      "Batch 114/387 ━━━━━━━━━━━━━━━━━━━━ 13:12:30\n",
      "Accuracy: 0.9889 - Precision: 0.6926 - Recall: 0.8541 - Specificity: 0.9908 - F1: 0.7135 - Loss: 0.5881\n",
      "\n",
      "Batch 115/387 ━━━━━━━━━━━━━━━━━━━━ 13:13:59\n",
      "Accuracy: 0.9890 - Precision: 0.6948 - Recall: 0.8544 - Specificity: 0.9909 - F1: 0.7153 - Loss: 0.5845\n",
      "\n",
      "Batch 116/387 ━━━━━━━━━━━━━━━━━━━━ 13:15:35\n",
      "Accuracy: 0.9891 - Precision: 0.6969 - Recall: 0.8553 - Specificity: 0.9909 - F1: 0.7173 - Loss: 0.5808\n",
      "\n",
      "Batch 117/387 ━━━━━━━━━━━━━━━━━━━━ 13:17:01\n",
      "Accuracy: 0.9892 - Precision: 0.6994 - Recall: 0.8551 - Specificity: 0.9910 - F1: 0.7189 - Loss: 0.5771\n",
      "\n",
      "Batch 118/387 ━━━━━━━━━━━━━━━━━━━━ 13:18:27\n",
      "Accuracy: 0.9892 - Precision: 0.7004 - Recall: 0.8563 - Specificity: 0.9911 - F1: 0.7204 - Loss: 0.5739\n",
      "\n",
      "Batch 119/387 ━━━━━━━━━━━━━━━━━━━━ 13:19:55\n",
      "Accuracy: 0.9893 - Precision: 0.7016 - Recall: 0.8570 - Specificity: 0.9911 - F1: 0.7218 - Loss: 0.5706\n",
      "\n",
      "Batch 120/387 ━━━━━━━━━━━━━━━━━━━━ 13:21:19\n",
      "Accuracy: 0.9894 - Precision: 0.7035 - Recall: 0.8577 - Specificity: 0.9912 - F1: 0.7236 - Loss: 0.5671\n",
      "\n",
      "Batch 121/387 ━━━━━━━━━━━━━━━━━━━━ 13:22:39\n",
      "Accuracy: 0.9894 - Precision: 0.7056 - Recall: 0.8568 - Specificity: 0.9913 - F1: 0.7246 - Loss: 0.5643\n",
      "\n",
      "Batch 122/387 ━━━━━━━━━━━━━━━━━━━━ 13:24:16\n",
      "Accuracy: 0.9895 - Precision: 0.7070 - Recall: 0.8571 - Specificity: 0.9913 - F1: 0.7259 - Loss: 0.5611\n",
      "\n",
      "Batch 123/387 ━━━━━━━━━━━━━━━━━━━━ 13:25:47\n",
      "Accuracy: 0.9895 - Precision: 0.7080 - Recall: 0.8580 - Specificity: 0.9913 - F1: 0.7272 - Loss: 0.5579\n",
      "\n",
      "Batch 124/387 ━━━━━━━━━━━━━━━━━━━━ 13:27:19\n",
      "Accuracy: 0.9895 - Precision: 0.7056 - Recall: 0.8577 - Specificity: 0.9913 - F1: 0.7258 - Loss: 0.5578\n",
      "\n",
      "Batch 125/387 ━━━━━━━━━━━━━━━━━━━━ 13:28:41\n",
      "Accuracy: 0.9896 - Precision: 0.7063 - Recall: 0.8588 - Specificity: 0.9914 - F1: 0.7271 - Loss: 0.5552\n",
      "\n",
      "Batch 126/387 ━━━━━━━━━━━━━━━━━━━━ 13:30:13\n",
      "Accuracy: 0.9896 - Precision: 0.7064 - Recall: 0.8579 - Specificity: 0.9914 - F1: 0.7271 - Loss: 0.5539\n",
      "\n",
      "Batch 127/387 ━━━━━━━━━━━━━━━━━━━━ 13:31:32\n",
      "Accuracy: 0.9897 - Precision: 0.7083 - Recall: 0.8569 - Specificity: 0.9915 - F1: 0.7279 - Loss: 0.5514\n",
      "\n",
      "Batch 128/387 ━━━━━━━━━━━━━━━━━━━━ 13:32:55\n",
      "Accuracy: 0.9897 - Precision: 0.7094 - Recall: 0.8535 - Specificity: 0.9916 - F1: 0.7266 - Loss: 0.5519\n",
      "\n",
      "Batch 129/387 ━━━━━━━━━━━━━━━━━━━━ 13:34:20\n",
      "Accuracy: 0.9898 - Precision: 0.7111 - Recall: 0.8544 - Specificity: 0.9916 - F1: 0.7283 - Loss: 0.5486\n",
      "\n",
      "Batch 130/387 ━━━━━━━━━━━━━━━━━━━━ 13:35:37\n",
      "Accuracy: 0.9898 - Precision: 0.7102 - Recall: 0.8540 - Specificity: 0.9916 - F1: 0.7280 - Loss: 0.5474\n",
      "\n",
      "Batch 131/387 ━━━━━━━━━━━━━━━━━━━━ 13:37:03\n",
      "Accuracy: 0.9899 - Precision: 0.7078 - Recall: 0.8550 - Specificity: 0.9917 - F1: 0.7267 - Loss: 0.5475\n",
      "\n",
      "Batch 132/387 ━━━━━━━━━━━━━━━━━━━━ 13:38:47\n",
      "Accuracy: 0.9899 - Precision: 0.7099 - Recall: 0.8546 - Specificity: 0.9917 - F1: 0.7279 - Loss: 0.5446\n",
      "\n",
      "Batch 133/387 ━━━━━━━━━━━━━━━━━━━━ 13:40:24\n",
      "Accuracy: 0.9899 - Precision: 0.7121 - Recall: 0.8526 - Specificity: 0.9918 - F1: 0.7280 - Loss: 0.5430\n",
      "\n",
      "Batch 134/387 ━━━━━━━━━━━━━━━━━━━━ 13:41:51\n",
      "Accuracy: 0.9900 - Precision: 0.7135 - Recall: 0.8527 - Specificity: 0.9919 - F1: 0.7291 - Loss: 0.5403\n",
      "\n",
      "Batch 135/387 ━━━━━━━━━━━━━━━━━━━━ 13:43:11\n",
      "Accuracy: 0.9900 - Precision: 0.7147 - Recall: 0.8529 - Specificity: 0.9919 - F1: 0.7303 - Loss: 0.5376\n",
      "\n",
      "Batch 136/387 ━━━━━━━━━━━━━━━━━━━━ 13:44:31\n",
      "Accuracy: 0.9901 - Precision: 0.7157 - Recall: 0.8528 - Specificity: 0.9919 - F1: 0.7311 - Loss: 0.5354\n",
      "\n",
      "Batch 137/387 ━━━━━━━━━━━━━━━━━━━━ 13:45:57\n",
      "Accuracy: 0.9901 - Precision: 0.7138 - Recall: 0.8538 - Specificity: 0.9920 - F1: 0.7303 - Loss: 0.5349\n",
      "\n",
      "Batch 138/387 ━━━━━━━━━━━━━━━━━━━━ 13:47:14\n",
      "Accuracy: 0.9901 - Precision: 0.7136 - Recall: 0.8547 - Specificity: 0.9920 - F1: 0.7309 - Loss: 0.5330\n",
      "\n",
      "Batch 139/387 ━━━━━━━━━━━━━━━━━━━━ 13:48:44\n",
      "Accuracy: 0.9902 - Precision: 0.7148 - Recall: 0.8553 - Specificity: 0.9920 - F1: 0.7321 - Loss: 0.5306\n",
      "\n",
      "Batch 140/387 ━━━━━━━━━━━━━━━━━━━━ 13:50:12\n",
      "Accuracy: 0.9902 - Precision: 0.7167 - Recall: 0.8539 - Specificity: 0.9921 - F1: 0.7326 - Loss: 0.5288\n",
      "\n",
      "Batch 141/387 ━━━━━━━━━━━━━━━━━━━━ 13:51:25\n",
      "Accuracy: 0.9903 - Precision: 0.7184 - Recall: 0.8513 - Specificity: 0.9922 - F1: 0.7319 - Loss: 0.5281\n",
      "\n",
      "Batch 142/387 ━━━━━━━━━━━━━━━━━━━━ 13:52:42\n",
      "Accuracy: 0.9903 - Precision: 0.7177 - Recall: 0.8521 - Specificity: 0.9922 - F1: 0.7321 - Loss: 0.5272\n",
      "\n",
      "Batch 143/387 ━━━━━━━━━━━━━━━━━━━━ 13:54:08\n",
      "Accuracy: 0.9903 - Precision: 0.7190 - Recall: 0.8493 - Specificity: 0.9922 - F1: 0.7311 - Loss: 0.5270\n",
      "\n",
      "Batch 144/387 ━━━━━━━━━━━━━━━━━━━━ 13:55:22\n",
      "Accuracy: 0.9904 - Precision: 0.7194 - Recall: 0.8501 - Specificity: 0.9923 - F1: 0.7321 - Loss: 0.5248\n",
      "\n",
      "Batch 145/387 ━━━━━━━━━━━━━━━━━━━━ 13:57:05\n",
      "Accuracy: 0.9904 - Precision: 0.7178 - Recall: 0.8509 - Specificity: 0.9923 - F1: 0.7314 - Loss: 0.5243\n",
      "\n",
      "Batch 146/387 ━━━━━━━━━━━━━━━━━━━━ 13:58:39\n",
      "Accuracy: 0.9905 - Precision: 0.7181 - Recall: 0.8517 - Specificity: 0.9924 - F1: 0.7323 - Loss: 0.5225\n",
      "\n",
      "Batch 147/387 ━━━━━━━━━━━━━━━━━━━━ 13:59:58\n",
      "Accuracy: 0.9906 - Precision: 0.7173 - Recall: 0.8523 - Specificity: 0.9924 - F1: 0.7323 - Loss: 0.5226\n",
      "\n",
      "Batch 148/387 ━━━━━━━━━━━━━━━━━━━━ 14:01:22\n",
      "Accuracy: 0.9906 - Precision: 0.7192 - Recall: 0.8502 - Specificity: 0.9925 - F1: 0.7320 - Loss: 0.5215\n",
      "\n",
      "Batch 149/387 ━━━━━━━━━━━━━━━━━━━━ 14:02:45\n",
      "Accuracy: 0.9906 - Precision: 0.7200 - Recall: 0.8495 - Specificity: 0.9925 - F1: 0.7325 - Loss: 0.5198\n",
      "\n",
      "Batch 150/387 ━━━━━━━━━━━━━━━━━━━━ 14:04:09\n",
      "Accuracy: 0.9907 - Precision: 0.7216 - Recall: 0.8490 - Specificity: 0.9925 - F1: 0.7333 - Loss: 0.5182\n",
      "\n",
      "Batch 151/387 ━━━━━━━━━━━━━━━━━━━━ 14:05:36\n",
      "Accuracy: 0.9907 - Precision: 0.7233 - Recall: 0.8487 - Specificity: 0.9926 - F1: 0.7343 - Loss: 0.5158\n",
      "\n",
      "Batch 152/387 ━━━━━━━━━━━━━━━━━━━━ 14:06:53\n",
      "Accuracy: 0.9908 - Precision: 0.7248 - Recall: 0.8492 - Specificity: 0.9926 - F1: 0.7357 - Loss: 0.5131\n",
      "\n",
      "Batch 153/387 ━━━━━━━━━━━━━━━━━━━━ 14:08:11\n",
      "Accuracy: 0.9908 - Precision: 0.7255 - Recall: 0.8500 - Specificity: 0.9927 - F1: 0.7367 - Loss: 0.5109\n",
      "\n",
      "Batch 154/387 ━━━━━━━━━━━━━━━━━━━━ 14:09:42\n",
      "Accuracy: 0.9908 - Precision: 0.7256 - Recall: 0.8503 - Specificity: 0.9927 - F1: 0.7371 - Loss: 0.5092\n",
      "\n",
      "Batch 155/387 ━━━━━━━━━━━━━━━━━━━━ 14:11:12\n",
      "Accuracy: 0.9908 - Precision: 0.7265 - Recall: 0.8486 - Specificity: 0.9927 - F1: 0.7369 - Loss: 0.5082\n",
      "\n",
      "Batch 156/387 ━━━━━━━━━━━━━━━━━━━━ 14:12:35\n",
      "Accuracy: 0.9909 - Precision: 0.7278 - Recall: 0.8493 - Specificity: 0.9928 - F1: 0.7383 - Loss: 0.5055\n",
      "\n",
      "Batch 157/387 ━━━━━━━━━━━━━━━━━━━━ 14:13:53\n",
      "Accuracy: 0.9909 - Precision: 0.7274 - Recall: 0.8502 - Specificity: 0.9928 - F1: 0.7386 - Loss: 0.5042\n",
      "\n",
      "Batch 158/387 ━━━━━━━━━━━━━━━━━━━━ 14:15:42\n",
      "Accuracy: 0.9910 - Precision: 0.7273 - Recall: 0.8509 - Specificity: 0.9928 - F1: 0.7391 - Loss: 0.5025\n",
      "\n",
      "Batch 159/387 ━━━━━━━━━━━━━━━━━━━━ 14:17:13\n",
      "Accuracy: 0.9909 - Precision: 0.7231 - Recall: 0.8516 - Specificity: 0.9928 - F1: 0.7352 - Loss: 0.5054\n",
      "\n",
      "Batch 160/387 ━━━━━━━━━━━━━━━━━━━━ 14:18:35\n",
      "Accuracy: 0.9910 - Precision: 0.7241 - Recall: 0.8513 - Specificity: 0.9928 - F1: 0.7359 - Loss: 0.5036\n",
      "\n",
      "Batch 161/387 ━━━━━━━━━━━━━━━━━━━━ 14:19:57\n",
      "Accuracy: 0.9910 - Precision: 0.7252 - Recall: 0.8517 - Specificity: 0.9928 - F1: 0.7369 - Loss: 0.5013\n",
      "\n",
      "Batch 162/387 ━━━━━━━━━━━━━━━━━━━━ 14:21:33\n",
      "Accuracy: 0.9910 - Precision: 0.7233 - Recall: 0.8501 - Specificity: 0.9929 - F1: 0.7354 - Loss: 0.5020\n",
      "\n",
      "Batch 163/387 ━━━━━━━━━━━━━━━━━━━━ 14:23:02\n",
      "Accuracy: 0.9911 - Precision: 0.7237 - Recall: 0.8501 - Specificity: 0.9929 - F1: 0.7359 - Loss: 0.5005\n",
      "\n",
      "Batch 164/387 ━━━━━━━━━━━━━━━━━━━━ 14:24:26\n",
      "Accuracy: 0.9911 - Precision: 0.7253 - Recall: 0.8485 - Specificity: 0.9930 - F1: 0.7359 - Loss: 0.4994\n",
      "\n",
      "Batch 165/387 ━━━━━━━━━━━━━━━━━━━━ 14:25:46\n",
      "Accuracy: 0.9911 - Precision: 0.7268 - Recall: 0.8463 - Specificity: 0.9930 - F1: 0.7353 - Loss: 0.4990\n",
      "\n",
      "Batch 166/387 ━━━━━━━━━━━━━━━━━━━━ 14:27:10\n",
      "Accuracy: 0.9911 - Precision: 0.7260 - Recall: 0.8446 - Specificity: 0.9930 - F1: 0.7344 - Loss: 0.4989\n",
      "\n",
      "Batch 167/387 ━━━━━━━━━━━━━━━━━━━━ 14:28:44\n",
      "Accuracy: 0.9911 - Precision: 0.7264 - Recall: 0.8432 - Specificity: 0.9930 - F1: 0.7341 - Loss: 0.4981\n",
      "\n",
      "Batch 168/387 ━━━━━━━━━━━━━━━━━━━━ 14:30:00\n",
      "Accuracy: 0.9912 - Precision: 0.7277 - Recall: 0.8433 - Specificity: 0.9931 - F1: 0.7351 - Loss: 0.4960\n",
      "\n",
      "Batch 169/387 ━━━━━━━━━━━━━━━━━━━━ 14:31:20\n",
      "Accuracy: 0.9912 - Precision: 0.7253 - Recall: 0.8427 - Specificity: 0.9931 - F1: 0.7334 - Loss: 0.4969\n",
      "\n",
      "Batch 170/387 ━━━━━━━━━━━━━━━━━━━━ 14:32:45\n",
      "Accuracy: 0.9911 - Precision: 0.7219 - Recall: 0.8435 - Specificity: 0.9930 - F1: 0.7306 - Loss: 0.4988\n",
      "\n",
      "Batch 171/387 ━━━━━━━━━━━━━━━━━━━━ 14:34:07\n",
      "Accuracy: 0.9912 - Precision: 0.7226 - Recall: 0.8442 - Specificity: 0.9930 - F1: 0.7315 - Loss: 0.4968\n",
      "\n",
      "Batch 172/387 ━━━━━━━━━━━━━━━━━━━━ 14:35:41\n",
      "Accuracy: 0.9912 - Precision: 0.7233 - Recall: 0.8446 - Specificity: 0.9931 - F1: 0.7324 - Loss: 0.4948\n",
      "\n",
      "Batch 173/387 ━━━━━━━━━━━━━━━━━━━━ 14:37:15\n",
      "Accuracy: 0.9912 - Precision: 0.7233 - Recall: 0.8453 - Specificity: 0.9931 - F1: 0.7330 - Loss: 0.4931\n",
      "\n",
      "Batch 174/387 ━━━━━━━━━━━━━━━━━━━━ 14:38:39\n",
      "Accuracy: 0.9912 - Precision: 0.7246 - Recall: 0.8459 - Specificity: 0.9931 - F1: 0.7342 - Loss: 0.4908\n",
      "\n",
      "Batch 175/387 ━━━━━━━━━━━━━━━━━━━━ 14:40:10\n",
      "Accuracy: 0.9913 - Precision: 0.7260 - Recall: 0.8463 - Specificity: 0.9931 - F1: 0.7354 - Loss: 0.4885\n",
      "\n",
      "Batch 176/387 ━━━━━━━━━━━━━━━━━━━━ 14:41:35\n",
      "Accuracy: 0.9913 - Precision: 0.7248 - Recall: 0.8472 - Specificity: 0.9932 - F1: 0.7351 - Loss: 0.4883\n",
      "\n",
      "Batch 177/387 ━━━━━━━━━━━━━━━━━━━━ 14:42:56\n",
      "Accuracy: 0.9914 - Precision: 0.7261 - Recall: 0.8475 - Specificity: 0.9932 - F1: 0.7362 - Loss: 0.4862\n",
      "\n",
      "Batch 178/387 ━━━━━━━━━━━━━━━━━━━━ 14:44:16\n",
      "Accuracy: 0.9914 - Precision: 0.7232 - Recall: 0.8478 - Specificity: 0.9932 - F1: 0.7339 - Loss: 0.4876\n",
      "\n",
      "Batch 179/387 ━━━━━━━━━━━━━━━━━━━━ 14:45:39\n",
      "Accuracy: 0.9914 - Precision: 0.7229 - Recall: 0.8477 - Specificity: 0.9933 - F1: 0.7340 - Loss: 0.4868\n",
      "\n",
      "Batch 180/387 ━━━━━━━━━━━━━━━━━━━━ 14:46:55\n",
      "Accuracy: 0.9914 - Precision: 0.7245 - Recall: 0.8431 - Specificity: 0.9933 - F1: 0.7300 - Loss: 0.4900\n",
      "\n",
      "Batch 181/387 ━━━━━━━━━━━━━━━━━━━━ 14:48:22\n",
      "Accuracy: 0.9915 - Precision: 0.7259 - Recall: 0.8394 - Specificity: 0.9933 - F1: 0.7276 - Loss: 0.4916\n",
      "\n",
      "Batch 182/387 ━━━━━━━━━━━━━━━━━━━━ 14:49:36\n",
      "Accuracy: 0.9915 - Precision: 0.7274 - Recall: 0.8368 - Specificity: 0.9934 - F1: 0.7266 - Loss: 0.4918\n",
      "\n",
      "Batch 183/387 ━━━━━━━━━━━━━━━━━━━━ 14:51:04\n",
      "Accuracy: 0.9915 - Precision: 0.7289 - Recall: 0.8352 - Specificity: 0.9934 - F1: 0.7264 - Loss: 0.4911\n",
      "\n",
      "Batch 184/387 ━━━━━━━━━━━━━━━━━━━━ 14:52:22\n",
      "Accuracy: 0.9915 - Precision: 0.7294 - Recall: 0.8351 - Specificity: 0.9934 - F1: 0.7270 - Loss: 0.4897\n",
      "\n",
      "Batch 185/387 ━━━━━━━━━━━━━━━━━━━━ 14:53:42\n",
      "Accuracy: 0.9915 - Precision: 0.7296 - Recall: 0.8356 - Specificity: 0.9935 - F1: 0.7275 - Loss: 0.4883\n",
      "\n",
      "Batch 186/387 ━━━━━━━━━━━━━━━━━━━━ 14:54:56\n",
      "Accuracy: 0.9916 - Precision: 0.7308 - Recall: 0.8358 - Specificity: 0.9935 - F1: 0.7285 - Loss: 0.4864\n",
      "\n",
      "Batch 187/387 ━━━━━━━━━━━━━━━━━━━━ 14:56:15\n",
      "Accuracy: 0.9916 - Precision: 0.7316 - Recall: 0.8363 - Specificity: 0.9935 - F1: 0.7295 - Loss: 0.4845\n",
      "\n",
      "Batch 188/387 ━━━━━━━━━━━━━━━━━━━━ 14:57:39\n",
      "Accuracy: 0.9916 - Precision: 0.7307 - Recall: 0.8371 - Specificity: 0.9935 - F1: 0.7294 - Loss: 0.4840\n",
      "\n",
      "Batch 189/387 ━━━━━━━━━━━━━━━━━━━━ 14:59:06\n",
      "Accuracy: 0.9916 - Precision: 0.7288 - Recall: 0.8369 - Specificity: 0.9936 - F1: 0.7282 - Loss: 0.4844\n",
      "\n",
      "Batch 190/387 ━━━━━━━━━━━━━━━━━━━━ 15:00:23\n",
      "Accuracy: 0.9917 - Precision: 0.7302 - Recall: 0.8363 - Specificity: 0.9936 - F1: 0.7288 - Loss: 0.4830\n",
      "\n",
      "Batch 191/387 ━━━━━━━━━━━━━━━━━━━━ 15:01:57\n",
      "Accuracy: 0.9917 - Precision: 0.7316 - Recall: 0.8355 - Specificity: 0.9936 - F1: 0.7292 - Loss: 0.4817\n",
      "\n",
      "Batch 192/387 ━━━━━━━━━━━━━━━━━━━━ 15:03:15\n",
      "Accuracy: 0.9917 - Precision: 0.7312 - Recall: 0.8358 - Specificity: 0.9936 - F1: 0.7293 - Loss: 0.4809\n",
      "\n",
      "Batch 193/387 ━━━━━━━━━━━━━━━━━━━━ 15:04:53\n",
      "Accuracy: 0.9917 - Precision: 0.7323 - Recall: 0.8345 - Specificity: 0.9937 - F1: 0.7293 - Loss: 0.4801\n",
      "\n",
      "Batch 194/387 ━━━━━━━━━━━━━━━━━━━━ 15:06:23\n",
      "Accuracy: 0.9918 - Precision: 0.7305 - Recall: 0.8347 - Specificity: 0.9937 - F1: 0.7283 - Loss: 0.4803\n",
      "\n",
      "Batch 195/387 ━━━━━━━━━━━━━━━━━━━━ 15:07:59\n",
      "Accuracy: 0.9918 - Precision: 0.7315 - Recall: 0.8350 - Specificity: 0.9937 - F1: 0.7292 - Loss: 0.4787\n",
      "\n",
      "Batch 196/387 ━━━━━━━━━━━━━━━━━━━━ 15:09:21\n",
      "Accuracy: 0.9918 - Precision: 0.7325 - Recall: 0.8346 - Specificity: 0.9937 - F1: 0.7298 - Loss: 0.4773\n",
      "\n",
      "Batch 197/387 ━━━━━━━━━━━━━━━━━━━━ 15:10:42\n",
      "Accuracy: 0.9918 - Precision: 0.7337 - Recall: 0.8347 - Specificity: 0.9938 - F1: 0.7307 - Loss: 0.4755\n",
      "\n",
      "Batch 198/387 ━━━━━━━━━━━━━━━━━━━━ 15:12:19\n",
      "Accuracy: 0.9918 - Precision: 0.7319 - Recall: 0.8343 - Specificity: 0.9938 - F1: 0.7295 - Loss: 0.4759\n",
      "\n",
      "Batch 199/387 ━━━━━━━━━━━━━━━━━━━━ 15:13:41\n",
      "Accuracy: 0.9919 - Precision: 0.7326 - Recall: 0.8341 - Specificity: 0.9938 - F1: 0.7301 - Loss: 0.4746\n",
      "\n",
      "Batch 200/387 ━━━━━━━━━━━━━━━━━━━━ 15:14:59\n",
      "Accuracy: 0.9919 - Precision: 0.7330 - Recall: 0.8346 - Specificity: 0.9938 - F1: 0.7308 - Loss: 0.4731\n",
      "\n",
      "Batch 201/387 ━━━━━━━━━━━━━━━━━━━━ 15:16:20\n",
      "Accuracy: 0.9919 - Precision: 0.7308 - Recall: 0.8354 - Specificity: 0.9938 - F1: 0.7294 - Loss: 0.4737\n",
      "\n",
      "Batch 202/387 ━━━━━━━━━━━━━━━━━━━━ 15:17:36\n",
      "Accuracy: 0.9919 - Precision: 0.7320 - Recall: 0.8355 - Specificity: 0.9938 - F1: 0.7303 - Loss: 0.4720\n",
      "\n",
      "Batch 203/387 ━━━━━━━━━━━━━━━━━━━━ 15:18:57\n",
      "Accuracy: 0.9919 - Precision: 0.7333 - Recall: 0.8353 - Specificity: 0.9939 - F1: 0.7310 - Loss: 0.4704\n",
      "\n",
      "Batch 204/387 ━━━━━━━━━━━━━━━━━━━━ 15:20:22\n",
      "Accuracy: 0.9920 - Precision: 0.7340 - Recall: 0.8353 - Specificity: 0.9939 - F1: 0.7316 - Loss: 0.4691\n",
      "\n",
      "Batch 205/387 ━━━━━━━━━━━━━━━━━━━━ 15:21:50\n",
      "Accuracy: 0.9920 - Precision: 0.7347 - Recall: 0.8345 - Specificity: 0.9939 - F1: 0.7317 - Loss: 0.4683\n",
      "\n",
      "Batch 206/387 ━━━━━━━━━━━━━━━━━━━━ 15:23:12\n",
      "Accuracy: 0.9920 - Precision: 0.7358 - Recall: 0.8346 - Specificity: 0.9939 - F1: 0.7326 - Loss: 0.4666\n",
      "\n",
      "Batch 207/387 ━━━━━━━━━━━━━━━━━━━━ 15:24:45\n",
      "Accuracy: 0.9921 - Precision: 0.7370 - Recall: 0.8346 - Specificity: 0.9940 - F1: 0.7335 - Loss: 0.4650\n",
      "\n",
      "Batch 208/387 ━━━━━━━━━━━━━━━━━━━━ 15:26:14\n",
      "Accuracy: 0.9921 - Precision: 0.7381 - Recall: 0.8341 - Specificity: 0.9940 - F1: 0.7339 - Loss: 0.4638\n",
      "\n",
      "Batch 209/387 ━━━━━━━━━━━━━━━━━━━━ 15:27:35\n",
      "Accuracy: 0.9921 - Precision: 0.7359 - Recall: 0.8327 - Specificity: 0.9940 - F1: 0.7322 - Loss: 0.4649\n",
      "\n",
      "Batch 210/387 ━━━━━━━━━━━━━━━━━━━━ 15:29:03\n",
      "Accuracy: 0.9921 - Precision: 0.7347 - Recall: 0.8334 - Specificity: 0.9940 - F1: 0.7318 - Loss: 0.4646\n",
      "\n",
      "Batch 211/387 ━━━━━━━━━━━━━━━━━━━━ 15:30:29\n",
      "Accuracy: 0.9921 - Precision: 0.7352 - Recall: 0.8337 - Specificity: 0.9940 - F1: 0.7325 - Loss: 0.4632\n",
      "\n",
      "Batch 212/387 ━━━━━━━━━━━━━━━━━━━━ 15:31:55\n",
      "Accuracy: 0.9921 - Precision: 0.7363 - Recall: 0.8334 - Specificity: 0.9941 - F1: 0.7330 - Loss: 0.4619\n",
      "\n",
      "Batch 213/387 ━━━━━━━━━━━━━━━━━━━━ 15:33:13\n",
      "Accuracy: 0.9921 - Precision: 0.7367 - Recall: 0.8339 - Specificity: 0.9941 - F1: 0.7337 - Loss: 0.4605\n",
      "\n",
      "Batch 214/387 ━━━━━━━━━━━━━━━━━━━━ 15:34:37\n",
      "Accuracy: 0.9922 - Precision: 0.7362 - Recall: 0.8345 - Specificity: 0.9941 - F1: 0.7338 - Loss: 0.4598\n",
      "\n",
      "Batch 215/387 ━━━━━━━━━━━━━━━━━━━━ 15:35:57\n",
      "Accuracy: 0.9922 - Precision: 0.7350 - Recall: 0.8352 - Specificity: 0.9941 - F1: 0.7335 - Loss: 0.4595\n",
      "\n",
      "Batch 216/387 ━━━━━━━━━━━━━━━━━━━━ 15:37:28\n",
      "Accuracy: 0.9922 - Precision: 0.7360 - Recall: 0.8351 - Specificity: 0.9941 - F1: 0.7341 - Loss: 0.4581\n",
      "\n",
      "Batch 217/387 ━━━━━━━━━━━━━━━━━━━━ 15:39:03\n",
      "Accuracy: 0.9922 - Precision: 0.7372 - Recall: 0.8344 - Specificity: 0.9942 - F1: 0.7344 - Loss: 0.4571\n",
      "\n",
      "Batch 218/387 ━━━━━━━━━━━━━━━━━━━━ 15:40:47\n",
      "Accuracy: 0.9923 - Precision: 0.7381 - Recall: 0.8345 - Specificity: 0.9942 - F1: 0.7352 - Loss: 0.4557\n",
      "\n",
      "Batch 219/387 ━━━━━━━━━━━━━━━━━━━━ 15:42:24\n",
      "Accuracy: 0.9923 - Precision: 0.7393 - Recall: 0.8332 - Specificity: 0.9942 - F1: 0.7351 - Loss: 0.4551\n",
      "\n",
      "Batch 220/387 ━━━━━━━━━━━━━━━━━━━━ 15:43:43\n",
      "Accuracy: 0.9922 - Precision: 0.7403 - Recall: 0.8311 - Specificity: 0.9942 - F1: 0.7342 - Loss: 0.4555\n",
      "\n",
      "Batch 221/387 ━━━━━━━━━━━━━━━━━━━━ 15:45:21\n",
      "Accuracy: 0.9923 - Precision: 0.7413 - Recall: 0.8315 - Specificity: 0.9943 - F1: 0.7351 - Loss: 0.4539\n",
      "\n",
      "Batch 222/387 ━━━━━━━━━━━━━━━━━━━━ 15:46:44\n",
      "Accuracy: 0.9923 - Precision: 0.7391 - Recall: 0.8321 - Specificity: 0.9943 - F1: 0.7336 - Loss: 0.4548\n",
      "\n",
      "Batch 223/387 ━━━━━━━━━━━━━━━━━━━━ 15:48:15\n",
      "Accuracy: 0.9923 - Precision: 0.7398 - Recall: 0.8328 - Specificity: 0.9943 - F1: 0.7345 - Loss: 0.4532\n",
      "\n",
      "Batch 224/387 ━━━━━━━━━━━━━━━━━━━━ 15:49:42\n",
      "Accuracy: 0.9923 - Precision: 0.7403 - Recall: 0.8333 - Specificity: 0.9943 - F1: 0.7352 - Loss: 0.4517\n",
      "\n",
      "Batch 225/387 ━━━━━━━━━━━━━━━━━━━━ 15:51:16\n",
      "Accuracy: 0.9923 - Precision: 0.7402 - Recall: 0.8331 - Specificity: 0.9943 - F1: 0.7353 - Loss: 0.4510\n",
      "\n",
      "Batch 226/387 ━━━━━━━━━━━━━━━━━━━━ 15:52:38\n",
      "Accuracy: 0.9924 - Precision: 0.7412 - Recall: 0.8333 - Specificity: 0.9943 - F1: 0.7361 - Loss: 0.4495\n",
      "\n",
      "Batch 227/387 ━━━━━━━━━━━━━━━━━━━━ 15:54:03\n",
      "Accuracy: 0.9924 - Precision: 0.7405 - Recall: 0.8328 - Specificity: 0.9943 - F1: 0.7357 - Loss: 0.4493\n",
      "\n",
      "Batch 228/387 ━━━━━━━━━━━━━━━━━━━━ 15:55:31\n",
      "Accuracy: 0.9924 - Precision: 0.7393 - Recall: 0.8335 - Specificity: 0.9943 - F1: 0.7353 - Loss: 0.4492\n",
      "\n",
      "Batch 229/387 ━━━━━━━━━━━━━━━━━━━━ 15:56:57\n",
      "Accuracy: 0.9924 - Precision: 0.7392 - Recall: 0.8321 - Specificity: 0.9944 - F1: 0.7346 - Loss: 0.4494\n",
      "\n",
      "Batch 230/387 ━━━━━━━━━━━━━━━━━━━━ 15:58:17\n",
      "Accuracy: 0.9924 - Precision: 0.7377 - Recall: 0.8326 - Specificity: 0.9944 - F1: 0.7339 - Loss: 0.4496\n",
      "\n",
      "Batch 231/387 ━━━━━━━━━━━━━━━━━━━━ 15:59:36\n",
      "Accuracy: 0.9924 - Precision: 0.7388 - Recall: 0.8316 - Specificity: 0.9944 - F1: 0.7339 - Loss: 0.4491\n",
      "\n",
      "Batch 232/387 ━━━━━━━━━━━━━━━━━━━━ 16:00:52\n",
      "Accuracy: 0.9924 - Precision: 0.7384 - Recall: 0.8323 - Specificity: 0.9944 - F1: 0.7341 - Loss: 0.4485\n",
      "\n",
      "Batch 233/387 ━━━━━━━━━━━━━━━━━━━━ 16:02:10\n",
      "Accuracy: 0.9924 - Precision: 0.7391 - Recall: 0.8314 - Specificity: 0.9944 - F1: 0.7341 - Loss: 0.4479\n",
      "\n",
      "Batch 234/387 ━━━━━━━━━━━━━━━━━━━━ 16:03:31\n",
      "Accuracy: 0.9924 - Precision: 0.7401 - Recall: 0.8295 - Specificity: 0.9945 - F1: 0.7334 - Loss: 0.4481\n",
      "\n",
      "Batch 235/387 ━━━━━━━━━━━━━━━━━━━━ 16:04:48\n",
      "Accuracy: 0.9924 - Precision: 0.7406 - Recall: 0.8271 - Specificity: 0.9945 - F1: 0.7319 - Loss: 0.4491\n",
      "\n",
      "Batch 236/387 ━━━━━━━━━━━━━━━━━━━━ 16:06:08\n",
      "Accuracy: 0.9924 - Precision: 0.7416 - Recall: 0.8266 - Specificity: 0.9945 - F1: 0.7323 - Loss: 0.4481\n",
      "\n",
      "Batch 237/387 ━━━━━━━━━━━━━━━━━━━━ 16:07:35\n",
      "Accuracy: 0.9924 - Precision: 0.7417 - Recall: 0.8262 - Specificity: 0.9945 - F1: 0.7324 - Loss: 0.4475\n",
      "\n",
      "Batch 238/387 ━━━━━━━━━━━━━━━━━━━━ 16:09:02\n",
      "Accuracy: 0.9925 - Precision: 0.7418 - Recall: 0.8269 - Specificity: 0.9945 - F1: 0.7329 - Loss: 0.4463\n",
      "\n",
      "Batch 239/387 ━━━━━━━━━━━━━━━━━━━━ 16:10:24\n",
      "Accuracy: 0.9925 - Precision: 0.7407 - Recall: 0.8275 - Specificity: 0.9945 - F1: 0.7326 - Loss: 0.4461\n",
      "\n",
      "Batch 240/387 ━━━━━━━━━━━━━━━━━━━━ 16:11:49\n",
      "Accuracy: 0.9925 - Precision: 0.7407 - Recall: 0.8279 - Specificity: 0.9945 - F1: 0.7329 - Loss: 0.4452\n",
      "\n",
      "Batch 241/387 ━━━━━━━━━━━━━━━━━━━━ 16:13:09\n",
      "Accuracy: 0.9925 - Precision: 0.7397 - Recall: 0.8275 - Specificity: 0.9945 - F1: 0.7323 - Loss: 0.4452\n",
      "\n",
      "Batch 242/387 ━━━━━━━━━━━━━━━━━━━━ 16:14:22\n",
      "Accuracy: 0.9925 - Precision: 0.7406 - Recall: 0.8275 - Specificity: 0.9946 - F1: 0.7330 - Loss: 0.4440\n",
      "\n",
      "Batch 243/387 ━━━━━━━━━━━━━━━━━━━━ 16:15:44\n",
      "Accuracy: 0.9925 - Precision: 0.7402 - Recall: 0.8275 - Specificity: 0.9946 - F1: 0.7330 - Loss: 0.4435\n",
      "\n",
      "Batch 244/387 ━━━━━━━━━━━━━━━━━━━━ 16:17:22\n",
      "Accuracy: 0.9925 - Precision: 0.7409 - Recall: 0.8279 - Specificity: 0.9946 - F1: 0.7337 - Loss: 0.4422\n",
      "\n",
      "Batch 245/387 ━━━━━━━━━━━━━━━━━━━━ 16:18:45\n",
      "Accuracy: 0.9925 - Precision: 0.7408 - Recall: 0.8276 - Specificity: 0.9946 - F1: 0.7337 - Loss: 0.4417\n",
      "\n",
      "Batch 246/387 ━━━━━━━━━━━━━━━━━━━━ 16:20:14\n",
      "Accuracy: 0.9926 - Precision: 0.7407 - Recall: 0.8281 - Specificity: 0.9946 - F1: 0.7340 - Loss: 0.4408\n",
      "\n",
      "Batch 247/387 ━━━━━━━━━━━━━━━━━━━━ 16:21:41\n",
      "Accuracy: 0.9926 - Precision: 0.7384 - Recall: 0.8287 - Specificity: 0.9946 - F1: 0.7323 - Loss: 0.4420\n",
      "\n",
      "Batch 248/387 ━━━━━━━━━━━━━━━━━━━━ 16:22:54\n",
      "Accuracy: 0.9926 - Precision: 0.7391 - Recall: 0.8290 - Specificity: 0.9946 - F1: 0.7330 - Loss: 0.4407\n",
      "\n",
      "Batch 249/387 ━━━━━━━━━━━━━━━━━━━━ 16:24:15\n",
      "Accuracy: 0.9926 - Precision: 0.7401 - Recall: 0.8283 - Specificity: 0.9946 - F1: 0.7332 - Loss: 0.4400\n",
      "\n",
      "Batch 250/387 ━━━━━━━━━━━━━━━━━━━━ 16:25:41\n",
      "Accuracy: 0.9926 - Precision: 0.7388 - Recall: 0.8285 - Specificity: 0.9947 - F1: 0.7326 - Loss: 0.4402\n",
      "\n",
      "Batch 251/387 ━━━━━━━━━━━━━━━━━━━━ 16:27:09\n",
      "Accuracy: 0.9926 - Precision: 0.7398 - Recall: 0.8263 - Specificity: 0.9947 - F1: 0.7313 - Loss: 0.4410\n",
      "\n",
      "Batch 252/387 ━━━━━━━━━━━━━━━━━━━━ 16:28:41\n",
      "Accuracy: 0.9926 - Precision: 0.7409 - Recall: 0.8252 - Specificity: 0.9947 - F1: 0.7313 - Loss: 0.4405\n",
      "\n",
      "Batch 253/387 ━━━━━━━━━━━━━━━━━━━━ 16:30:14\n",
      "Accuracy: 0.9927 - Precision: 0.7418 - Recall: 0.8250 - Specificity: 0.9947 - F1: 0.7317 - Loss: 0.4395\n",
      "\n",
      "Batch 254/387 ━━━━━━━━━━━━━━━━━━━━ 16:31:40\n",
      "Accuracy: 0.9926 - Precision: 0.7427 - Recall: 0.8233 - Specificity: 0.9947 - F1: 0.7311 - Loss: 0.4397\n",
      "\n",
      "Batch 255/387 ━━━━━━━━━━━━━━━━━━━━ 16:33:10\n",
      "Accuracy: 0.9926 - Precision: 0.7435 - Recall: 0.8229 - Specificity: 0.9948 - F1: 0.7314 - Loss: 0.4389\n",
      "\n",
      "Batch 256/387 ━━━━━━━━━━━━━━━━━━━━ 16:34:36\n",
      "Accuracy: 0.9927 - Precision: 0.7424 - Recall: 0.8235 - Specificity: 0.9948 - F1: 0.7311 - Loss: 0.4388\n",
      "\n",
      "Batch 257/387 ━━━━━━━━━━━━━━━━━━━━ 16:36:00\n",
      "Accuracy: 0.9927 - Precision: 0.7429 - Recall: 0.8239 - Specificity: 0.9948 - F1: 0.7317 - Loss: 0.4376\n",
      "\n",
      "Batch 258/387 ━━━━━━━━━━━━━━━━━━━━ 16:37:25\n",
      "Accuracy: 0.9927 - Precision: 0.7426 - Recall: 0.8243 - Specificity: 0.9948 - F1: 0.7319 - Loss: 0.4370\n",
      "\n",
      "Batch 259/387 ━━━━━━━━━━━━━━━━━━━━ 16:38:48\n",
      "Accuracy: 0.9927 - Precision: 0.7429 - Recall: 0.8248 - Specificity: 0.9948 - F1: 0.7325 - Loss: 0.4358\n",
      "\n",
      "Batch 260/387 ━━━━━━━━━━━━━━━━━━━━ 16:40:14\n",
      "Accuracy: 0.9927 - Precision: 0.7426 - Recall: 0.8254 - Specificity: 0.9948 - F1: 0.7327 - Loss: 0.4352\n",
      "\n",
      "Batch 261/387 ━━━━━━━━━━━━━━━━━━━━ 16:41:34\n",
      "Accuracy: 0.9927 - Precision: 0.7426 - Recall: 0.8256 - Specificity: 0.9948 - F1: 0.7330 - Loss: 0.4344\n",
      "\n",
      "Batch 262/387 ━━━━━━━━━━━━━━━━━━━━ 16:42:53\n",
      "Accuracy: 0.9927 - Precision: 0.7434 - Recall: 0.8260 - Specificity: 0.9948 - F1: 0.7338 - Loss: 0.4330\n",
      "\n",
      "Batch 263/387 ━━━━━━━━━━━━━━━━━━━━ 16:44:10\n",
      "Accuracy: 0.9927 - Precision: 0.7442 - Recall: 0.8259 - Specificity: 0.9948 - F1: 0.7343 - Loss: 0.4320\n",
      "\n",
      "Batch 264/387 ━━━━━━━━━━━━━━━━━━━━ 16:45:31\n",
      "Accuracy: 0.9928 - Precision: 0.7449 - Recall: 0.8263 - Specificity: 0.9949 - F1: 0.7350 - Loss: 0.4307\n",
      "\n",
      "Batch 265/387 ━━━━━━━━━━━━━━━━━━━━ 16:46:56\n",
      "Accuracy: 0.9928 - Precision: 0.7457 - Recall: 0.8267 - Specificity: 0.9949 - F1: 0.7358 - Loss: 0.4294\n",
      "\n",
      "Batch 266/387 ━━━━━━━━━━━━━━━━━━━━ 16:48:21\n",
      "Accuracy: 0.9928 - Precision: 0.7454 - Recall: 0.8273 - Specificity: 0.9949 - F1: 0.7361 - Loss: 0.4288\n",
      "\n",
      "Batch 267/387 ━━━━━━━━━━━━━━━━━━━━ 16:49:51\n",
      "Accuracy: 0.9928 - Precision: 0.7459 - Recall: 0.8273 - Specificity: 0.9949 - F1: 0.7365 - Loss: 0.4279\n",
      "\n",
      "Batch 268/387 ━━━━━━━━━━━━━━━━━━━━ 16:51:22\n",
      "Accuracy: 0.9928 - Precision: 0.7461 - Recall: 0.8274 - Specificity: 0.9949 - F1: 0.7368 - Loss: 0.4271\n",
      "\n",
      "Batch 269/387 ━━━━━━━━━━━━━━━━━━━━ 16:52:49\n",
      "Accuracy: 0.9928 - Precision: 0.7457 - Recall: 0.8279 - Specificity: 0.9949 - F1: 0.7369 - Loss: 0.4266\n",
      "\n",
      "Batch 270/387 ━━━━━━━━━━━━━━━━━━━━ 16:54:17\n",
      "Accuracy: 0.9928 - Precision: 0.7465 - Recall: 0.8279 - Specificity: 0.9949 - F1: 0.7375 - Loss: 0.4255\n",
      "\n",
      "Batch 271/387 ━━━━━━━━━━━━━━━━━━━━ 16:55:44\n",
      "Accuracy: 0.9928 - Precision: 0.7472 - Recall: 0.8279 - Specificity: 0.9949 - F1: 0.7380 - Loss: 0.4244\n",
      "\n",
      "Batch 272/387 ━━━━━━━━━━━━━━━━━━━━ 16:57:14\n",
      "Accuracy: 0.9929 - Precision: 0.7470 - Recall: 0.8284 - Specificity: 0.9949 - F1: 0.7383 - Loss: 0.4237\n",
      "\n",
      "Batch 273/387 ━━━━━━━━━━━━━━━━━━━━ 16:58:49\n",
      "Accuracy: 0.9929 - Precision: 0.7479 - Recall: 0.8285 - Specificity: 0.9950 - F1: 0.7389 - Loss: 0.4226\n",
      "\n",
      "Batch 274/387 ━━━━━━━━━━━━━━━━━━━━ 17:00:20\n",
      "Accuracy: 0.9929 - Precision: 0.7487 - Recall: 0.8289 - Specificity: 0.9950 - F1: 0.7397 - Loss: 0.4213\n",
      "\n",
      "Batch 275/387 ━━━━━━━━━━━━━━━━━━━━ 17:01:39\n",
      "Accuracy: 0.9929 - Precision: 0.7487 - Recall: 0.8286 - Specificity: 0.9950 - F1: 0.7397 - Loss: 0.4209\n",
      "\n",
      "Batch 276/387 ━━━━━━━━━━━━━━━━━━━━ 17:03:06\n",
      "Accuracy: 0.9929 - Precision: 0.7495 - Recall: 0.8277 - Specificity: 0.9950 - F1: 0.7397 - Loss: 0.4205\n",
      "\n",
      "Batch 277/387 ━━━━━━━━━━━━━━━━━━━━ 17:04:25\n",
      "Accuracy: 0.9929 - Precision: 0.7493 - Recall: 0.8283 - Specificity: 0.9950 - F1: 0.7399 - Loss: 0.4199\n",
      "\n",
      "Batch 278/387 ━━━━━━━━━━━━━━━━━━━━ 17:05:46\n",
      "Accuracy: 0.9929 - Precision: 0.7500 - Recall: 0.8284 - Specificity: 0.9950 - F1: 0.7405 - Loss: 0.4188\n",
      "\n",
      "Batch 279/387 ━━━━━━━━━━━━━━━━━━━━ 17:07:04\n",
      "Accuracy: 0.9929 - Precision: 0.7491 - Recall: 0.8288 - Specificity: 0.9950 - F1: 0.7401 - Loss: 0.4188\n",
      "\n",
      "Batch 280/387 ━━━━━━━━━━━━━━━━━━━━ 17:08:33\n",
      "Accuracy: 0.9929 - Precision: 0.7499 - Recall: 0.8279 - Specificity: 0.9950 - F1: 0.7401 - Loss: 0.4185\n",
      "\n",
      "Batch 281/387 ━━━━━━━━━━━━━━━━━━━━ 17:09:54\n",
      "Accuracy: 0.9929 - Precision: 0.7482 - Recall: 0.8276 - Specificity: 0.9950 - F1: 0.7388 - Loss: 0.4194\n",
      "\n",
      "Batch 282/387 ━━━━━━━━━━━━━━━━━━━━ 17:11:24\n",
      "Accuracy: 0.9929 - Precision: 0.7485 - Recall: 0.8276 - Specificity: 0.9950 - F1: 0.7392 - Loss: 0.4186\n",
      "\n",
      "Batch 283/387 ━━━━━━━━━━━━━━━━━━━━ 17:12:51\n",
      "Accuracy: 0.9930 - Precision: 0.7489 - Recall: 0.8280 - Specificity: 0.9951 - F1: 0.7397 - Loss: 0.4176\n",
      "\n",
      "Batch 284/387 ━━━━━━━━━━━━━━━━━━━━ 17:14:35\n",
      "Accuracy: 0.9930 - Precision: 0.7495 - Recall: 0.8282 - Specificity: 0.9951 - F1: 0.7403 - Loss: 0.4166\n",
      "\n",
      "Batch 285/387 ━━━━━━━━━━━━━━━━━━━━ 17:16:01\n",
      "Accuracy: 0.9930 - Precision: 0.7503 - Recall: 0.8274 - Specificity: 0.9951 - F1: 0.7403 - Loss: 0.4162\n",
      "\n",
      "Batch 286/387 ━━━━━━━━━━━━━━━━━━━━ 17:17:28\n",
      "Accuracy: 0.9930 - Precision: 0.7511 - Recall: 0.8267 - Specificity: 0.9951 - F1: 0.7404 - Loss: 0.4157\n",
      "\n",
      "Batch 287/387 ━━━━━━━━━━━━━━━━━━━━ 17:19:00\n",
      "Accuracy: 0.9930 - Precision: 0.7519 - Recall: 0.8268 - Specificity: 0.9951 - F1: 0.7410 - Loss: 0.4146\n",
      "\n",
      "Batch 288/387 ━━━━━━━━━━━━━━━━━━━━ 17:20:25\n",
      "Accuracy: 0.9930 - Precision: 0.7520 - Recall: 0.8269 - Specificity: 0.9951 - F1: 0.7413 - Loss: 0.4140\n",
      "\n",
      "Batch 289/387 ━━━━━━━━━━━━━━━━━━━━ 17:21:45\n",
      "Accuracy: 0.9930 - Precision: 0.7528 - Recall: 0.8271 - Specificity: 0.9951 - F1: 0.7419 - Loss: 0.4129\n",
      "\n",
      "Batch 290/387 ━━━━━━━━━━━━━━━━━━━━ 17:23:11\n",
      "Accuracy: 0.9930 - Precision: 0.7535 - Recall: 0.8270 - Specificity: 0.9952 - F1: 0.7423 - Loss: 0.4120\n",
      "\n",
      "Batch 291/387 ━━━━━━━━━━━━━━━━━━━━ 17:24:34\n",
      "Accuracy: 0.9930 - Precision: 0.7543 - Recall: 0.8271 - Specificity: 0.9952 - F1: 0.7430 - Loss: 0.4109\n",
      "\n",
      "Batch 292/387 ━━━━━━━━━━━━━━━━━━━━ 17:25:47\n",
      "Accuracy: 0.9930 - Precision: 0.7549 - Recall: 0.8275 - Specificity: 0.9952 - F1: 0.7436 - Loss: 0.4099\n",
      "\n",
      "Batch 293/387 ━━━━━━━━━━━━━━━━━━━━ 17:27:17\n",
      "Accuracy: 0.9931 - Precision: 0.7555 - Recall: 0.8278 - Specificity: 0.9952 - F1: 0.7442 - Loss: 0.4089\n",
      "\n",
      "Batch 294/387 ━━━━━━━━━━━━━━━━━━━━ 17:28:40\n",
      "Accuracy: 0.9931 - Precision: 0.7558 - Recall: 0.8279 - Specificity: 0.9952 - F1: 0.7446 - Loss: 0.4081\n",
      "\n",
      "Batch 295/387 ━━━━━━━━━━━━━━━━━━━━ 17:30:08\n",
      "Accuracy: 0.9931 - Precision: 0.7548 - Recall: 0.8285 - Specificity: 0.9952 - F1: 0.7442 - Loss: 0.4082\n",
      "\n",
      "Batch 296/387 ━━━━━━━━━━━━━━━━━━━━ 17:31:34\n",
      "Accuracy: 0.9931 - Precision: 0.7546 - Recall: 0.8282 - Specificity: 0.9952 - F1: 0.7441 - Loss: 0.4080\n",
      "\n",
      "Batch 297/387 ━━━━━━━━━━━━━━━━━━━━ 17:33:01\n",
      "Accuracy: 0.9931 - Precision: 0.7554 - Recall: 0.8284 - Specificity: 0.9952 - F1: 0.7448 - Loss: 0.4069\n",
      "\n",
      "Batch 298/387 ━━━━━━━━━━━━━━━━━━━━ 17:34:29\n",
      "Accuracy: 0.9931 - Precision: 0.7548 - Recall: 0.8284 - Specificity: 0.9952 - F1: 0.7446 - Loss: 0.4068\n",
      "\n",
      "Batch 299/387 ━━━━━━━━━━━━━━━━━━━━ 17:35:55\n",
      "Accuracy: 0.9931 - Precision: 0.7544 - Recall: 0.8271 - Specificity: 0.9952 - F1: 0.7438 - Loss: 0.4072\n",
      "\n",
      "Batch 300/387 ━━━━━━━━━━━━━━━━━━━━ 17:37:20\n",
      "Accuracy: 0.9931 - Precision: 0.7552 - Recall: 0.8274 - Specificity: 0.9952 - F1: 0.7445 - Loss: 0.4061\n",
      "\n",
      "Batch 301/387 ━━━━━━━━━━━━━━━━━━━━ 17:38:46\n",
      "Accuracy: 0.9931 - Precision: 0.7552 - Recall: 0.8279 - Specificity: 0.9953 - F1: 0.7449 - Loss: 0.4053\n",
      "\n",
      "Batch 302/387 ━━━━━━━━━━━━━━━━━━━━ 17:40:07\n",
      "Accuracy: 0.9931 - Precision: 0.7545 - Recall: 0.8277 - Specificity: 0.9953 - F1: 0.7445 - Loss: 0.4054\n",
      "\n",
      "Batch 303/387 ━━━━━━━━━━━━━━━━━━━━ 17:41:36\n",
      "Accuracy: 0.9931 - Precision: 0.7552 - Recall: 0.8274 - Specificity: 0.9953 - F1: 0.7448 - Loss: 0.4047\n",
      "\n",
      "Batch 304/387 ━━━━━━━━━━━━━━━━━━━━ 17:42:52\n",
      "Accuracy: 0.9931 - Precision: 0.7557 - Recall: 0.8274 - Specificity: 0.9953 - F1: 0.7452 - Loss: 0.4039\n",
      "\n",
      "Batch 305/387 ━━━━━━━━━━━━━━━━━━━━ 17:44:24\n",
      "Accuracy: 0.9932 - Precision: 0.7564 - Recall: 0.8275 - Specificity: 0.9953 - F1: 0.7458 - Loss: 0.4029\n",
      "\n",
      "Batch 306/387 ━━━━━━━━━━━━━━━━━━━━ 17:45:48\n",
      "Accuracy: 0.9932 - Precision: 0.7572 - Recall: 0.8275 - Specificity: 0.9953 - F1: 0.7463 - Loss: 0.4020\n",
      "\n",
      "Batch 307/387 ━━━━━━━━━━━━━━━━━━━━ 17:47:13\n",
      "Accuracy: 0.9932 - Precision: 0.7580 - Recall: 0.8272 - Specificity: 0.9953 - F1: 0.7466 - Loss: 0.4013\n",
      "\n",
      "Batch 308/387 ━━━━━━━━━━━━━━━━━━━━ 17:48:30\n",
      "Accuracy: 0.9932 - Precision: 0.7587 - Recall: 0.8272 - Specificity: 0.9953 - F1: 0.7471 - Loss: 0.4004\n",
      "\n",
      "Batch 309/387 ━━━━━━━━━━━━━━━━━━━━ 17:49:41\n",
      "Accuracy: 0.9932 - Precision: 0.7593 - Recall: 0.8273 - Specificity: 0.9954 - F1: 0.7476 - Loss: 0.3995\n",
      "\n",
      "Batch 310/387 ━━━━━━━━━━━━━━━━━━━━ 17:51:06\n",
      "Accuracy: 0.9932 - Precision: 0.7599 - Recall: 0.8272 - Specificity: 0.9954 - F1: 0.7480 - Loss: 0.3988\n",
      "\n",
      "Batch 311/387 ━━━━━━━━━━━━━━━━━━━━ 17:52:27\n",
      "Accuracy: 0.9932 - Precision: 0.7603 - Recall: 0.8276 - Specificity: 0.9954 - F1: 0.7485 - Loss: 0.3978\n",
      "\n",
      "Batch 312/387 ━━━━━━━━━━━━━━━━━━━━ 17:53:48\n",
      "Accuracy: 0.9932 - Precision: 0.7591 - Recall: 0.8281 - Specificity: 0.9954 - F1: 0.7479 - Loss: 0.3981\n",
      "\n",
      "Batch 313/387 ━━━━━━━━━━━━━━━━━━━━ 17:55:14\n",
      "Accuracy: 0.9933 - Precision: 0.7596 - Recall: 0.8283 - Specificity: 0.9954 - F1: 0.7484 - Loss: 0.3972\n",
      "\n",
      "Batch 314/387 ━━━━━━━━━━━━━━━━━━━━ 17:56:47\n",
      "Accuracy: 0.9933 - Precision: 0.7598 - Recall: 0.8284 - Specificity: 0.9954 - F1: 0.7487 - Loss: 0.3966\n",
      "\n",
      "Batch 315/387 ━━━━━━━━━━━━━━━━━━━━ 17:58:12\n",
      "Accuracy: 0.9933 - Precision: 0.7604 - Recall: 0.8284 - Specificity: 0.9954 - F1: 0.7491 - Loss: 0.3958\n",
      "\n",
      "Batch 316/387 ━━━━━━━━━━━━━━━━━━━━ 17:59:44\n",
      "Accuracy: 0.9933 - Precision: 0.7609 - Recall: 0.8282 - Specificity: 0.9954 - F1: 0.7494 - Loss: 0.3951\n",
      "\n",
      "Batch 317/387 ━━━━━━━━━━━━━━━━━━━━ 18:01:17\n",
      "Accuracy: 0.9933 - Precision: 0.7616 - Recall: 0.8279 - Specificity: 0.9954 - F1: 0.7497 - Loss: 0.3945\n",
      "\n",
      "Batch 318/387 ━━━━━━━━━━━━━━━━━━━━ 18:02:52\n",
      "Accuracy: 0.9933 - Precision: 0.7620 - Recall: 0.8283 - Specificity: 0.9955 - F1: 0.7502 - Loss: 0.3936\n",
      "\n",
      "Batch 319/387 ━━━━━━━━━━━━━━━━━━━━ 18:04:19\n",
      "Accuracy: 0.9933 - Precision: 0.7622 - Recall: 0.8287 - Specificity: 0.9955 - F1: 0.7507 - Loss: 0.3928\n",
      "\n",
      "Batch 320/387 ━━━━━━━━━━━━━━━━━━━━ 18:05:52\n",
      "Accuracy: 0.9933 - Precision: 0.7605 - Recall: 0.8286 - Specificity: 0.9955 - F1: 0.7493 - Loss: 0.3938\n",
      "\n",
      "Batch 321/387 ━━━━━━━━━━━━━━━━━━━━ 18:07:17\n",
      "Accuracy: 0.9933 - Precision: 0.7601 - Recall: 0.8291 - Specificity: 0.9955 - F1: 0.7494 - Loss: 0.3935\n",
      "\n",
      "Batch 322/387 ━━━━━━━━━━━━━━━━━━━━ 18:08:39\n",
      "Accuracy: 0.9933 - Precision: 0.7606 - Recall: 0.8295 - Specificity: 0.9955 - F1: 0.7500 - Loss: 0.3925\n",
      "\n",
      "Batch 323/387 ━━━━━━━━━━━━━━━━━━━━ 18:10:04\n",
      "Accuracy: 0.9933 - Precision: 0.7611 - Recall: 0.8293 - Specificity: 0.9955 - F1: 0.7502 - Loss: 0.3919\n",
      "\n",
      "Batch 324/387 ━━━━━━━━━━━━━━━━━━━━ 18:11:32\n",
      "Accuracy: 0.9934 - Precision: 0.7617 - Recall: 0.8290 - Specificity: 0.9955 - F1: 0.7505 - Loss: 0.3913\n",
      "\n",
      "Batch 325/387 ━━━━━━━━━━━━━━━━━━━━ 18:13:03\n",
      "Accuracy: 0.9934 - Precision: 0.7616 - Recall: 0.8292 - Specificity: 0.9955 - F1: 0.7506 - Loss: 0.3909\n",
      "\n",
      "Batch 326/387 ━━━━━━━━━━━━━━━━━━━━ 18:14:32\n",
      "Accuracy: 0.9934 - Precision: 0.7622 - Recall: 0.8295 - Specificity: 0.9955 - F1: 0.7512 - Loss: 0.3899\n",
      "\n",
      "Batch 327/387 ━━━━━━━━━━━━━━━━━━━━ 18:15:57\n",
      "Accuracy: 0.9934 - Precision: 0.7629 - Recall: 0.8294 - Specificity: 0.9955 - F1: 0.7516 - Loss: 0.3891\n",
      "\n",
      "Batch 328/387 ━━━━━━━━━━━━━━━━━━━━ 18:17:20\n",
      "Accuracy: 0.9934 - Precision: 0.7631 - Recall: 0.8298 - Specificity: 0.9955 - F1: 0.7521 - Loss: 0.3883\n",
      "\n",
      "Batch 329/387 ━━━━━━━━━━━━━━━━━━━━ 18:18:47\n",
      "Accuracy: 0.9934 - Precision: 0.7638 - Recall: 0.8300 - Specificity: 0.9956 - F1: 0.7526 - Loss: 0.3874\n",
      "\n",
      "Batch 330/387 ━━━━━━━━━━━━━━━━━━━━ 18:20:05\n",
      "Accuracy: 0.9934 - Precision: 0.7644 - Recall: 0.8291 - Specificity: 0.9956 - F1: 0.7524 - Loss: 0.3873\n",
      "\n",
      "Batch 331/387 ━━━━━━━━━━━━━━━━━━━━ 18:21:25\n",
      "Accuracy: 0.9935 - Precision: 0.7649 - Recall: 0.8294 - Specificity: 0.9956 - F1: 0.7529 - Loss: 0.3864\n",
      "\n",
      "Batch 332/387 ━━━━━━━━━━━━━━━━━━━━ 18:22:49\n",
      "Accuracy: 0.9935 - Precision: 0.7649 - Recall: 0.8298 - Specificity: 0.9956 - F1: 0.7533 - Loss: 0.3858\n",
      "\n",
      "Batch 333/387 ━━━━━━━━━━━━━━━━━━━━ 18:24:14\n",
      "Accuracy: 0.9935 - Precision: 0.7654 - Recall: 0.8301 - Specificity: 0.9956 - F1: 0.7538 - Loss: 0.3849\n",
      "\n",
      "Batch 334/387 ━━━━━━━━━━━━━━━━━━━━ 18:25:35\n",
      "Accuracy: 0.9935 - Precision: 0.7660 - Recall: 0.8303 - Specificity: 0.9956 - F1: 0.7543 - Loss: 0.3840\n",
      "\n",
      "Batch 335/387 ━━━━━━━━━━━━━━━━━━━━ 18:26:51\n",
      "Accuracy: 0.9935 - Precision: 0.7666 - Recall: 0.8303 - Specificity: 0.9956 - F1: 0.7547 - Loss: 0.3833\n",
      "\n",
      "Batch 336/387 ━━━━━━━━━━━━━━━━━━━━ 18:28:12\n",
      "Accuracy: 0.9935 - Precision: 0.7670 - Recall: 0.8305 - Specificity: 0.9956 - F1: 0.7551 - Loss: 0.3825\n",
      "\n",
      "Batch 337/387 ━━━━━━━━━━━━━━━━━━━━ 18:29:44\n",
      "Accuracy: 0.9935 - Precision: 0.7659 - Recall: 0.8310 - Specificity: 0.9956 - F1: 0.7546 - Loss: 0.3828\n",
      "\n",
      "Batch 338/387 ━━━━━━━━━━━━━━━━━━━━ 18:31:08\n",
      "Accuracy: 0.9935 - Precision: 0.7660 - Recall: 0.8306 - Specificity: 0.9956 - F1: 0.7546 - Loss: 0.3825\n",
      "\n",
      "Batch 339/387 ━━━━━━━━━━━━━━━━━━━━ 18:32:46\n",
      "Accuracy: 0.9935 - Precision: 0.7665 - Recall: 0.8310 - Specificity: 0.9957 - F1: 0.7552 - Loss: 0.3815\n",
      "\n",
      "Batch 340/387 ━━━━━━━━━━━━━━━━━━━━ 18:34:11\n",
      "Accuracy: 0.9936 - Precision: 0.7659 - Recall: 0.8314 - Specificity: 0.9957 - F1: 0.7550 - Loss: 0.3814\n",
      "\n",
      "Batch 341/387 ━━━━━━━━━━━━━━━━━━━━ 18:35:37\n",
      "Accuracy: 0.9936 - Precision: 0.7664 - Recall: 0.8317 - Specificity: 0.9957 - F1: 0.7556 - Loss: 0.3805\n",
      "\n",
      "Batch 342/387 ━━━━━━━━━━━━━━━━━━━━ 18:37:01\n",
      "Accuracy: 0.9936 - Precision: 0.7669 - Recall: 0.8319 - Specificity: 0.9957 - F1: 0.7560 - Loss: 0.3797\n",
      "\n",
      "Batch 343/387 ━━━━━━━━━━━━━━━━━━━━ 18:38:28\n",
      "Accuracy: 0.9936 - Precision: 0.7674 - Recall: 0.8314 - Specificity: 0.9957 - F1: 0.7561 - Loss: 0.3794\n",
      "\n",
      "Batch 344/387 ━━━━━━━━━━━━━━━━━━━━ 18:39:47\n",
      "Accuracy: 0.9936 - Precision: 0.7681 - Recall: 0.8314 - Specificity: 0.9957 - F1: 0.7565 - Loss: 0.3787\n",
      "\n",
      "Batch 345/387 ━━━━━━━━━━━━━━━━━━━━ 18:41:14\n",
      "Accuracy: 0.9936 - Precision: 0.7686 - Recall: 0.8301 - Specificity: 0.9957 - F1: 0.7559 - Loss: 0.3789\n",
      "\n",
      "Batch 346/387 ━━━━━━━━━━━━━━━━━━━━ 18:42:50\n",
      "Accuracy: 0.9936 - Precision: 0.7692 - Recall: 0.8294 - Specificity: 0.9957 - F1: 0.7559 - Loss: 0.3787\n",
      "\n",
      "Batch 347/387 ━━━━━━━━━━━━━━━━━━━━ 18:44:07\n",
      "Accuracy: 0.9936 - Precision: 0.7694 - Recall: 0.8289 - Specificity: 0.9957 - F1: 0.7558 - Loss: 0.3785\n",
      "\n",
      "Batch 348/387 ━━━━━━━━━━━━━━━━━━━━ 18:45:39\n",
      "Accuracy: 0.9936 - Precision: 0.7696 - Recall: 0.8293 - Specificity: 0.9958 - F1: 0.7562 - Loss: 0.3777\n",
      "\n",
      "Batch 349/387 ━━━━━━━━━━━━━━━━━━━━ 18:47:00\n",
      "Accuracy: 0.9936 - Precision: 0.7686 - Recall: 0.8298 - Specificity: 0.9957 - F1: 0.7557 - Loss: 0.3780\n",
      "\n",
      "Batch 350/387 ━━━━━━━━━━━━━━━━━━━━ 18:48:23\n",
      "Accuracy: 0.9936 - Precision: 0.7684 - Recall: 0.8301 - Specificity: 0.9957 - F1: 0.7559 - Loss: 0.3776\n",
      "\n",
      "Batch 351/387 ━━━━━━━━━━━━━━━━━━━━ 18:49:39\n",
      "Accuracy: 0.9936 - Precision: 0.7684 - Recall: 0.8305 - Specificity: 0.9957 - F1: 0.7561 - Loss: 0.3770\n",
      "\n",
      "Batch 352/387 ━━━━━━━━━━━━━━━━━━━━ 18:51:06\n",
      "Accuracy: 0.9936 - Precision: 0.7679 - Recall: 0.8301 - Specificity: 0.9957 - F1: 0.7558 - Loss: 0.3772\n",
      "\n",
      "Batch 353/387 ━━━━━━━━━━━━━━━━━━━━ 18:52:21\n",
      "Accuracy: 0.9936 - Precision: 0.7672 - Recall: 0.8306 - Specificity: 0.9957 - F1: 0.7557 - Loss: 0.3771\n",
      "\n",
      "Batch 354/387 ━━━━━━━━━━━━━━━━━━━━ 18:53:48\n",
      "Accuracy: 0.9936 - Precision: 0.7677 - Recall: 0.8304 - Specificity: 0.9957 - F1: 0.7559 - Loss: 0.3766\n",
      "\n",
      "Batch 355/387 ━━━━━━━━━━━━━━━━━━━━ 18:55:10\n",
      "Accuracy: 0.9936 - Precision: 0.7680 - Recall: 0.8305 - Specificity: 0.9957 - F1: 0.7562 - Loss: 0.3760\n",
      "\n",
      "Batch 356/387 ━━━━━━━━━━━━━━━━━━━━ 18:56:34\n",
      "Accuracy: 0.9936 - Precision: 0.7685 - Recall: 0.8306 - Specificity: 0.9958 - F1: 0.7566 - Loss: 0.3753\n",
      "\n",
      "Batch 357/387 ━━━━━━━━━━━━━━━━━━━━ 18:57:58\n",
      "Accuracy: 0.9937 - Precision: 0.7691 - Recall: 0.8308 - Specificity: 0.9958 - F1: 0.7571 - Loss: 0.3744\n",
      "\n",
      "Batch 358/387 ━━━━━━━━━━━━━━━━━━━━ 18:59:32\n",
      "Accuracy: 0.9937 - Precision: 0.7696 - Recall: 0.8310 - Specificity: 0.9958 - F1: 0.7576 - Loss: 0.3736\n",
      "\n",
      "Batch 359/387 ━━━━━━━━━━━━━━━━━━━━ 19:00:52\n",
      "Accuracy: 0.9937 - Precision: 0.7701 - Recall: 0.8313 - Specificity: 0.9958 - F1: 0.7581 - Loss: 0.3728\n",
      "\n",
      "Batch 360/387 ━━━━━━━━━━━━━━━━━━━━ 19:02:30\n",
      "Accuracy: 0.9937 - Precision: 0.7700 - Recall: 0.8318 - Specificity: 0.9958 - F1: 0.7584 - Loss: 0.3722\n",
      "\n",
      "Batch 361/387 ━━━━━━━━━━━━━━━━━━━━ 19:04:00\n",
      "Accuracy: 0.9937 - Precision: 0.7704 - Recall: 0.8322 - Specificity: 0.9958 - F1: 0.7589 - Loss: 0.3714\n",
      "\n",
      "Batch 362/387 ━━━━━━━━━━━━━━━━━━━━ 19:05:28\n",
      "Accuracy: 0.9937 - Precision: 0.7709 - Recall: 0.8322 - Specificity: 0.9958 - F1: 0.7593 - Loss: 0.3708\n",
      "\n",
      "Batch 363/387 ━━━━━━━━━━━━━━━━━━━━ 19:06:48\n",
      "Accuracy: 0.9937 - Precision: 0.7714 - Recall: 0.8322 - Specificity: 0.9958 - F1: 0.7596 - Loss: 0.3702\n",
      "\n",
      "Batch 364/387 ━━━━━━━━━━━━━━━━━━━━ 19:08:17\n",
      "Accuracy: 0.9937 - Precision: 0.7718 - Recall: 0.8323 - Specificity: 0.9958 - F1: 0.7600 - Loss: 0.3695\n",
      "\n",
      "Batch 365/387 ━━━━━━━━━━━━━━━━━━━━ 19:09:33\n",
      "Accuracy: 0.9937 - Precision: 0.7715 - Recall: 0.8327 - Specificity: 0.9958 - F1: 0.7601 - Loss: 0.3692\n",
      "\n",
      "Batch 366/387 ━━━━━━━━━━━━━━━━━━━━ 19:10:57\n",
      "Accuracy: 0.9938 - Precision: 0.7719 - Recall: 0.8330 - Specificity: 0.9958 - F1: 0.7605 - Loss: 0.3684\n",
      "\n",
      "Batch 367/387 ━━━━━━━━━━━━━━━━━━━━ 19:12:20\n",
      "Accuracy: 0.9938 - Precision: 0.7710 - Recall: 0.8331 - Specificity: 0.9959 - F1: 0.7601 - Loss: 0.3686\n",
      "\n",
      "Batch 368/387 ━━━━━━━━━━━━━━━━━━━━ 19:13:44\n",
      "Accuracy: 0.9938 - Precision: 0.7712 - Recall: 0.8335 - Specificity: 0.9959 - F1: 0.7604 - Loss: 0.3679\n",
      "\n",
      "Batch 369/387 ━━━━━━━━━━━━━━━━━━━━ 19:15:02\n",
      "Accuracy: 0.9938 - Precision: 0.7717 - Recall: 0.8336 - Specificity: 0.9959 - F1: 0.7609 - Loss: 0.3672\n",
      "\n",
      "Batch 370/387 ━━━━━━━━━━━━━━━━━━━━ 19:16:27\n",
      "Accuracy: 0.9938 - Precision: 0.7722 - Recall: 0.8329 - Specificity: 0.9959 - F1: 0.7608 - Loss: 0.3671\n",
      "\n",
      "Batch 371/387 ━━━━━━━━━━━━━━━━━━━━ 19:17:43\n",
      "Accuracy: 0.9938 - Precision: 0.7728 - Recall: 0.8327 - Specificity: 0.9959 - F1: 0.7610 - Loss: 0.3666\n",
      "\n",
      "Batch 372/387 ━━━━━━━━━━━━━━━━━━━━ 19:19:06\n",
      "Accuracy: 0.9938 - Precision: 0.7734 - Recall: 0.8327 - Specificity: 0.9959 - F1: 0.7614 - Loss: 0.3659\n",
      "\n",
      "Batch 373/387 ━━━━━━━━━━━━━━━━━━━━ 19:20:25\n",
      "Accuracy: 0.9938 - Precision: 0.7734 - Recall: 0.8330 - Specificity: 0.9959 - F1: 0.7617 - Loss: 0.3654\n",
      "\n",
      "Batch 374/387 ━━━━━━━━━━━━━━━━━━━━ 19:21:35\n",
      "Accuracy: 0.9938 - Precision: 0.7740 - Recall: 0.8326 - Specificity: 0.9959 - F1: 0.7618 - Loss: 0.3651\n",
      "\n",
      "Batch 375/387 ━━━━━━━━━━━━━━━━━━━━ 19:22:53\n",
      "Accuracy: 0.9938 - Precision: 0.7745 - Recall: 0.8328 - Specificity: 0.9959 - F1: 0.7622 - Loss: 0.3643\n",
      "\n",
      "Batch 376/387 ━━━━━━━━━━━━━━━━━━━━ 19:24:04\n",
      "Accuracy: 0.9938 - Precision: 0.7750 - Recall: 0.8319 - Specificity: 0.9959 - F1: 0.7620 - Loss: 0.3644\n",
      "\n",
      "Batch 377/387 ━━━━━━━━━━━━━━━━━━━━ 19:25:22\n",
      "Accuracy: 0.9938 - Precision: 0.7755 - Recall: 0.8318 - Specificity: 0.9959 - F1: 0.7623 - Loss: 0.3638\n",
      "\n",
      "Batch 378/387 ━━━━━━━━━━━━━━━━━━━━ 19:26:34\n",
      "Accuracy: 0.9938 - Precision: 0.7758 - Recall: 0.8321 - Specificity: 0.9960 - F1: 0.7627 - Loss: 0.3631\n",
      "\n",
      "Batch 379/387 ━━━━━━━━━━━━━━━━━━━━ 19:27:55\n",
      "Accuracy: 0.9938 - Precision: 0.7755 - Recall: 0.8325 - Specificity: 0.9960 - F1: 0.7628 - Loss: 0.3628\n",
      "\n",
      "Batch 380/387 ━━━━━━━━━━━━━━━━━━━━ 19:29:11\n",
      "Accuracy: 0.9939 - Precision: 0.7746 - Recall: 0.8328 - Specificity: 0.9960 - F1: 0.7623 - Loss: 0.3631\n",
      "\n",
      "Batch 381/387 ━━━━━━━━━━━━━━━━━━━━ 19:30:29\n",
      "Accuracy: 0.9939 - Precision: 0.7751 - Recall: 0.8332 - Specificity: 0.9960 - F1: 0.7628 - Loss: 0.3623\n",
      "\n",
      "Batch 382/387 ━━━━━━━━━━━━━━━━━━━━ 19:31:53\n",
      "Accuracy: 0.9939 - Precision: 0.7751 - Recall: 0.8332 - Specificity: 0.9960 - F1: 0.7629 - Loss: 0.3620\n",
      "\n",
      "Batch 383/387 ━━━━━━━━━━━━━━━━━━━━ 19:33:11\n",
      "Accuracy: 0.9939 - Precision: 0.7754 - Recall: 0.8333 - Specificity: 0.9960 - F1: 0.7632 - Loss: 0.3614\n",
      "\n",
      "Batch 384/387 ━━━━━━━━━━━━━━━━━━━━ 19:34:37\n",
      "Accuracy: 0.9939 - Precision: 0.7754 - Recall: 0.8335 - Specificity: 0.9960 - F1: 0.7635 - Loss: 0.3609\n",
      "\n",
      "Batch 385/387 ━━━━━━━━━━━━━━━━━━━━ 19:35:53\n",
      "Accuracy: 0.9939 - Precision: 0.7745 - Recall: 0.8337 - Specificity: 0.9960 - F1: 0.7629 - Loss: 0.3612\n",
      "\n",
      "Batch 386/387 ━━━━━━━━━━━━━━━━━━━━ 19:37:07\n",
      "Accuracy: 0.9939 - Precision: 0.7746 - Recall: 0.8334 - Specificity: 0.9960 - F1: 0.7630 - Loss: 0.3609\n",
      "\n",
      "Batch 387/387 ━━━━━━━━━━━━━━━━━━━━ 19:38:23\n",
      "Accuracy: 0.9939 - Precision: 0.7748 - Recall: 0.8328 - Specificity: 0.9960 - F1: 0.7628 - Loss: 0.3609\n",
      "\n",
      "End of Epoch 1\n",
      "\n",
      "Epoch 2/50\n",
      "Batch 1/387 ━━━━━━━━━━━━━━━━━━━━ 19:59:55\n",
      "Accuracy: 0.9985 - Precision: 0.9850 - Recall: 0.8892 - Specificity: 0.9998 - F1: 0.9346 - Loss: 0.0811\n",
      "\n",
      "Batch 2/387 ━━━━━━━━━━━━━━━━━━━━ 20:01:15\n",
      "Accuracy: 0.9985 - Precision: 0.9769 - Recall: 0.8261 - Specificity: 0.9998 - F1: 0.8942 - Loss: 0.1269\n",
      "\n",
      "Batch 3/387 ━━━━━━━━━━━━━━━━━━━━ 20:02:38\n",
      "Accuracy: 0.9984 - Precision: 0.9740 - Recall: 0.8252 - Specificity: 0.9998 - F1: 0.8927 - Loss: 0.1281\n",
      "\n",
      "Batch 4/387 ━━━━━━━━━━━━━━━━━━━━ 20:04:00\n",
      "Accuracy: 0.9982 - Precision: 0.9583 - Recall: 0.8505 - Specificity: 0.9995 - F1: 0.8993 - Loss: 0.1208\n",
      "\n",
      "Batch 5/387 ━━━━━━━━━━━━━━━━━━━━ 20:05:27\n",
      "Accuracy: 0.9982 - Precision: 0.9610 - Recall: 0.8583 - Specificity: 0.9996 - F1: 0.9052 - Loss: 0.1145\n",
      "\n",
      "Batch 6/387 ━━━━━━━━━━━━━━━━━━━━ 20:06:53\n",
      "Accuracy: 0.9983 - Precision: 0.9633 - Recall: 0.8634 - Specificity: 0.9996 - F1: 0.9093 - Loss: 0.1098\n",
      "\n",
      "Batch 7/387 ━━━━━━━━━━━━━━━━━━━━ 20:08:09\n",
      "Accuracy: 0.9984 - Precision: 0.9530 - Recall: 0.8696 - Specificity: 0.9996 - F1: 0.9078 - Loss: 0.1118\n",
      "\n",
      "Batch 8/387 ━━━━━━━━━━━━━━━━━━━━ 20:09:35\n",
      "Accuracy: 0.9983 - Precision: 0.9325 - Recall: 0.8845 - Specificity: 0.9994 - F1: 0.9040 - Loss: 0.1158\n",
      "\n",
      "Batch 9/387 ━━━━━━━━━━━━━━━━━━━━ 20:10:50\n",
      "Accuracy: 0.9980 - Precision: 0.9179 - Recall: 0.8764 - Specificity: 0.9992 - F1: 0.8932 - Loss: 0.1279\n",
      "\n",
      "Batch 10/387 ━━━━━━━━━━━━━━━━━━━━ 20:12:07\n",
      "Accuracy: 0.9981 - Precision: 0.9064 - Recall: 0.8869 - Specificity: 0.9991 - F1: 0.8922 - Loss: 0.1291\n",
      "\n",
      "Batch 11/387 ━━━━━━━━━━━━━━━━━━━━ 20:13:27\n",
      "Accuracy: 0.9975 - Precision: 0.9137 - Recall: 0.8726 - Specificity: 0.9992 - F1: 0.8873 - Loss: 0.1364\n",
      "\n",
      "Batch 12/387 ━━━━━━━━━━━━━━━━━━━━ 20:14:42\n",
      "Accuracy: 0.9975 - Precision: 0.8846 - Recall: 0.8800 - Specificity: 0.9991 - F1: 0.8727 - Loss: 0.1516\n",
      "\n",
      "Batch 13/387 ━━━━━━━━━━━━━━━━━━━━ 20:16:01\n",
      "Accuracy: 0.9976 - Precision: 0.8891 - Recall: 0.8843 - Specificity: 0.9991 - F1: 0.8779 - Loss: 0.1457\n",
      "\n",
      "Batch 14/387 ━━━━━━━━━━━━━━━━━━━━ 20:17:22\n",
      "Accuracy: 0.9976 - Precision: 0.8867 - Recall: 0.8888 - Specificity: 0.9990 - F1: 0.8794 - Loss: 0.1439\n",
      "\n",
      "Batch 15/387 ━━━━━━━━━━━━━━━━━━━━ 20:18:45\n",
      "Accuracy: 0.9974 - Precision: 0.8553 - Recall: 0.8842 - Specificity: 0.9988 - F1: 0.8576 - Loss: 0.1666\n",
      "\n",
      "Batch 16/387 ━━━━━━━━━━━━━━━━━━━━ 20:20:02\n",
      "Accuracy: 0.9974 - Precision: 0.8609 - Recall: 0.8799 - Specificity: 0.9989 - F1: 0.8586 - Loss: 0.1656\n",
      "\n",
      "Batch 17/387 ━━━━━━━━━━━━━━━━━━━━ 20:21:18\n",
      "Accuracy: 0.9972 - Precision: 0.8432 - Recall: 0.8861 - Specificity: 0.9986 - F1: 0.8501 - Loss: 0.1750\n",
      "\n",
      "Batch 18/387 ━━━━━━━━━━━━━━━━━━━━ 20:22:39\n",
      "Accuracy: 0.9973 - Precision: 0.8470 - Recall: 0.8888 - Specificity: 0.9986 - F1: 0.8542 - Loss: 0.1707\n",
      "\n",
      "Batch 19/387 ━━━━━━━━━━━━━━━━━━━━ 20:23:56\n",
      "Accuracy: 0.9973 - Precision: 0.8532 - Recall: 0.8797 - Specificity: 0.9987 - F1: 0.8524 - Loss: 0.1727\n",
      "\n",
      "Batch 20/387 ━━━━━━━━━━━━━━━━━━━━ 20:25:09\n",
      "Accuracy: 0.9972 - Precision: 0.8599 - Recall: 0.8714 - Specificity: 0.9987 - F1: 0.8513 - Loss: 0.1741\n",
      "\n",
      "Batch 21/387 ━━━━━━━━━━━━━━━━━━━━ 20:26:38\n",
      "Accuracy: 0.9973 - Precision: 0.8634 - Recall: 0.8659 - Specificity: 0.9988 - F1: 0.8505 - Loss: 0.1751\n",
      "\n",
      "Batch 22/387 ━━━━━━━━━━━━━━━━━━━━ 20:28:02\n",
      "Accuracy: 0.9973 - Precision: 0.8616 - Recall: 0.8704 - Specificity: 0.9988 - F1: 0.8523 - Loss: 0.1731\n",
      "\n",
      "Batch 23/387 ━━━━━━━━━━━━━━━━━━━━ 20:29:28\n",
      "Accuracy: 0.9974 - Precision: 0.8668 - Recall: 0.8718 - Specificity: 0.9988 - F1: 0.8561 - Loss: 0.1688\n",
      "\n",
      "Batch 24/387 ━━━━━━━━━━━━━━━━━━━━ 20:30:59\n",
      "Accuracy: 0.9974 - Precision: 0.8702 - Recall: 0.8647 - Specificity: 0.9989 - F1: 0.8540 - Loss: 0.1714\n",
      "\n",
      "Batch 25/387 ━━━━━━━━━━━━━━━━━━━━ 20:32:27\n",
      "Accuracy: 0.9972 - Precision: 0.8750 - Recall: 0.8536 - Specificity: 0.9989 - F1: 0.8494 - Loss: 0.1774\n",
      "\n",
      "Batch 26/387 ━━━━━━━━━━━━━━━━━━━━ 20:33:49\n",
      "Accuracy: 0.9971 - Precision: 0.8706 - Recall: 0.8515 - Specificity: 0.9988 - F1: 0.8466 - Loss: 0.1803\n",
      "\n",
      "Batch 27/387 ━━━━━━━━━━━━━━━━━━━━ 20:35:14\n",
      "Accuracy: 0.9971 - Precision: 0.8739 - Recall: 0.8504 - Specificity: 0.9989 - F1: 0.8481 - Loss: 0.1786\n",
      "\n",
      "Batch 28/387 ━━━━━━━━━━━━━━━━━━━━ 20:36:40\n",
      "Accuracy: 0.9972 - Precision: 0.8573 - Recall: 0.8523 - Specificity: 0.9989 - F1: 0.8379 - Loss: 0.1902\n",
      "\n",
      "Batch 29/387 ━━━━━━━━━━━━━━━━━━━━ 20:38:19\n",
      "Accuracy: 0.9972 - Precision: 0.8617 - Recall: 0.8540 - Specificity: 0.9989 - F1: 0.8415 - Loss: 0.1862\n",
      "\n",
      "Batch 30/387 ━━━━━━━━━━━━━━━━━━━━ 20:39:40\n",
      "Accuracy: 0.9973 - Precision: 0.8652 - Recall: 0.8564 - Specificity: 0.9989 - F1: 0.8449 - Loss: 0.1823\n",
      "\n",
      "Batch 31/387 ━━━━━━━━━━━━━━━━━━━━ 20:40:57\n",
      "Accuracy: 0.9973 - Precision: 0.8606 - Recall: 0.8591 - Specificity: 0.9989 - F1: 0.8441 - Loss: 0.1830\n",
      "\n",
      "Batch 32/387 ━━━━━━━━━━━━━━━━━━━━ 20:42:16\n",
      "Accuracy: 0.9971 - Precision: 0.8648 - Recall: 0.8563 - Specificity: 0.9989 - F1: 0.8448 - Loss: 0.1829\n",
      "\n",
      "Batch 33/387 ━━━━━━━━━━━━━━━━━━━━ 20:43:36\n",
      "Accuracy: 0.9970 - Precision: 0.8688 - Recall: 0.8523 - Specificity: 0.9990 - F1: 0.8446 - Loss: 0.1834\n",
      "\n",
      "Batch 34/387 ━━━━━━━━━━━━━━━━━━━━ 20:45:03\n",
      "Accuracy: 0.9971 - Precision: 0.8680 - Recall: 0.8524 - Specificity: 0.9990 - F1: 0.8447 - Loss: 0.1841\n",
      "\n",
      "Batch 35/387 ━━━━━━━━━━━━━━━━━━━━ 20:46:29\n",
      "Accuracy: 0.9971 - Precision: 0.8610 - Recall: 0.8523 - Specificity: 0.9990 - F1: 0.8411 - Loss: 0.1878\n",
      "\n",
      "Batch 36/387 ━━━━━━━━━━━━━━━━━━━━ 20:48:01\n",
      "Accuracy: 0.9971 - Precision: 0.8625 - Recall: 0.8448 - Specificity: 0.9990 - F1: 0.8375 - Loss: 0.1919\n",
      "\n",
      "Batch 37/387 ━━━━━━━━━━━━━━━━━━━━ 20:49:24\n",
      "Accuracy: 0.9971 - Precision: 0.8594 - Recall: 0.8414 - Specificity: 0.9990 - F1: 0.8347 - Loss: 0.1949\n",
      "\n",
      "Batch 38/387 ━━━━━━━━━━━━━━━━━━━━ 20:50:43\n",
      "Accuracy: 0.9972 - Precision: 0.8623 - Recall: 0.8441 - Specificity: 0.9990 - F1: 0.8380 - Loss: 0.1912\n",
      "\n",
      "Batch 39/387 ━━━━━━━━━━━━━━━━━━━━ 20:52:02\n",
      "Accuracy: 0.9970 - Precision: 0.8649 - Recall: 0.8373 - Specificity: 0.9990 - F1: 0.8350 - Loss: 0.1948\n",
      "\n",
      "Batch 40/387 ━━━━━━━━━━━━━━━━━━━━ 20:53:18\n",
      "Accuracy: 0.9970 - Precision: 0.8674 - Recall: 0.8345 - Specificity: 0.9990 - F1: 0.8349 - Loss: 0.1952\n",
      "\n",
      "Batch 41/387 ━━━━━━━━━━━━━━━━━━━━ 20:54:37\n",
      "Accuracy: 0.9970 - Precision: 0.8697 - Recall: 0.8359 - Specificity: 0.9990 - F1: 0.8370 - Loss: 0.1927\n",
      "\n",
      "Batch 42/387 ━━━━━━━━━━━━━━━━━━━━ 20:56:02\n",
      "Accuracy: 0.9969 - Precision: 0.8725 - Recall: 0.8352 - Specificity: 0.9990 - F1: 0.8382 - Loss: 0.1916\n",
      "\n",
      "Batch 43/387 ━━━━━━━━━━━━━━━━━━━━ 20:57:19\n",
      "Accuracy: 0.9969 - Precision: 0.8664 - Recall: 0.8388 - Specificity: 0.9990 - F1: 0.8363 - Loss: 0.1936\n",
      "\n",
      "Batch 44/387 ━━━━━━━━━━━━━━━━━━━━ 20:58:54\n",
      "Accuracy: 0.9969 - Precision: 0.8659 - Recall: 0.8411 - Specificity: 0.9990 - F1: 0.8375 - Loss: 0.1922\n",
      "\n",
      "Batch 45/387 ━━━━━━━━━━━━━━━━━━━━ 21:00:14\n",
      "Accuracy: 0.9969 - Precision: 0.8666 - Recall: 0.8434 - Specificity: 0.9990 - F1: 0.8394 - Loss: 0.1900\n",
      "\n",
      "Batch 46/387 ━━━━━━━━━━━━━━━━━━━━ 21:01:35\n",
      "Accuracy: 0.9969 - Precision: 0.8660 - Recall: 0.8456 - Specificity: 0.9989 - F1: 0.8404 - Loss: 0.1888\n",
      "\n",
      "Batch 47/387 ━━━━━━━━━━━━━━━━━━━━ 21:03:04\n",
      "Accuracy: 0.9969 - Precision: 0.8680 - Recall: 0.8478 - Specificity: 0.9989 - F1: 0.8429 - Loss: 0.1860\n",
      "\n",
      "Batch 48/387 ━━━━━━━━━━━━━━━━━━━━ 21:04:26\n",
      "Accuracy: 0.9969 - Precision: 0.8664 - Recall: 0.8503 - Specificity: 0.9989 - F1: 0.8434 - Loss: 0.1852\n",
      "\n",
      "Batch 49/387 ━━━━━━━━━━━━━━━━━━━━ 21:05:46\n",
      "Accuracy: 0.9969 - Precision: 0.8682 - Recall: 0.8508 - Specificity: 0.9989 - F1: 0.8449 - Loss: 0.1836\n",
      "\n",
      "Batch 50/387 ━━━━━━━━━━━━━━━━━━━━ 21:07:04\n",
      "Accuracy: 0.9969 - Precision: 0.8693 - Recall: 0.8525 - Specificity: 0.9989 - F1: 0.8466 - Loss: 0.1817\n",
      "\n",
      "Batch 51/387 ━━━━━━━━━━━━━━━━━━━━ 21:08:38\n",
      "Accuracy: 0.9970 - Precision: 0.8712 - Recall: 0.8533 - Specificity: 0.9989 - F1: 0.8481 - Loss: 0.1798\n",
      "\n",
      "Batch 52/387 ━━━━━━━━━━━━━━━━━━━━ 21:10:06\n",
      "Accuracy: 0.9969 - Precision: 0.8723 - Recall: 0.8521 - Specificity: 0.9989 - F1: 0.8482 - Loss: 0.1796\n",
      "\n",
      "Batch 53/387 ━━━━━━━━━━━━━━━━━━━━ 21:11:23\n",
      "Accuracy: 0.9970 - Precision: 0.8741 - Recall: 0.8531 - Specificity: 0.9989 - F1: 0.8499 - Loss: 0.1777\n",
      "\n",
      "Batch 54/387 ━━━━━━━━━━━━━━━━━━━━ 21:12:40\n",
      "Accuracy: 0.9969 - Precision: 0.8733 - Recall: 0.8535 - Specificity: 0.9989 - F1: 0.8499 - Loss: 0.1778\n",
      "\n",
      "Batch 55/387 ━━━━━━━━━━━━━━━━━━━━ 21:14:09\n",
      "Accuracy: 0.9969 - Precision: 0.8730 - Recall: 0.8555 - Specificity: 0.9989 - F1: 0.8510 - Loss: 0.1765\n",
      "\n",
      "Batch 56/387 ━━━━━━━━━━━━━━━━━━━━ 21:15:32\n",
      "Accuracy: 0.9969 - Precision: 0.8736 - Recall: 0.8566 - Specificity: 0.9988 - F1: 0.8521 - Loss: 0.1753\n",
      "\n",
      "Batch 57/387 ━━━━━━━━━━━━━━━━━━━━ 21:17:05\n",
      "Accuracy: 0.9969 - Precision: 0.8696 - Recall: 0.8586 - Specificity: 0.9988 - F1: 0.8507 - Loss: 0.1766\n",
      "\n",
      "Batch 58/387 ━━━━━━━━━━━━━━━━━━━━ 21:18:32\n",
      "Accuracy: 0.9969 - Precision: 0.8675 - Recall: 0.8603 - Specificity: 0.9988 - F1: 0.8505 - Loss: 0.1771\n",
      "\n",
      "Batch 59/387 ━━━━━━━━━━━━━━━━━━━━ 21:19:59\n",
      "Accuracy: 0.9970 - Precision: 0.8677 - Recall: 0.8615 - Specificity: 0.9988 - F1: 0.8514 - Loss: 0.1761\n",
      "\n",
      "Batch 60/387 ━━━━━━━━━━━━━━━━━━━━ 21:21:28\n",
      "Accuracy: 0.9970 - Precision: 0.8698 - Recall: 0.8596 - Specificity: 0.9988 - F1: 0.8515 - Loss: 0.1759\n",
      "\n",
      "Batch 61/387 ━━━━━━━━━━━━━━━━━━━━ 21:22:57\n",
      "Accuracy: 0.9970 - Precision: 0.8712 - Recall: 0.8585 - Specificity: 0.9988 - F1: 0.8518 - Loss: 0.1756\n",
      "\n",
      "Batch 62/387 ━━━━━━━━━━━━━━━━━━━━ 21:24:14\n",
      "Accuracy: 0.9970 - Precision: 0.8730 - Recall: 0.8577 - Specificity: 0.9989 - F1: 0.8523 - Loss: 0.1749\n",
      "\n",
      "Batch 63/387 ━━━━━━━━━━━━━━━━━━━━ 21:25:43\n",
      "Accuracy: 0.9970 - Precision: 0.8746 - Recall: 0.8487 - Specificity: 0.9989 - F1: 0.8459 - Loss: 0.1812\n",
      "\n",
      "Batch 64/387 ━━━━━━━━━━━━━━━━━━━━ 21:27:11\n",
      "Accuracy: 0.9970 - Precision: 0.8762 - Recall: 0.8497 - Specificity: 0.9989 - F1: 0.8474 - Loss: 0.1794\n",
      "\n",
      "Batch 65/387 ━━━━━━━━━━━━━━━━━━━━ 21:28:38\n",
      "Accuracy: 0.9970 - Precision: 0.8775 - Recall: 0.8509 - Specificity: 0.9989 - F1: 0.8489 - Loss: 0.1777\n",
      "\n",
      "Batch 66/387 ━━━━━━━━━━━━━━━━━━━━ 21:30:04\n",
      "Accuracy: 0.9970 - Precision: 0.8792 - Recall: 0.8485 - Specificity: 0.9989 - F1: 0.8484 - Loss: 0.1782\n",
      "\n",
      "Batch 67/387 ━━━━━━━━━━━━━━━━━━━━ 21:31:29\n",
      "Accuracy: 0.9970 - Precision: 0.8764 - Recall: 0.8479 - Specificity: 0.9989 - F1: 0.8469 - Loss: 0.1799\n",
      "\n",
      "Batch 68/387 ━━━━━━━━━━━━━━━━━━━━ 21:32:56\n",
      "Accuracy: 0.9969 - Precision: 0.8759 - Recall: 0.8496 - Specificity: 0.9988 - F1: 0.8476 - Loss: 0.1791\n",
      "\n",
      "Batch 69/387 ━━━━━━━━━━━━━━━━━━━━ 21:34:17\n",
      "Accuracy: 0.9969 - Precision: 0.8738 - Recall: 0.8513 - Specificity: 0.9988 - F1: 0.8474 - Loss: 0.1794\n",
      "\n",
      "Batch 70/387 ━━━━━━━━━━━━━━━━━━━━ 21:35:39\n",
      "Accuracy: 0.9969 - Precision: 0.8705 - Recall: 0.8533 - Specificity: 0.9988 - F1: 0.8464 - Loss: 0.1804\n",
      "\n",
      "Batch 71/387 ━━━━━━━━━━━━━━━━━━━━ 21:37:01\n",
      "Accuracy: 0.9969 - Precision: 0.8718 - Recall: 0.8539 - Specificity: 0.9988 - F1: 0.8476 - Loss: 0.1791\n",
      "\n",
      "Batch 72/387 ━━━━━━━━━━━━━━━━━━━━ 21:38:24\n",
      "Accuracy: 0.9969 - Precision: 0.8731 - Recall: 0.8543 - Specificity: 0.9988 - F1: 0.8487 - Loss: 0.1778\n",
      "\n",
      "Batch 73/387 ━━━━━━━━━━━━━━━━━━━━ 21:39:45\n",
      "Accuracy: 0.9969 - Precision: 0.8695 - Recall: 0.8542 - Specificity: 0.9988 - F1: 0.8468 - Loss: 0.1799\n",
      "\n",
      "Batch 74/387 ━━━━━━━━━━━━━━━━━━━━ 21:41:04\n",
      "Accuracy: 0.9969 - Precision: 0.8655 - Recall: 0.8557 - Specificity: 0.9987 - F1: 0.8450 - Loss: 0.1817\n",
      "\n",
      "Batch 75/387 ━━━━━━━━━━━━━━━━━━━━ 21:42:25\n",
      "Accuracy: 0.9969 - Precision: 0.8646 - Recall: 0.8565 - Specificity: 0.9987 - F1: 0.8451 - Loss: 0.1816\n",
      "\n",
      "Batch 76/387 ━━━━━━━━━━━━━━━━━━━━ 21:43:49\n",
      "Accuracy: 0.9969 - Precision: 0.8639 - Recall: 0.8563 - Specificity: 0.9987 - F1: 0.8449 - Loss: 0.1819\n",
      "\n",
      "Batch 77/387 ━━━━━━━━━━━━━━━━━━━━ 21:45:14\n",
      "Accuracy: 0.9969 - Precision: 0.8633 - Recall: 0.8551 - Specificity: 0.9987 - F1: 0.8442 - Loss: 0.1827\n",
      "\n",
      "Batch 78/387 ━━━━━━━━━━━━━━━━━━━━ 21:46:30\n",
      "Accuracy: 0.9969 - Precision: 0.8613 - Recall: 0.8565 - Specificity: 0.9987 - F1: 0.8438 - Loss: 0.1830\n",
      "\n",
      "Batch 79/387 ━━━━━━━━━━━━━━━━━━━━ 21:47:46\n",
      "Accuracy: 0.9969 - Precision: 0.8622 - Recall: 0.8558 - Specificity: 0.9987 - F1: 0.8441 - Loss: 0.1828\n",
      "\n",
      "Batch 80/387 ━━━━━━━━━━━━━━━━━━━━ 21:49:13\n",
      "Accuracy: 0.9968 - Precision: 0.8628 - Recall: 0.8524 - Specificity: 0.9987 - F1: 0.8424 - Loss: 0.1847\n",
      "\n",
      "Batch 81/387 ━━━━━━━━━━━━━━━━━━━━ 21:50:35\n",
      "Accuracy: 0.9968 - Precision: 0.8627 - Recall: 0.8537 - Specificity: 0.9987 - F1: 0.8431 - Loss: 0.1838\n",
      "\n",
      "Batch 82/387 ━━━━━━━━━━━━━━━━━━━━ 21:51:55\n",
      "Accuracy: 0.9968 - Precision: 0.8619 - Recall: 0.8520 - Specificity: 0.9987 - F1: 0.8420 - Loss: 0.1850\n",
      "\n",
      "Batch 83/387 ━━━━━━━━━━━━━━━━━━━━ 21:53:22\n",
      "Accuracy: 0.9968 - Precision: 0.8634 - Recall: 0.8528 - Specificity: 0.9987 - F1: 0.8433 - Loss: 0.1835\n",
      "\n",
      "Batch 84/387 ━━━━━━━━━━━━━━━━━━━━ 21:54:44\n",
      "Accuracy: 0.9968 - Precision: 0.8602 - Recall: 0.8532 - Specificity: 0.9987 - F1: 0.8417 - Loss: 0.1851\n",
      "\n",
      "Batch 85/387 ━━━━━━━━━━━━━━━━━━━━ 21:56:12\n",
      "Accuracy: 0.9969 - Precision: 0.8603 - Recall: 0.8528 - Specificity: 0.9987 - F1: 0.8418 - Loss: 0.1850\n",
      "\n",
      "Batch 86/387 ━━━━━━━━━━━━━━━━━━━━ 21:57:41\n",
      "Accuracy: 0.9969 - Precision: 0.8580 - Recall: 0.8536 - Specificity: 0.9987 - F1: 0.8410 - Loss: 0.1858\n",
      "\n",
      "Batch 87/387 ━━━━━━━━━━━━━━━━━━━━ 21:59:10\n",
      "Accuracy: 0.9969 - Precision: 0.8592 - Recall: 0.8519 - Specificity: 0.9987 - F1: 0.8406 - Loss: 0.1861\n",
      "\n",
      "Batch 88/387 ━━━━━━━━━━━━━━━━━━━━ 22:00:33\n",
      "Accuracy: 0.9969 - Precision: 0.8592 - Recall: 0.8507 - Specificity: 0.9987 - F1: 0.8401 - Loss: 0.1866\n",
      "\n",
      "Batch 89/387 ━━━━━━━━━━━━━━━━━━━━ 22:01:46\n",
      "Accuracy: 0.9969 - Precision: 0.8602 - Recall: 0.8512 - Specificity: 0.9987 - F1: 0.8411 - Loss: 0.1855\n",
      "\n",
      "Batch 90/387 ━━━━━━━━━━━━━━━━━━━━ 22:03:05\n",
      "Accuracy: 0.9968 - Precision: 0.8535 - Recall: 0.8529 - Specificity: 0.9986 - F1: 0.8363 - Loss: 0.1905\n",
      "\n",
      "Batch 91/387 ━━━━━━━━━━━━━━━━━━━━ 22:04:26\n",
      "Accuracy: 0.9968 - Precision: 0.8548 - Recall: 0.8533 - Specificity: 0.9986 - F1: 0.8373 - Loss: 0.1894\n",
      "\n",
      "Batch 92/387 ━━━━━━━━━━━━━━━━━━━━ 22:05:39\n",
      "Accuracy: 0.9968 - Precision: 0.8484 - Recall: 0.8544 - Specificity: 0.9986 - F1: 0.8327 - Loss: 0.1942\n",
      "\n",
      "Batch 93/387 ━━━━━━━━━━━━━━━━━━━━ 22:07:06\n",
      "Accuracy: 0.9968 - Precision: 0.8482 - Recall: 0.8555 - Specificity: 0.9986 - F1: 0.8334 - Loss: 0.1935\n",
      "\n",
      "Batch 94/387 ━━━━━━━━━━━━━━━━━━━━ 22:08:23\n",
      "Accuracy: 0.9968 - Precision: 0.8478 - Recall: 0.8530 - Specificity: 0.9986 - F1: 0.8319 - Loss: 0.1951\n",
      "\n",
      "Batch 95/387 ━━━━━━━━━━━━━━━━━━━━ 22:09:40\n",
      "Accuracy: 0.9968 - Precision: 0.8491 - Recall: 0.8505 - Specificity: 0.9986 - F1: 0.8311 - Loss: 0.1960\n",
      "\n",
      "Batch 96/387 ━━━━━━━━━━━━━━━━━━━━ 22:11:06\n",
      "Accuracy: 0.9968 - Precision: 0.8504 - Recall: 0.8484 - Specificity: 0.9986 - F1: 0.8306 - Loss: 0.1966\n",
      "\n",
      "Batch 97/387 ━━━━━━━━━━━━━━━━━━━━ 22:12:21\n",
      "Accuracy: 0.9968 - Precision: 0.8505 - Recall: 0.8470 - Specificity: 0.9986 - F1: 0.8301 - Loss: 0.1971\n",
      "\n",
      "Batch 98/387 ━━━━━━━━━━━━━━━━━━━━ 22:13:52\n",
      "Accuracy: 0.9968 - Precision: 0.8500 - Recall: 0.8468 - Specificity: 0.9986 - F1: 0.8299 - Loss: 0.1973\n",
      "\n",
      "Batch 99/387 ━━━━━━━━━━━━━━━━━━━━ 22:15:19\n",
      "Accuracy: 0.9968 - Precision: 0.8507 - Recall: 0.8475 - Specificity: 0.9986 - F1: 0.8308 - Loss: 0.1963\n",
      "\n",
      "Batch 100/387 ━━━━━━━━━━━━━━━━━━━━ 22:16:42\n",
      "Accuracy: 0.9968 - Precision: 0.8499 - Recall: 0.8478 - Specificity: 0.9986 - F1: 0.8307 - Loss: 0.1963\n",
      "\n",
      "Batch 101/387 ━━━━━━━━━━━━━━━━━━━━ 22:18:08\n",
      "Accuracy: 0.9968 - Precision: 0.8502 - Recall: 0.8480 - Specificity: 0.9986 - F1: 0.8311 - Loss: 0.1959\n",
      "\n",
      "Batch 102/387 ━━━━━━━━━━━━━━━━━━━━ 22:19:30\n",
      "Accuracy: 0.9968 - Precision: 0.8515 - Recall: 0.8465 - Specificity: 0.9986 - F1: 0.8310 - Loss: 0.1962\n",
      "\n",
      "Batch 103/387 ━━━━━━━━━━━━━━━━━━━━ 22:20:52\n",
      "Accuracy: 0.9968 - Precision: 0.8525 - Recall: 0.8470 - Specificity: 0.9986 - F1: 0.8319 - Loss: 0.1952\n",
      "\n",
      "Batch 104/387 ━━━━━━━━━━━━━━━━━━━━ 22:22:23\n",
      "Accuracy: 0.9968 - Precision: 0.8524 - Recall: 0.8452 - Specificity: 0.9986 - F1: 0.8310 - Loss: 0.1961\n",
      "\n",
      "Batch 105/387 ━━━━━━━━━━━━━━━━━━━━ 22:23:42\n",
      "Accuracy: 0.9968 - Precision: 0.8503 - Recall: 0.8467 - Specificity: 0.9986 - F1: 0.8305 - Loss: 0.1966\n",
      "\n",
      "Batch 106/387 ━━━━━━━━━━━━━━━━━━━━ 22:24:57\n",
      "Accuracy: 0.9968 - Precision: 0.8504 - Recall: 0.8472 - Specificity: 0.9986 - F1: 0.8309 - Loss: 0.1961\n",
      "\n",
      "Batch 107/387 ━━━━━━━━━━━━━━━━━━━━ 22:26:23\n",
      "Accuracy: 0.9968 - Precision: 0.8516 - Recall: 0.8457 - Specificity: 0.9986 - F1: 0.8307 - Loss: 0.1964\n",
      "\n",
      "Batch 108/387 ━━━━━━━━━━━━━━━━━━━━ 22:27:39\n",
      "Accuracy: 0.9968 - Precision: 0.8502 - Recall: 0.8468 - Specificity: 0.9986 - F1: 0.8306 - Loss: 0.1966\n",
      "\n",
      "Batch 109/387 ━━━━━━━━━━━━━━━━━━━━ 22:29:01\n",
      "Accuracy: 0.9968 - Precision: 0.8509 - Recall: 0.8469 - Specificity: 0.9986 - F1: 0.8311 - Loss: 0.1960\n",
      "\n",
      "Batch 110/387 ━━━━━━━━━━━━━━━━━━━━ 22:30:22\n",
      "Accuracy: 0.9968 - Precision: 0.8518 - Recall: 0.8476 - Specificity: 0.9986 - F1: 0.8321 - Loss: 0.1949\n",
      "\n",
      "Batch 111/387 ━━━━━━━━━━━━━━━━━━━━ 22:31:51\n",
      "Accuracy: 0.9968 - Precision: 0.8516 - Recall: 0.8485 - Specificity: 0.9986 - F1: 0.8326 - Loss: 0.1944\n",
      "\n",
      "Batch 112/387 ━━━━━━━━━━━━━━━━━━━━ 22:33:20\n",
      "Accuracy: 0.9968 - Precision: 0.8496 - Recall: 0.8465 - Specificity: 0.9986 - F1: 0.8307 - Loss: 0.1964\n",
      "\n",
      "Batch 113/387 ━━━━━━━━━━━━━━━━━━━━ 22:34:47\n",
      "Accuracy: 0.9968 - Precision: 0.8505 - Recall: 0.8466 - Specificity: 0.9986 - F1: 0.8314 - Loss: 0.1956\n",
      "\n",
      "Batch 114/387 ━━━━━━━━━━━━━━━━━━━━ 22:36:05\n",
      "Accuracy: 0.9968 - Precision: 0.8502 - Recall: 0.8469 - Specificity: 0.9986 - F1: 0.8315 - Loss: 0.1956\n",
      "\n",
      "Batch 115/387 ━━━━━━━━━━━━━━━━━━━━ 22:37:29\n",
      "Accuracy: 0.9968 - Precision: 0.8509 - Recall: 0.8475 - Specificity: 0.9986 - F1: 0.8323 - Loss: 0.1947\n",
      "\n",
      "Batch 116/387 ━━━━━━━━━━━━━━━━━━━━ 22:38:54\n",
      "Accuracy: 0.9968 - Precision: 0.8519 - Recall: 0.8453 - Specificity: 0.9986 - F1: 0.8315 - Loss: 0.1955\n",
      "\n",
      "Batch 117/387 ━━━━━━━━━━━━━━━━━━━━ 22:40:20\n",
      "Accuracy: 0.9968 - Precision: 0.8528 - Recall: 0.8462 - Specificity: 0.9986 - F1: 0.8325 - Loss: 0.1944\n",
      "\n",
      "Batch 118/387 ━━━━━━━━━━━━━━━━━━━━ 22:41:49\n",
      "Accuracy: 0.9968 - Precision: 0.8515 - Recall: 0.8473 - Specificity: 0.9987 - F1: 0.8323 - Loss: 0.1947\n",
      "\n",
      "Batch 119/387 ━━━━━━━━━━━━━━━━━━━━ 22:43:07\n",
      "Accuracy: 0.9968 - Precision: 0.8522 - Recall: 0.8474 - Specificity: 0.9987 - F1: 0.8328 - Loss: 0.1940\n",
      "\n",
      "Batch 120/387 ━━━━━━━━━━━━━━━━━━━━ 22:44:32\n",
      "Accuracy: 0.9968 - Precision: 0.8531 - Recall: 0.8479 - Specificity: 0.9987 - F1: 0.8337 - Loss: 0.1931\n",
      "\n",
      "Batch 121/387 ━━━━━━━━━━━━━━━━━━━━ 22:46:00\n",
      "Accuracy: 0.9968 - Precision: 0.8543 - Recall: 0.8476 - Specificity: 0.9987 - F1: 0.8342 - Loss: 0.1926\n",
      "\n",
      "Batch 122/387 ━━━━━━━━━━━━━━━━━━━━ 22:47:22\n",
      "Accuracy: 0.9968 - Precision: 0.8545 - Recall: 0.8458 - Specificity: 0.9987 - F1: 0.8334 - Loss: 0.1934\n",
      "\n",
      "Batch 123/387 ━━━━━━━━━━━━━━━━━━━━ 22:48:47\n",
      "Accuracy: 0.9968 - Precision: 0.8556 - Recall: 0.8446 - Specificity: 0.9987 - F1: 0.8332 - Loss: 0.1936\n",
      "\n",
      "Batch 124/387 ━━━━━━━━━━━━━━━━━━━━ 22:50:05\n",
      "Accuracy: 0.9968 - Precision: 0.8567 - Recall: 0.8441 - Specificity: 0.9987 - F1: 0.8336 - Loss: 0.1932\n",
      "\n",
      "Batch 125/387 ━━━━━━━━━━━━━━━━━━━━ 22:51:31\n",
      "Accuracy: 0.9968 - Precision: 0.8574 - Recall: 0.8445 - Specificity: 0.9987 - F1: 0.8342 - Loss: 0.1925\n",
      "\n",
      "Batch 126/387 ━━━━━━━━━━━━━━━━━━━━ 22:52:54\n",
      "Accuracy: 0.9968 - Precision: 0.8567 - Recall: 0.8454 - Specificity: 0.9987 - F1: 0.8344 - Loss: 0.1923\n",
      "\n",
      "Batch 127/387 ━━━━━━━━━━━━━━━━━━━━ 22:54:11\n",
      "Accuracy: 0.9968 - Precision: 0.8544 - Recall: 0.8466 - Specificity: 0.9987 - F1: 0.8335 - Loss: 0.1932\n",
      "\n",
      "Batch 128/387 ━━━━━━━━━━━━━━━━━━━━ 22:55:31\n",
      "Accuracy: 0.9968 - Precision: 0.8533 - Recall: 0.8476 - Specificity: 0.9986 - F1: 0.8334 - Loss: 0.1934\n",
      "\n",
      "Batch 129/387 ━━━━━━━━━━━━━━━━━━━━ 22:56:55\n",
      "Accuracy: 0.9968 - Precision: 0.8537 - Recall: 0.8484 - Specificity: 0.9986 - F1: 0.8342 - Loss: 0.1925\n",
      "\n",
      "Batch 130/387 ━━━━━━━━━━━━━━━━━━━━ 22:58:21\n",
      "Accuracy: 0.9968 - Precision: 0.8545 - Recall: 0.8492 - Specificity: 0.9986 - F1: 0.8351 - Loss: 0.1915\n",
      "\n",
      "Batch 131/387 ━━━━━━━━━━━━━━━━━━━━ 22:59:50\n",
      "Accuracy: 0.9968 - Precision: 0.8544 - Recall: 0.8494 - Specificity: 0.9986 - F1: 0.8353 - Loss: 0.1913\n",
      "\n",
      "Batch 132/387 ━━━━━━━━━━━━━━━━━━━━ 23:01:07\n",
      "Accuracy: 0.9968 - Precision: 0.8541 - Recall: 0.8487 - Specificity: 0.9986 - F1: 0.8349 - Loss: 0.1916\n",
      "\n",
      "Batch 133/387 ━━━━━━━━━━━━━━━━━━━━ 23:02:34\n",
      "Accuracy: 0.9968 - Precision: 0.8550 - Recall: 0.8487 - Specificity: 0.9987 - F1: 0.8354 - Loss: 0.1911\n",
      "\n",
      "Batch 134/387 ━━━━━━━━━━━━━━━━━━━━ 23:04:01\n",
      "Accuracy: 0.9968 - Precision: 0.8520 - Recall: 0.8490 - Specificity: 0.9986 - F1: 0.8336 - Loss: 0.1929\n",
      "\n",
      "Batch 135/387 ━━━━━━━━━━━━━━━━━━━━ 23:05:26\n",
      "Accuracy: 0.9968 - Precision: 0.8529 - Recall: 0.8490 - Specificity: 0.9987 - F1: 0.8342 - Loss: 0.1923\n",
      "\n",
      "Batch 136/387 ━━━━━━━━━━━━━━━━━━━━ 23:06:38\n",
      "Accuracy: 0.9968 - Precision: 0.8524 - Recall: 0.8479 - Specificity: 0.9987 - F1: 0.8335 - Loss: 0.1930\n",
      "\n",
      "Batch 137/387 ━━━━━━━━━━━━━━━━━━━━ 23:08:02\n",
      "Accuracy: 0.9968 - Precision: 0.8523 - Recall: 0.8483 - Specificity: 0.9987 - F1: 0.8337 - Loss: 0.1927\n",
      "\n",
      "Batch 138/387 ━━━━━━━━━━━━━━━━━━━━ 23:09:23\n",
      "Accuracy: 0.9968 - Precision: 0.8514 - Recall: 0.8492 - Specificity: 0.9987 - F1: 0.8338 - Loss: 0.1927\n",
      "\n",
      "Batch 139/387 ━━━━━━━━━━━━━━━━━━━━ 23:10:47\n",
      "Accuracy: 0.9968 - Precision: 0.8514 - Recall: 0.8501 - Specificity: 0.9987 - F1: 0.8343 - Loss: 0.1921\n",
      "\n",
      "Batch 140/387 ━━━━━━━━━━━━━━━━━━━━ 23:12:10\n",
      "Accuracy: 0.9969 - Precision: 0.8515 - Recall: 0.8507 - Specificity: 0.9987 - F1: 0.8347 - Loss: 0.1916\n",
      "\n",
      "Batch 141/387 ━━━━━━━━━━━━━━━━━━━━ 23:13:24\n",
      "Accuracy: 0.9968 - Precision: 0.8525 - Recall: 0.8506 - Specificity: 0.9987 - F1: 0.8352 - Loss: 0.1910\n",
      "\n",
      "Batch 142/387 ━━━━━━━━━━━━━━━━━━━━ 23:14:37\n",
      "Accuracy: 0.9968 - Precision: 0.8531 - Recall: 0.8504 - Specificity: 0.9987 - F1: 0.8356 - Loss: 0.1907\n",
      "\n",
      "Batch 143/387 ━━━━━━━━━━━━━━━━━━━━ 23:15:55\n",
      "Accuracy: 0.9969 - Precision: 0.8522 - Recall: 0.8510 - Specificity: 0.9987 - F1: 0.8354 - Loss: 0.1908\n",
      "\n",
      "Batch 144/387 ━━━━━━━━━━━━━━━━━━━━ 23:17:26\n",
      "Accuracy: 0.9969 - Precision: 0.8528 - Recall: 0.8507 - Specificity: 0.9987 - F1: 0.8357 - Loss: 0.1906\n",
      "\n",
      "Batch 145/387 ━━━━━━━━━━━━━━━━━━━━ 23:18:44\n",
      "Accuracy: 0.9968 - Precision: 0.8538 - Recall: 0.8498 - Specificity: 0.9987 - F1: 0.8357 - Loss: 0.1906\n",
      "\n",
      "Batch 146/387 ━━━━━━━━━━━━━━━━━━━━ 23:20:04\n",
      "Accuracy: 0.9968 - Precision: 0.8548 - Recall: 0.8501 - Specificity: 0.9987 - F1: 0.8364 - Loss: 0.1898\n",
      "\n",
      "Batch 147/387 ━━━━━━━━━━━━━━━━━━━━ 23:21:34\n",
      "Accuracy: 0.9968 - Precision: 0.8551 - Recall: 0.8509 - Specificity: 0.9987 - F1: 0.8371 - Loss: 0.1891\n",
      "\n",
      "Batch 148/387 ━━━━━━━━━━━━━━━━━━━━ 23:22:50\n",
      "Accuracy: 0.9968 - Precision: 0.8560 - Recall: 0.8498 - Specificity: 0.9987 - F1: 0.8369 - Loss: 0.1893\n",
      "\n",
      "Batch 149/387 ━━━━━━━━━━━━━━━━━━━━ 23:24:17\n",
      "Accuracy: 0.9968 - Precision: 0.8560 - Recall: 0.8496 - Specificity: 0.9987 - F1: 0.8369 - Loss: 0.1893\n",
      "\n",
      "Batch 150/387 ━━━━━━━━━━━━━━━━━━━━ 23:25:44\n",
      "Accuracy: 0.9969 - Precision: 0.8568 - Recall: 0.8501 - Specificity: 0.9987 - F1: 0.8377 - Loss: 0.1885\n",
      "\n",
      "Batch 151/387 ━━━━━━━━━━━━━━━━━━━━ 23:27:13\n",
      "Accuracy: 0.9969 - Precision: 0.8559 - Recall: 0.8488 - Specificity: 0.9987 - F1: 0.8366 - Loss: 0.1895\n",
      "\n",
      "Batch 152/387 ━━━━━━━━━━━━━━━━━━━━ 23:28:45\n",
      "Accuracy: 0.9969 - Precision: 0.8559 - Recall: 0.8497 - Specificity: 0.9987 - F1: 0.8372 - Loss: 0.1889\n",
      "\n",
      "Batch 153/387 ━━━━━━━━━━━━━━━━━━━━ 23:30:21\n",
      "Accuracy: 0.9969 - Precision: 0.8560 - Recall: 0.8501 - Specificity: 0.9987 - F1: 0.8376 - Loss: 0.1884\n",
      "\n",
      "Batch 154/387 ━━━━━━━━━━━━━━━━━━━━ 23:31:42\n",
      "Accuracy: 0.9969 - Precision: 0.8561 - Recall: 0.8508 - Specificity: 0.9987 - F1: 0.8380 - Loss: 0.1879\n",
      "\n",
      "Batch 155/387 ━━━━━━━━━━━━━━━━━━━━ 23:33:07\n",
      "Accuracy: 0.9969 - Precision: 0.8561 - Recall: 0.8516 - Specificity: 0.9987 - F1: 0.8385 - Loss: 0.1874\n",
      "\n",
      "Batch 156/387 ━━━━━━━━━━━━━━━━━━━━ 23:34:31\n",
      "Accuracy: 0.9969 - Precision: 0.8562 - Recall: 0.8513 - Specificity: 0.9987 - F1: 0.8385 - Loss: 0.1874\n",
      "\n",
      "Batch 157/387 ━━━━━━━━━━━━━━━━━━━━ 23:35:51\n",
      "Accuracy: 0.9969 - Precision: 0.8557 - Recall: 0.8522 - Specificity: 0.9987 - F1: 0.8387 - Loss: 0.1871\n",
      "\n",
      "Batch 158/387 ━━━━━━━━━━━━━━━━━━━━ 23:37:08\n",
      "Accuracy: 0.9969 - Precision: 0.8547 - Recall: 0.8524 - Specificity: 0.9987 - F1: 0.8384 - Loss: 0.1875\n",
      "\n",
      "Batch 159/387 ━━━━━━━━━━━━━━━━━━━━ 23:38:33\n",
      "Accuracy: 0.9969 - Precision: 0.8542 - Recall: 0.8528 - Specificity: 0.9987 - F1: 0.8383 - Loss: 0.1876\n",
      "\n",
      "Batch 160/387 ━━━━━━━━━━━━━━━━━━━━ 23:39:58\n",
      "Accuracy: 0.9969 - Precision: 0.8540 - Recall: 0.8535 - Specificity: 0.9987 - F1: 0.8387 - Loss: 0.1872\n",
      "\n",
      "Batch 161/387 ━━━━━━━━━━━━━━━━━━━━ 23:41:21\n",
      "Accuracy: 0.9969 - Precision: 0.8546 - Recall: 0.8540 - Specificity: 0.9987 - F1: 0.8393 - Loss: 0.1865\n",
      "\n",
      "Batch 162/387 ━━━━━━━━━━━━━━━━━━━━ 23:42:38\n",
      "Accuracy: 0.9969 - Precision: 0.8547 - Recall: 0.8540 - Specificity: 0.9987 - F1: 0.8394 - Loss: 0.1863\n",
      "\n",
      "Batch 163/387 ━━━━━━━━━━━━━━━━━━━━ 23:43:48\n",
      "Accuracy: 0.9969 - Precision: 0.8554 - Recall: 0.8540 - Specificity: 0.9987 - F1: 0.8399 - Loss: 0.1858\n",
      "\n",
      "Batch 164/387 ━━━━━━━━━━━━━━━━━━━━ 23:45:00\n",
      "Accuracy: 0.9969 - Precision: 0.8551 - Recall: 0.8545 - Specificity: 0.9987 - F1: 0.8400 - Loss: 0.1856\n",
      "\n",
      "Batch 165/387 ━━━━━━━━━━━━━━━━━━━━ 23:46:22\n",
      "Accuracy: 0.9969 - Precision: 0.8552 - Recall: 0.8537 - Specificity: 0.9987 - F1: 0.8397 - Loss: 0.1859\n",
      "\n",
      "Batch 166/387 ━━━━━━━━━━━━━━━━━━━━ 23:47:32\n",
      "Accuracy: 0.9969 - Precision: 0.8558 - Recall: 0.8524 - Specificity: 0.9987 - F1: 0.8393 - Loss: 0.1864\n",
      "\n",
      "Batch 167/387 ━━━━━━━━━━━━━━━━━━━━ 23:48:56\n",
      "Accuracy: 0.9969 - Precision: 0.8566 - Recall: 0.8526 - Specificity: 0.9987 - F1: 0.8398 - Loss: 0.1858\n",
      "\n",
      "Batch 168/387 ━━━━━━━━━━━━━━━━━━━━ 23:50:20\n",
      "Accuracy: 0.9969 - Precision: 0.8553 - Recall: 0.8533 - Specificity: 0.9987 - F1: 0.8394 - Loss: 0.1861\n",
      "\n",
      "Batch 169/387 ━━━━━━━━━━━━━━━━━━━━ 23:51:45\n",
      "Accuracy: 0.9969 - Precision: 0.8560 - Recall: 0.8531 - Specificity: 0.9987 - F1: 0.8397 - Loss: 0.1858\n",
      "\n",
      "Batch 170/387 ━━━━━━━━━━━━━━━━━━━━ 23:52:52\n",
      "Accuracy: 0.9970 - Precision: 0.8561 - Recall: 0.8535 - Specificity: 0.9987 - F1: 0.8400 - Loss: 0.1855\n",
      "\n",
      "Batch 171/387 ━━━━━━━━━━━━━━━━━━━━ 23:54:10\n",
      "Accuracy: 0.9969 - Precision: 0.8567 - Recall: 0.8528 - Specificity: 0.9987 - F1: 0.8400 - Loss: 0.1855\n",
      "\n",
      "Batch 172/387 ━━━━━━━━━━━━━━━━━━━━ 23:55:25\n",
      "Accuracy: 0.9970 - Precision: 0.8571 - Recall: 0.8534 - Specificity: 0.9987 - F1: 0.8406 - Loss: 0.1849\n",
      "\n",
      "Batch 173/387 ━━━━━━━━━━━━━━━━━━━━ 23:56:38\n",
      "Accuracy: 0.9969 - Precision: 0.8576 - Recall: 0.8533 - Specificity: 0.9987 - F1: 0.8408 - Loss: 0.1846\n",
      "\n",
      "Batch 174/387 ━━━━━━━━━━━━━━━━━━━━ 23:57:50\n",
      "Accuracy: 0.9970 - Precision: 0.8577 - Recall: 0.8537 - Specificity: 0.9987 - F1: 0.8412 - Loss: 0.1842\n",
      "\n",
      "Batch 175/387 ━━━━━━━━━━━━━━━━━━━━ 23:59:07\n",
      "Accuracy: 0.9970 - Precision: 0.8579 - Recall: 0.8541 - Specificity: 0.9987 - F1: 0.8416 - Loss: 0.1837\n",
      "\n",
      "Batch 176/387 ━━━━━━━━━━━━━━━━━━━━ 00:00:18\n",
      "Accuracy: 0.9970 - Precision: 0.8585 - Recall: 0.8544 - Specificity: 0.9987 - F1: 0.8421 - Loss: 0.1832\n",
      "\n",
      "Batch 177/387 ━━━━━━━━━━━━━━━━━━━━ 00:01:26\n",
      "Accuracy: 0.9970 - Precision: 0.8591 - Recall: 0.8544 - Specificity: 0.9987 - F1: 0.8424 - Loss: 0.1827\n",
      "\n",
      "Batch 178/387 ━━━━━━━━━━━━━━━━━━━━ 00:02:46\n",
      "Accuracy: 0.9970 - Precision: 0.8592 - Recall: 0.8546 - Specificity: 0.9987 - F1: 0.8427 - Loss: 0.1824\n",
      "\n",
      "Batch 179/387 ━━━━━━━━━━━━━━━━━━━━ 00:04:08\n",
      "Accuracy: 0.9970 - Precision: 0.8589 - Recall: 0.8552 - Specificity: 0.9987 - F1: 0.8429 - Loss: 0.1822\n",
      "\n",
      "Batch 180/387 ━━━━━━━━━━━━━━━━━━━━ 00:05:28\n",
      "Accuracy: 0.9970 - Precision: 0.8591 - Recall: 0.8552 - Specificity: 0.9987 - F1: 0.8431 - Loss: 0.1820\n",
      "\n",
      "Batch 181/387 ━━━━━━━━━━━━━━━━━━━━ 00:06:41\n",
      "Accuracy: 0.9970 - Precision: 0.8595 - Recall: 0.8558 - Specificity: 0.9987 - F1: 0.8436 - Loss: 0.1814\n",
      "\n",
      "Batch 182/387 ━━━━━━━━━━━━━━━━━━━━ 00:07:51\n",
      "Accuracy: 0.9970 - Precision: 0.8579 - Recall: 0.8557 - Specificity: 0.9987 - F1: 0.8427 - Loss: 0.1824\n",
      "\n",
      "Batch 183/387 ━━━━━━━━━━━━━━━━━━━━ 00:09:16\n",
      "Accuracy: 0.9969 - Precision: 0.8561 - Recall: 0.8563 - Specificity: 0.9987 - F1: 0.8418 - Loss: 0.1834\n",
      "\n",
      "Batch 184/387 ━━━━━━━━━━━━━━━━━━━━ 00:10:36\n",
      "Accuracy: 0.9970 - Precision: 0.8564 - Recall: 0.8569 - Specificity: 0.9987 - F1: 0.8424 - Loss: 0.1828\n",
      "\n",
      "Batch 185/387 ━━━━━━━━━━━━━━━━━━━━ 00:11:48\n",
      "Accuracy: 0.9969 - Precision: 0.8568 - Recall: 0.8560 - Specificity: 0.9987 - F1: 0.8421 - Loss: 0.1831\n",
      "\n",
      "Batch 186/387 ━━━━━━━━━━━━━━━━━━━━ 00:13:07\n",
      "Accuracy: 0.9969 - Precision: 0.8574 - Recall: 0.8565 - Specificity: 0.9987 - F1: 0.8427 - Loss: 0.1824\n",
      "\n",
      "Batch 187/387 ━━━━━━━━━━━━━━━━━━━━ 00:14:25\n",
      "Accuracy: 0.9970 - Precision: 0.8578 - Recall: 0.8571 - Specificity: 0.9987 - F1: 0.8433 - Loss: 0.1817\n",
      "\n",
      "Batch 188/387 ━━━━━━━━━━━━━━━━━━━━ 00:15:49\n",
      "Accuracy: 0.9970 - Precision: 0.8580 - Recall: 0.8576 - Specificity: 0.9987 - F1: 0.8437 - Loss: 0.1812\n",
      "\n",
      "Batch 189/387 ━━━━━━━━━━━━━━━━━━━━ 00:17:05\n",
      "Accuracy: 0.9970 - Precision: 0.8546 - Recall: 0.8580 - Specificity: 0.9987 - F1: 0.8411 - Loss: 0.1840\n",
      "\n",
      "Batch 190/387 ━━━━━━━━━━━━━━━━━━━━ 00:18:29\n",
      "Accuracy: 0.9970 - Precision: 0.8537 - Recall: 0.8585 - Specificity: 0.9987 - F1: 0.8409 - Loss: 0.1841\n",
      "\n",
      "Batch 191/387 ━━━━━━━━━━━━━━━━━━━━ 00:19:55\n",
      "Accuracy: 0.9970 - Precision: 0.8542 - Recall: 0.8583 - Specificity: 0.9987 - F1: 0.8411 - Loss: 0.1839\n",
      "\n",
      "Batch 192/387 ━━━━━━━━━━━━━━━━━━━━ 00:21:25\n",
      "Accuracy: 0.9970 - Precision: 0.8548 - Recall: 0.8589 - Specificity: 0.9987 - F1: 0.8417 - Loss: 0.1832\n",
      "\n",
      "Batch 193/387 ━━━━━━━━━━━━━━━━━━━━ 00:22:41\n",
      "Accuracy: 0.9970 - Precision: 0.8555 - Recall: 0.8587 - Specificity: 0.9987 - F1: 0.8420 - Loss: 0.1828\n",
      "\n",
      "Batch 194/387 ━━━━━━━━━━━━━━━━━━━━ 00:24:07\n",
      "Accuracy: 0.9970 - Precision: 0.8562 - Recall: 0.8578 - Specificity: 0.9987 - F1: 0.8418 - Loss: 0.1830\n",
      "\n",
      "Batch 195/387 ━━━━━━━━━━━━━━━━━━━━ 00:25:30\n",
      "Accuracy: 0.9970 - Precision: 0.8551 - Recall: 0.8583 - Specificity: 0.9987 - F1: 0.8415 - Loss: 0.1834\n",
      "\n",
      "Batch 196/387 ━━━━━━━━━━━━━━━━━━━━ 00:26:54\n",
      "Accuracy: 0.9970 - Precision: 0.8557 - Recall: 0.8573 - Specificity: 0.9987 - F1: 0.8412 - Loss: 0.1837\n",
      "\n",
      "Batch 197/387 ━━━━━━━━━━━━━━━━━━━━ 00:28:08\n",
      "Accuracy: 0.9970 - Precision: 0.8562 - Recall: 0.8567 - Specificity: 0.9987 - F1: 0.8412 - Loss: 0.1837\n",
      "\n",
      "Batch 198/387 ━━━━━━━━━━━━━━━━━━━━ 00:29:20\n",
      "Accuracy: 0.9970 - Precision: 0.8567 - Recall: 0.8566 - Specificity: 0.9987 - F1: 0.8414 - Loss: 0.1835\n",
      "\n",
      "Batch 199/387 ━━━━━━━━━━━━━━━━━━━━ 00:30:35\n",
      "Accuracy: 0.9970 - Precision: 0.8570 - Recall: 0.8561 - Specificity: 0.9987 - F1: 0.8414 - Loss: 0.1835\n",
      "\n",
      "Batch 200/387 ━━━━━━━━━━━━━━━━━━━━ 00:31:58\n",
      "Accuracy: 0.9970 - Precision: 0.8573 - Recall: 0.8558 - Specificity: 0.9987 - F1: 0.8414 - Loss: 0.1834\n",
      "\n",
      "Batch 201/387 ━━━━━━━━━━━━━━━━━━━━ 00:33:26\n",
      "Accuracy: 0.9970 - Precision: 0.8562 - Recall: 0.8558 - Specificity: 0.9987 - F1: 0.8408 - Loss: 0.1840\n",
      "\n",
      "Batch 202/387 ━━━━━━━━━━━━━━━━━━━━ 00:34:48\n",
      "Accuracy: 0.9970 - Precision: 0.8569 - Recall: 0.8557 - Specificity: 0.9987 - F1: 0.8412 - Loss: 0.1837\n",
      "\n",
      "Batch 203/387 ━━━━━━━━━━━━━━━━━━━━ 00:36:13\n",
      "Accuracy: 0.9970 - Precision: 0.8567 - Recall: 0.8562 - Specificity: 0.9987 - F1: 0.8414 - Loss: 0.1834\n",
      "\n",
      "Batch 204/387 ━━━━━━━━━━━━━━━━━━━━ 00:37:33\n",
      "Accuracy: 0.9970 - Precision: 0.8554 - Recall: 0.8568 - Specificity: 0.9987 - F1: 0.8409 - Loss: 0.1840\n",
      "\n",
      "Batch 205/387 ━━━━━━━━━━━━━━━━━━━━ 00:38:58\n",
      "Accuracy: 0.9970 - Precision: 0.8553 - Recall: 0.8572 - Specificity: 0.9987 - F1: 0.8411 - Loss: 0.1837\n",
      "\n",
      "Batch 206/387 ━━━━━━━━━━━━━━━━━━━━ 00:40:20\n",
      "Accuracy: 0.9970 - Precision: 0.8547 - Recall: 0.8576 - Specificity: 0.9987 - F1: 0.8410 - Loss: 0.1838\n",
      "\n",
      "Batch 207/387 ━━━━━━━━━━━━━━━━━━━━ 00:41:38\n",
      "Accuracy: 0.9970 - Precision: 0.8546 - Recall: 0.8582 - Specificity: 0.9987 - F1: 0.8413 - Loss: 0.1835\n",
      "\n",
      "Batch 208/387 ━━━━━━━━━━━━━━━━━━━━ 00:42:52\n",
      "Accuracy: 0.9970 - Precision: 0.8552 - Recall: 0.8574 - Specificity: 0.9987 - F1: 0.8411 - Loss: 0.1838\n",
      "\n",
      "Batch 209/387 ━━━━━━━━━━━━━━━━━━━━ 00:44:10\n",
      "Accuracy: 0.9970 - Precision: 0.8555 - Recall: 0.8577 - Specificity: 0.9987 - F1: 0.8415 - Loss: 0.1833\n",
      "\n",
      "Batch 210/387 ━━━━━━━━━━━━━━━━━━━━ 00:45:36\n",
      "Accuracy: 0.9970 - Precision: 0.8561 - Recall: 0.8564 - Specificity: 0.9987 - F1: 0.8410 - Loss: 0.1840\n",
      "\n",
      "Batch 211/387 ━━━━━━━━━━━━━━━━━━━━ 00:46:45\n",
      "Accuracy: 0.9970 - Precision: 0.8567 - Recall: 0.8557 - Specificity: 0.9987 - F1: 0.8409 - Loss: 0.1840\n",
      "\n",
      "Batch 212/387 ━━━━━━━━━━━━━━━━━━━━ 00:48:04\n",
      "Accuracy: 0.9969 - Precision: 0.8572 - Recall: 0.8534 - Specificity: 0.9987 - F1: 0.8394 - Loss: 0.1858\n",
      "\n",
      "Batch 213/387 ━━━━━━━━━━━━━━━━━━━━ 00:49:24\n",
      "Accuracy: 0.9969 - Precision: 0.8572 - Recall: 0.8539 - Specificity: 0.9987 - F1: 0.8397 - Loss: 0.1854\n",
      "\n",
      "Batch 214/387 ━━━━━━━━━━━━━━━━━━━━ 00:50:40\n",
      "Accuracy: 0.9969 - Precision: 0.8578 - Recall: 0.8529 - Specificity: 0.9987 - F1: 0.8394 - Loss: 0.1858\n",
      "\n",
      "Batch 215/387 ━━━━━━━━━━━━━━━━━━━━ 00:51:55\n",
      "Accuracy: 0.9969 - Precision: 0.8582 - Recall: 0.8530 - Specificity: 0.9987 - F1: 0.8397 - Loss: 0.1854\n",
      "\n",
      "Batch 216/387 ━━━━━━━━━━━━━━━━━━━━ 00:53:13\n",
      "Accuracy: 0.9969 - Precision: 0.8576 - Recall: 0.8536 - Specificity: 0.9987 - F1: 0.8397 - Loss: 0.1854\n",
      "\n",
      "Batch 217/387 ━━━━━━━━━━━━━━━━━━━━ 00:54:27\n",
      "Accuracy: 0.9969 - Precision: 0.8579 - Recall: 0.8540 - Specificity: 0.9987 - F1: 0.8402 - Loss: 0.1850\n",
      "\n",
      "Batch 218/387 ━━━━━━━━━━━━━━━━━━━━ 00:55:43\n",
      "Accuracy: 0.9969 - Precision: 0.8560 - Recall: 0.8544 - Specificity: 0.9987 - F1: 0.8391 - Loss: 0.1861\n",
      "\n",
      "Batch 219/387 ━━━━━━━━━━━━━━━━━━━━ 00:56:58\n",
      "Accuracy: 0.9969 - Precision: 0.8561 - Recall: 0.8550 - Specificity: 0.9987 - F1: 0.8395 - Loss: 0.1856\n",
      "\n",
      "Batch 220/387 ━━━━━━━━━━━━━━━━━━━━ 00:58:16\n",
      "Accuracy: 0.9969 - Precision: 0.8563 - Recall: 0.8554 - Specificity: 0.9987 - F1: 0.8399 - Loss: 0.1852\n",
      "\n",
      "Batch 221/387 ━━━━━━━━━━━━━━━━━━━━ 00:59:37\n",
      "Accuracy: 0.9969 - Precision: 0.8569 - Recall: 0.8555 - Specificity: 0.9987 - F1: 0.8403 - Loss: 0.1848\n",
      "\n",
      "Batch 222/387 ━━━━━━━━━━━━━━━━━━━━ 01:00:52\n",
      "Accuracy: 0.9969 - Precision: 0.8573 - Recall: 0.8558 - Specificity: 0.9987 - F1: 0.8407 - Loss: 0.1843\n",
      "\n",
      "Batch 223/387 ━━━━━━━━━━━━━━━━━━━━ 01:02:15\n",
      "Accuracy: 0.9969 - Precision: 0.8567 - Recall: 0.8551 - Specificity: 0.9987 - F1: 0.8401 - Loss: 0.1849\n",
      "\n",
      "Batch 224/387 ━━━━━━━━━━━━━━━━━━━━ 01:03:37\n",
      "Accuracy: 0.9969 - Precision: 0.8547 - Recall: 0.8543 - Specificity: 0.9987 - F1: 0.8386 - Loss: 0.1866\n",
      "\n",
      "Batch 225/387 ━━━━━━━━━━━━━━━━━━━━ 01:04:58\n",
      "Accuracy: 0.9969 - Precision: 0.8553 - Recall: 0.8546 - Specificity: 0.9987 - F1: 0.8391 - Loss: 0.1861\n",
      "\n",
      "Batch 226/387 ━━━━━━━━━━━━━━━━━━━━ 01:06:19\n",
      "Accuracy: 0.9969 - Precision: 0.8558 - Recall: 0.8544 - Specificity: 0.9987 - F1: 0.8394 - Loss: 0.1858\n",
      "\n",
      "Batch 227/387 ━━━━━━━━━━━━━━━━━━━━ 01:07:41\n",
      "Accuracy: 0.9969 - Precision: 0.8560 - Recall: 0.8547 - Specificity: 0.9987 - F1: 0.8397 - Loss: 0.1855\n",
      "\n",
      "Batch 228/387 ━━━━━━━━━━━━━━━━━━━━ 01:08:58\n",
      "Accuracy: 0.9969 - Precision: 0.8562 - Recall: 0.8552 - Specificity: 0.9987 - F1: 0.8400 - Loss: 0.1851\n",
      "\n",
      "Batch 229/387 ━━━━━━━━━━━━━━━━━━━━ 01:10:14\n",
      "Accuracy: 0.9969 - Precision: 0.8552 - Recall: 0.8556 - Specificity: 0.9986 - F1: 0.8397 - Loss: 0.1854\n",
      "\n",
      "Batch 230/387 ━━━━━━━━━━━━━━━━━━━━ 01:11:33\n",
      "Accuracy: 0.9969 - Precision: 0.8550 - Recall: 0.8561 - Specificity: 0.9986 - F1: 0.8399 - Loss: 0.1851\n",
      "\n",
      "Batch 231/387 ━━━━━━━━━━━━━━━━━━━━ 01:12:53\n",
      "Accuracy: 0.9969 - Precision: 0.8554 - Recall: 0.8564 - Specificity: 0.9986 - F1: 0.8403 - Loss: 0.1847\n",
      "\n",
      "Batch 232/387 ━━━━━━━━━━━━━━━━━━━━ 01:14:09\n",
      "Accuracy: 0.9969 - Precision: 0.8558 - Recall: 0.8567 - Specificity: 0.9987 - F1: 0.8408 - Loss: 0.1842\n",
      "\n",
      "Batch 233/387 ━━━━━━━━━━━━━━━━━━━━ 01:15:23\n",
      "Accuracy: 0.9969 - Precision: 0.8535 - Recall: 0.8556 - Specificity: 0.9986 - F1: 0.8389 - Loss: 0.1860\n",
      "\n",
      "Batch 234/387 ━━━━━━━━━━━━━━━━━━━━ 01:16:40\n",
      "Accuracy: 0.9969 - Precision: 0.8527 - Recall: 0.8554 - Specificity: 0.9986 - F1: 0.8384 - Loss: 0.1865\n",
      "\n",
      "Batch 235/387 ━━━━━━━━━━━━━━━━━━━━ 01:18:12\n",
      "Accuracy: 0.9969 - Precision: 0.8507 - Recall: 0.8547 - Specificity: 0.9986 - F1: 0.8370 - Loss: 0.1880\n",
      "\n",
      "Batch 236/387 ━━━━━━━━━━━━━━━━━━━━ 01:19:37\n",
      "Accuracy: 0.9969 - Precision: 0.8504 - Recall: 0.8551 - Specificity: 0.9986 - F1: 0.8371 - Loss: 0.1879\n",
      "\n",
      "Batch 237/387 ━━━━━━━━━━━━━━━━━━━━ 01:20:49\n",
      "Accuracy: 0.9969 - Precision: 0.8510 - Recall: 0.8553 - Specificity: 0.9986 - F1: 0.8375 - Loss: 0.1874\n",
      "\n",
      "Batch 238/387 ━━━━━━━━━━━━━━━━━━━━ 01:22:13\n",
      "Accuracy: 0.9969 - Precision: 0.8510 - Recall: 0.8558 - Specificity: 0.9986 - F1: 0.8378 - Loss: 0.1871\n",
      "\n",
      "Batch 239/387 ━━━━━━━━━━━━━━━━━━━━ 01:23:36\n",
      "Accuracy: 0.9969 - Precision: 0.8515 - Recall: 0.8558 - Specificity: 0.9986 - F1: 0.8381 - Loss: 0.1867\n",
      "\n",
      "Batch 240/387 ━━━━━━━━━━━━━━━━━━━━ 01:24:59\n",
      "Accuracy: 0.9969 - Precision: 0.8521 - Recall: 0.8555 - Specificity: 0.9986 - F1: 0.8383 - Loss: 0.1865\n",
      "\n",
      "Batch 241/387 ━━━━━━━━━━━━━━━━━━━━ 01:26:18\n",
      "Accuracy: 0.9969 - Precision: 0.8527 - Recall: 0.8543 - Specificity: 0.9986 - F1: 0.8378 - Loss: 0.1871\n",
      "\n",
      "Batch 242/387 ━━━━━━━━━━━━━━━━━━━━ 01:27:37\n",
      "Accuracy: 0.9969 - Precision: 0.8533 - Recall: 0.8539 - Specificity: 0.9987 - F1: 0.8379 - Loss: 0.1870\n",
      "\n",
      "Batch 243/387 ━━━━━━━━━━━━━━━━━━━━ 01:28:58\n",
      "Accuracy: 0.9969 - Precision: 0.8534 - Recall: 0.8535 - Specificity: 0.9987 - F1: 0.8378 - Loss: 0.1871\n",
      "\n",
      "Batch 244/387 ━━━━━━━━━━━━━━━━━━━━ 01:30:15\n",
      "Accuracy: 0.9969 - Precision: 0.8538 - Recall: 0.8530 - Specificity: 0.9987 - F1: 0.8377 - Loss: 0.1871\n",
      "\n",
      "Batch 245/387 ━━━━━━━━━━━━━━━━━━━━ 01:31:25\n",
      "Accuracy: 0.9969 - Precision: 0.8544 - Recall: 0.8526 - Specificity: 0.9987 - F1: 0.8378 - Loss: 0.1871\n",
      "\n",
      "Batch 246/387 ━━━━━━━━━━━━━━━━━━━━ 01:32:48\n",
      "Accuracy: 0.9969 - Precision: 0.8548 - Recall: 0.8528 - Specificity: 0.9987 - F1: 0.8382 - Loss: 0.1867\n",
      "\n",
      "Batch 247/387 ━━━━━━━━━━━━━━━━━━━━ 01:34:05\n",
      "Accuracy: 0.9969 - Precision: 0.8551 - Recall: 0.8510 - Specificity: 0.9987 - F1: 0.8371 - Loss: 0.1880\n",
      "\n",
      "Batch 248/387 ━━━━━━━━━━━━━━━━━━━━ 01:35:20\n",
      "Accuracy: 0.9968 - Precision: 0.8531 - Recall: 0.8511 - Specificity: 0.9987 - F1: 0.8358 - Loss: 0.1894\n",
      "\n",
      "Batch 249/387 ━━━━━━━━━━━━━━━━━━━━ 01:36:34\n",
      "Accuracy: 0.9969 - Precision: 0.8532 - Recall: 0.8517 - Specificity: 0.9987 - F1: 0.8362 - Loss: 0.1889\n",
      "\n",
      "Batch 250/387 ━━━━━━━━━━━━━━━━━━━━ 01:37:48\n",
      "Accuracy: 0.9968 - Precision: 0.8526 - Recall: 0.8507 - Specificity: 0.9987 - F1: 0.8354 - Loss: 0.1898\n",
      "\n",
      "Batch 251/387 ━━━━━━━━━━━━━━━━━━━━ 01:39:07\n",
      "Accuracy: 0.9968 - Precision: 0.8529 - Recall: 0.8509 - Specificity: 0.9987 - F1: 0.8357 - Loss: 0.1894\n",
      "\n",
      "Batch 252/387 ━━━━━━━━━━━━━━━━━━━━ 01:40:21\n",
      "Accuracy: 0.9968 - Precision: 0.8531 - Recall: 0.8509 - Specificity: 0.9986 - F1: 0.8359 - Loss: 0.1893\n",
      "\n",
      "Batch 253/387 ━━━━━━━━━━━━━━━━━━━━ 01:41:30\n",
      "Accuracy: 0.9968 - Precision: 0.8531 - Recall: 0.8510 - Specificity: 0.9986 - F1: 0.8360 - Loss: 0.1892\n",
      "\n",
      "Batch 254/387 ━━━━━━━━━━━━━━━━━━━━ 01:42:54\n",
      "Accuracy: 0.9968 - Precision: 0.8532 - Recall: 0.8513 - Specificity: 0.9986 - F1: 0.8363 - Loss: 0.1889\n",
      "\n",
      "Batch 255/387 ━━━━━━━━━━━━━━━━━━━━ 01:44:06\n",
      "Accuracy: 0.9968 - Precision: 0.8531 - Recall: 0.8511 - Specificity: 0.9986 - F1: 0.8362 - Loss: 0.1890\n",
      "\n",
      "Batch 256/387 ━━━━━━━━━━━━━━━━━━━━ 01:45:23\n",
      "Accuracy: 0.9968 - Precision: 0.8530 - Recall: 0.8517 - Specificity: 0.9986 - F1: 0.8365 - Loss: 0.1887\n",
      "\n",
      "Batch 257/387 ━━━━━━━━━━━━━━━━━━━━ 01:46:50\n",
      "Accuracy: 0.9968 - Precision: 0.8534 - Recall: 0.8517 - Specificity: 0.9986 - F1: 0.8368 - Loss: 0.1884\n",
      "\n",
      "Batch 258/387 ━━━━━━━━━━━━━━━━━━━━ 01:48:11\n",
      "Accuracy: 0.9968 - Precision: 0.8530 - Recall: 0.8518 - Specificity: 0.9986 - F1: 0.8366 - Loss: 0.1885\n",
      "\n",
      "Batch 259/387 ━━━━━━━━━━━━━━━━━━━━ 01:49:31\n",
      "Accuracy: 0.9968 - Precision: 0.8523 - Recall: 0.8523 - Specificity: 0.9986 - F1: 0.8365 - Loss: 0.1887\n",
      "\n",
      "Batch 260/387 ━━━━━━━━━━━━━━━━━━━━ 01:50:50\n",
      "Accuracy: 0.9968 - Precision: 0.8522 - Recall: 0.8527 - Specificity: 0.9986 - F1: 0.8367 - Loss: 0.1885\n",
      "\n",
      "Batch 261/387 ━━━━━━━━━━━━━━━━━━━━ 01:52:07\n",
      "Accuracy: 0.9968 - Precision: 0.8525 - Recall: 0.8528 - Specificity: 0.9986 - F1: 0.8369 - Loss: 0.1882\n",
      "\n",
      "Batch 262/387 ━━━━━━━━━━━━━━━━━━━━ 01:53:21\n",
      "Accuracy: 0.9968 - Precision: 0.8523 - Recall: 0.8532 - Specificity: 0.9986 - F1: 0.8371 - Loss: 0.1880\n",
      "\n",
      "Batch 263/387 ━━━━━━━━━━━━━━━━━━━━ 01:54:52\n",
      "Accuracy: 0.9968 - Precision: 0.8524 - Recall: 0.8537 - Specificity: 0.9986 - F1: 0.8374 - Loss: 0.1876\n",
      "\n",
      "Batch 264/387 ━━━━━━━━━━━━━━━━━━━━ 01:56:09\n",
      "Accuracy: 0.9968 - Precision: 0.8521 - Recall: 0.8541 - Specificity: 0.9986 - F1: 0.8375 - Loss: 0.1876\n",
      "\n",
      "Batch 265/387 ━━━━━━━━━━━━━━━━━━━━ 01:57:23\n",
      "Accuracy: 0.9968 - Precision: 0.8524 - Recall: 0.8543 - Specificity: 0.9986 - F1: 0.8378 - Loss: 0.1872\n",
      "\n",
      "Batch 266/387 ━━━━━━━━━━━━━━━━━━━━ 01:58:45\n",
      "Accuracy: 0.9968 - Precision: 0.8528 - Recall: 0.8541 - Specificity: 0.9986 - F1: 0.8380 - Loss: 0.1871\n",
      "\n",
      "Batch 267/387 ━━━━━━━━━━━━━━━━━━━━ 01:59:59\n",
      "Accuracy: 0.9968 - Precision: 0.8525 - Recall: 0.8535 - Specificity: 0.9986 - F1: 0.8375 - Loss: 0.1875\n",
      "\n",
      "Batch 268/387 ━━━━━━━━━━━━━━━━━━━━ 02:01:14\n",
      "Accuracy: 0.9968 - Precision: 0.8530 - Recall: 0.8533 - Specificity: 0.9986 - F1: 0.8377 - Loss: 0.1874\n",
      "\n",
      "Batch 269/387 ━━━━━━━━━━━━━━━━━━━━ 02:02:20\n",
      "Accuracy: 0.9968 - Precision: 0.8534 - Recall: 0.8526 - Specificity: 0.9986 - F1: 0.8375 - Loss: 0.1875\n",
      "\n",
      "Batch 270/387 ━━━━━━━━━━━━━━━━━━━━ 02:03:42\n",
      "Accuracy: 0.9968 - Precision: 0.8521 - Recall: 0.8526 - Specificity: 0.9986 - F1: 0.8368 - Loss: 0.1883\n",
      "\n",
      "Batch 271/387 ━━━━━━━━━━━━━━━━━━━━ 02:05:06\n",
      "Accuracy: 0.9968 - Precision: 0.8527 - Recall: 0.8524 - Specificity: 0.9986 - F1: 0.8370 - Loss: 0.1881\n",
      "\n",
      "Batch 272/387 ━━━━━━━━━━━━━━━━━━━━ 02:06:27\n",
      "Accuracy: 0.9968 - Precision: 0.8532 - Recall: 0.8523 - Specificity: 0.9986 - F1: 0.8372 - Loss: 0.1878\n",
      "\n",
      "Batch 273/387 ━━━━━━━━━━━━━━━━━━━━ 02:07:34\n",
      "Accuracy: 0.9968 - Precision: 0.8536 - Recall: 0.8521 - Specificity: 0.9986 - F1: 0.8373 - Loss: 0.1877\n",
      "\n",
      "Batch 274/387 ━━━━━━━━━━━━━━━━━━━━ 02:08:50\n",
      "Accuracy: 0.9968 - Precision: 0.8522 - Recall: 0.8526 - Specificity: 0.9986 - F1: 0.8366 - Loss: 0.1884\n",
      "\n",
      "Batch 275/387 ━━━━━━━━━━━━━━━━━━━━ 02:10:17\n",
      "Accuracy: 0.9968 - Precision: 0.8523 - Recall: 0.8527 - Specificity: 0.9986 - F1: 0.8367 - Loss: 0.1883\n",
      "\n",
      "Batch 276/387 ━━━━━━━━━━━━━━━━━━━━ 02:11:33\n",
      "Accuracy: 0.9968 - Precision: 0.8528 - Recall: 0.8523 - Specificity: 0.9986 - F1: 0.8368 - Loss: 0.1883\n",
      "\n",
      "Batch 277/387 ━━━━━━━━━━━━━━━━━━━━ 02:13:01\n",
      "Accuracy: 0.9968 - Precision: 0.8526 - Recall: 0.8515 - Specificity: 0.9986 - F1: 0.8363 - Loss: 0.1887\n",
      "\n",
      "Batch 278/387 ━━━━━━━━━━━━━━━━━━━━ 02:14:12\n",
      "Accuracy: 0.9968 - Precision: 0.8521 - Recall: 0.8519 - Specificity: 0.9986 - F1: 0.8362 - Loss: 0.1888\n",
      "\n",
      "Batch 279/387 ━━━━━━━━━━━━━━━━━━━━ 02:15:32\n",
      "Accuracy: 0.9968 - Precision: 0.8525 - Recall: 0.8521 - Specificity: 0.9986 - F1: 0.8366 - Loss: 0.1883\n",
      "\n",
      "Batch 280/387 ━━━━━━━━━━━━━━━━━━━━ 02:16:47\n",
      "Accuracy: 0.9968 - Precision: 0.8530 - Recall: 0.8523 - Specificity: 0.9986 - F1: 0.8370 - Loss: 0.1879\n",
      "\n",
      "Batch 281/387 ━━━━━━━━━━━━━━━━━━━━ 02:18:01\n",
      "Accuracy: 0.9968 - Precision: 0.8533 - Recall: 0.8526 - Specificity: 0.9986 - F1: 0.8374 - Loss: 0.1875\n",
      "\n",
      "Batch 282/387 ━━━━━━━━━━━━━━━━━━━━ 02:19:18\n",
      "Accuracy: 0.9968 - Precision: 0.8526 - Recall: 0.8510 - Specificity: 0.9986 - F1: 0.8362 - Loss: 0.1889\n",
      "\n",
      "Batch 283/387 ━━━━━━━━━━━━━━━━━━━━ 02:20:43\n",
      "Accuracy: 0.9968 - Precision: 0.8531 - Recall: 0.8508 - Specificity: 0.9986 - F1: 0.8364 - Loss: 0.1888\n",
      "\n",
      "Batch 284/387 ━━━━━━━━━━━━━━━━━━━━ 02:22:05\n",
      "Accuracy: 0.9968 - Precision: 0.8536 - Recall: 0.8505 - Specificity: 0.9986 - F1: 0.8364 - Loss: 0.1887\n",
      "\n",
      "Batch 285/387 ━━━━━━━━━━━━━━━━━━━━ 02:23:35\n",
      "Accuracy: 0.9968 - Precision: 0.8531 - Recall: 0.8510 - Specificity: 0.9986 - F1: 0.8364 - Loss: 0.1887\n",
      "\n",
      "Batch 286/387 ━━━━━━━━━━━━━━━━━━━━ 02:25:02\n",
      "Accuracy: 0.9968 - Precision: 0.8533 - Recall: 0.8512 - Specificity: 0.9986 - F1: 0.8366 - Loss: 0.1885\n",
      "\n",
      "Batch 287/387 ━━━━━━━━━━━━━━━━━━━━ 02:26:17\n",
      "Accuracy: 0.9968 - Precision: 0.8533 - Recall: 0.8514 - Specificity: 0.9986 - F1: 0.8369 - Loss: 0.1883\n",
      "\n",
      "Batch 288/387 ━━━━━━━━━━━━━━━━━━━━ 02:27:36\n",
      "Accuracy: 0.9968 - Precision: 0.8534 - Recall: 0.8513 - Specificity: 0.9986 - F1: 0.8369 - Loss: 0.1883\n",
      "\n",
      "Batch 289/387 ━━━━━━━━━━━━━━━━━━━━ 02:28:58\n",
      "Accuracy: 0.9968 - Precision: 0.8525 - Recall: 0.8518 - Specificity: 0.9986 - F1: 0.8366 - Loss: 0.1886\n",
      "\n",
      "Batch 290/387 ━━━━━━━━━━━━━━━━━━━━ 02:30:36\n",
      "Accuracy: 0.9968 - Precision: 0.8525 - Recall: 0.8522 - Specificity: 0.9986 - F1: 0.8368 - Loss: 0.1883\n",
      "\n",
      "Batch 291/387 ━━━━━━━━━━━━━━━━━━━━ 02:31:58\n",
      "Accuracy: 0.9968 - Precision: 0.8525 - Recall: 0.8526 - Specificity: 0.9986 - F1: 0.8371 - Loss: 0.1880\n",
      "\n",
      "Batch 292/387 ━━━━━━━━━━━━━━━━━━━━ 02:33:10\n",
      "Accuracy: 0.9968 - Precision: 0.8528 - Recall: 0.8527 - Specificity: 0.9986 - F1: 0.8373 - Loss: 0.1879\n",
      "\n",
      "Batch 293/387 ━━━━━━━━━━━━━━━━━━━━ 02:34:28\n",
      "Accuracy: 0.9968 - Precision: 0.8532 - Recall: 0.8528 - Specificity: 0.9986 - F1: 0.8376 - Loss: 0.1875\n",
      "\n",
      "Batch 294/387 ━━━━━━━━━━━━━━━━━━━━ 02:35:44\n",
      "Accuracy: 0.9968 - Precision: 0.8531 - Recall: 0.8527 - Specificity: 0.9986 - F1: 0.8376 - Loss: 0.1875\n",
      "\n",
      "Batch 295/387 ━━━━━━━━━━━━━━━━━━━━ 02:37:07\n",
      "Accuracy: 0.9968 - Precision: 0.8533 - Recall: 0.8529 - Specificity: 0.9986 - F1: 0.8378 - Loss: 0.1873\n",
      "\n",
      "Batch 296/387 ━━━━━━━━━━━━━━━━━━━━ 02:38:19\n",
      "Accuracy: 0.9968 - Precision: 0.8531 - Recall: 0.8530 - Specificity: 0.9986 - F1: 0.8378 - Loss: 0.1873\n",
      "\n",
      "Batch 297/387 ━━━━━━━━━━━━━━━━━━━━ 02:39:41\n",
      "Accuracy: 0.9968 - Precision: 0.8528 - Recall: 0.8535 - Specificity: 0.9986 - F1: 0.8379 - Loss: 0.1871\n",
      "\n",
      "Batch 298/387 ━━━━━━━━━━━━━━━━━━━━ 02:41:07\n",
      "Accuracy: 0.9968 - Precision: 0.8533 - Recall: 0.8537 - Specificity: 0.9986 - F1: 0.8383 - Loss: 0.1867\n",
      "\n",
      "Batch 299/387 ━━━━━━━━━━━━━━━━━━━━ 02:42:15\n",
      "Accuracy: 0.9968 - Precision: 0.8526 - Recall: 0.8536 - Specificity: 0.9986 - F1: 0.8379 - Loss: 0.1871\n",
      "\n",
      "Batch 300/387 ━━━━━━━━━━━━━━━━━━━━ 02:43:37\n",
      "Accuracy: 0.9968 - Precision: 0.8530 - Recall: 0.8539 - Specificity: 0.9986 - F1: 0.8383 - Loss: 0.1867\n",
      "\n",
      "Batch 301/387 ━━━━━━━━━━━━━━━━━━━━ 02:44:55\n",
      "Accuracy: 0.9968 - Precision: 0.8534 - Recall: 0.8537 - Specificity: 0.9986 - F1: 0.8384 - Loss: 0.1866\n",
      "\n",
      "Batch 302/387 ━━━━━━━━━━━━━━━━━━━━ 02:46:14\n",
      "Accuracy: 0.9968 - Precision: 0.8536 - Recall: 0.8538 - Specificity: 0.9986 - F1: 0.8387 - Loss: 0.1863\n",
      "\n",
      "Batch 303/387 ━━━━━━━━━━━━━━━━━━━━ 02:47:42\n",
      "Accuracy: 0.9968 - Precision: 0.8523 - Recall: 0.8538 - Specificity: 0.9986 - F1: 0.8379 - Loss: 0.1871\n",
      "\n",
      "Batch 304/387 ━━━━━━━━━━━━━━━━━━━━ 02:48:58\n",
      "Accuracy: 0.9968 - Precision: 0.8520 - Recall: 0.8542 - Specificity: 0.9986 - F1: 0.8379 - Loss: 0.1871\n",
      "\n",
      "Batch 305/387 ━━━━━━━━━━━━━━━━━━━━ 02:50:26\n",
      "Accuracy: 0.9968 - Precision: 0.8524 - Recall: 0.8541 - Specificity: 0.9986 - F1: 0.8381 - Loss: 0.1869\n",
      "\n",
      "Batch 306/387 ━━━━━━━━━━━━━━━━━━━━ 02:51:45\n",
      "Accuracy: 0.9968 - Precision: 0.8520 - Recall: 0.8531 - Specificity: 0.9986 - F1: 0.8374 - Loss: 0.1876\n",
      "\n",
      "Batch 307/387 ━━━━━━━━━━━━━━━━━━━━ 02:53:05\n",
      "Accuracy: 0.9968 - Precision: 0.8524 - Recall: 0.8530 - Specificity: 0.9986 - F1: 0.8376 - Loss: 0.1873\n",
      "\n",
      "Batch 308/387 ━━━━━━━━━━━━━━━━━━━━ 02:54:29\n",
      "Accuracy: 0.9968 - Precision: 0.8523 - Recall: 0.8531 - Specificity: 0.9986 - F1: 0.8376 - Loss: 0.1873\n",
      "\n",
      "Batch 309/387 ━━━━━━━━━━━━━━━━━━━━ 02:55:40\n",
      "Accuracy: 0.9968 - Precision: 0.8527 - Recall: 0.8533 - Specificity: 0.9986 - F1: 0.8380 - Loss: 0.1869\n",
      "\n",
      "Batch 310/387 ━━━━━━━━━━━━━━━━━━━━ 02:57:00\n",
      "Accuracy: 0.9968 - Precision: 0.8519 - Recall: 0.8533 - Specificity: 0.9986 - F1: 0.8376 - Loss: 0.1873\n",
      "\n",
      "Batch 311/387 ━━━━━━━━━━━━━━━━━━━━ 02:58:13\n",
      "Accuracy: 0.9968 - Precision: 0.8523 - Recall: 0.8533 - Specificity: 0.9986 - F1: 0.8378 - Loss: 0.1871\n",
      "\n",
      "Batch 312/387 ━━━━━━━━━━━━━━━━━━━━ 02:59:34\n",
      "Accuracy: 0.9968 - Precision: 0.8523 - Recall: 0.8533 - Specificity: 0.9986 - F1: 0.8378 - Loss: 0.1870\n",
      "\n",
      "Batch 313/387 ━━━━━━━━━━━━━━━━━━━━ 03:00:56\n",
      "Accuracy: 0.9968 - Precision: 0.8526 - Recall: 0.8534 - Specificity: 0.9986 - F1: 0.8381 - Loss: 0.1867\n",
      "\n",
      "Batch 314/387 ━━━━━━━━━━━━━━━━━━━━ 03:02:17\n",
      "Accuracy: 0.9968 - Precision: 0.8529 - Recall: 0.8534 - Specificity: 0.9986 - F1: 0.8383 - Loss: 0.1865\n",
      "\n",
      "Batch 315/387 ━━━━━━━━━━━━━━━━━━━━ 03:03:36\n",
      "Accuracy: 0.9968 - Precision: 0.8530 - Recall: 0.8537 - Specificity: 0.9986 - F1: 0.8385 - Loss: 0.1862\n",
      "\n",
      "Batch 316/387 ━━━━━━━━━━━━━━━━━━━━ 03:04:55\n",
      "Accuracy: 0.9968 - Precision: 0.8534 - Recall: 0.8540 - Specificity: 0.9986 - F1: 0.8389 - Loss: 0.1858\n",
      "\n",
      "Batch 317/387 ━━━━━━━━━━━━━━━━━━━━ 03:06:13\n",
      "Accuracy: 0.9968 - Precision: 0.8517 - Recall: 0.8544 - Specificity: 0.9986 - F1: 0.8378 - Loss: 0.1869\n",
      "\n",
      "Batch 318/387 ━━━━━━━━━━━━━━━━━━━━ 03:07:36\n",
      "Accuracy: 0.9968 - Precision: 0.8519 - Recall: 0.8534 - Specificity: 0.9986 - F1: 0.8373 - Loss: 0.1875\n",
      "\n",
      "Batch 319/387 ━━━━━━━━━━━━━━━━━━━━ 03:08:46\n",
      "Accuracy: 0.9968 - Precision: 0.8523 - Recall: 0.8535 - Specificity: 0.9986 - F1: 0.8376 - Loss: 0.1872\n",
      "\n",
      "Batch 320/387 ━━━━━━━━━━━━━━━━━━━━ 03:10:06\n",
      "Accuracy: 0.9968 - Precision: 0.8526 - Recall: 0.8534 - Specificity: 0.9986 - F1: 0.8377 - Loss: 0.1871\n",
      "\n",
      "Batch 321/387 ━━━━━━━━━━━━━━━━━━━━ 03:11:26\n",
      "Accuracy: 0.9968 - Precision: 0.8520 - Recall: 0.8532 - Specificity: 0.9986 - F1: 0.8373 - Loss: 0.1875\n",
      "\n",
      "Batch 322/387 ━━━━━━━━━━━━━━━━━━━━ 03:12:46\n",
      "Accuracy: 0.9968 - Precision: 0.8510 - Recall: 0.8535 - Specificity: 0.9986 - F1: 0.8369 - Loss: 0.1879\n",
      "\n",
      "Batch 323/387 ━━━━━━━━━━━━━━━━━━━━ 03:14:05\n",
      "Accuracy: 0.9968 - Precision: 0.8506 - Recall: 0.8540 - Specificity: 0.9986 - F1: 0.8369 - Loss: 0.1879\n",
      "\n",
      "Batch 324/387 ━━━━━━━━━━━━━━━━━━━━ 03:15:27\n",
      "Accuracy: 0.9968 - Precision: 0.8495 - Recall: 0.8532 - Specificity: 0.9986 - F1: 0.8360 - Loss: 0.1889\n",
      "\n",
      "Batch 325/387 ━━━━━━━━━━━━━━━━━━━━ 03:16:47\n",
      "Accuracy: 0.9968 - Precision: 0.8497 - Recall: 0.8536 - Specificity: 0.9986 - F1: 0.8363 - Loss: 0.1885\n",
      "\n",
      "Batch 326/387 ━━━━━━━━━━━━━━━━━━━━ 03:18:01\n",
      "Accuracy: 0.9968 - Precision: 0.8489 - Recall: 0.8533 - Specificity: 0.9986 - F1: 0.8358 - Loss: 0.1890\n",
      "\n",
      "Batch 327/387 ━━━━━━━━━━━━━━━━━━━━ 03:19:20\n",
      "Accuracy: 0.9968 - Precision: 0.8489 - Recall: 0.8533 - Specificity: 0.9986 - F1: 0.8359 - Loss: 0.1889\n",
      "\n",
      "Batch 328/387 ━━━━━━━━━━━━━━━━━━━━ 03:20:33\n",
      "Accuracy: 0.9968 - Precision: 0.8493 - Recall: 0.8532 - Specificity: 0.9986 - F1: 0.8360 - Loss: 0.1888\n",
      "\n",
      "Batch 329/387 ━━━━━━━━━━━━━━━━━━━━ 03:21:59\n",
      "Accuracy: 0.9968 - Precision: 0.8497 - Recall: 0.8534 - Specificity: 0.9986 - F1: 0.8363 - Loss: 0.1884\n",
      "\n",
      "Batch 330/387 ━━━━━━━━━━━━━━━━━━━━ 03:23:20\n",
      "Accuracy: 0.9968 - Precision: 0.8501 - Recall: 0.8531 - Specificity: 0.9986 - F1: 0.8364 - Loss: 0.1884\n",
      "\n",
      "Batch 331/387 ━━━━━━━━━━━━━━━━━━━━ 03:24:34\n",
      "Accuracy: 0.9968 - Precision: 0.8504 - Recall: 0.8533 - Specificity: 0.9986 - F1: 0.8367 - Loss: 0.1880\n",
      "\n",
      "Batch 332/387 ━━━━━━━━━━━━━━━━━━━━ 03:26:01\n",
      "Accuracy: 0.9968 - Precision: 0.8504 - Recall: 0.8535 - Specificity: 0.9986 - F1: 0.8368 - Loss: 0.1878\n",
      "\n",
      "Batch 333/387 ━━━━━━━━━━━━━━━━━━━━ 03:27:17\n",
      "Accuracy: 0.9968 - Precision: 0.8505 - Recall: 0.8539 - Specificity: 0.9986 - F1: 0.8371 - Loss: 0.1875\n",
      "\n",
      "Batch 334/387 ━━━━━━━━━━━━━━━━━━━━ 03:28:40\n",
      "Accuracy: 0.9968 - Precision: 0.8509 - Recall: 0.8541 - Specificity: 0.9986 - F1: 0.8374 - Loss: 0.1872\n",
      "\n",
      "Batch 335/387 ━━━━━━━━━━━━━━━━━━━━ 03:30:00\n",
      "Accuracy: 0.9968 - Precision: 0.8511 - Recall: 0.8536 - Specificity: 0.9986 - F1: 0.8373 - Loss: 0.1873\n",
      "\n",
      "Batch 336/387 ━━━━━━━━━━━━━━━━━━━━ 03:31:12\n",
      "Accuracy: 0.9968 - Precision: 0.8502 - Recall: 0.8533 - Specificity: 0.9986 - F1: 0.8367 - Loss: 0.1880\n",
      "\n",
      "Batch 337/387 ━━━━━━━━━━━━━━━━━━━━ 03:32:43\n",
      "Accuracy: 0.9968 - Precision: 0.8506 - Recall: 0.8530 - Specificity: 0.9987 - F1: 0.8367 - Loss: 0.1879\n",
      "\n",
      "Batch 338/387 ━━━━━━━━━━━━━━━━━━━━ 03:33:50\n",
      "Accuracy: 0.9968 - Precision: 0.8501 - Recall: 0.8529 - Specificity: 0.9987 - F1: 0.8364 - Loss: 0.1883\n",
      "\n",
      "Batch 339/387 ━━━━━━━━━━━━━━━━━━━━ 03:35:18\n",
      "Accuracy: 0.9968 - Precision: 0.8503 - Recall: 0.8530 - Specificity: 0.9987 - F1: 0.8366 - Loss: 0.1880\n",
      "\n",
      "Batch 340/387 ━━━━━━━━━━━━━━━━━━━━ 03:36:35\n",
      "Accuracy: 0.9968 - Precision: 0.8507 - Recall: 0.8521 - Specificity: 0.9987 - F1: 0.8363 - Loss: 0.1885\n",
      "\n",
      "Batch 341/387 ━━━━━━━━━━━━━━━━━━━━ 03:37:53\n",
      "Accuracy: 0.9968 - Precision: 0.8506 - Recall: 0.8519 - Specificity: 0.9987 - F1: 0.8362 - Loss: 0.1886\n",
      "\n",
      "Batch 342/387 ━━━━━━━━━━━━━━━━━━━━ 03:39:15\n",
      "Accuracy: 0.9968 - Precision: 0.8506 - Recall: 0.8522 - Specificity: 0.9987 - F1: 0.8364 - Loss: 0.1884\n",
      "\n",
      "Batch 343/387 ━━━━━━━━━━━━━━━━━━━━ 03:40:34\n",
      "Accuracy: 0.9968 - Precision: 0.8509 - Recall: 0.8520 - Specificity: 0.9987 - F1: 0.8364 - Loss: 0.1883\n",
      "\n",
      "Batch 344/387 ━━━━━━━━━━━━━━━━━━━━ 03:42:00\n",
      "Accuracy: 0.9968 - Precision: 0.8512 - Recall: 0.8523 - Specificity: 0.9987 - F1: 0.8368 - Loss: 0.1879\n",
      "\n",
      "Batch 345/387 ━━━━━━━━━━━━━━━━━━━━ 03:43:16\n",
      "Accuracy: 0.9968 - Precision: 0.8514 - Recall: 0.8516 - Specificity: 0.9987 - F1: 0.8365 - Loss: 0.1882\n",
      "\n",
      "Batch 346/387 ━━━━━━━━━━━━━━━━━━━━ 03:44:35\n",
      "Accuracy: 0.9968 - Precision: 0.8513 - Recall: 0.8518 - Specificity: 0.9987 - F1: 0.8365 - Loss: 0.1881\n",
      "\n",
      "Batch 347/387 ━━━━━━━━━━━━━━━━━━━━ 03:45:53\n",
      "Accuracy: 0.9968 - Precision: 0.8511 - Recall: 0.8520 - Specificity: 0.9987 - F1: 0.8366 - Loss: 0.1881\n",
      "\n",
      "Batch 348/387 ━━━━━━━━━━━━━━━━━━━━ 03:47:08\n",
      "Accuracy: 0.9968 - Precision: 0.8503 - Recall: 0.8522 - Specificity: 0.9987 - F1: 0.8362 - Loss: 0.1884\n",
      "\n",
      "Batch 349/387 ━━━━━━━━━━━━━━━━━━━━ 03:48:18\n",
      "Accuracy: 0.9968 - Precision: 0.8500 - Recall: 0.8525 - Specificity: 0.9987 - F1: 0.8362 - Loss: 0.1884\n",
      "\n",
      "Batch 350/387 ━━━━━━━━━━━━━━━━━━━━ 03:49:31\n",
      "Accuracy: 0.9969 - Precision: 0.8493 - Recall: 0.8528 - Specificity: 0.9987 - F1: 0.8359 - Loss: 0.1887\n",
      "\n",
      "Batch 351/387 ━━━━━━━━━━━━━━━━━━━━ 03:50:44\n",
      "Accuracy: 0.9969 - Precision: 0.8489 - Recall: 0.8528 - Specificity: 0.9987 - F1: 0.8358 - Loss: 0.1889\n",
      "\n",
      "Batch 352/387 ━━━━━━━━━━━━━━━━━━━━ 03:52:04\n",
      "Accuracy: 0.9969 - Precision: 0.8492 - Recall: 0.8518 - Specificity: 0.9987 - F1: 0.8352 - Loss: 0.1895\n",
      "\n",
      "Batch 353/387 ━━━━━━━━━━━━━━━━━━━━ 03:53:18\n",
      "Accuracy: 0.9969 - Precision: 0.8494 - Recall: 0.8518 - Specificity: 0.9987 - F1: 0.8354 - Loss: 0.1892\n",
      "\n",
      "Batch 354/387 ━━━━━━━━━━━━━━━━━━━━ 03:54:32\n",
      "Accuracy: 0.9969 - Precision: 0.8496 - Recall: 0.8522 - Specificity: 0.9987 - F1: 0.8357 - Loss: 0.1889\n",
      "\n",
      "Batch 355/387 ━━━━━━━━━━━━━━━━━━━━ 03:55:44\n",
      "Accuracy: 0.9969 - Precision: 0.8500 - Recall: 0.8513 - Specificity: 0.9987 - F1: 0.8354 - Loss: 0.1893\n",
      "\n",
      "Batch 356/387 ━━━━━━━━━━━━━━━━━━━━ 03:57:12\n",
      "Accuracy: 0.9968 - Precision: 0.8503 - Recall: 0.8510 - Specificity: 0.9987 - F1: 0.8353 - Loss: 0.1893\n",
      "\n",
      "Batch 357/387 ━━━━━━━━━━━━━━━━━━━━ 03:58:43\n",
      "Accuracy: 0.9968 - Precision: 0.8505 - Recall: 0.8510 - Specificity: 0.9987 - F1: 0.8355 - Loss: 0.1892\n",
      "\n",
      "Batch 358/387 ━━━━━━━━━━━━━━━━━━━━ 04:00:06\n",
      "Accuracy: 0.9969 - Precision: 0.8508 - Recall: 0.8507 - Specificity: 0.9987 - F1: 0.8355 - Loss: 0.1891\n",
      "\n",
      "Batch 359/387 ━━━━━━━━━━━━━━━━━━━━ 04:01:25\n",
      "Accuracy: 0.9969 - Precision: 0.8511 - Recall: 0.8509 - Specificity: 0.9987 - F1: 0.8358 - Loss: 0.1888\n",
      "\n",
      "Batch 360/387 ━━━━━━━━━━━━━━━━━━━━ 04:02:36\n",
      "Accuracy: 0.9969 - Precision: 0.8511 - Recall: 0.8511 - Specificity: 0.9987 - F1: 0.8359 - Loss: 0.1886\n",
      "\n",
      "Batch 361/387 ━━━━━━━━━━━━━━━━━━━━ 04:03:52\n",
      "Accuracy: 0.9969 - Precision: 0.8514 - Recall: 0.8512 - Specificity: 0.9987 - F1: 0.8362 - Loss: 0.1884\n",
      "\n",
      "Batch 362/387 ━━━━━━━━━━━━━━━━━━━━ 04:05:11\n",
      "Accuracy: 0.9969 - Precision: 0.8508 - Recall: 0.8516 - Specificity: 0.9987 - F1: 0.8360 - Loss: 0.1885\n",
      "\n",
      "Batch 363/387 ━━━━━━━━━━━━━━━━━━━━ 04:06:24\n",
      "Accuracy: 0.9969 - Precision: 0.8510 - Recall: 0.8518 - Specificity: 0.9987 - F1: 0.8362 - Loss: 0.1883\n",
      "\n",
      "Batch 364/387 ━━━━━━━━━━━━━━━━━━━━ 04:07:42\n",
      "Accuracy: 0.9969 - Precision: 0.8512 - Recall: 0.8520 - Specificity: 0.9987 - F1: 0.8365 - Loss: 0.1879\n",
      "\n",
      "Batch 365/387 ━━━━━━━━━━━━━━━━━━━━ 04:08:59\n",
      "Accuracy: 0.9969 - Precision: 0.8515 - Recall: 0.8522 - Specificity: 0.9987 - F1: 0.8368 - Loss: 0.1876\n",
      "\n",
      "Batch 366/387 ━━━━━━━━━━━━━━━━━━━━ 04:10:15\n",
      "Accuracy: 0.9969 - Precision: 0.8517 - Recall: 0.8526 - Specificity: 0.9987 - F1: 0.8371 - Loss: 0.1873\n",
      "\n",
      "Batch 367/387 ━━━━━━━━━━━━━━━━━━━━ 04:11:34\n",
      "Accuracy: 0.9969 - Precision: 0.8511 - Recall: 0.8530 - Specificity: 0.9987 - F1: 0.8369 - Loss: 0.1874\n",
      "\n",
      "Batch 368/387 ━━━━━━━━━━━━━━━━━━━━ 04:12:54\n",
      "Accuracy: 0.9969 - Precision: 0.8515 - Recall: 0.8526 - Specificity: 0.9987 - F1: 0.8370 - Loss: 0.1874\n",
      "\n",
      "Batch 369/387 ━━━━━━━━━━━━━━━━━━━━ 04:14:11\n",
      "Accuracy: 0.9969 - Precision: 0.8518 - Recall: 0.8526 - Specificity: 0.9987 - F1: 0.8371 - Loss: 0.1872\n",
      "\n",
      "Batch 370/387 ━━━━━━━━━━━━━━━━━━━━ 04:15:23\n",
      "Accuracy: 0.9969 - Precision: 0.8520 - Recall: 0.8530 - Specificity: 0.9987 - F1: 0.8374 - Loss: 0.1869\n",
      "\n",
      "Batch 371/387 ━━━━━━━━━━━━━━━━━━━━ 04:16:41\n",
      "Accuracy: 0.9969 - Precision: 0.8523 - Recall: 0.8532 - Specificity: 0.9987 - F1: 0.8377 - Loss: 0.1866\n",
      "\n",
      "Batch 372/387 ━━━━━━━━━━━━━━━━━━━━ 04:18:01\n",
      "Accuracy: 0.9969 - Precision: 0.8526 - Recall: 0.8533 - Specificity: 0.9987 - F1: 0.8380 - Loss: 0.1862\n",
      "\n",
      "Batch 373/387 ━━━━━━━━━━━━━━━━━━━━ 04:19:27\n",
      "Accuracy: 0.9969 - Precision: 0.8526 - Recall: 0.8533 - Specificity: 0.9987 - F1: 0.8380 - Loss: 0.1862\n",
      "\n",
      "Batch 374/387 ━━━━━━━━━━━━━━━━━━━━ 04:20:40\n",
      "Accuracy: 0.9969 - Precision: 0.8528 - Recall: 0.8535 - Specificity: 0.9987 - F1: 0.8383 - Loss: 0.1859\n",
      "\n",
      "Batch 375/387 ━━━━━━━━━━━━━━━━━━━━ 04:21:53\n",
      "Accuracy: 0.9969 - Precision: 0.8530 - Recall: 0.8537 - Specificity: 0.9987 - F1: 0.8385 - Loss: 0.1857\n",
      "\n",
      "Batch 376/387 ━━━━━━━━━━━━━━━━━━━━ 04:23:04\n",
      "Accuracy: 0.9969 - Precision: 0.8534 - Recall: 0.8535 - Specificity: 0.9987 - F1: 0.8386 - Loss: 0.1855\n",
      "\n",
      "Batch 377/387 ━━━━━━━━━━━━━━━━━━━━ 04:24:18\n",
      "Accuracy: 0.9969 - Precision: 0.8537 - Recall: 0.8535 - Specificity: 0.9987 - F1: 0.8388 - Loss: 0.1853\n",
      "\n",
      "Batch 378/387 ━━━━━━━━━━━━━━━━━━━━ 04:25:38\n",
      "Accuracy: 0.9969 - Precision: 0.8538 - Recall: 0.8538 - Specificity: 0.9987 - F1: 0.8390 - Loss: 0.1851\n",
      "\n",
      "Batch 379/387 ━━━━━━━━━━━━━━━━━━━━ 04:26:57\n",
      "Accuracy: 0.9969 - Precision: 0.8541 - Recall: 0.8539 - Specificity: 0.9987 - F1: 0.8393 - Loss: 0.1848\n",
      "\n",
      "Batch 380/387 ━━━━━━━━━━━━━━━━━━━━ 04:28:07\n",
      "Accuracy: 0.9969 - Precision: 0.8544 - Recall: 0.8542 - Specificity: 0.9987 - F1: 0.8396 - Loss: 0.1844\n",
      "\n",
      "Batch 381/387 ━━━━━━━━━━━━━━━━━━━━ 04:29:21\n",
      "Accuracy: 0.9969 - Precision: 0.8543 - Recall: 0.8543 - Specificity: 0.9987 - F1: 0.8396 - Loss: 0.1843\n",
      "\n",
      "Batch 382/387 ━━━━━━━━━━━━━━━━━━━━ 04:30:32\n",
      "Accuracy: 0.9969 - Precision: 0.8543 - Recall: 0.8546 - Specificity: 0.9987 - F1: 0.8398 - Loss: 0.1841\n",
      "\n",
      "Batch 383/387 ━━━━━━━━━━━━━━━━━━━━ 04:31:39\n",
      "Accuracy: 0.9969 - Precision: 0.8545 - Recall: 0.8546 - Specificity: 0.9987 - F1: 0.8400 - Loss: 0.1840\n",
      "\n",
      "Batch 384/387 ━━━━━━━━━━━━━━━━━━━━ 04:32:51\n",
      "Accuracy: 0.9969 - Precision: 0.8545 - Recall: 0.8549 - Specificity: 0.9987 - F1: 0.8401 - Loss: 0.1838\n",
      "\n",
      "Batch 385/387 ━━━━━━━━━━━━━━━━━━━━ 04:34:13\n",
      "Accuracy: 0.9969 - Precision: 0.8547 - Recall: 0.8551 - Specificity: 0.9987 - F1: 0.8404 - Loss: 0.1835\n",
      "\n",
      "Batch 386/387 ━━━━━━━━━━━━━━━━━━━━ 04:35:29\n",
      "Accuracy: 0.9969 - Precision: 0.8550 - Recall: 0.8552 - Specificity: 0.9987 - F1: 0.8406 - Loss: 0.1833\n",
      "\n",
      "Batch 387/387 ━━━━━━━━━━━━━━━━━━━━ 04:36:47\n",
      "Accuracy: 0.9969 - Precision: 0.8551 - Recall: 0.8552 - Specificity: 0.9987 - F1: 0.8407 - Loss: 0.1832\n",
      "\n",
      "End of Epoch 2\n",
      "\n",
      "Epoch 3/50\n",
      "Batch 1/387 ━━━━━━━━━━━━━━━━━━━━ 04:58:27\n",
      "Accuracy: 0.9990 - Precision: 0.7090 - Recall: 0.9881 - Specificity: 0.9990 - F1: 0.8256 - Loss: 0.1944\n",
      "\n",
      "Batch 2/387 ━━━━━━━━━━━━━━━━━━━━ 04:59:51\n",
      "Accuracy: 0.9975 - Precision: 0.8427 - Recall: 0.8861 - Specificity: 0.9993 - F1: 0.8477 - Loss: 0.1747\n",
      "\n",
      "Batch 3/387 ━━━━━━━━━━━━━━━━━━━━ 05:01:11\n",
      "Accuracy: 0.9976 - Precision: 0.8629 - Recall: 0.9147 - Specificity: 0.9990 - F1: 0.8772 - Loss: 0.1415\n",
      "\n",
      "Batch 4/387 ━━━━━━━━━━━━━━━━━━━━ 05:02:32\n",
      "Accuracy: 0.9978 - Precision: 0.8281 - Recall: 0.9322 - Specificity: 0.9988 - F1: 0.8665 - Loss: 0.1518\n",
      "\n",
      "Batch 5/387 ━━━━━━━━━━━━━━━━━━━━ 05:03:49\n",
      "Accuracy: 0.9974 - Precision: 0.7983 - Recall: 0.9440 - Specificity: 0.9983 - F1: 0.8544 - Loss: 0.1651\n",
      "\n",
      "Batch 6/387 ━━━━━━━━━━━━━━━━━━━━ 05:05:11\n",
      "Accuracy: 0.9976 - Precision: 0.8147 - Recall: 0.9304 - Specificity: 0.9985 - F1: 0.8585 - Loss: 0.1597\n",
      "\n",
      "Batch 7/387 ━━━━━━━━━━━━━━━━━━━━ 05:06:32\n",
      "Accuracy: 0.9974 - Precision: 0.7584 - Recall: 0.9383 - Specificity: 0.9981 - F1: 0.8201 - Loss: 0.1998\n",
      "\n",
      "Batch 8/387 ━━━━━━━━━━━━━━━━━━━━ 05:08:04\n",
      "Accuracy: 0.9971 - Precision: 0.7875 - Recall: 0.9151 - Specificity: 0.9984 - F1: 0.8246 - Loss: 0.1957\n",
      "\n",
      "Batch 9/387 ━━━━━━━━━━━━━━━━━━━━ 05:09:21\n",
      "Accuracy: 0.9971 - Precision: 0.8098 - Recall: 0.9098 - Specificity: 0.9985 - F1: 0.8356 - Loss: 0.1845\n",
      "\n",
      "Batch 10/387 ━━━━━━━━━━━━━━━━━━━━ 05:10:42\n",
      "Accuracy: 0.9970 - Precision: 0.8149 - Recall: 0.9020 - Specificity: 0.9985 - F1: 0.8367 - Loss: 0.1835\n",
      "\n",
      "Batch 11/387 ━━━━━━━━━━━━━━━━━━━━ 05:12:03\n",
      "Accuracy: 0.9971 - Precision: 0.8310 - Recall: 0.9013 - Specificity: 0.9986 - F1: 0.8461 - Loss: 0.1733\n",
      "\n",
      "Batch 12/387 ━━━━━━━━━━━━━━━━━━━━ 05:13:18\n",
      "Accuracy: 0.9969 - Precision: 0.8409 - Recall: 0.8882 - Specificity: 0.9987 - F1: 0.8451 - Loss: 0.1754\n",
      "\n",
      "Batch 13/387 ━━━━━━━━━━━━━━━━━━━━ 05:14:39\n",
      "Accuracy: 0.9969 - Precision: 0.8452 - Recall: 0.8667 - Specificity: 0.9987 - F1: 0.8359 - Loss: 0.1847\n",
      "\n",
      "Batch 14/387 ━━━━━━━━━━━━━━━━━━━━ 05:16:07\n",
      "Accuracy: 0.9970 - Precision: 0.8359 - Recall: 0.8572 - Specificity: 0.9988 - F1: 0.8279 - Loss: 0.1927\n",
      "\n",
      "Batch 15/387 ━━━━━━━━━━━━━━━━━━━━ 05:17:28\n",
      "Accuracy: 0.9970 - Precision: 0.8278 - Recall: 0.8558 - Specificity: 0.9987 - F1: 0.8241 - Loss: 0.1966\n",
      "\n",
      "Batch 16/387 ━━━━━━━━━━━━━━━━━━━━ 05:18:47\n",
      "Accuracy: 0.9971 - Precision: 0.8343 - Recall: 0.8619 - Specificity: 0.9988 - F1: 0.8315 - Loss: 0.1886\n",
      "\n",
      "Batch 17/387 ━━━━━━━━━━━━━━━━━━━━ 05:20:02\n",
      "Accuracy: 0.9971 - Precision: 0.8183 - Recall: 0.8658 - Specificity: 0.9987 - F1: 0.8237 - Loss: 0.1969\n",
      "\n",
      "Batch 18/387 ━━━━━━━━━━━━━━━━━━━━ 05:21:24\n",
      "Accuracy: 0.9971 - Precision: 0.8198 - Recall: 0.8719 - Specificity: 0.9986 - F1: 0.8283 - Loss: 0.1919\n",
      "\n",
      "Batch 19/387 ━━━━━━━━━━━━━━━━━━━━ 05:22:37\n",
      "Accuracy: 0.9967 - Precision: 0.7881 - Recall: 0.8781 - Specificity: 0.9982 - F1: 0.8035 - Loss: 0.2187\n",
      "\n",
      "Batch 20/387 ━━━━━━━━━━━━━━━━━━━━ 05:23:50\n",
      "Accuracy: 0.9967 - Precision: 0.7983 - Recall: 0.8758 - Specificity: 0.9982 - F1: 0.8085 - Loss: 0.2135\n",
      "\n",
      "Batch 21/387 ━━━━━━━━━━━━━━━━━━━━ 05:25:18\n",
      "Accuracy: 0.9968 - Precision: 0.8013 - Recall: 0.8802 - Specificity: 0.9983 - F1: 0.8134 - Loss: 0.2081\n",
      "\n",
      "Batch 22/387 ━━━━━━━━━━━━━━━━━━━━ 05:26:33\n",
      "Accuracy: 0.9969 - Precision: 0.8080 - Recall: 0.8840 - Specificity: 0.9983 - F1: 0.8199 - Loss: 0.2010\n",
      "\n",
      "Batch 23/387 ━━━━━━━━━━━━━━━━━━━━ 05:27:43\n",
      "Accuracy: 0.9970 - Precision: 0.8157 - Recall: 0.8835 - Specificity: 0.9984 - F1: 0.8245 - Loss: 0.1962\n",
      "\n",
      "Batch 24/387 ━━━━━━━━━━━━━━━━━━━━ 05:28:59\n",
      "Accuracy: 0.9971 - Precision: 0.8213 - Recall: 0.8850 - Specificity: 0.9985 - F1: 0.8291 - Loss: 0.1910\n",
      "\n",
      "Batch 25/387 ━━━━━━━━━━━━━━━━━━━━ 05:30:21\n",
      "Accuracy: 0.9971 - Precision: 0.8282 - Recall: 0.8810 - Specificity: 0.9985 - F1: 0.8311 - Loss: 0.1890\n",
      "\n",
      "Batch 26/387 ━━━━━━━━━━━━━━━━━━━━ 09:11:12\n",
      "Accuracy: 0.9970 - Precision: 0.8339 - Recall: 0.8720 - Specificity: 0.9986 - F1: 0.8290 - Loss: 0.1915\n",
      "\n",
      "Batch 27/387 ━━━━━━━━━━━━━━━━━━━━ 09:12:56\n",
      "Accuracy: 0.9970 - Precision: 0.8399 - Recall: 0.8675 - Specificity: 0.9986 - F1: 0.8300 - Loss: 0.1911\n",
      "\n",
      "Batch 28/387 ━━━━━━━━━━━━━━━━━━━━ 09:14:35\n",
      "Accuracy: 0.9970 - Precision: 0.8451 - Recall: 0.8655 - Specificity: 0.9987 - F1: 0.8322 - Loss: 0.1888\n",
      "\n",
      "Batch 29/387 ━━━━━━━━━━━━━━━━━━━━ 09:16:27\n",
      "Accuracy: 0.9971 - Precision: 0.8498 - Recall: 0.8668 - Specificity: 0.9987 - F1: 0.8359 - Loss: 0.1847\n",
      "\n",
      "Batch 30/387 ━━━━━━━━━━━━━━━━━━━━ 09:18:00\n",
      "Accuracy: 0.9970 - Precision: 0.8545 - Recall: 0.8614 - Specificity: 0.9987 - F1: 0.8355 - Loss: 0.1860\n",
      "\n",
      "Batch 31/387 ━━━━━━━━━━━━━━━━━━━━ 09:19:21\n",
      "Accuracy: 0.9970 - Precision: 0.8574 - Recall: 0.8641 - Specificity: 0.9988 - F1: 0.8390 - Loss: 0.1821\n",
      "\n",
      "Batch 32/387 ━━━━━━━━━━━━━━━━━━━━ 09:20:47\n",
      "Accuracy: 0.9970 - Precision: 0.8617 - Recall: 0.8651 - Specificity: 0.9988 - F1: 0.8422 - Loss: 0.1786\n",
      "\n",
      "Batch 33/387 ━━━━━━━━━━━━━━━━━━━━ 09:22:12\n",
      "Accuracy: 0.9971 - Precision: 0.8636 - Recall: 0.8683 - Specificity: 0.9988 - F1: 0.8454 - Loss: 0.1750\n",
      "\n",
      "Batch 34/387 ━━━━━━━━━━━━━━━━━━━━ 09:23:34\n",
      "Accuracy: 0.9971 - Precision: 0.8623 - Recall: 0.8721 - Specificity: 0.9988 - F1: 0.8470 - Loss: 0.1732\n",
      "\n",
      "Batch 35/387 ━━━━━━━━━━━━━━━━━━━━ 09:24:55\n",
      "Accuracy: 0.9971 - Precision: 0.8657 - Recall: 0.8729 - Specificity: 0.9988 - F1: 0.8497 - Loss: 0.1706\n",
      "\n",
      "Batch 36/387 ━━━━━━━━━━━━━━━━━━━━ 09:26:18\n",
      "Accuracy: 0.9971 - Precision: 0.8659 - Recall: 0.8757 - Specificity: 0.9988 - F1: 0.8516 - Loss: 0.1684\n",
      "\n",
      "Batch 37/387 ━━━━━━━━━━━━━━━━━━━━ 09:27:45\n",
      "Accuracy: 0.9971 - Precision: 0.8663 - Recall: 0.8783 - Specificity: 0.9988 - F1: 0.8536 - Loss: 0.1662\n",
      "\n",
      "Batch 38/387 ━━━━━━━━━━━━━━━━━━━━ 09:29:10\n",
      "Accuracy: 0.9971 - Precision: 0.8657 - Recall: 0.8796 - Specificity: 0.9987 - F1: 0.8544 - Loss: 0.1655\n",
      "\n",
      "Batch 39/387 ━━━━━━━━━━━━━━━━━━━━ 09:30:34\n",
      "Accuracy: 0.9970 - Precision: 0.8687 - Recall: 0.8787 - Specificity: 0.9987 - F1: 0.8558 - Loss: 0.1643\n",
      "\n",
      "Batch 40/387 ━━━━━━━━━━━━━━━━━━━━ 09:32:00\n",
      "Accuracy: 0.9970 - Precision: 0.8652 - Recall: 0.8803 - Specificity: 0.9987 - F1: 0.8549 - Loss: 0.1652\n",
      "\n",
      "Batch 41/387 ━━━━━━━━━━━━━━━━━━━━ 09:33:19\n",
      "Accuracy: 0.9971 - Precision: 0.8674 - Recall: 0.8822 - Specificity: 0.9987 - F1: 0.8575 - Loss: 0.1624\n",
      "\n",
      "Batch 42/387 ━━━━━━━━━━━━━━━━━━━━ 09:34:45\n",
      "Accuracy: 0.9971 - Precision: 0.8695 - Recall: 0.8843 - Specificity: 0.9987 - F1: 0.8599 - Loss: 0.1597\n",
      "\n",
      "Batch 43/387 ━━━━━━━━━━━━━━━━━━━━ 09:35:58\n",
      "Accuracy: 0.9970 - Precision: 0.8666 - Recall: 0.8854 - Specificity: 0.9986 - F1: 0.8591 - Loss: 0.1608\n",
      "\n",
      "Batch 44/387 ━━━━━━━━━━━━━━━━━━━━ 09:37:26\n",
      "Accuracy: 0.9969 - Precision: 0.8636 - Recall: 0.8859 - Specificity: 0.9985 - F1: 0.8581 - Loss: 0.1621\n",
      "\n",
      "Batch 45/387 ━━━━━━━━━━━━━━━━━━━━ 09:38:46\n",
      "Accuracy: 0.9969 - Precision: 0.8571 - Recall: 0.8876 - Specificity: 0.9984 - F1: 0.8550 - Loss: 0.1655\n",
      "\n",
      "Batch 46/387 ━━━━━━━━━━━━━━━━━━━━ 09:40:16\n",
      "Accuracy: 0.9968 - Precision: 0.8545 - Recall: 0.8890 - Specificity: 0.9984 - F1: 0.8545 - Loss: 0.1662\n",
      "\n",
      "Batch 47/387 ━━━━━━━━━━━━━━━━━━━━ 09:41:36\n",
      "Accuracy: 0.9968 - Precision: 0.8513 - Recall: 0.8903 - Specificity: 0.9984 - F1: 0.8535 - Loss: 0.1672\n",
      "\n",
      "Batch 48/387 ━━━━━━━━━━━━━━━━━━━━ 09:42:53\n",
      "Accuracy: 0.9967 - Precision: 0.8420 - Recall: 0.8857 - Specificity: 0.9983 - F1: 0.8462 - Loss: 0.1749\n",
      "\n",
      "Batch 49/387 ━━━━━━━━━━━━━━━━━━━━ 09:44:24\n",
      "Accuracy: 0.9967 - Precision: 0.8418 - Recall: 0.8852 - Specificity: 0.9982 - F1: 0.8462 - Loss: 0.1752\n",
      "\n",
      "Batch 50/387 ━━━━━━━━━━━━━━━━━━━━ 09:45:53\n",
      "Accuracy: 0.9967 - Precision: 0.8445 - Recall: 0.8854 - Specificity: 0.9983 - F1: 0.8480 - Loss: 0.1733\n",
      "\n",
      "Batch 51/387 ━━━━━━━━━━━━━━━━━━━━ 09:47:19\n",
      "Accuracy: 0.9968 - Precision: 0.8472 - Recall: 0.8848 - Specificity: 0.9983 - F1: 0.8493 - Loss: 0.1718\n",
      "\n",
      "Batch 52/387 ━━━━━━━━━━━━━━━━━━━━ 09:48:39\n",
      "Accuracy: 0.9968 - Precision: 0.8496 - Recall: 0.8819 - Specificity: 0.9983 - F1: 0.8490 - Loss: 0.1720\n",
      "\n",
      "Batch 53/387 ━━━━━━━━━━━━━━━━━━━━ 09:49:59\n",
      "Accuracy: 0.9968 - Precision: 0.8511 - Recall: 0.8789 - Specificity: 0.9984 - F1: 0.8483 - Loss: 0.1726\n",
      "\n",
      "Batch 54/387 ━━━━━━━━━━━━━━━━━━━━ 09:51:18\n",
      "Accuracy: 0.9968 - Precision: 0.8536 - Recall: 0.8777 - Specificity: 0.9984 - F1: 0.8492 - Loss: 0.1716\n",
      "\n",
      "Batch 55/387 ━━━━━━━━━━━━━━━━━━━━ 09:52:48\n",
      "Accuracy: 0.9968 - Precision: 0.8563 - Recall: 0.8756 - Specificity: 0.9984 - F1: 0.8494 - Loss: 0.1714\n",
      "\n",
      "Batch 56/387 ━━━━━━━━━━━━━━━━━━━━ 09:54:07\n",
      "Accuracy: 0.9967 - Precision: 0.8581 - Recall: 0.8721 - Specificity: 0.9984 - F1: 0.8485 - Loss: 0.1728\n",
      "\n",
      "Batch 57/387 ━━━━━━━━━━━━━━━━━━━━ 09:55:23\n",
      "Accuracy: 0.9968 - Precision: 0.8602 - Recall: 0.8732 - Specificity: 0.9985 - F1: 0.8503 - Loss: 0.1707\n",
      "\n",
      "Batch 58/387 ━━━━━━━━━━━━━━━━━━━━ 09:56:36\n",
      "Accuracy: 0.9968 - Precision: 0.8592 - Recall: 0.8710 - Specificity: 0.9985 - F1: 0.8490 - Loss: 0.1721\n",
      "\n",
      "Batch 59/387 ━━━━━━━━━━━━━━━━━━━━ 09:58:11\n",
      "Accuracy: 0.9968 - Precision: 0.8611 - Recall: 0.8717 - Specificity: 0.9985 - F1: 0.8506 - Loss: 0.1704\n",
      "\n",
      "Batch 60/387 ━━━━━━━━━━━━━━━━━━━━ 09:59:32\n",
      "Accuracy: 0.9968 - Precision: 0.8606 - Recall: 0.8733 - Specificity: 0.9985 - F1: 0.8513 - Loss: 0.1695\n",
      "\n",
      "Batch 61/387 ━━━━━━━━━━━━━━━━━━━━ 10:01:02\n",
      "Accuracy: 0.9968 - Precision: 0.8620 - Recall: 0.8715 - Specificity: 0.9985 - F1: 0.8512 - Loss: 0.1697\n",
      "\n",
      "Batch 62/387 ━━━━━━━━━━━━━━━━━━━━ 10:02:32\n",
      "Accuracy: 0.9968 - Precision: 0.8630 - Recall: 0.8732 - Specificity: 0.9985 - F1: 0.8528 - Loss: 0.1680\n",
      "\n",
      "Batch 63/387 ━━━━━━━━━━━━━━━━━━━━ 10:03:55\n",
      "Accuracy: 0.9968 - Precision: 0.8648 - Recall: 0.8737 - Specificity: 0.9985 - F1: 0.8542 - Loss: 0.1665\n",
      "\n",
      "Batch 64/387 ━━━━━━━━━━━━━━━━━━━━ 10:05:28\n",
      "Accuracy: 0.9968 - Precision: 0.8632 - Recall: 0.8733 - Specificity: 0.9985 - F1: 0.8534 - Loss: 0.1674\n",
      "\n",
      "Batch 65/387 ━━━━━━━━━━━━━━━━━━━━ 10:07:04\n",
      "Accuracy: 0.9969 - Precision: 0.8615 - Recall: 0.8749 - Specificity: 0.9985 - F1: 0.8533 - Loss: 0.1675\n",
      "\n",
      "Batch 66/387 ━━━━━━━━━━━━━━━━━━━━ 10:08:29\n",
      "Accuracy: 0.9969 - Precision: 0.8634 - Recall: 0.8746 - Specificity: 0.9985 - F1: 0.8542 - Loss: 0.1665\n",
      "\n",
      "Batch 67/387 ━━━━━━━━━━━━━━━━━━━━ 10:09:51\n",
      "Accuracy: 0.9969 - Precision: 0.8612 - Recall: 0.8758 - Specificity: 0.9985 - F1: 0.8538 - Loss: 0.1670\n",
      "\n",
      "Batch 68/387 ━━━━━━━━━━━━━━━━━━━━ 10:11:07\n",
      "Accuracy: 0.9969 - Precision: 0.8599 - Recall: 0.8773 - Specificity: 0.9985 - F1: 0.8539 - Loss: 0.1668\n",
      "\n",
      "Batch 69/387 ━━━━━━━━━━━━━━━━━━━━ 10:12:28\n",
      "Accuracy: 0.9969 - Precision: 0.8601 - Recall: 0.8758 - Specificity: 0.9985 - F1: 0.8534 - Loss: 0.1673\n",
      "\n",
      "Batch 70/387 ━━━━━━━━━━━━━━━━━━━━ 10:13:48\n",
      "Accuracy: 0.9969 - Precision: 0.8573 - Recall: 0.8754 - Specificity: 0.9985 - F1: 0.8518 - Loss: 0.1688\n",
      "\n",
      "Batch 71/387 ━━━━━━━━━━━━━━━━━━━━ 10:15:28\n",
      "Accuracy: 0.9969 - Precision: 0.8576 - Recall: 0.8765 - Specificity: 0.9985 - F1: 0.8528 - Loss: 0.1678\n",
      "\n",
      "Batch 72/387 ━━━━━━━━━━━━━━━━━━━━ 10:16:46\n",
      "Accuracy: 0.9969 - Precision: 0.8591 - Recall: 0.8752 - Specificity: 0.9985 - F1: 0.8529 - Loss: 0.1679\n",
      "\n",
      "Batch 73/387 ━━━━━━━━━━━━━━━━━━━━ 10:18:08\n",
      "Accuracy: 0.9969 - Precision: 0.8605 - Recall: 0.8751 - Specificity: 0.9985 - F1: 0.8537 - Loss: 0.1669\n",
      "\n",
      "Batch 74/387 ━━━━━━━━━━━━━━━━━━━━ 10:19:29\n",
      "Accuracy: 0.9969 - Precision: 0.8614 - Recall: 0.8750 - Specificity: 0.9985 - F1: 0.8543 - Loss: 0.1663\n",
      "\n",
      "Batch 75/387 ━━━━━━━━━━━━━━━━━━━━ 10:20:45\n",
      "Accuracy: 0.9968 - Precision: 0.8632 - Recall: 0.8730 - Specificity: 0.9986 - F1: 0.8541 - Loss: 0.1668\n",
      "\n",
      "Batch 76/387 ━━━━━━━━━━━━━━━━━━━━ 10:22:12\n",
      "Accuracy: 0.9969 - Precision: 0.8646 - Recall: 0.8737 - Specificity: 0.9986 - F1: 0.8553 - Loss: 0.1655\n",
      "\n",
      "Batch 77/387 ━━━━━━━━━━━━━━━━━━━━ 10:23:36\n",
      "Accuracy: 0.9969 - Precision: 0.8658 - Recall: 0.8719 - Specificity: 0.9986 - F1: 0.8550 - Loss: 0.1659\n",
      "\n",
      "Batch 78/387 ━━━━━━━━━━━━━━━━━━━━ 10:24:57\n",
      "Accuracy: 0.9969 - Precision: 0.8671 - Recall: 0.8721 - Specificity: 0.9986 - F1: 0.8559 - Loss: 0.1651\n",
      "\n",
      "Batch 79/387 ━━━━━━━━━━━━━━━━━━━━ 10:26:19\n",
      "Accuracy: 0.9969 - Precision: 0.8678 - Recall: 0.8728 - Specificity: 0.9986 - F1: 0.8567 - Loss: 0.1641\n",
      "\n",
      "Batch 80/387 ━━━━━━━━━━━━━━━━━━━━ 10:27:46\n",
      "Accuracy: 0.9969 - Precision: 0.8641 - Recall: 0.8710 - Specificity: 0.9986 - F1: 0.8541 - Loss: 0.1670\n",
      "\n",
      "Batch 81/387 ━━━━━━━━━━━━━━━━━━━━ 10:29:00\n",
      "Accuracy: 0.9968 - Precision: 0.8593 - Recall: 0.8675 - Specificity: 0.9986 - F1: 0.8500 - Loss: 0.1711\n",
      "\n",
      "Batch 82/387 ━━━━━━━━━━━━━━━━━━━━ 10:30:23\n",
      "Accuracy: 0.9969 - Precision: 0.8593 - Recall: 0.8684 - Specificity: 0.9986 - F1: 0.8506 - Loss: 0.1706\n",
      "\n",
      "Batch 83/387 ━━━━━━━━━━━━━━━━━━━━ 10:31:51\n",
      "Accuracy: 0.9969 - Precision: 0.8570 - Recall: 0.8681 - Specificity: 0.9985 - F1: 0.8493 - Loss: 0.1719\n",
      "\n",
      "Batch 84/387 ━━━━━━━━━━━━━━━━━━━━ 10:33:11\n",
      "Accuracy: 0.9969 - Precision: 0.8563 - Recall: 0.8691 - Specificity: 0.9985 - F1: 0.8495 - Loss: 0.1716\n",
      "\n",
      "Batch 85/387 ━━━━━━━━━━━━━━━━━━━━ 10:34:37\n",
      "Accuracy: 0.9969 - Precision: 0.8571 - Recall: 0.8683 - Specificity: 0.9986 - F1: 0.8496 - Loss: 0.1716\n",
      "\n",
      "Batch 86/387 ━━━━━━━━━━━━━━━━━━━━ 10:36:05\n",
      "Accuracy: 0.9969 - Precision: 0.8577 - Recall: 0.8691 - Specificity: 0.9986 - F1: 0.8505 - Loss: 0.1706\n",
      "\n",
      "Batch 87/387 ━━━━━━━━━━━━━━━━━━━━ 10:37:29\n",
      "Accuracy: 0.9969 - Precision: 0.8570 - Recall: 0.8694 - Specificity: 0.9986 - F1: 0.8504 - Loss: 0.1707\n",
      "\n",
      "Batch 88/387 ━━━━━━━━━━━━━━━━━━━━ 10:38:52\n",
      "Accuracy: 0.9969 - Precision: 0.8566 - Recall: 0.8708 - Specificity: 0.9986 - F1: 0.8510 - Loss: 0.1700\n",
      "\n",
      "Batch 89/387 ━━━━━━━━━━━━━━━━━━━━ 10:40:13\n",
      "Accuracy: 0.9970 - Precision: 0.8581 - Recall: 0.8712 - Specificity: 0.9986 - F1: 0.8521 - Loss: 0.1688\n",
      "\n",
      "Batch 90/387 ━━━━━━━━━━━━━━━━━━━━ 10:41:51\n",
      "Accuracy: 0.9970 - Precision: 0.8596 - Recall: 0.8709 - Specificity: 0.9986 - F1: 0.8527 - Loss: 0.1680\n",
      "\n",
      "Batch 91/387 ━━━━━━━━━━━━━━━━━━━━ 10:43:16\n",
      "Accuracy: 0.9970 - Precision: 0.8603 - Recall: 0.8704 - Specificity: 0.9986 - F1: 0.8529 - Loss: 0.1678\n",
      "\n",
      "Batch 92/387 ━━━━━━━━━━━━━━━━━━━━ 10:44:42\n",
      "Accuracy: 0.9970 - Precision: 0.8602 - Recall: 0.8686 - Specificity: 0.9986 - F1: 0.8520 - Loss: 0.1687\n",
      "\n",
      "Batch 93/387 ━━━━━━━━━━━━━━━━━━━━ 10:46:05\n",
      "Accuracy: 0.9970 - Precision: 0.8590 - Recall: 0.8683 - Specificity: 0.9986 - F1: 0.8514 - Loss: 0.1693\n",
      "\n",
      "Batch 94/387 ━━━━━━━━━━━━━━━━━━━━ 10:47:31\n",
      "Accuracy: 0.9970 - Precision: 0.8605 - Recall: 0.8677 - Specificity: 0.9986 - F1: 0.8518 - Loss: 0.1689\n",
      "\n",
      "Batch 95/387 ━━━━━━━━━━━━━━━━━━━━ 10:48:50\n",
      "Accuracy: 0.9970 - Precision: 0.8618 - Recall: 0.8663 - Specificity: 0.9987 - F1: 0.8518 - Loss: 0.1690\n",
      "\n",
      "Batch 96/387 ━━━━━━━━━━━━━━━━━━━━ 10:50:05\n",
      "Accuracy: 0.9970 - Precision: 0.8620 - Recall: 0.8669 - Specificity: 0.9987 - F1: 0.8523 - Loss: 0.1685\n",
      "\n",
      "Batch 97/387 ━━━━━━━━━━━━━━━━━━━━ 10:51:29\n",
      "Accuracy: 0.9970 - Precision: 0.8602 - Recall: 0.8675 - Specificity: 0.9987 - F1: 0.8516 - Loss: 0.1691\n",
      "\n",
      "Batch 98/387 ━━━━━━━━━━━━━━━━━━━━ 10:52:56\n",
      "Accuracy: 0.9970 - Precision: 0.8594 - Recall: 0.8679 - Specificity: 0.9987 - F1: 0.8515 - Loss: 0.1692\n",
      "\n",
      "Batch 99/387 ━━━━━━━━━━━━━━━━━━━━ 10:54:17\n",
      "Accuracy: 0.9970 - Precision: 0.8585 - Recall: 0.8681 - Specificity: 0.9987 - F1: 0.8513 - Loss: 0.1694\n",
      "\n",
      "Batch 100/387 ━━━━━━━━━━━━━━━━━━━━ 10:55:49\n",
      "Accuracy: 0.9971 - Precision: 0.8599 - Recall: 0.8681 - Specificity: 0.9987 - F1: 0.8520 - Loss: 0.1686\n",
      "\n",
      "Batch 101/387 ━━━━━━━━━━━━━━━━━━━━ 10:57:12\n",
      "Accuracy: 0.9971 - Precision: 0.8610 - Recall: 0.8684 - Specificity: 0.9987 - F1: 0.8528 - Loss: 0.1677\n",
      "\n",
      "Batch 102/387 ━━━━━━━━━━━━━━━━━━━━ 10:58:38\n",
      "Accuracy: 0.9971 - Precision: 0.8607 - Recall: 0.8691 - Specificity: 0.9987 - F1: 0.8531 - Loss: 0.1674\n",
      "\n",
      "Batch 103/387 ━━━━━━━━━━━━━━━━━━━━ 11:00:09\n",
      "Accuracy: 0.9970 - Precision: 0.8620 - Recall: 0.8664 - Specificity: 0.9987 - F1: 0.8520 - Loss: 0.1690\n",
      "\n",
      "Batch 104/387 ━━━━━━━━━━━━━━━━━━━━ 11:01:30\n",
      "Accuracy: 0.9970 - Precision: 0.8633 - Recall: 0.8650 - Specificity: 0.9987 - F1: 0.8518 - Loss: 0.1692\n",
      "\n",
      "Batch 105/387 ━━━━━━━━━━━━━━━━━━━━ 11:02:58\n",
      "Accuracy: 0.9970 - Precision: 0.8634 - Recall: 0.8657 - Specificity: 0.9987 - F1: 0.8523 - Loss: 0.1687\n",
      "\n",
      "Batch 106/387 ━━━━━━━━━━━━━━━━━━━━ 11:04:22\n",
      "Accuracy: 0.9970 - Precision: 0.8633 - Recall: 0.8664 - Specificity: 0.9987 - F1: 0.8527 - Loss: 0.1682\n",
      "\n",
      "Batch 107/387 ━━━━━━━━━━━━━━━━━━━━ 11:05:42\n",
      "Accuracy: 0.9970 - Precision: 0.8639 - Recall: 0.8673 - Specificity: 0.9987 - F1: 0.8536 - Loss: 0.1672\n",
      "\n",
      "Batch 108/387 ━━━━━━━━━━━━━━━━━━━━ 11:07:02\n",
      "Accuracy: 0.9970 - Precision: 0.8642 - Recall: 0.8680 - Specificity: 0.9987 - F1: 0.8542 - Loss: 0.1665\n",
      "\n",
      "Batch 109/387 ━━━━━━━━━━━━━━━━━━━━ 11:08:25\n",
      "Accuracy: 0.9970 - Precision: 0.8642 - Recall: 0.8689 - Specificity: 0.9987 - F1: 0.8547 - Loss: 0.1660\n",
      "\n",
      "Batch 110/387 ━━━━━━━━━━━━━━━━━━━━ 11:09:37\n",
      "Accuracy: 0.9970 - Precision: 0.8647 - Recall: 0.8696 - Specificity: 0.9987 - F1: 0.8554 - Loss: 0.1652\n",
      "\n",
      "Batch 111/387 ━━━━━━━━━━━━━━━━━━━━ 11:11:00\n",
      "Accuracy: 0.9970 - Precision: 0.8652 - Recall: 0.8704 - Specificity: 0.9987 - F1: 0.8562 - Loss: 0.1644\n",
      "\n",
      "Batch 112/387 ━━━━━━━━━━━━━━━━━━━━ 11:12:26\n",
      "Accuracy: 0.9970 - Precision: 0.8658 - Recall: 0.8712 - Specificity: 0.9987 - F1: 0.8570 - Loss: 0.1635\n",
      "\n",
      "Batch 113/387 ━━━━━━━━━━━━━━━━━━━━ 11:13:56\n",
      "Accuracy: 0.9970 - Precision: 0.8657 - Recall: 0.8720 - Specificity: 0.9987 - F1: 0.8574 - Loss: 0.1631\n",
      "\n",
      "Batch 114/387 ━━━━━━━━━━━━━━━━━━━━ 11:15:16\n",
      "Accuracy: 0.9971 - Precision: 0.8655 - Recall: 0.8730 - Specificity: 0.9987 - F1: 0.8578 - Loss: 0.1627\n",
      "\n",
      "Batch 115/387 ━━━━━━━━━━━━━━━━━━━━ 11:16:38\n",
      "Accuracy: 0.9970 - Precision: 0.8626 - Recall: 0.8735 - Specificity: 0.9987 - F1: 0.8563 - Loss: 0.1643\n",
      "\n",
      "Batch 116/387 ━━━━━━━━━━━━━━━━━━━━ 11:18:00\n",
      "Accuracy: 0.9970 - Precision: 0.8635 - Recall: 0.8738 - Specificity: 0.9987 - F1: 0.8570 - Loss: 0.1636\n",
      "\n",
      "Batch 117/387 ━━━━━━━━━━━━━━━━━━━━ 11:19:21\n",
      "Accuracy: 0.9971 - Precision: 0.8635 - Recall: 0.8746 - Specificity: 0.9987 - F1: 0.8575 - Loss: 0.1630\n",
      "\n",
      "Batch 118/387 ━━━━━━━━━━━━━━━━━━━━ 11:20:46\n",
      "Accuracy: 0.9970 - Precision: 0.8639 - Recall: 0.8721 - Specificity: 0.9987 - F1: 0.8562 - Loss: 0.1645\n",
      "\n",
      "Batch 119/387 ━━━━━━━━━━━━━━━━━━━━ 11:22:06\n",
      "Accuracy: 0.9970 - Precision: 0.8606 - Recall: 0.8698 - Specificity: 0.9987 - F1: 0.8535 - Loss: 0.1672\n",
      "\n",
      "Batch 120/387 ━━━━━━━━━━━━━━━━━━━━ 11:23:18\n",
      "Accuracy: 0.9970 - Precision: 0.8610 - Recall: 0.8686 - Specificity: 0.9987 - F1: 0.8530 - Loss: 0.1676\n",
      "\n",
      "Batch 121/387 ━━━━━━━━━━━━━━━━━━━━ 11:24:37\n",
      "Accuracy: 0.9970 - Precision: 0.8615 - Recall: 0.8676 - Specificity: 0.9987 - F1: 0.8528 - Loss: 0.1678\n",
      "\n",
      "Batch 122/387 ━━━━━━━━━━━━━━━━━━━━ 11:25:52\n",
      "Accuracy: 0.9970 - Precision: 0.8623 - Recall: 0.8654 - Specificity: 0.9987 - F1: 0.8519 - Loss: 0.1688\n",
      "\n",
      "Batch 123/387 ━━━━━━━━━━━━━━━━━━━━ 11:27:11\n",
      "Accuracy: 0.9970 - Precision: 0.8634 - Recall: 0.8635 - Specificity: 0.9987 - F1: 0.8513 - Loss: 0.1697\n",
      "\n",
      "Batch 124/387 ━━━━━━━━━━━━━━━━━━━━ 11:28:33\n",
      "Accuracy: 0.9970 - Precision: 0.8614 - Recall: 0.8629 - Specificity: 0.9987 - F1: 0.8500 - Loss: 0.1710\n",
      "\n",
      "Batch 125/387 ━━━━━━━━━━━━━━━━━━━━ 11:29:54\n",
      "Accuracy: 0.9970 - Precision: 0.8617 - Recall: 0.8640 - Specificity: 0.9987 - F1: 0.8507 - Loss: 0.1702\n",
      "\n",
      "Batch 126/387 ━━━━━━━━━━━━━━━━━━━━ 11:31:12\n",
      "Accuracy: 0.9970 - Precision: 0.8626 - Recall: 0.8641 - Specificity: 0.9987 - F1: 0.8513 - Loss: 0.1696\n",
      "\n",
      "Batch 127/387 ━━━━━━━━━━━━━━━━━━━━ 11:32:35\n",
      "Accuracy: 0.9970 - Precision: 0.8632 - Recall: 0.8650 - Specificity: 0.9987 - F1: 0.8521 - Loss: 0.1687\n",
      "\n",
      "Batch 128/387 ━━━━━━━━━━━━━━━━━━━━ 11:33:57\n",
      "Accuracy: 0.9970 - Precision: 0.8616 - Recall: 0.8660 - Specificity: 0.9987 - F1: 0.8517 - Loss: 0.1691\n",
      "\n",
      "Batch 129/387 ━━━━━━━━━━━━━━━━━━━━ 11:35:24\n",
      "Accuracy: 0.9971 - Precision: 0.8620 - Recall: 0.8663 - Specificity: 0.9987 - F1: 0.8521 - Loss: 0.1686\n",
      "\n",
      "Batch 130/387 ━━━━━━━━━━━━━━━━━━━━ 11:36:46\n",
      "Accuracy: 0.9971 - Precision: 0.8616 - Recall: 0.8670 - Specificity: 0.9987 - F1: 0.8523 - Loss: 0.1683\n",
      "\n",
      "Batch 131/387 ━━━━━━━━━━━━━━━━━━━━ 11:38:13\n",
      "Accuracy: 0.9970 - Precision: 0.8608 - Recall: 0.8678 - Specificity: 0.9987 - F1: 0.8523 - Loss: 0.1684\n",
      "\n",
      "Batch 132/387 ━━━━━━━━━━━━━━━━━━━━ 11:39:37\n",
      "Accuracy: 0.9970 - Precision: 0.8615 - Recall: 0.8678 - Specificity: 0.9987 - F1: 0.8527 - Loss: 0.1680\n",
      "\n",
      "Batch 133/387 ━━━━━━━━━━━━━━━━━━━━ 11:40:59\n",
      "Accuracy: 0.9970 - Precision: 0.8621 - Recall: 0.8673 - Specificity: 0.9987 - F1: 0.8528 - Loss: 0.1678\n",
      "\n",
      "Batch 134/387 ━━━━━━━━━━━━━━━━━━━━ 11:42:13\n",
      "Accuracy: 0.9970 - Precision: 0.8603 - Recall: 0.8680 - Specificity: 0.9987 - F1: 0.8521 - Loss: 0.1687\n",
      "\n",
      "Batch 135/387 ━━━━━━━━━━━━━━━━━━━━ 11:43:42\n",
      "Accuracy: 0.9970 - Precision: 0.8610 - Recall: 0.8676 - Specificity: 0.9987 - F1: 0.8523 - Loss: 0.1687\n",
      "\n",
      "Batch 136/387 ━━━━━━━━━━━━━━━━━━━━ 11:45:02\n",
      "Accuracy: 0.9970 - Precision: 0.8590 - Recall: 0.8679 - Specificity: 0.9987 - F1: 0.8513 - Loss: 0.1697\n",
      "\n",
      "Batch 137/387 ━━━━━━━━━━━━━━━━━━━━ 11:46:17\n",
      "Accuracy: 0.9970 - Precision: 0.8597 - Recall: 0.8670 - Specificity: 0.9987 - F1: 0.8511 - Loss: 0.1698\n",
      "\n",
      "Batch 138/387 ━━━━━━━━━━━━━━━━━━━━ 11:47:33\n",
      "Accuracy: 0.9970 - Precision: 0.8604 - Recall: 0.8668 - Specificity: 0.9987 - F1: 0.8514 - Loss: 0.1695\n",
      "\n",
      "Batch 139/387 ━━━━━━━━━━━━━━━━━━━━ 11:48:50\n",
      "Accuracy: 0.9970 - Precision: 0.8602 - Recall: 0.8668 - Specificity: 0.9987 - F1: 0.8515 - Loss: 0.1695\n",
      "\n",
      "Batch 140/387 ━━━━━━━━━━━━━━━━━━━━ 11:50:14\n",
      "Accuracy: 0.9970 - Precision: 0.8611 - Recall: 0.8668 - Specificity: 0.9987 - F1: 0.8520 - Loss: 0.1689\n",
      "\n",
      "Batch 141/387 ━━━━━━━━━━━━━━━━━━━━ 11:51:40\n",
      "Accuracy: 0.9970 - Precision: 0.8609 - Recall: 0.8677 - Specificity: 0.9987 - F1: 0.8523 - Loss: 0.1684\n",
      "\n",
      "Batch 142/387 ━━━━━━━━━━━━━━━━━━━━ 11:52:55\n",
      "Accuracy: 0.9971 - Precision: 0.8617 - Recall: 0.8673 - Specificity: 0.9987 - F1: 0.8526 - Loss: 0.1681\n",
      "\n",
      "Batch 143/387 ━━━━━━━━━━━━━━━━━━━━ 11:54:33\n",
      "Accuracy: 0.9971 - Precision: 0.8626 - Recall: 0.8671 - Specificity: 0.9987 - F1: 0.8529 - Loss: 0.1677\n",
      "\n",
      "Batch 144/387 ━━━━━━━━━━━━━━━━━━━━ 11:55:58\n",
      "Accuracy: 0.9970 - Precision: 0.8636 - Recall: 0.8650 - Specificity: 0.9987 - F1: 0.8520 - Loss: 0.1688\n",
      "\n",
      "Batch 145/387 ━━━━━━━━━━━━━━━━━━━━ 11:57:17\n",
      "Accuracy: 0.9970 - Precision: 0.8643 - Recall: 0.8629 - Specificity: 0.9987 - F1: 0.8511 - Loss: 0.1698\n",
      "\n",
      "Batch 146/387 ━━━━━━━━━━━━━━━━━━━━ 11:58:42\n",
      "Accuracy: 0.9970 - Precision: 0.8625 - Recall: 0.8622 - Specificity: 0.9987 - F1: 0.8498 - Loss: 0.1710\n",
      "\n",
      "Batch 147/387 ━━━━━━━━━━━━━━━━━━━━ 12:00:10\n",
      "Accuracy: 0.9970 - Precision: 0.8629 - Recall: 0.8623 - Specificity: 0.9988 - F1: 0.8502 - Loss: 0.1706\n",
      "\n",
      "Batch 148/387 ━━━━━━━━━━━━━━━━━━━━ 12:01:35\n",
      "Accuracy: 0.9971 - Precision: 0.8623 - Recall: 0.8629 - Specificity: 0.9988 - F1: 0.8502 - Loss: 0.1706\n",
      "\n",
      "Batch 149/387 ━━━━━━━━━━━━━━━━━━━━ 12:03:06\n",
      "Accuracy: 0.9970 - Precision: 0.8630 - Recall: 0.8617 - Specificity: 0.9988 - F1: 0.8499 - Loss: 0.1709\n",
      "\n",
      "Batch 150/387 ━━━━━━━━━━━━━━━━━━━━ 12:04:37\n",
      "Accuracy: 0.9970 - Precision: 0.8635 - Recall: 0.8591 - Specificity: 0.9988 - F1: 0.8484 - Loss: 0.1727\n",
      "\n",
      "Batch 151/387 ━━━━━━━━━━━━━━━━━━━━ 12:06:09\n",
      "Accuracy: 0.9970 - Precision: 0.8638 - Recall: 0.8599 - Specificity: 0.9988 - F1: 0.8490 - Loss: 0.1719\n",
      "\n",
      "Batch 152/387 ━━━━━━━━━━━━━━━━━━━━ 12:07:40\n",
      "Accuracy: 0.9970 - Precision: 0.8644 - Recall: 0.8606 - Specificity: 0.9988 - F1: 0.8497 - Loss: 0.1711\n",
      "\n",
      "Batch 153/387 ━━━━━━━━━━━━━━━━━━━━ 12:09:10\n",
      "Accuracy: 0.9970 - Precision: 0.8636 - Recall: 0.8611 - Specificity: 0.9988 - F1: 0.8496 - Loss: 0.1713\n",
      "\n",
      "Batch 154/387 ━━━━━━━━━━━━━━━━━━━━ 12:10:44\n",
      "Accuracy: 0.9970 - Precision: 0.8634 - Recall: 0.8617 - Specificity: 0.9987 - F1: 0.8499 - Loss: 0.1710\n",
      "\n",
      "Batch 155/387 ━━━━━━━━━━━━━━━━━━━━ 12:12:28\n",
      "Accuracy: 0.9970 - Precision: 0.8638 - Recall: 0.8624 - Specificity: 0.9987 - F1: 0.8505 - Loss: 0.1703\n",
      "\n",
      "Batch 156/387 ━━━━━━━━━━━━━━━━━━━━ 12:14:11\n",
      "Accuracy: 0.9970 - Precision: 0.8640 - Recall: 0.8632 - Specificity: 0.9987 - F1: 0.8511 - Loss: 0.1697\n",
      "\n",
      "Batch 157/387 ━━━━━━━━━━━━━━━━━━━━ 12:15:59\n",
      "Accuracy: 0.9970 - Precision: 0.8632 - Recall: 0.8640 - Specificity: 0.9987 - F1: 0.8510 - Loss: 0.1698\n",
      "\n",
      "Batch 158/387 ━━━━━━━━━━━━━━━━━━━━ 12:17:38\n",
      "Accuracy: 0.9970 - Precision: 0.8626 - Recall: 0.8632 - Specificity: 0.9987 - F1: 0.8504 - Loss: 0.1705\n",
      "\n",
      "Batch 159/387 ━━━━━━━━━━━━━━━━━━━━ 12:19:26\n",
      "Accuracy: 0.9970 - Precision: 0.8627 - Recall: 0.8637 - Specificity: 0.9987 - F1: 0.8508 - Loss: 0.1701\n",
      "\n",
      "Batch 160/387 ━━━━━━━━━━━━━━━━━━━━ 12:20:59\n",
      "Accuracy: 0.9970 - Precision: 0.8611 - Recall: 0.8632 - Specificity: 0.9987 - F1: 0.8497 - Loss: 0.1712\n",
      "\n",
      "Batch 161/387 ━━━━━━━━━━━━━━━━━━━━ 12:22:40\n",
      "Accuracy: 0.9970 - Precision: 0.8613 - Recall: 0.8623 - Specificity: 0.9987 - F1: 0.8494 - Loss: 0.1717\n",
      "\n",
      "Batch 162/387 ━━━━━━━━━━━━━━━━━━━━ 12:24:25\n",
      "Accuracy: 0.9970 - Precision: 0.8593 - Recall: 0.8627 - Specificity: 0.9987 - F1: 0.8483 - Loss: 0.1728\n",
      "\n",
      "Batch 163/387 ━━━━━━━━━━━━━━━━━━━━ 12:26:01\n",
      "Accuracy: 0.9970 - Precision: 0.8599 - Recall: 0.8633 - Specificity: 0.9987 - F1: 0.8490 - Loss: 0.1720\n",
      "\n",
      "Batch 164/387 ━━━━━━━━━━━━━━━━━━━━ 12:27:39\n",
      "Accuracy: 0.9970 - Precision: 0.8580 - Recall: 0.8640 - Specificity: 0.9987 - F1: 0.8482 - Loss: 0.1729\n",
      "\n",
      "Batch 165/387 ━━━━━━━━━━━━━━━━━━━━ 12:29:11\n",
      "Accuracy: 0.9970 - Precision: 0.8571 - Recall: 0.8644 - Specificity: 0.9987 - F1: 0.8479 - Loss: 0.1731\n",
      "\n",
      "Batch 166/387 ━━━━━━━━━━━━━━━━━━━━ 12:30:35\n",
      "Accuracy: 0.9970 - Precision: 0.8577 - Recall: 0.8641 - Specificity: 0.9987 - F1: 0.8481 - Loss: 0.1729\n",
      "\n",
      "Batch 167/387 ━━━━━━━━━━━━━━━━━━━━ 12:32:19\n",
      "Accuracy: 0.9970 - Precision: 0.8578 - Recall: 0.8648 - Specificity: 0.9987 - F1: 0.8485 - Loss: 0.1724\n",
      "\n",
      "Batch 168/387 ━━━━━━━━━━━━━━━━━━━━ 12:33:54\n",
      "Accuracy: 0.9969 - Precision: 0.8586 - Recall: 0.8597 - Specificity: 0.9987 - F1: 0.8435 - Loss: 0.1784\n",
      "\n",
      "Batch 169/387 ━━━━━━━━━━━━━━━━━━━━ 12:35:21\n",
      "Accuracy: 0.9969 - Precision: 0.8535 - Recall: 0.8546 - Specificity: 0.9987 - F1: 0.8385 - Loss: 0.1833\n",
      "\n",
      "Batch 170/387 ━━━━━━━━━━━━━━━━━━━━ 12:36:54\n",
      "Accuracy: 0.9969 - Precision: 0.8543 - Recall: 0.8544 - Specificity: 0.9987 - F1: 0.8388 - Loss: 0.1829\n",
      "\n",
      "Batch 171/387 ━━━━━━━━━━━━━━━━━━━━ 12:38:21\n",
      "Accuracy: 0.9969 - Precision: 0.8550 - Recall: 0.8540 - Specificity: 0.9987 - F1: 0.8390 - Loss: 0.1827\n",
      "\n",
      "Batch 172/387 ━━━━━━━━━━━━━━━━━━━━ 12:39:51\n",
      "Accuracy: 0.9969 - Precision: 0.8555 - Recall: 0.8530 - Specificity: 0.9987 - F1: 0.8388 - Loss: 0.1829\n",
      "\n",
      "Batch 173/387 ━━━━━━━━━━━━━━━━━━━━ 12:41:30\n",
      "Accuracy: 0.9969 - Precision: 0.8563 - Recall: 0.8504 - Specificity: 0.9987 - F1: 0.8372 - Loss: 0.1846\n",
      "\n",
      "Batch 174/387 ━━━━━━━━━━━━━━━━━━━━ 12:43:02\n",
      "Accuracy: 0.9969 - Precision: 0.8571 - Recall: 0.8498 - Specificity: 0.9987 - F1: 0.8373 - Loss: 0.1845\n",
      "\n",
      "Batch 175/387 ━━━━━━━━━━━━━━━━━━━━ 12:44:35\n",
      "Accuracy: 0.9970 - Precision: 0.8579 - Recall: 0.8497 - Specificity: 0.9987 - F1: 0.8377 - Loss: 0.1840\n",
      "\n",
      "Batch 176/387 ━━━━━━━━━━━━━━━━━━━━ 12:46:10\n",
      "Accuracy: 0.9970 - Precision: 0.8585 - Recall: 0.8485 - Specificity: 0.9987 - F1: 0.8373 - Loss: 0.1846\n",
      "\n",
      "Batch 177/387 ━━━━━━━━━━━━━━━━━━━━ 12:47:39\n",
      "Accuracy: 0.9970 - Precision: 0.8587 - Recall: 0.8487 - Specificity: 0.9987 - F1: 0.8376 - Loss: 0.1843\n",
      "\n",
      "Batch 178/387 ━━━━━━━━━━━━━━━━━━━━ 12:48:57\n",
      "Accuracy: 0.9970 - Precision: 0.8594 - Recall: 0.8483 - Specificity: 0.9987 - F1: 0.8378 - Loss: 0.1841\n",
      "\n",
      "Batch 179/387 ━━━━━━━━━━━━━━━━━━━━ 12:50:26\n",
      "Accuracy: 0.9970 - Precision: 0.8570 - Recall: 0.8485 - Specificity: 0.9987 - F1: 0.8363 - Loss: 0.1857\n",
      "\n",
      "Batch 180/387 ━━━━━━━━━━━━━━━━━━━━ 12:51:49\n",
      "Accuracy: 0.9970 - Precision: 0.8575 - Recall: 0.8468 - Specificity: 0.9987 - F1: 0.8355 - Loss: 0.1865\n",
      "\n",
      "Batch 181/387 ━━━━━━━━━━━━━━━━━━━━ 12:53:22\n",
      "Accuracy: 0.9970 - Precision: 0.8578 - Recall: 0.8473 - Specificity: 0.9987 - F1: 0.8359 - Loss: 0.1859\n",
      "\n",
      "Batch 182/387 ━━━━━━━━━━━━━━━━━━━━ 12:54:46\n",
      "Accuracy: 0.9970 - Precision: 0.8573 - Recall: 0.8473 - Specificity: 0.9987 - F1: 0.8358 - Loss: 0.1861\n",
      "\n",
      "Batch 183/387 ━━━━━━━━━━━━━━━━━━━━ 12:56:15\n",
      "Accuracy: 0.9970 - Precision: 0.8570 - Recall: 0.8449 - Specificity: 0.9988 - F1: 0.8342 - Loss: 0.1876\n",
      "\n",
      "Batch 184/387 ━━━━━━━━━━━━━━━━━━━━ 12:57:41\n",
      "Accuracy: 0.9970 - Precision: 0.8575 - Recall: 0.8450 - Specificity: 0.9988 - F1: 0.8346 - Loss: 0.1872\n",
      "\n",
      "Batch 185/387 ━━━━━━━━━━━━━━━━━━━━ 12:59:05\n",
      "Accuracy: 0.9970 - Precision: 0.8580 - Recall: 0.8448 - Specificity: 0.9988 - F1: 0.8348 - Loss: 0.1870\n",
      "\n",
      "Batch 186/387 ━━━━━━━━━━━━━━━━━━━━ 13:00:28\n",
      "Accuracy: 0.9970 - Precision: 0.8586 - Recall: 0.8452 - Specificity: 0.9988 - F1: 0.8353 - Loss: 0.1864\n",
      "\n",
      "Batch 187/387 ━━━━━━━━━━━━━━━━━━━━ 13:01:53\n",
      "Accuracy: 0.9970 - Precision: 0.8585 - Recall: 0.8460 - Specificity: 0.9988 - F1: 0.8358 - Loss: 0.1859\n",
      "\n",
      "Batch 188/387 ━━━━━━━━━━━━━━━━━━━━ 13:03:20\n",
      "Accuracy: 0.9970 - Precision: 0.8564 - Recall: 0.8468 - Specificity: 0.9987 - F1: 0.8347 - Loss: 0.1872\n",
      "\n",
      "Batch 189/387 ━━━━━━━━━━━━━━━━━━━━ 13:04:38\n",
      "Accuracy: 0.9970 - Precision: 0.8565 - Recall: 0.8474 - Specificity: 0.9987 - F1: 0.8351 - Loss: 0.1867\n",
      "\n",
      "Batch 190/387 ━━━━━━━━━━━━━━━━━━━━ 13:06:05\n",
      "Accuracy: 0.9970 - Precision: 0.8560 - Recall: 0.8482 - Specificity: 0.9987 - F1: 0.8353 - Loss: 0.1865\n",
      "\n",
      "Batch 191/387 ━━━━━━━━━━━━━━━━━━━━ 13:07:24\n",
      "Accuracy: 0.9970 - Precision: 0.8565 - Recall: 0.8486 - Specificity: 0.9987 - F1: 0.8358 - Loss: 0.1859\n",
      "\n",
      "Batch 192/387 ━━━━━━━━━━━━━━━━━━━━ 13:08:48\n",
      "Accuracy: 0.9970 - Precision: 0.8548 - Recall: 0.8493 - Specificity: 0.9987 - F1: 0.8351 - Loss: 0.1867\n",
      "\n",
      "Batch 193/387 ━━━━━━━━━━━━━━━━━━━━ 13:10:10\n",
      "Accuracy: 0.9970 - Precision: 0.8540 - Recall: 0.8499 - Specificity: 0.9987 - F1: 0.8349 - Loss: 0.1869\n",
      "\n",
      "Batch 194/387 ━━━━━━━━━━━━━━━━━━━━ 13:11:41\n",
      "Accuracy: 0.9970 - Precision: 0.8545 - Recall: 0.8501 - Specificity: 0.9987 - F1: 0.8353 - Loss: 0.1864\n",
      "\n",
      "Batch 195/387 ━━━━━━━━━━━━━━━━━━━━ 13:13:10\n",
      "Accuracy: 0.9970 - Precision: 0.8548 - Recall: 0.8478 - Specificity: 0.9987 - F1: 0.8340 - Loss: 0.1881\n",
      "\n",
      "Batch 196/387 ━━━━━━━━━━━━━━━━━━━━ 13:14:28\n",
      "Accuracy: 0.9970 - Precision: 0.8534 - Recall: 0.8484 - Specificity: 0.9987 - F1: 0.8334 - Loss: 0.1886\n",
      "\n",
      "Batch 197/387 ━━━━━━━━━━━━━━━━━━━━ 13:15:47\n",
      "Accuracy: 0.9970 - Precision: 0.8527 - Recall: 0.8484 - Specificity: 0.9987 - F1: 0.8331 - Loss: 0.1889\n",
      "\n",
      "Batch 198/387 ━━━━━━━━━━━━━━━━━━━━ 13:17:09\n",
      "Accuracy: 0.9970 - Precision: 0.8534 - Recall: 0.8478 - Specificity: 0.9987 - F1: 0.8331 - Loss: 0.1890\n",
      "\n",
      "Batch 199/387 ━━━━━━━━━━━━━━━━━━━━ 13:18:33\n",
      "Accuracy: 0.9970 - Precision: 0.8541 - Recall: 0.8480 - Specificity: 0.9987 - F1: 0.8336 - Loss: 0.1885\n",
      "\n",
      "Batch 200/387 ━━━━━━━━━━━━━━━━━━━━ 13:19:54\n",
      "Accuracy: 0.9970 - Precision: 0.8544 - Recall: 0.8478 - Specificity: 0.9987 - F1: 0.8338 - Loss: 0.1883\n",
      "\n",
      "Batch 201/387 ━━━━━━━━━━━━━━━━━━━━ 13:21:19\n",
      "Accuracy: 0.9970 - Precision: 0.8551 - Recall: 0.8458 - Specificity: 0.9987 - F1: 0.8326 - Loss: 0.1896\n",
      "\n",
      "Batch 202/387 ━━━━━━━━━━━━━━━━━━━━ 13:22:38\n",
      "Accuracy: 0.9970 - Precision: 0.8557 - Recall: 0.8460 - Specificity: 0.9987 - F1: 0.8331 - Loss: 0.1890\n",
      "\n",
      "Batch 203/387 ━━━━━━━━━━━━━━━━━━━━ 13:24:05\n",
      "Accuracy: 0.9970 - Precision: 0.8562 - Recall: 0.8463 - Specificity: 0.9987 - F1: 0.8336 - Loss: 0.1885\n",
      "\n",
      "Batch 204/387 ━━━━━━━━━━━━━━━━━━━━ 13:25:27\n",
      "Accuracy: 0.9970 - Precision: 0.8568 - Recall: 0.8460 - Specificity: 0.9988 - F1: 0.8338 - Loss: 0.1883\n",
      "\n",
      "Batch 205/387 ━━━━━━━━━━━━━━━━━━━━ 13:26:50\n",
      "Accuracy: 0.9970 - Precision: 0.8573 - Recall: 0.8463 - Specificity: 0.9988 - F1: 0.8343 - Loss: 0.1877\n",
      "\n",
      "Batch 206/387 ━━━━━━━━━━━━━━━━━━━━ 13:28:20\n",
      "Accuracy: 0.9969 - Precision: 0.8566 - Recall: 0.8445 - Specificity: 0.9987 - F1: 0.8330 - Loss: 0.1893\n",
      "\n",
      "Batch 207/387 ━━━━━━━━━━━━━━━━━━━━ 13:29:50\n",
      "Accuracy: 0.9969 - Precision: 0.8566 - Recall: 0.8442 - Specificity: 0.9987 - F1: 0.8330 - Loss: 0.1894\n",
      "\n",
      "Batch 208/387 ━━━━━━━━━━━━━━━━━━━━ 13:31:12\n",
      "Accuracy: 0.9969 - Precision: 0.8568 - Recall: 0.8438 - Specificity: 0.9987 - F1: 0.8329 - Loss: 0.1895\n",
      "\n",
      "Batch 209/387 ━━━━━━━━━━━━━━━━━━━━ 13:32:42\n",
      "Accuracy: 0.9969 - Precision: 0.8566 - Recall: 0.8441 - Specificity: 0.9987 - F1: 0.8330 - Loss: 0.1895\n",
      "\n",
      "Batch 210/387 ━━━━━━━━━━━━━━━━━━━━ 13:34:02\n",
      "Accuracy: 0.9969 - Precision: 0.8555 - Recall: 0.8448 - Specificity: 0.9987 - F1: 0.8328 - Loss: 0.1897\n",
      "\n",
      "Batch 211/387 ━━━━━━━━━━━━━━━━━━━━ 13:35:28\n",
      "Accuracy: 0.9969 - Precision: 0.8554 - Recall: 0.8454 - Specificity: 0.9987 - F1: 0.8330 - Loss: 0.1894\n",
      "\n",
      "Batch 212/387 ━━━━━━━━━━━━━━━━━━━━ 13:36:52\n",
      "Accuracy: 0.9969 - Precision: 0.8555 - Recall: 0.8461 - Specificity: 0.9987 - F1: 0.8335 - Loss: 0.1889\n",
      "\n",
      "Batch 213/387 ━━━━━━━━━━━━━━━━━━━━ 13:38:21\n",
      "Accuracy: 0.9969 - Precision: 0.8534 - Recall: 0.8468 - Specificity: 0.9987 - F1: 0.8323 - Loss: 0.1902\n",
      "\n",
      "Batch 214/387 ━━━━━━━━━━━━━━━━━━━━ 13:39:43\n",
      "Accuracy: 0.9969 - Precision: 0.8533 - Recall: 0.8474 - Specificity: 0.9987 - F1: 0.8326 - Loss: 0.1898\n",
      "\n",
      "Batch 215/387 ━━━━━━━━━━━━━━━━━━━━ 13:41:11\n",
      "Accuracy: 0.9969 - Precision: 0.8528 - Recall: 0.8479 - Specificity: 0.9987 - F1: 0.8326 - Loss: 0.1898\n",
      "\n",
      "Batch 216/387 ━━━━━━━━━━━━━━━━━━━━ 13:42:33\n",
      "Accuracy: 0.9969 - Precision: 0.8517 - Recall: 0.8480 - Specificity: 0.9987 - F1: 0.8321 - Loss: 0.1904\n",
      "\n",
      "Batch 217/387 ━━━━━━━━━━━━━━━━━━━━ 13:44:00\n",
      "Accuracy: 0.9969 - Precision: 0.8519 - Recall: 0.8482 - Specificity: 0.9987 - F1: 0.8323 - Loss: 0.1901\n",
      "\n",
      "Batch 218/387 ━━━━━━━━━━━━━━━━━━━━ 13:45:22\n",
      "Accuracy: 0.9969 - Precision: 0.8520 - Recall: 0.8487 - Specificity: 0.9987 - F1: 0.8328 - Loss: 0.1896\n",
      "\n",
      "Batch 219/387 ━━━━━━━━━━━━━━━━━━━━ 13:47:06\n",
      "Accuracy: 0.9969 - Precision: 0.8526 - Recall: 0.8492 - Specificity: 0.9987 - F1: 0.8334 - Loss: 0.1889\n",
      "\n",
      "Batch 220/387 ━━━━━━━━━━━━━━━━━━━━ 13:48:34\n",
      "Accuracy: 0.9969 - Precision: 0.8531 - Recall: 0.8489 - Specificity: 0.9987 - F1: 0.8335 - Loss: 0.1888\n",
      "\n",
      "Batch 221/387 ━━━━━━━━━━━━━━━━━━━━ 13:50:09\n",
      "Accuracy: 0.9969 - Precision: 0.8532 - Recall: 0.8493 - Specificity: 0.9987 - F1: 0.8338 - Loss: 0.1885\n",
      "\n",
      "Batch 222/387 ━━━━━━━━━━━━━━━━━━━━ 13:51:38\n",
      "Accuracy: 0.9969 - Precision: 0.8537 - Recall: 0.8494 - Specificity: 0.9987 - F1: 0.8342 - Loss: 0.1880\n",
      "\n",
      "Batch 223/387 ━━━━━━━━━━━━━━━━━━━━ 13:53:18\n",
      "Accuracy: 0.9969 - Precision: 0.8542 - Recall: 0.8494 - Specificity: 0.9987 - F1: 0.8345 - Loss: 0.1877\n",
      "\n",
      "Batch 224/387 ━━━━━━━━━━━━━━━━━━━━ 13:54:50\n",
      "Accuracy: 0.9969 - Precision: 0.8541 - Recall: 0.8490 - Specificity: 0.9987 - F1: 0.8343 - Loss: 0.1879\n",
      "\n",
      "Batch 225/387 ━━━━━━━━━━━━━━━━━━━━ 13:56:29\n",
      "Accuracy: 0.9969 - Precision: 0.8514 - Recall: 0.8482 - Specificity: 0.9987 - F1: 0.8323 - Loss: 0.1901\n",
      "\n",
      "Batch 226/387 ━━━━━━━━━━━━━━━━━━━━ 13:57:51\n",
      "Accuracy: 0.9969 - Precision: 0.8520 - Recall: 0.8480 - Specificity: 0.9987 - F1: 0.8324 - Loss: 0.1900\n",
      "\n",
      "Batch 227/387 ━━━━━━━━━━━━━━━━━━━━ 13:59:07\n",
      "Accuracy: 0.9969 - Precision: 0.8524 - Recall: 0.8482 - Specificity: 0.9987 - F1: 0.8329 - Loss: 0.1895\n",
      "\n",
      "Batch 228/387 ━━━━━━━━━━━━━━━━━━━━ 14:00:31\n",
      "Accuracy: 0.9969 - Precision: 0.8519 - Recall: 0.8479 - Specificity: 0.9987 - F1: 0.8325 - Loss: 0.1898\n",
      "\n",
      "Batch 229/387 ━━━━━━━━━━━━━━━━━━━━ 14:02:07\n",
      "Accuracy: 0.9969 - Precision: 0.8524 - Recall: 0.8482 - Specificity: 0.9987 - F1: 0.8330 - Loss: 0.1893\n",
      "\n",
      "Batch 230/387 ━━━━━━━━━━━━━━━━━━━━ 14:03:31\n",
      "Accuracy: 0.9969 - Precision: 0.8530 - Recall: 0.8477 - Specificity: 0.9987 - F1: 0.8331 - Loss: 0.1893\n",
      "\n",
      "Batch 231/387 ━━━━━━━━━━━━━━━━━━━━ 14:05:02\n",
      "Accuracy: 0.9969 - Precision: 0.8534 - Recall: 0.8483 - Specificity: 0.9987 - F1: 0.8336 - Loss: 0.1887\n",
      "\n",
      "Batch 232/387 ━━━━━━━━━━━━━━━━━━━━ 14:06:34\n",
      "Accuracy: 0.9969 - Precision: 0.8533 - Recall: 0.8483 - Specificity: 0.9987 - F1: 0.8336 - Loss: 0.1886\n",
      "\n",
      "Batch 233/387 ━━━━━━━━━━━━━━━━━━━━ 14:07:52\n",
      "Accuracy: 0.9969 - Precision: 0.8518 - Recall: 0.8482 - Specificity: 0.9987 - F1: 0.8327 - Loss: 0.1895\n",
      "\n",
      "Batch 234/387 ━━━━━━━━━━━━━━━━━━━━ 14:09:19\n",
      "Accuracy: 0.9969 - Precision: 0.8519 - Recall: 0.8485 - Specificity: 0.9987 - F1: 0.8330 - Loss: 0.1892\n",
      "\n",
      "Batch 235/387 ━━━━━━━━━━━━━━━━━━━━ 14:10:45\n",
      "Accuracy: 0.9969 - Precision: 0.8521 - Recall: 0.8489 - Specificity: 0.9987 - F1: 0.8334 - Loss: 0.1888\n",
      "\n",
      "Batch 236/387 ━━━━━━━━━━━━━━━━━━━━ 14:12:07\n",
      "Accuracy: 0.9969 - Precision: 0.8524 - Recall: 0.8483 - Specificity: 0.9987 - F1: 0.8333 - Loss: 0.1889\n",
      "\n",
      "Batch 237/387 ━━━━━━━━━━━━━━━━━━━━ 14:13:29\n",
      "Accuracy: 0.9969 - Precision: 0.8528 - Recall: 0.8488 - Specificity: 0.9987 - F1: 0.8338 - Loss: 0.1883\n",
      "\n",
      "Batch 238/387 ━━━━━━━━━━━━━━━━━━━━ 14:14:54\n",
      "Accuracy: 0.9969 - Precision: 0.8534 - Recall: 0.8487 - Specificity: 0.9987 - F1: 0.8340 - Loss: 0.1881\n",
      "\n",
      "Batch 239/387 ━━━━━━━━━━━━━━━━━━━━ 14:16:18\n",
      "Accuracy: 0.9969 - Precision: 0.8536 - Recall: 0.8482 - Specificity: 0.9987 - F1: 0.8339 - Loss: 0.1882\n",
      "\n",
      "Batch 240/387 ━━━━━━━━━━━━━━━━━━━━ 14:17:46\n",
      "Accuracy: 0.9969 - Precision: 0.8536 - Recall: 0.8481 - Specificity: 0.9987 - F1: 0.8339 - Loss: 0.1882\n",
      "\n",
      "Batch 241/387 ━━━━━━━━━━━━━━━━━━━━ 14:19:11\n",
      "Accuracy: 0.9969 - Precision: 0.8541 - Recall: 0.8481 - Specificity: 0.9987 - F1: 0.8342 - Loss: 0.1878\n",
      "\n",
      "Batch 242/387 ━━━━━━━━━━━━━━━━━━━━ 14:20:23\n",
      "Accuracy: 0.9969 - Precision: 0.8530 - Recall: 0.8486 - Specificity: 0.9987 - F1: 0.8338 - Loss: 0.1883\n",
      "\n",
      "Batch 243/387 ━━━━━━━━━━━━━━━━━━━━ 14:21:50\n",
      "Accuracy: 0.9969 - Precision: 0.8533 - Recall: 0.8490 - Specificity: 0.9987 - F1: 0.8343 - Loss: 0.1878\n",
      "\n",
      "Batch 244/387 ━━━━━━━━━━━━━━━━━━━━ 14:23:29\n",
      "Accuracy: 0.9969 - Precision: 0.8534 - Recall: 0.8486 - Specificity: 0.9987 - F1: 0.8341 - Loss: 0.1880\n",
      "\n",
      "Batch 245/387 ━━━━━━━━━━━━━━━━━━━━ 14:24:39\n",
      "Accuracy: 0.9969 - Precision: 0.8539 - Recall: 0.8485 - Specificity: 0.9987 - F1: 0.8344 - Loss: 0.1877\n",
      "\n",
      "Batch 246/387 ━━━━━━━━━━━━━━━━━━━━ 14:25:59\n",
      "Accuracy: 0.9969 - Precision: 0.8537 - Recall: 0.8489 - Specificity: 0.9987 - F1: 0.8345 - Loss: 0.1875\n",
      "\n",
      "Batch 247/387 ━━━━━━━━━━━━━━━━━━━━ 14:27:21\n",
      "Accuracy: 0.9969 - Precision: 0.8534 - Recall: 0.8490 - Specificity: 0.9987 - F1: 0.8344 - Loss: 0.1876\n",
      "\n",
      "Batch 248/387 ━━━━━━━━━━━━━━━━━━━━ 14:28:40\n",
      "Accuracy: 0.9969 - Precision: 0.8536 - Recall: 0.8494 - Specificity: 0.9987 - F1: 0.8348 - Loss: 0.1872\n",
      "\n",
      "Batch 249/387 ━━━━━━━━━━━━━━━━━━━━ 14:30:02\n",
      "Accuracy: 0.9969 - Precision: 0.8538 - Recall: 0.8497 - Specificity: 0.9987 - F1: 0.8352 - Loss: 0.1868\n",
      "\n",
      "Batch 250/387 ━━━━━━━━━━━━━━━━━━━━ 14:31:31\n",
      "Accuracy: 0.9969 - Precision: 0.8531 - Recall: 0.8500 - Specificity: 0.9987 - F1: 0.8349 - Loss: 0.1871\n",
      "\n",
      "Batch 251/387 ━━━━━━━━━━━━━━━━━━━━ 14:32:51\n",
      "Accuracy: 0.9969 - Precision: 0.8522 - Recall: 0.8504 - Specificity: 0.9987 - F1: 0.8346 - Loss: 0.1874\n",
      "\n",
      "Batch 252/387 ━━━━━━━━━━━━━━━━━━━━ 14:34:14\n",
      "Accuracy: 0.9969 - Precision: 0.8514 - Recall: 0.8504 - Specificity: 0.9987 - F1: 0.8342 - Loss: 0.1878\n",
      "\n",
      "Batch 253/387 ━━━━━━━━━━━━━━━━━━━━ 14:35:40\n",
      "Accuracy: 0.9969 - Precision: 0.8519 - Recall: 0.8504 - Specificity: 0.9987 - F1: 0.8345 - Loss: 0.1875\n",
      "\n",
      "Batch 254/387 ━━━━━━━━━━━━━━━━━━━━ 14:37:11\n",
      "Accuracy: 0.9969 - Precision: 0.8522 - Recall: 0.8500 - Specificity: 0.9987 - F1: 0.8345 - Loss: 0.1874\n",
      "\n",
      "Batch 255/387 ━━━━━━━━━━━━━━━━━━━━ 14:38:31\n",
      "Accuracy: 0.9969 - Precision: 0.8517 - Recall: 0.8493 - Specificity: 0.9987 - F1: 0.8340 - Loss: 0.1880\n",
      "\n",
      "Batch 256/387 ━━━━━━━━━━━━━━━━━━━━ 14:40:03\n",
      "Accuracy: 0.9969 - Precision: 0.8522 - Recall: 0.8491 - Specificity: 0.9987 - F1: 0.8342 - Loss: 0.1878\n",
      "\n",
      "Batch 257/387 ━━━━━━━━━━━━━━━━━━━━ 14:41:22\n",
      "Accuracy: 0.9969 - Precision: 0.8524 - Recall: 0.8492 - Specificity: 0.9987 - F1: 0.8344 - Loss: 0.1876\n",
      "\n",
      "Batch 258/387 ━━━━━━━━━━━━━━━━━━━━ 14:42:45\n",
      "Accuracy: 0.9969 - Precision: 0.8529 - Recall: 0.8486 - Specificity: 0.9987 - F1: 0.8343 - Loss: 0.1877\n",
      "\n",
      "Batch 259/387 ━━━━━━━━━━━━━━━━━━━━ 14:44:22\n",
      "Accuracy: 0.9969 - Precision: 0.8533 - Recall: 0.8486 - Specificity: 0.9987 - F1: 0.8346 - Loss: 0.1875\n",
      "\n",
      "Batch 260/387 ━━━━━━━━━━━━━━━━━━━━ 14:45:40\n",
      "Accuracy: 0.9969 - Precision: 0.8522 - Recall: 0.8492 - Specificity: 0.9987 - F1: 0.8342 - Loss: 0.1879\n",
      "\n",
      "Batch 261/387 ━━━━━━━━━━━━━━━━━━━━ 14:46:59\n",
      "Accuracy: 0.9969 - Precision: 0.8506 - Recall: 0.8479 - Specificity: 0.9987 - F1: 0.8327 - Loss: 0.1895\n",
      "\n",
      "Batch 262/387 ━━━━━━━━━━━━━━━━━━━━ 14:48:22\n",
      "Accuracy: 0.9969 - Precision: 0.8506 - Recall: 0.8480 - Specificity: 0.9987 - F1: 0.8328 - Loss: 0.1893\n",
      "\n",
      "Batch 263/387 ━━━━━━━━━━━━━━━━━━━━ 14:49:46\n",
      "Accuracy: 0.9969 - Precision: 0.8502 - Recall: 0.8485 - Specificity: 0.9987 - F1: 0.8329 - Loss: 0.1892\n",
      "\n",
      "Batch 264/387 ━━━━━━━━━━━━━━━━━━━━ 14:50:59\n",
      "Accuracy: 0.9969 - Precision: 0.8507 - Recall: 0.8483 - Specificity: 0.9987 - F1: 0.8331 - Loss: 0.1890\n",
      "\n",
      "Batch 265/387 ━━━━━━━━━━━━━━━━━━━━ 14:52:18\n",
      "Accuracy: 0.9969 - Precision: 0.8513 - Recall: 0.8482 - Specificity: 0.9987 - F1: 0.8333 - Loss: 0.1888\n",
      "\n",
      "Batch 266/387 ━━━━━━━━━━━━━━━━━━━━ 14:53:42\n",
      "Accuracy: 0.9969 - Precision: 0.8518 - Recall: 0.8481 - Specificity: 0.9987 - F1: 0.8336 - Loss: 0.1886\n",
      "\n",
      "Batch 267/387 ━━━━━━━━━━━━━━━━━━━━ 14:55:03\n",
      "Accuracy: 0.9969 - Precision: 0.8523 - Recall: 0.8479 - Specificity: 0.9987 - F1: 0.8338 - Loss: 0.1884\n",
      "\n",
      "Batch 268/387 ━━━━━━━━━━━━━━━━━━━━ 14:56:29\n",
      "Accuracy: 0.9969 - Precision: 0.8524 - Recall: 0.8474 - Specificity: 0.9987 - F1: 0.8336 - Loss: 0.1885\n",
      "\n",
      "Batch 269/387 ━━━━━━━━━━━━━━━━━━━━ 14:57:50\n",
      "Accuracy: 0.9969 - Precision: 0.8527 - Recall: 0.8476 - Specificity: 0.9987 - F1: 0.8339 - Loss: 0.1883\n",
      "\n",
      "Batch 270/387 ━━━━━━━━━━━━━━━━━━━━ 14:59:06\n",
      "Accuracy: 0.9969 - Precision: 0.8531 - Recall: 0.8479 - Specificity: 0.9987 - F1: 0.8343 - Loss: 0.1879\n",
      "\n",
      "Batch 271/387 ━━━━━━━━━━━━━━━━━━━━ 15:00:27\n",
      "Accuracy: 0.9969 - Precision: 0.8523 - Recall: 0.8484 - Specificity: 0.9987 - F1: 0.8340 - Loss: 0.1881\n",
      "\n",
      "Batch 272/387 ━━━━━━━━━━━━━━━━━━━━ 15:01:39\n",
      "Accuracy: 0.9969 - Precision: 0.8524 - Recall: 0.8488 - Specificity: 0.9987 - F1: 0.8344 - Loss: 0.1877\n",
      "\n",
      "Batch 273/387 ━━━━━━━━━━━━━━━━━━━━ 15:03:08\n",
      "Accuracy: 0.9969 - Precision: 0.8525 - Recall: 0.8492 - Specificity: 0.9987 - F1: 0.8347 - Loss: 0.1874\n",
      "\n",
      "Batch 274/387 ━━━━━━━━━━━━━━━━━━━━ 15:04:25\n",
      "Accuracy: 0.9969 - Precision: 0.8517 - Recall: 0.8495 - Specificity: 0.9987 - F1: 0.8344 - Loss: 0.1877\n",
      "\n",
      "Batch 275/387 ━━━━━━━━━━━━━━━━━━━━ 15:05:57\n",
      "Accuracy: 0.9969 - Precision: 0.8515 - Recall: 0.8500 - Specificity: 0.9987 - F1: 0.8346 - Loss: 0.1874\n",
      "\n",
      "Batch 276/387 ━━━━━━━━━━━━━━━━━━━━ 15:07:23\n",
      "Accuracy: 0.9969 - Precision: 0.8518 - Recall: 0.8501 - Specificity: 0.9987 - F1: 0.8348 - Loss: 0.1871\n",
      "\n",
      "Batch 277/387 ━━━━━━━━━━━━━━━━━━━━ 15:08:45\n",
      "Accuracy: 0.9969 - Precision: 0.8521 - Recall: 0.8503 - Specificity: 0.9987 - F1: 0.8351 - Loss: 0.1869\n",
      "\n",
      "Batch 278/387 ━━━━━━━━━━━━━━━━━━━━ 15:10:12\n",
      "Accuracy: 0.9969 - Precision: 0.8526 - Recall: 0.8503 - Specificity: 0.9987 - F1: 0.8354 - Loss: 0.1866\n",
      "\n",
      "Batch 279/387 ━━━━━━━━━━━━━━━━━━━━ 15:11:26\n",
      "Accuracy: 0.9969 - Precision: 0.8525 - Recall: 0.8506 - Specificity: 0.9987 - F1: 0.8356 - Loss: 0.1864\n",
      "\n",
      "Batch 280/387 ━━━━━━━━━━━━━━━━━━━━ 15:13:04\n",
      "Accuracy: 0.9969 - Precision: 0.8529 - Recall: 0.8508 - Specificity: 0.9987 - F1: 0.8359 - Loss: 0.1860\n",
      "\n",
      "Batch 281/387 ━━━━━━━━━━━━━━━━━━━━ 15:14:25\n",
      "Accuracy: 0.9969 - Precision: 0.8529 - Recall: 0.8512 - Specificity: 0.9987 - F1: 0.8362 - Loss: 0.1857\n",
      "\n",
      "Batch 282/387 ━━━━━━━━━━━━━━━━━━━━ 15:15:41\n",
      "Accuracy: 0.9969 - Precision: 0.8526 - Recall: 0.8517 - Specificity: 0.9987 - F1: 0.8363 - Loss: 0.1856\n",
      "\n",
      "Batch 283/387 ━━━━━━━━━━━━━━━━━━━━ 15:17:00\n",
      "Accuracy: 0.9969 - Precision: 0.8527 - Recall: 0.8515 - Specificity: 0.9987 - F1: 0.8362 - Loss: 0.1856\n",
      "\n",
      "Batch 284/387 ━━━━━━━━━━━━━━━━━━━━ 15:18:43\n",
      "Accuracy: 0.9969 - Precision: 0.8528 - Recall: 0.8516 - Specificity: 0.9987 - F1: 0.8364 - Loss: 0.1854\n",
      "\n",
      "Batch 285/387 ━━━━━━━━━━━━━━━━━━━━ 15:20:01\n",
      "Accuracy: 0.9969 - Precision: 0.8531 - Recall: 0.8516 - Specificity: 0.9987 - F1: 0.8367 - Loss: 0.1852\n",
      "\n",
      "Batch 286/387 ━━━━━━━━━━━━━━━━━━━━ 15:21:22\n",
      "Accuracy: 0.9969 - Precision: 0.8535 - Recall: 0.8514 - Specificity: 0.9987 - F1: 0.8368 - Loss: 0.1850\n",
      "\n",
      "Batch 287/387 ━━━━━━━━━━━━━━━━━━━━ 15:22:37\n",
      "Accuracy: 0.9969 - Precision: 0.8538 - Recall: 0.8518 - Specificity: 0.9987 - F1: 0.8371 - Loss: 0.1847\n",
      "\n",
      "Batch 288/387 ━━━━━━━━━━━━━━━━━━━━ 15:23:57\n",
      "Accuracy: 0.9969 - Precision: 0.8542 - Recall: 0.8520 - Specificity: 0.9987 - F1: 0.8375 - Loss: 0.1842\n",
      "\n",
      "Batch 289/387 ━━━━━━━━━━━━━━━━━━━━ 15:25:14\n",
      "Accuracy: 0.9969 - Precision: 0.8544 - Recall: 0.8517 - Specificity: 0.9987 - F1: 0.8375 - Loss: 0.1842\n",
      "\n",
      "Batch 290/387 ━━━━━━━━━━━━━━━━━━━━ 15:26:33\n",
      "Accuracy: 0.9969 - Precision: 0.8547 - Recall: 0.8520 - Specificity: 0.9987 - F1: 0.8379 - Loss: 0.1838\n",
      "\n",
      "Batch 291/387 ━━━━━━━━━━━━━━━━━━━━ 15:28:04\n",
      "Accuracy: 0.9970 - Precision: 0.8547 - Recall: 0.8524 - Specificity: 0.9987 - F1: 0.8381 - Loss: 0.1836\n",
      "\n",
      "Batch 292/387 ━━━━━━━━━━━━━━━━━━━━ 15:29:21\n",
      "Accuracy: 0.9969 - Precision: 0.8551 - Recall: 0.8523 - Specificity: 0.9987 - F1: 0.8383 - Loss: 0.1834\n",
      "\n",
      "Batch 293/387 ━━━━━━━━━━━━━━━━━━━━ 15:30:32\n",
      "Accuracy: 0.9969 - Precision: 0.8554 - Recall: 0.8524 - Specificity: 0.9987 - F1: 0.8385 - Loss: 0.1832\n",
      "\n",
      "Batch 294/387 ━━━━━━━━━━━━━━━━━━━━ 15:32:02\n",
      "Accuracy: 0.9969 - Precision: 0.8556 - Recall: 0.8526 - Specificity: 0.9987 - F1: 0.8388 - Loss: 0.1829\n",
      "\n",
      "Batch 295/387 ━━━━━━━━━━━━━━━━━━━━ 15:33:20\n",
      "Accuracy: 0.9969 - Precision: 0.8557 - Recall: 0.8526 - Specificity: 0.9987 - F1: 0.8389 - Loss: 0.1828\n",
      "\n",
      "Batch 296/387 ━━━━━━━━━━━━━━━━━━━━ 15:34:42\n",
      "Accuracy: 0.9969 - Precision: 0.8560 - Recall: 0.8530 - Specificity: 0.9987 - F1: 0.8393 - Loss: 0.1824\n",
      "\n",
      "Batch 297/387 ━━━━━━━━━━━━━━━━━━━━ 15:36:13\n",
      "Accuracy: 0.9970 - Precision: 0.8562 - Recall: 0.8532 - Specificity: 0.9987 - F1: 0.8395 - Loss: 0.1821\n",
      "\n",
      "Batch 298/387 ━━━━━━━━━━━━━━━━━━━━ 15:37:34\n",
      "Accuracy: 0.9969 - Precision: 0.8566 - Recall: 0.8531 - Specificity: 0.9987 - F1: 0.8397 - Loss: 0.1819\n",
      "\n",
      "Batch 299/387 ━━━━━━━━━━━━━━━━━━━━ 15:39:06\n",
      "Accuracy: 0.9969 - Precision: 0.8559 - Recall: 0.8532 - Specificity: 0.9987 - F1: 0.8394 - Loss: 0.1822\n",
      "\n",
      "Batch 300/387 ━━━━━━━━━━━━━━━━━━━━ 15:40:33\n",
      "Accuracy: 0.9969 - Precision: 0.8563 - Recall: 0.8535 - Specificity: 0.9987 - F1: 0.8398 - Loss: 0.1818\n",
      "\n",
      "Batch 301/387 ━━━━━━━━━━━━━━━━━━━━ 15:41:51\n",
      "Accuracy: 0.9969 - Precision: 0.8564 - Recall: 0.8539 - Specificity: 0.9987 - F1: 0.8401 - Loss: 0.1814\n",
      "\n",
      "Batch 302/387 ━━━━━━━━━━━━━━━━━━━━ 15:43:22\n",
      "Accuracy: 0.9969 - Precision: 0.8554 - Recall: 0.8544 - Specificity: 0.9987 - F1: 0.8396 - Loss: 0.1820\n",
      "\n",
      "Batch 303/387 ━━━━━━━━━━━━━━━━━━━━ 15:44:45\n",
      "Accuracy: 0.9969 - Precision: 0.8546 - Recall: 0.8548 - Specificity: 0.9987 - F1: 0.8394 - Loss: 0.1822\n",
      "\n",
      "Batch 304/387 ━━━━━━━━━━━━━━━━━━━━ 15:46:04\n",
      "Accuracy: 0.9969 - Precision: 0.8550 - Recall: 0.8552 - Specificity: 0.9987 - F1: 0.8398 - Loss: 0.1818\n",
      "\n",
      "Batch 305/387 ━━━━━━━━━━━━━━━━━━━━ 15:47:36\n",
      "Accuracy: 0.9969 - Precision: 0.8551 - Recall: 0.8554 - Specificity: 0.9987 - F1: 0.8400 - Loss: 0.1815\n",
      "\n",
      "Batch 306/387 ━━━━━━━━━━━━━━━━━━━━ 15:48:59\n",
      "Accuracy: 0.9969 - Precision: 0.8547 - Recall: 0.8557 - Specificity: 0.9987 - F1: 0.8400 - Loss: 0.1815\n",
      "\n",
      "Batch 307/387 ━━━━━━━━━━━━━━━━━━━━ 15:50:27\n",
      "Accuracy: 0.9970 - Precision: 0.8544 - Recall: 0.8559 - Specificity: 0.9987 - F1: 0.8400 - Loss: 0.1815\n",
      "\n",
      "Batch 308/387 ━━━━━━━━━━━━━━━━━━━━ 15:51:59\n",
      "Accuracy: 0.9970 - Precision: 0.8542 - Recall: 0.8562 - Specificity: 0.9987 - F1: 0.8400 - Loss: 0.1814\n",
      "\n",
      "Batch 309/387 ━━━━━━━━━━━━━━━━━━━━ 15:53:19\n",
      "Accuracy: 0.9970 - Precision: 0.8544 - Recall: 0.8564 - Specificity: 0.9987 - F1: 0.8403 - Loss: 0.1812\n",
      "\n",
      "Batch 310/387 ━━━━━━━━━━━━━━━━━━━━ 15:54:43\n",
      "Accuracy: 0.9970 - Precision: 0.8548 - Recall: 0.8566 - Specificity: 0.9987 - F1: 0.8406 - Loss: 0.1808\n",
      "\n",
      "Batch 311/387 ━━━━━━━━━━━━━━━━━━━━ 15:56:12\n",
      "Accuracy: 0.9970 - Precision: 0.8552 - Recall: 0.8565 - Specificity: 0.9987 - F1: 0.8408 - Loss: 0.1806\n",
      "\n",
      "Batch 312/387 ━━━━━━━━━━━━━━━━━━━━ 15:57:32\n",
      "Accuracy: 0.9969 - Precision: 0.8557 - Recall: 0.8557 - Specificity: 0.9987 - F1: 0.8405 - Loss: 0.1810\n",
      "\n",
      "Batch 313/387 ━━━━━━━━━━━━━━━━━━━━ 15:59:04\n",
      "Accuracy: 0.9969 - Precision: 0.8560 - Recall: 0.8558 - Specificity: 0.9987 - F1: 0.8408 - Loss: 0.1807\n",
      "\n",
      "Batch 314/387 ━━━━━━━━━━━━━━━━━━━━ 16:00:30\n",
      "Accuracy: 0.9969 - Precision: 0.8563 - Recall: 0.8547 - Specificity: 0.9987 - F1: 0.8402 - Loss: 0.1813\n",
      "\n",
      "Batch 315/387 ━━━━━━━━━━━━━━━━━━━━ 16:01:46\n",
      "Accuracy: 0.9969 - Precision: 0.8567 - Recall: 0.8540 - Specificity: 0.9987 - F1: 0.8400 - Loss: 0.1816\n",
      "\n",
      "Batch 316/387 ━━━━━━━━━━━━━━━━━━━━ 16:03:08\n",
      "Accuracy: 0.9969 - Precision: 0.8569 - Recall: 0.8537 - Specificity: 0.9987 - F1: 0.8400 - Loss: 0.1816\n",
      "\n",
      "Batch 317/387 ━━━━━━━━━━━━━━━━━━━━ 16:04:26\n",
      "Accuracy: 0.9969 - Precision: 0.8572 - Recall: 0.8534 - Specificity: 0.9987 - F1: 0.8400 - Loss: 0.1816\n",
      "\n",
      "Batch 318/387 ━━━━━━━━━━━━━━━━━━━━ 16:05:53\n",
      "Accuracy: 0.9969 - Precision: 0.8575 - Recall: 0.8537 - Specificity: 0.9987 - F1: 0.8404 - Loss: 0.1812\n",
      "\n",
      "Batch 319/387 ━━━━━━━━━━━━━━━━━━━━ 16:07:11\n",
      "Accuracy: 0.9969 - Precision: 0.8578 - Recall: 0.8537 - Specificity: 0.9987 - F1: 0.8405 - Loss: 0.1811\n",
      "\n",
      "Batch 320/387 ━━━━━━━━━━━━━━━━━━━━ 16:08:34\n",
      "Accuracy: 0.9969 - Precision: 0.8581 - Recall: 0.8540 - Specificity: 0.9987 - F1: 0.8409 - Loss: 0.1807\n",
      "\n",
      "Batch 321/387 ━━━━━━━━━━━━━━━━━━━━ 16:10:06\n",
      "Accuracy: 0.9969 - Precision: 0.8577 - Recall: 0.8544 - Specificity: 0.9987 - F1: 0.8409 - Loss: 0.1807\n",
      "\n",
      "Batch 322/387 ━━━━━━━━━━━━━━━━━━━━ 16:11:35\n",
      "Accuracy: 0.9969 - Precision: 0.8575 - Recall: 0.8547 - Specificity: 0.9987 - F1: 0.8410 - Loss: 0.1806\n",
      "\n",
      "Batch 323/387 ━━━━━━━━━━━━━━━━━━━━ 16:12:56\n",
      "Accuracy: 0.9969 - Precision: 0.8574 - Recall: 0.8550 - Specificity: 0.9987 - F1: 0.8411 - Loss: 0.1805\n",
      "\n",
      "Batch 324/387 ━━━━━━━━━━━━━━━━━━━━ 16:14:30\n",
      "Accuracy: 0.9969 - Precision: 0.8572 - Recall: 0.8554 - Specificity: 0.9987 - F1: 0.8412 - Loss: 0.1803\n",
      "\n",
      "Batch 325/387 ━━━━━━━━━━━━━━━━━━━━ 16:15:51\n",
      "Accuracy: 0.9969 - Precision: 0.8570 - Recall: 0.8558 - Specificity: 0.9987 - F1: 0.8413 - Loss: 0.1802\n",
      "\n",
      "Batch 326/387 ━━━━━━━━━━━━━━━━━━━━ 16:17:20\n",
      "Accuracy: 0.9969 - Precision: 0.8572 - Recall: 0.8558 - Specificity: 0.9987 - F1: 0.8415 - Loss: 0.1800\n",
      "\n",
      "Batch 327/387 ━━━━━━━━━━━━━━━━━━━━ 16:18:40\n",
      "Accuracy: 0.9970 - Precision: 0.8575 - Recall: 0.8561 - Specificity: 0.9987 - F1: 0.8418 - Loss: 0.1797\n",
      "\n",
      "Batch 328/387 ━━━━━━━━━━━━━━━━━━━━ 16:19:59\n",
      "Accuracy: 0.9970 - Precision: 0.8577 - Recall: 0.8565 - Specificity: 0.9987 - F1: 0.8422 - Loss: 0.1793\n",
      "\n",
      "Batch 329/387 ━━━━━━━━━━━━━━━━━━━━ 16:21:38\n",
      "Accuracy: 0.9969 - Precision: 0.8571 - Recall: 0.8567 - Specificity: 0.9987 - F1: 0.8419 - Loss: 0.1796\n",
      "\n",
      "Batch 330/387 ━━━━━━━━━━━━━━━━━━━━ 16:22:59\n",
      "Accuracy: 0.9970 - Precision: 0.8572 - Recall: 0.8570 - Specificity: 0.9987 - F1: 0.8422 - Loss: 0.1793\n",
      "\n",
      "Batch 331/387 ━━━━━━━━━━━━━━━━━━━━ 16:24:20\n",
      "Accuracy: 0.9970 - Precision: 0.8573 - Recall: 0.8573 - Specificity: 0.9987 - F1: 0.8424 - Loss: 0.1790\n",
      "\n",
      "Batch 332/387 ━━━━━━━━━━━━━━━━━━━━ 16:25:39\n",
      "Accuracy: 0.9970 - Precision: 0.8576 - Recall: 0.8575 - Specificity: 0.9987 - F1: 0.8427 - Loss: 0.1787\n",
      "\n",
      "Batch 333/387 ━━━━━━━━━━━━━━━━━━━━ 16:27:06\n",
      "Accuracy: 0.9970 - Precision: 0.8579 - Recall: 0.8578 - Specificity: 0.9987 - F1: 0.8431 - Loss: 0.1783\n",
      "\n",
      "Batch 334/387 ━━━━━━━━━━━━━━━━━━━━ 16:28:29\n",
      "Accuracy: 0.9970 - Precision: 0.8581 - Recall: 0.8582 - Specificity: 0.9987 - F1: 0.8434 - Loss: 0.1780\n",
      "\n",
      "Batch 335/387 ━━━━━━━━━━━━━━━━━━━━ 16:29:50\n",
      "Accuracy: 0.9970 - Precision: 0.8584 - Recall: 0.8573 - Specificity: 0.9987 - F1: 0.8430 - Loss: 0.1783\n",
      "\n",
      "Batch 336/387 ━━━━━━━━━━━━━━━━━━━━ 16:31:10\n",
      "Accuracy: 0.9970 - Precision: 0.8584 - Recall: 0.8576 - Specificity: 0.9987 - F1: 0.8431 - Loss: 0.1782\n",
      "\n",
      "Batch 337/387 ━━━━━━━━━━━━━━━━━━━━ 16:32:33\n",
      "Accuracy: 0.9970 - Precision: 0.8586 - Recall: 0.8578 - Specificity: 0.9987 - F1: 0.8434 - Loss: 0.1779\n",
      "\n",
      "Batch 338/387 ━━━━━━━━━━━━━━━━━━━━ 16:33:52\n",
      "Accuracy: 0.9970 - Precision: 0.8587 - Recall: 0.8579 - Specificity: 0.9987 - F1: 0.8435 - Loss: 0.1778\n",
      "\n",
      "Batch 339/387 ━━━━━━━━━━━━━━━━━━━━ 16:35:23\n",
      "Accuracy: 0.9970 - Precision: 0.8587 - Recall: 0.8581 - Specificity: 0.9987 - F1: 0.8437 - Loss: 0.1776\n",
      "\n",
      "Batch 340/387 ━━━━━━━━━━━━━━━━━━━━ 16:36:50\n",
      "Accuracy: 0.9970 - Precision: 0.8582 - Recall: 0.8585 - Specificity: 0.9987 - F1: 0.8436 - Loss: 0.1777\n",
      "\n",
      "Batch 341/387 ━━━━━━━━━━━━━━━━━━━━ 16:38:13\n",
      "Accuracy: 0.9970 - Precision: 0.8586 - Recall: 0.8584 - Specificity: 0.9987 - F1: 0.8437 - Loss: 0.1775\n",
      "\n",
      "Batch 342/387 ━━━━━━━━━━━━━━━━━━━━ 16:39:35\n",
      "Accuracy: 0.9970 - Precision: 0.8586 - Recall: 0.8585 - Specificity: 0.9987 - F1: 0.8439 - Loss: 0.1773\n",
      "\n",
      "Batch 343/387 ━━━━━━━━━━━━━━━━━━━━ 16:40:50\n",
      "Accuracy: 0.9970 - Precision: 0.8580 - Recall: 0.8586 - Specificity: 0.9987 - F1: 0.8436 - Loss: 0.1776\n",
      "\n",
      "Batch 344/387 ━━━━━━━━━━━━━━━━━━━━ 16:42:08\n",
      "Accuracy: 0.9970 - Precision: 0.8583 - Recall: 0.8588 - Specificity: 0.9987 - F1: 0.8439 - Loss: 0.1772\n",
      "\n",
      "Batch 345/387 ━━━━━━━━━━━━━━━━━━━━ 16:43:31\n",
      "Accuracy: 0.9970 - Precision: 0.8587 - Recall: 0.8585 - Specificity: 0.9987 - F1: 0.8440 - Loss: 0.1772\n",
      "\n",
      "Batch 346/387 ━━━━━━━━━━━━━━━━━━━━ 16:44:50\n",
      "Accuracy: 0.9970 - Precision: 0.8590 - Recall: 0.8586 - Specificity: 0.9987 - F1: 0.8442 - Loss: 0.1769\n",
      "\n",
      "Batch 347/387 ━━━━━━━━━━━━━━━━━━━━ 16:46:21\n",
      "Accuracy: 0.9970 - Precision: 0.8594 - Recall: 0.8577 - Specificity: 0.9987 - F1: 0.8438 - Loss: 0.1774\n",
      "\n",
      "Batch 348/387 ━━━━━━━━━━━━━━━━━━━━ 16:47:43\n",
      "Accuracy: 0.9970 - Precision: 0.8598 - Recall: 0.8571 - Specificity: 0.9987 - F1: 0.8436 - Loss: 0.1777\n",
      "\n",
      "Batch 349/387 ━━━━━━━━━━━━━━━━━━━━ 16:49:15\n",
      "Accuracy: 0.9970 - Precision: 0.8602 - Recall: 0.8569 - Specificity: 0.9987 - F1: 0.8437 - Loss: 0.1776\n",
      "\n",
      "Batch 350/387 ━━━━━━━━━━━━━━━━━━━━ 16:50:44\n",
      "Accuracy: 0.9970 - Precision: 0.8605 - Recall: 0.8572 - Specificity: 0.9987 - F1: 0.8440 - Loss: 0.1772\n",
      "\n",
      "Batch 351/387 ━━━━━━━━━━━━━━━━━━━━ 16:52:13\n",
      "Accuracy: 0.9970 - Precision: 0.8601 - Recall: 0.8564 - Specificity: 0.9987 - F1: 0.8435 - Loss: 0.1777\n",
      "\n",
      "Batch 352/387 ━━━━━━━━━━━━━━━━━━━━ 16:53:31\n",
      "Accuracy: 0.9970 - Precision: 0.8604 - Recall: 0.8565 - Specificity: 0.9987 - F1: 0.8437 - Loss: 0.1775\n",
      "\n",
      "Batch 353/387 ━━━━━━━━━━━━━━━━━━━━ 16:55:04\n",
      "Accuracy: 0.9970 - Precision: 0.8596 - Recall: 0.8569 - Specificity: 0.9987 - F1: 0.8434 - Loss: 0.1778\n",
      "\n",
      "Batch 354/387 ━━━━━━━━━━━━━━━━━━━━ 16:56:27\n",
      "Accuracy: 0.9970 - Precision: 0.8599 - Recall: 0.8569 - Specificity: 0.9987 - F1: 0.8436 - Loss: 0.1776\n",
      "\n",
      "Batch 355/387 ━━━━━━━━━━━━━━━━━━━━ 16:57:51\n",
      "Accuracy: 0.9970 - Precision: 0.8599 - Recall: 0.8568 - Specificity: 0.9987 - F1: 0.8436 - Loss: 0.1776\n",
      "\n",
      "Batch 356/387 ━━━━━━━━━━━━━━━━━━━━ 16:59:15\n",
      "Accuracy: 0.9970 - Precision: 0.8595 - Recall: 0.8571 - Specificity: 0.9987 - F1: 0.8435 - Loss: 0.1777\n",
      "\n",
      "Batch 357/387 ━━━━━━━━━━━━━━━━━━━━ 17:00:42\n",
      "Accuracy: 0.9970 - Precision: 0.8597 - Recall: 0.8573 - Specificity: 0.9987 - F1: 0.8437 - Loss: 0.1774\n",
      "\n",
      "Batch 358/387 ━━━━━━━━━━━━━━━━━━━━ 17:02:03\n",
      "Accuracy: 0.9970 - Precision: 0.8598 - Recall: 0.8574 - Specificity: 0.9987 - F1: 0.8439 - Loss: 0.1772\n",
      "\n",
      "Batch 359/387 ━━━━━━━━━━━━━━━━━━━━ 17:03:26\n",
      "Accuracy: 0.9970 - Precision: 0.8597 - Recall: 0.8578 - Specificity: 0.9987 - F1: 0.8441 - Loss: 0.1770\n",
      "\n",
      "Batch 360/387 ━━━━━━━━━━━━━━━━━━━━ 17:04:43\n",
      "Accuracy: 0.9970 - Precision: 0.8593 - Recall: 0.8581 - Specificity: 0.9987 - F1: 0.8440 - Loss: 0.1771\n",
      "\n",
      "Batch 361/387 ━━━━━━━━━━━━━━━━━━━━ 17:06:26\n",
      "Accuracy: 0.9970 - Precision: 0.8588 - Recall: 0.8585 - Specificity: 0.9987 - F1: 0.8439 - Loss: 0.1772\n",
      "\n",
      "Batch 362/387 ━━━━━━━━━━━━━━━━━━━━ 17:07:54\n",
      "Accuracy: 0.9970 - Precision: 0.8590 - Recall: 0.8584 - Specificity: 0.9987 - F1: 0.8440 - Loss: 0.1772\n",
      "\n",
      "Batch 363/387 ━━━━━━━━━━━━━━━━━━━━ 17:09:16\n",
      "Accuracy: 0.9970 - Precision: 0.8590 - Recall: 0.8587 - Specificity: 0.9987 - F1: 0.8442 - Loss: 0.1769\n",
      "\n",
      "Batch 364/387 ━━━━━━━━━━━━━━━━━━━━ 17:10:47\n",
      "Accuracy: 0.9970 - Precision: 0.8584 - Recall: 0.8588 - Specificity: 0.9987 - F1: 0.8439 - Loss: 0.1773\n",
      "\n",
      "Batch 365/387 ━━━━━━━━━━━━━━━━━━━━ 17:12:08\n",
      "Accuracy: 0.9970 - Precision: 0.8585 - Recall: 0.8587 - Specificity: 0.9987 - F1: 0.8439 - Loss: 0.1773\n",
      "\n",
      "Batch 366/387 ━━━━━━━━━━━━━━━━━━━━ 17:13:40\n",
      "Accuracy: 0.9970 - Precision: 0.8587 - Recall: 0.8587 - Specificity: 0.9987 - F1: 0.8440 - Loss: 0.1771\n",
      "\n",
      "Batch 367/387 ━━━━━━━━━━━━━━━━━━━━ 17:15:16\n",
      "Accuracy: 0.9970 - Precision: 0.8590 - Recall: 0.8588 - Specificity: 0.9987 - F1: 0.8443 - Loss: 0.1768\n",
      "\n",
      "Batch 368/387 ━━━━━━━━━━━━━━━━━━━━ 17:16:39\n",
      "Accuracy: 0.9970 - Precision: 0.8592 - Recall: 0.8588 - Specificity: 0.9987 - F1: 0.8444 - Loss: 0.1767\n",
      "\n",
      "Batch 369/387 ━━━━━━━━━━━━━━━━━━━━ 17:18:15\n",
      "Accuracy: 0.9970 - Precision: 0.8586 - Recall: 0.8581 - Specificity: 0.9987 - F1: 0.8438 - Loss: 0.1773\n",
      "\n",
      "Batch 370/387 ━━━━━━━━━━━━━━━━━━━━ 17:19:42\n",
      "Accuracy: 0.9970 - Precision: 0.8582 - Recall: 0.8584 - Specificity: 0.9987 - F1: 0.8438 - Loss: 0.1774\n",
      "\n",
      "Batch 371/387 ━━━━━━━━━━━━━━━━━━━━ 17:20:59\n",
      "Accuracy: 0.9970 - Precision: 0.8583 - Recall: 0.8587 - Specificity: 0.9987 - F1: 0.8440 - Loss: 0.1771\n",
      "\n",
      "Batch 372/387 ━━━━━━━━━━━━━━━━━━━━ 17:22:22\n",
      "Accuracy: 0.9970 - Precision: 0.8582 - Recall: 0.8587 - Specificity: 0.9987 - F1: 0.8440 - Loss: 0.1771\n",
      "\n",
      "Batch 373/387 ━━━━━━━━━━━━━━━━━━━━ 17:23:39\n",
      "Accuracy: 0.9970 - Precision: 0.8585 - Recall: 0.8586 - Specificity: 0.9987 - F1: 0.8441 - Loss: 0.1770\n",
      "\n",
      "Batch 374/387 ━━━━━━━━━━━━━━━━━━━━ 17:24:58\n",
      "Accuracy: 0.9970 - Precision: 0.8588 - Recall: 0.8588 - Specificity: 0.9987 - F1: 0.8443 - Loss: 0.1767\n",
      "\n",
      "Batch 375/387 ━━━━━━━━━━━━━━━━━━━━ 17:26:22\n",
      "Accuracy: 0.9970 - Precision: 0.8590 - Recall: 0.8590 - Specificity: 0.9987 - F1: 0.8446 - Loss: 0.1765\n",
      "\n",
      "Batch 376/387 ━━━━━━━━━━━━━━━━━━━━ 17:27:57\n",
      "Accuracy: 0.9970 - Precision: 0.8590 - Recall: 0.8592 - Specificity: 0.9987 - F1: 0.8447 - Loss: 0.1763\n",
      "\n",
      "Batch 377/387 ━━━━━━━━━━━━━━━━━━━━ 17:29:19\n",
      "Accuracy: 0.9970 - Precision: 0.8590 - Recall: 0.8593 - Specificity: 0.9987 - F1: 0.8448 - Loss: 0.1762\n",
      "\n",
      "Batch 378/387 ━━━━━━━━━━━━━━━━━━━━ 17:30:54\n",
      "Accuracy: 0.9970 - Precision: 0.8592 - Recall: 0.8589 - Specificity: 0.9987 - F1: 0.8447 - Loss: 0.1763\n",
      "\n",
      "Batch 379/387 ━━━━━━━━━━━━━━━━━━━━ 17:32:14\n",
      "Accuracy: 0.9970 - Precision: 0.8595 - Recall: 0.8589 - Specificity: 0.9987 - F1: 0.8449 - Loss: 0.1762\n",
      "\n",
      "Batch 380/387 ━━━━━━━━━━━━━━━━━━━━ 17:33:52\n",
      "Accuracy: 0.9970 - Precision: 0.8598 - Recall: 0.8591 - Specificity: 0.9987 - F1: 0.8452 - Loss: 0.1759\n",
      "\n",
      "Batch 381/387 ━━━━━━━━━━━━━━━━━━━━ 17:35:36\n",
      "Accuracy: 0.9970 - Precision: 0.8593 - Recall: 0.8594 - Specificity: 0.9987 - F1: 0.8450 - Loss: 0.1760\n",
      "\n",
      "Batch 382/387 ━━━━━━━━━━━━━━━━━━━━ 17:37:17\n",
      "Accuracy: 0.9970 - Precision: 0.8592 - Recall: 0.8597 - Specificity: 0.9987 - F1: 0.8452 - Loss: 0.1758\n",
      "\n",
      "Batch 383/387 ━━━━━━━━━━━━━━━━━━━━ 17:38:33\n",
      "Accuracy: 0.9970 - Precision: 0.8594 - Recall: 0.8597 - Specificity: 0.9987 - F1: 0.8453 - Loss: 0.1756\n",
      "\n",
      "Batch 384/387 ━━━━━━━━━━━━━━━━━━━━ 17:39:51\n",
      "Accuracy: 0.9970 - Precision: 0.8579 - Recall: 0.8599 - Specificity: 0.9987 - F1: 0.8442 - Loss: 0.1767\n",
      "\n",
      "Batch 385/387 ━━━━━━━━━━━━━━━━━━━━ 17:41:16\n",
      "Accuracy: 0.9970 - Precision: 0.8576 - Recall: 0.8602 - Specificity: 0.9987 - F1: 0.8443 - Loss: 0.1767\n",
      "\n",
      "Batch 386/387 ━━━━━━━━━━━━━━━━━━━━ 17:42:31\n",
      "Accuracy: 0.9970 - Precision: 0.8578 - Recall: 0.8603 - Specificity: 0.9987 - F1: 0.8445 - Loss: 0.1764\n",
      "\n",
      "Batch 387/387 ━━━━━━━━━━━━━━━━━━━━ 17:43:43\n",
      "Accuracy: 0.9970 - Precision: 0.8581 - Recall: 0.8598 - Specificity: 0.9987 - F1: 0.8443 - Loss: 0.1766\n",
      "\n",
      "End of Epoch 3\n",
      "\n",
      "Epoch 4/50\n",
      "Batch 1/387 ━━━━━━━━━━━━━━━━━━━━ 18:06:06\n",
      "Accuracy: 0.9982 - Precision: 0.9207 - Recall: 0.8800 - Specificity: 0.9993 - F1: 0.8999 - Loss: 0.1145\n",
      "\n",
      "Batch 2/387 ━━━━━━━━━━━━━━━━━━━━ 18:07:24\n",
      "Accuracy: 0.9974 - Precision: 0.9548 - Recall: 0.8522 - Specificity: 0.9996 - F1: 0.8996 - Loss: 0.1181\n",
      "\n",
      "Batch 3/387 ━━━━━━━━━━━━━━━━━━━━ 18:08:43\n",
      "Accuracy: 0.9976 - Precision: 0.9544 - Recall: 0.8714 - Specificity: 0.9995 - F1: 0.9101 - Loss: 0.1062\n",
      "\n",
      "Batch 4/387 ━━━━━━━━━━━━━━━━━━━━ 18:09:57\n",
      "Accuracy: 0.9974 - Precision: 0.8999 - Recall: 0.8275 - Specificity: 0.9993 - F1: 0.8615 - Loss: 0.1557\n",
      "\n",
      "Batch 5/387 ━━━━━━━━━━━━━━━━━━━━ 18:11:19\n",
      "Accuracy: 0.9972 - Precision: 0.9128 - Recall: 0.8290 - Specificity: 0.9993 - F1: 0.8681 - Loss: 0.1505\n",
      "\n",
      "Batch 6/387 ━━━━━━━━━━━━━━━━━━━━ 18:12:42\n",
      "Accuracy: 0.9971 - Precision: 0.9261 - Recall: 0.8276 - Specificity: 0.9994 - F1: 0.8732 - Loss: 0.1459\n",
      "\n",
      "Batch 7/387 ━━━━━━━━━━━━━━━━━━━━ 18:13:58\n",
      "Accuracy: 0.9966 - Precision: 0.9338 - Recall: 0.8125 - Specificity: 0.9994 - F1: 0.8673 - Loss: 0.1546\n",
      "\n",
      "Batch 8/387 ━━━━━━━━━━━━━━━━━━━━ 18:15:26\n",
      "Accuracy: 0.9959 - Precision: 0.9416 - Recall: 0.7980 - Specificity: 0.9995 - F1: 0.8613 - Loss: 0.1639\n",
      "\n",
      "Batch 9/387 ━━━━━━━━━━━━━━━━━━━━ 18:16:55\n",
      "Accuracy: 0.9957 - Precision: 0.9468 - Recall: 0.7969 - Specificity: 0.9995 - F1: 0.8630 - Loss: 0.1630\n",
      "\n",
      "Batch 10/387 ━━━━━━━━━━━━━━━━━━━━ 18:18:21\n",
      "Accuracy: 0.9957 - Precision: 0.9284 - Recall: 0.8142 - Specificity: 0.9992 - F1: 0.8621 - Loss: 0.1630\n",
      "\n",
      "Batch 11/387 ━━━━━━━━━━━━━━━━━━━━ 18:19:43\n",
      "Accuracy: 0.9960 - Precision: 0.9291 - Recall: 0.8176 - Specificity: 0.9993 - F1: 0.8648 - Loss: 0.1595\n",
      "\n",
      "Batch 12/387 ━━━━━━━━━━━━━━━━━━━━ 18:21:03\n",
      "Accuracy: 0.9962 - Precision: 0.9250 - Recall: 0.8301 - Specificity: 0.9992 - F1: 0.8696 - Loss: 0.1536\n",
      "\n",
      "Batch 13/387 ━━━━━━━━━━━━━━━━━━━━ 18:22:37\n",
      "Accuracy: 0.9963 - Precision: 0.9178 - Recall: 0.8381 - Specificity: 0.9991 - F1: 0.8704 - Loss: 0.1524\n",
      "\n",
      "Batch 14/387 ━━━━━━━━━━━━━━━━━━━━ 18:24:15\n",
      "Accuracy: 0.9964 - Precision: 0.9011 - Recall: 0.8480 - Specificity: 0.9990 - F1: 0.8657 - Loss: 0.1568\n",
      "\n",
      "Batch 15/387 ━━━━━━━━━━━━━━━━━━━━ 18:25:42\n",
      "Accuracy: 0.9965 - Precision: 0.8986 - Recall: 0.8565 - Specificity: 0.9990 - F1: 0.8691 - Loss: 0.1526\n",
      "\n",
      "Batch 16/387 ━━━━━━━━━━━━━━━━━━━━ 18:27:04\n",
      "Accuracy: 0.9964 - Precision: 0.8824 - Recall: 0.8522 - Specificity: 0.9989 - F1: 0.8588 - Loss: 0.1634\n",
      "\n",
      "Batch 17/387 ━━━━━━━━━━━━━━━━━━━━ 18:28:29\n",
      "Accuracy: 0.9965 - Precision: 0.8803 - Recall: 0.8607 - Specificity: 0.9988 - F1: 0.8622 - Loss: 0.1594\n",
      "\n",
      "Batch 18/387 ━━━━━━━━━━━━━━━━━━━━ 18:29:46\n",
      "Accuracy: 0.9966 - Precision: 0.8719 - Recall: 0.8665 - Specificity: 0.9987 - F1: 0.8604 - Loss: 0.1609\n",
      "\n",
      "Batch 19/387 ━━━━━━━━━━━━━━━━━━━━ 18:31:03\n",
      "Accuracy: 0.9966 - Precision: 0.8740 - Recall: 0.8711 - Specificity: 0.9987 - F1: 0.8642 - Loss: 0.1567\n",
      "\n",
      "Batch 20/387 ━━━━━━━━━━━━━━━━━━━━ 18:32:30\n",
      "Accuracy: 0.9967 - Precision: 0.8780 - Recall: 0.8750 - Specificity: 0.9987 - F1: 0.8686 - Loss: 0.1518\n",
      "\n",
      "Batch 21/387 ━━━━━━━━━━━━━━━━━━━━ 18:33:47\n",
      "Accuracy: 0.9966 - Precision: 0.8825 - Recall: 0.8695 - Specificity: 0.9988 - F1: 0.8678 - Loss: 0.1530\n",
      "\n",
      "Batch 22/387 ━━━━━━━━━━━━━━━━━━━━ 18:35:21\n",
      "Accuracy: 0.9966 - Precision: 0.8876 - Recall: 0.8664 - Specificity: 0.9988 - F1: 0.8687 - Loss: 0.1521\n",
      "\n",
      "Batch 23/387 ━━━━━━━━━━━━━━━━━━━━ 18:36:35\n",
      "Accuracy: 0.9967 - Precision: 0.8909 - Recall: 0.8686 - Specificity: 0.9988 - F1: 0.8718 - Loss: 0.1487\n",
      "\n",
      "Batch 24/387 ━━━━━━━━━━━━━━━━━━━━ 18:38:09\n",
      "Accuracy: 0.9968 - Precision: 0.8930 - Recall: 0.8684 - Specificity: 0.9989 - F1: 0.8730 - Loss: 0.1471\n",
      "\n",
      "Batch 25/387 ━━━━━━━━━━━━━━━━━━━━ 18:39:31\n",
      "Accuracy: 0.9969 - Precision: 0.8961 - Recall: 0.8720 - Specificity: 0.9989 - F1: 0.8767 - Loss: 0.1430\n",
      "\n",
      "Batch 26/387 ━━━━━━━━━━━━━━━━━━━━ 18:40:56\n",
      "Accuracy: 0.9968 - Precision: 0.8968 - Recall: 0.8730 - Specificity: 0.9989 - F1: 0.8778 - Loss: 0.1419\n",
      "\n",
      "Batch 27/387 ━━━━━━━━━━━━━━━━━━━━ 18:42:14\n",
      "Accuracy: 0.9969 - Precision: 0.8954 - Recall: 0.8763 - Specificity: 0.9989 - F1: 0.8789 - Loss: 0.1407\n",
      "\n",
      "Batch 28/387 ━━━━━━━━━━━━━━━━━━━━ 18:43:35\n",
      "Accuracy: 0.9970 - Precision: 0.8919 - Recall: 0.8730 - Specificity: 0.9989 - F1: 0.8758 - Loss: 0.1438\n",
      "\n",
      "Batch 29/387 ━━━━━━━━━━━━━━━━━━━━ 18:44:54\n",
      "Accuracy: 0.9970 - Precision: 0.8898 - Recall: 0.8759 - Specificity: 0.9989 - F1: 0.8762 - Loss: 0.1430\n",
      "\n",
      "Batch 30/387 ━━━━━━━━━━━━━━━━━━━━ 18:46:11\n",
      "Accuracy: 0.9971 - Precision: 0.8881 - Recall: 0.8758 - Specificity: 0.9989 - F1: 0.8756 - Loss: 0.1435\n",
      "\n",
      "Batch 31/387 ━━━━━━━━━━━━━━━━━━━━ 18:47:34\n",
      "Accuracy: 0.9972 - Precision: 0.8809 - Recall: 0.8787 - Specificity: 0.9990 - F1: 0.8727 - Loss: 0.1464\n",
      "\n",
      "Batch 32/387 ━━━━━━━━━━━━━━━━━━━━ 18:48:48\n",
      "Accuracy: 0.9971 - Precision: 0.8821 - Recall: 0.8769 - Specificity: 0.9990 - F1: 0.8725 - Loss: 0.1466\n",
      "\n",
      "Batch 33/387 ━━━━━━━━━━━━━━━━━━━━ 18:50:19\n",
      "Accuracy: 0.9971 - Precision: 0.8831 - Recall: 0.8758 - Specificity: 0.9989 - F1: 0.8727 - Loss: 0.1464\n",
      "\n",
      "Batch 34/387 ━━━━━━━━━━━━━━━━━━━━ 18:51:50\n",
      "Accuracy: 0.9971 - Precision: 0.8858 - Recall: 0.8761 - Specificity: 0.9990 - F1: 0.8743 - Loss: 0.1448\n",
      "\n",
      "Batch 35/387 ━━━━━━━━━━━━━━━━━━━━ 18:53:03\n",
      "Accuracy: 0.9972 - Precision: 0.8889 - Recall: 0.8764 - Specificity: 0.9990 - F1: 0.8761 - Loss: 0.1427\n",
      "\n",
      "Batch 36/387 ━━━━━━━━━━━━━━━━━━━━ 18:54:27\n",
      "Accuracy: 0.9972 - Precision: 0.8909 - Recall: 0.8687 - Specificity: 0.9990 - F1: 0.8723 - Loss: 0.1463\n",
      "\n",
      "Batch 37/387 ━━━━━━━━━━━━━━━━━━━━ 18:55:51\n",
      "Accuracy: 0.9973 - Precision: 0.8924 - Recall: 0.8642 - Specificity: 0.9990 - F1: 0.8705 - Loss: 0.1478\n",
      "\n",
      "Batch 38/387 ━━━━━━━━━━━━━━━━━━━━ 18:57:12\n",
      "Accuracy: 0.9973 - Precision: 0.8877 - Recall: 0.8650 - Specificity: 0.9990 - F1: 0.8685 - Loss: 0.1498\n",
      "\n",
      "Batch 39/387 ━━━━━━━━━━━━━━━━━━━━ 18:58:37\n",
      "Accuracy: 0.9973 - Precision: 0.8889 - Recall: 0.8679 - Specificity: 0.9990 - F1: 0.8707 - Loss: 0.1473\n",
      "\n",
      "Batch 40/387 ━━━━━━━━━━━━━━━━━━━━ 18:59:54\n",
      "Accuracy: 0.9974 - Precision: 0.8893 - Recall: 0.8693 - Specificity: 0.9991 - F1: 0.8718 - Loss: 0.1460\n",
      "\n",
      "Batch 41/387 ━━━━━━━━━━━━━━━━━━━━ 19:01:12\n",
      "Accuracy: 0.9974 - Precision: 0.8915 - Recall: 0.8692 - Specificity: 0.9991 - F1: 0.8730 - Loss: 0.1449\n",
      "\n",
      "Batch 42/387 ━━━━━━━━━━━━━━━━━━━━ 19:02:45\n",
      "Accuracy: 0.9974 - Precision: 0.8921 - Recall: 0.8680 - Specificity: 0.9991 - F1: 0.8728 - Loss: 0.1451\n",
      "\n",
      "Batch 43/387 ━━━━━━━━━━━━━━━━━━━━ 19:04:09\n",
      "Accuracy: 0.9973 - Precision: 0.8944 - Recall: 0.8653 - Specificity: 0.9991 - F1: 0.8724 - Loss: 0.1456\n",
      "\n",
      "Batch 44/387 ━━━━━━━━━━━━━━━━━━━━ 19:05:27\n",
      "Accuracy: 0.9973 - Precision: 0.8961 - Recall: 0.8655 - Specificity: 0.9991 - F1: 0.8735 - Loss: 0.1445\n",
      "\n",
      "Batch 45/387 ━━━━━━━━━━━━━━━━━━━━ 19:06:48\n",
      "Accuracy: 0.9973 - Precision: 0.8979 - Recall: 0.8639 - Specificity: 0.9991 - F1: 0.8734 - Loss: 0.1444\n",
      "\n",
      "Batch 46/387 ━━━━━━━━━━━━━━━━━━━━ 19:08:25\n",
      "Accuracy: 0.9974 - Precision: 0.8941 - Recall: 0.8652 - Specificity: 0.9991 - F1: 0.8721 - Loss: 0.1456\n",
      "\n",
      "Batch 47/387 ━━━━━━━━━━━━━━━━━━━━ 19:09:52\n",
      "Accuracy: 0.9974 - Precision: 0.8951 - Recall: 0.8655 - Specificity: 0.9991 - F1: 0.8729 - Loss: 0.1448\n",
      "\n",
      "Batch 48/387 ━━━━━━━━━━━━━━━━━━━━ 19:11:11\n",
      "Accuracy: 0.9973 - Precision: 0.8925 - Recall: 0.8652 - Specificity: 0.9991 - F1: 0.8716 - Loss: 0.1461\n",
      "\n",
      "Batch 49/387 ━━━━━━━━━━━━━━━━━━━━ 19:12:42\n",
      "Accuracy: 0.9974 - Precision: 0.8916 - Recall: 0.8633 - Specificity: 0.9991 - F1: 0.8702 - Loss: 0.1474\n",
      "\n",
      "Batch 50/387 ━━━━━━━━━━━━━━━━━━━━ 19:14:08\n",
      "Accuracy: 0.9974 - Precision: 0.8913 - Recall: 0.8653 - Specificity: 0.9991 - F1: 0.8713 - Loss: 0.1463\n",
      "\n",
      "Batch 51/387 ━━━━━━━━━━━━━━━━━━━━ 19:15:27\n",
      "Accuracy: 0.9974 - Precision: 0.8916 - Recall: 0.8654 - Specificity: 0.9991 - F1: 0.8716 - Loss: 0.1459\n",
      "\n",
      "Batch 52/387 ━━━━━━━━━━━━━━━━━━━━ 19:16:50\n",
      "Accuracy: 0.9974 - Precision: 0.8880 - Recall: 0.8679 - Specificity: 0.9990 - F1: 0.8707 - Loss: 0.1469\n",
      "\n",
      "Batch 53/387 ━━━━━━━━━━━━━━━━━━━━ 19:18:09\n",
      "Accuracy: 0.9974 - Precision: 0.8872 - Recall: 0.8684 - Specificity: 0.9990 - F1: 0.8707 - Loss: 0.1468\n",
      "\n",
      "Batch 54/387 ━━━━━━━━━━━━━━━━━━━━ 19:19:24\n",
      "Accuracy: 0.9974 - Precision: 0.8877 - Recall: 0.8706 - Specificity: 0.9990 - F1: 0.8721 - Loss: 0.1452\n",
      "\n",
      "Batch 55/387 ━━━━━━━━━━━━━━━━━━━━ 19:20:51\n",
      "Accuracy: 0.9973 - Precision: 0.8836 - Recall: 0.8712 - Specificity: 0.9989 - F1: 0.8702 - Loss: 0.1475\n",
      "\n",
      "Batch 56/387 ━━━━━━━━━━━━━━━━━━━━ 19:22:13\n",
      "Accuracy: 0.9973 - Precision: 0.8833 - Recall: 0.8710 - Specificity: 0.9989 - F1: 0.8700 - Loss: 0.1477\n",
      "\n",
      "Batch 57/387 ━━━━━━━━━━━━━━━━━━━━ 19:23:37\n",
      "Accuracy: 0.9973 - Precision: 0.8820 - Recall: 0.8731 - Specificity: 0.9989 - F1: 0.8703 - Loss: 0.1473\n",
      "\n",
      "Batch 58/387 ━━━━━━━━━━━━━━━━━━━━ 19:25:03\n",
      "Accuracy: 0.9973 - Precision: 0.8825 - Recall: 0.8739 - Specificity: 0.9989 - F1: 0.8711 - Loss: 0.1464\n",
      "\n",
      "Batch 59/387 ━━━━━━━━━━━━━━━━━━━━ 19:26:36\n",
      "Accuracy: 0.9974 - Precision: 0.8826 - Recall: 0.8727 - Specificity: 0.9989 - F1: 0.8707 - Loss: 0.1468\n",
      "\n",
      "Batch 60/387 ━━━━━━━━━━━━━━━━━━━━ 19:28:00\n",
      "Accuracy: 0.9973 - Precision: 0.8841 - Recall: 0.8695 - Specificity: 0.9989 - F1: 0.8695 - Loss: 0.1482\n",
      "\n",
      "Batch 61/387 ━━━━━━━━━━━━━━━━━━━━ 19:29:24\n",
      "Accuracy: 0.9973 - Precision: 0.8856 - Recall: 0.8703 - Specificity: 0.9989 - F1: 0.8708 - Loss: 0.1468\n",
      "\n",
      "Batch 62/387 ━━━━━━━━━━━━━━━━━━━━ 19:30:45\n",
      "Accuracy: 0.9973 - Precision: 0.8871 - Recall: 0.8713 - Specificity: 0.9990 - F1: 0.8721 - Loss: 0.1453\n",
      "\n",
      "Batch 63/387 ━━━━━━━━━━━━━━━━━━━━ 19:32:06\n",
      "Accuracy: 0.9973 - Precision: 0.8803 - Recall: 0.8722 - Specificity: 0.9989 - F1: 0.8681 - Loss: 0.1494\n",
      "\n",
      "Batch 64/387 ━━━━━━━━━━━━━━━━━━━━ 19:33:29\n",
      "Accuracy: 0.9974 - Precision: 0.8786 - Recall: 0.8742 - Specificity: 0.9989 - F1: 0.8681 - Loss: 0.1493\n",
      "\n",
      "Batch 65/387 ━━━━━━━━━━━━━━━━━━━━ 19:34:44\n",
      "Accuracy: 0.9974 - Precision: 0.8801 - Recall: 0.8720 - Specificity: 0.9989 - F1: 0.8676 - Loss: 0.1498\n",
      "\n",
      "Batch 66/387 ━━━━━━━━━━━━━━━━━━━━ 19:36:13\n",
      "Accuracy: 0.9974 - Precision: 0.8779 - Recall: 0.8732 - Specificity: 0.9989 - F1: 0.8670 - Loss: 0.1502\n",
      "\n",
      "Batch 67/387 ━━━━━━━━━━━━━━━━━━━━ 19:37:37\n",
      "Accuracy: 0.9974 - Precision: 0.8771 - Recall: 0.8728 - Specificity: 0.9990 - F1: 0.8665 - Loss: 0.1507\n",
      "\n",
      "Batch 68/387 ━━━━━━━━━━━━━━━━━━━━ 19:38:59\n",
      "Accuracy: 0.9974 - Precision: 0.8787 - Recall: 0.8709 - Specificity: 0.9990 - F1: 0.8663 - Loss: 0.1511\n",
      "\n",
      "Batch 69/387 ━━━━━━━━━━━━━━━━━━━━ 19:40:25\n",
      "Accuracy: 0.9974 - Precision: 0.8803 - Recall: 0.8713 - Specificity: 0.9990 - F1: 0.8674 - Loss: 0.1499\n",
      "\n",
      "Batch 70/387 ━━━━━━━━━━━━━━━━━━━━ 19:41:40\n",
      "Accuracy: 0.9974 - Precision: 0.8820 - Recall: 0.8703 - Specificity: 0.9990 - F1: 0.8677 - Loss: 0.1497\n",
      "\n",
      "Batch 71/387 ━━━━━━━━━━━━━━━━━━━━ 19:43:11\n",
      "Accuracy: 0.9974 - Precision: 0.8796 - Recall: 0.8718 - Specificity: 0.9990 - F1: 0.8670 - Loss: 0.1504\n",
      "\n",
      "Batch 72/387 ━━━━━━━━━━━━━━━━━━━━ 19:44:34\n",
      "Accuracy: 0.9974 - Precision: 0.8808 - Recall: 0.8714 - Specificity: 0.9990 - F1: 0.8675 - Loss: 0.1499\n",
      "\n",
      "Batch 73/387 ━━━━━━━━━━━━━━━━━━━━ 19:45:53\n",
      "Accuracy: 0.9974 - Precision: 0.8823 - Recall: 0.8715 - Specificity: 0.9990 - F1: 0.8684 - Loss: 0.1490\n",
      "\n",
      "Batch 74/387 ━━━━━━━━━━━━━━━━━━━━ 19:47:12\n",
      "Accuracy: 0.9974 - Precision: 0.8831 - Recall: 0.8721 - Specificity: 0.9990 - F1: 0.8692 - Loss: 0.1481\n",
      "\n",
      "Batch 75/387 ━━━━━━━━━━━━━━━━━━━━ 19:48:23\n",
      "Accuracy: 0.9974 - Precision: 0.8846 - Recall: 0.8697 - Specificity: 0.9990 - F1: 0.8685 - Loss: 0.1489\n",
      "\n",
      "Batch 76/387 ━━━━━━━━━━━━━━━━━━━━ 19:49:51\n",
      "Accuracy: 0.9974 - Precision: 0.8859 - Recall: 0.8698 - Specificity: 0.9990 - F1: 0.8693 - Loss: 0.1480\n",
      "\n",
      "Batch 77/387 ━━━━━━━━━━━━━━━━━━━━ 19:51:14\n",
      "Accuracy: 0.9974 - Precision: 0.8871 - Recall: 0.8702 - Specificity: 0.9990 - F1: 0.8702 - Loss: 0.1469\n",
      "\n",
      "Batch 78/387 ━━━━━━━━━━━━━━━━━━━━ 19:52:41\n",
      "Accuracy: 0.9974 - Precision: 0.8884 - Recall: 0.8693 - Specificity: 0.9991 - F1: 0.8703 - Loss: 0.1469\n",
      "\n",
      "Batch 79/387 ━━━━━━━━━━━━━━━━━━━━ 19:54:02\n",
      "Accuracy: 0.9974 - Precision: 0.8891 - Recall: 0.8683 - Specificity: 0.9991 - F1: 0.8702 - Loss: 0.1471\n",
      "\n",
      "Batch 80/387 ━━━━━━━━━━━━━━━━━━━━ 19:55:11\n",
      "Accuracy: 0.9973 - Precision: 0.8901 - Recall: 0.8666 - Specificity: 0.9991 - F1: 0.8697 - Loss: 0.1476\n",
      "\n",
      "Batch 81/387 ━━━━━━━━━━━━━━━━━━━━ 19:56:35\n",
      "Accuracy: 0.9974 - Precision: 0.8909 - Recall: 0.8678 - Specificity: 0.9991 - F1: 0.8709 - Loss: 0.1464\n",
      "\n",
      "Batch 82/387 ━━━━━━━━━━━━━━━━━━━━ 19:57:53\n",
      "Accuracy: 0.9974 - Precision: 0.8900 - Recall: 0.8691 - Specificity: 0.9991 - F1: 0.8711 - Loss: 0.1462\n",
      "\n",
      "Batch 83/387 ━━━━━━━━━━━━━━━━━━━━ 19:59:21\n",
      "Accuracy: 0.9974 - Precision: 0.8904 - Recall: 0.8703 - Specificity: 0.9991 - F1: 0.8720 - Loss: 0.1451\n",
      "\n",
      "Batch 84/387 ━━━━━━━━━━━━━━━━━━━━ 20:00:45\n",
      "Accuracy: 0.9973 - Precision: 0.8872 - Recall: 0.8697 - Specificity: 0.9990 - F1: 0.8700 - Loss: 0.1474\n",
      "\n",
      "Batch 85/387 ━━━━━━━━━━━━━━━━━━━━ 20:02:02\n",
      "Accuracy: 0.9973 - Precision: 0.8877 - Recall: 0.8698 - Specificity: 0.9990 - F1: 0.8704 - Loss: 0.1470\n",
      "\n",
      "Batch 86/387 ━━━━━━━━━━━━━━━━━━━━ 20:03:17\n",
      "Accuracy: 0.9973 - Precision: 0.8872 - Recall: 0.8705 - Specificity: 0.9990 - F1: 0.8706 - Loss: 0.1468\n",
      "\n",
      "Batch 87/387 ━━━━━━━━━━━━━━━━━━━━ 20:04:43\n",
      "Accuracy: 0.9973 - Precision: 0.8873 - Recall: 0.8713 - Specificity: 0.9990 - F1: 0.8711 - Loss: 0.1463\n",
      "\n",
      "Batch 88/387 ━━━━━━━━━━━━━━━━━━━━ 20:05:57\n",
      "Accuracy: 0.9974 - Precision: 0.8876 - Recall: 0.8723 - Specificity: 0.9990 - F1: 0.8718 - Loss: 0.1455\n",
      "\n",
      "Batch 89/387 ━━━━━━━━━━━━━━━━━━━━ 20:07:24\n",
      "Accuracy: 0.9973 - Precision: 0.8880 - Recall: 0.8722 - Specificity: 0.9990 - F1: 0.8721 - Loss: 0.1453\n",
      "\n",
      "Batch 90/387 ━━━━━━━━━━━━━━━━━━━━ 20:25:40\n",
      "Accuracy: 0.9973 - Precision: 0.8889 - Recall: 0.8732 - Specificity: 0.9990 - F1: 0.8731 - Loss: 0.1442\n",
      "\n",
      "Batch 91/387 ━━━━━━━━━━━━━━━━━━━━ 20:27:36\n",
      "Accuracy: 0.9973 - Precision: 0.8868 - Recall: 0.8742 - Specificity: 0.9990 - F1: 0.8724 - Loss: 0.1449\n",
      "\n",
      "Batch 92/387 ━━━━━━━━━━━━━━━━━━━━ 20:29:05\n",
      "Accuracy: 0.9974 - Precision: 0.8848 - Recall: 0.8747 - Specificity: 0.9990 - F1: 0.8716 - Loss: 0.1458\n",
      "\n",
      "Batch 93/387 ━━━━━━━━━━━━━━━━━━━━ 20:30:36\n",
      "Accuracy: 0.9974 - Precision: 0.8848 - Recall: 0.8750 - Specificity: 0.9990 - F1: 0.8718 - Loss: 0.1456\n",
      "\n",
      "Batch 94/387 ━━━━━━━━━━━━━━━━━━━━ 20:32:10\n",
      "Accuracy: 0.9974 - Precision: 0.8859 - Recall: 0.8751 - Specificity: 0.9990 - F1: 0.8725 - Loss: 0.1449\n",
      "\n",
      "Batch 95/387 ━━━━━━━━━━━━━━━━━━━━ 20:33:45\n",
      "Accuracy: 0.9973 - Precision: 0.8863 - Recall: 0.8754 - Specificity: 0.9990 - F1: 0.8729 - Loss: 0.1444\n",
      "\n",
      "Batch 96/387 ━━━━━━━━━━━━━━━━━━━━ 20:35:13\n",
      "Accuracy: 0.9974 - Precision: 0.8858 - Recall: 0.8763 - Specificity: 0.9990 - F1: 0.8731 - Loss: 0.1442\n",
      "\n",
      "Batch 97/387 ━━━━━━━━━━━━━━━━━━━━ 20:36:43\n",
      "Accuracy: 0.9973 - Precision: 0.8869 - Recall: 0.8749 - Specificity: 0.9990 - F1: 0.8729 - Loss: 0.1446\n",
      "\n",
      "Batch 98/387 ━━━━━━━━━━━━━━━━━━━━ 20:38:13\n",
      "Accuracy: 0.9973 - Precision: 0.8873 - Recall: 0.8749 - Specificity: 0.9990 - F1: 0.8732 - Loss: 0.1443\n",
      "\n",
      "Batch 99/387 ━━━━━━━━━━━━━━━━━━━━ 20:39:41\n",
      "Accuracy: 0.9973 - Precision: 0.8870 - Recall: 0.8759 - Specificity: 0.9990 - F1: 0.8736 - Loss: 0.1439\n",
      "\n",
      "Batch 100/387 ━━━━━━━━━━━━━━━━━━━━ 20:41:10\n",
      "Accuracy: 0.9973 - Precision: 0.8881 - Recall: 0.8744 - Specificity: 0.9990 - F1: 0.8733 - Loss: 0.1444\n",
      "\n",
      "Batch 101/387 ━━━━━━━━━━━━━━━━━━━━ 20:42:31\n",
      "Accuracy: 0.9973 - Precision: 0.8879 - Recall: 0.8751 - Specificity: 0.9990 - F1: 0.8735 - Loss: 0.1441\n",
      "\n",
      "Batch 102/387 ━━━━━━━━━━━━━━━━━━━━ 20:43:51\n",
      "Accuracy: 0.9974 - Precision: 0.8888 - Recall: 0.8755 - Specificity: 0.9990 - F1: 0.8743 - Loss: 0.1433\n",
      "\n",
      "Batch 103/387 ━━━━━━━━━━━━━━━━━━━━ 20:45:18\n",
      "Accuracy: 0.9973 - Precision: 0.8897 - Recall: 0.8748 - Specificity: 0.9990 - F1: 0.8744 - Loss: 0.1432\n",
      "\n",
      "Batch 104/387 ━━━━━━━━━━━━━━━━━━━━ 20:46:39\n",
      "Accuracy: 0.9974 - Precision: 0.8899 - Recall: 0.8735 - Specificity: 0.9990 - F1: 0.8738 - Loss: 0.1439\n",
      "\n",
      "Batch 105/387 ━━━━━━━━━━━━━━━━━━━━ 20:48:05\n",
      "Accuracy: 0.9974 - Precision: 0.8906 - Recall: 0.8738 - Specificity: 0.9990 - F1: 0.8744 - Loss: 0.1432\n",
      "\n",
      "Batch 106/387 ━━━━━━━━━━━━━━━━━━━━ 20:49:25\n",
      "Accuracy: 0.9974 - Precision: 0.8903 - Recall: 0.8735 - Specificity: 0.9990 - F1: 0.8741 - Loss: 0.1434\n",
      "\n",
      "Batch 107/387 ━━━━━━━━━━━━━━━━━━━━ 20:50:48\n",
      "Accuracy: 0.9974 - Precision: 0.8901 - Recall: 0.8741 - Specificity: 0.9990 - F1: 0.8744 - Loss: 0.1431\n",
      "\n",
      "Batch 108/387 ━━━━━━━━━━━━━━━━━━━━ 20:52:06\n",
      "Accuracy: 0.9973 - Precision: 0.8908 - Recall: 0.8697 - Specificity: 0.9990 - F1: 0.8715 - Loss: 0.1467\n",
      "\n",
      "Batch 109/387 ━━━━━━━━━━━━━━━━━━━━ 20:53:26\n",
      "Accuracy: 0.9974 - Precision: 0.8908 - Recall: 0.8702 - Specificity: 0.9990 - F1: 0.8719 - Loss: 0.1462\n",
      "\n",
      "Batch 110/387 ━━━━━━━━━━━━━━━━━━━━ 20:54:51\n",
      "Accuracy: 0.9974 - Precision: 0.8914 - Recall: 0.8706 - Specificity: 0.9990 - F1: 0.8724 - Loss: 0.1456\n",
      "\n",
      "Batch 111/387 ━━━━━━━━━━━━━━━━━━━━ 20:56:18\n",
      "Accuracy: 0.9974 - Precision: 0.8890 - Recall: 0.8713 - Specificity: 0.9990 - F1: 0.8714 - Loss: 0.1467\n",
      "\n",
      "Batch 112/387 ━━━━━━━━━━━━━━━━━━━━ 20:57:36\n",
      "Accuracy: 0.9974 - Precision: 0.8888 - Recall: 0.8720 - Specificity: 0.9990 - F1: 0.8717 - Loss: 0.1463\n",
      "\n",
      "Batch 113/387 ━━━━━━━━━━━━━━━━━━━━ 20:59:07\n",
      "Accuracy: 0.9974 - Precision: 0.8894 - Recall: 0.8726 - Specificity: 0.9990 - F1: 0.8724 - Loss: 0.1455\n",
      "\n",
      "Batch 114/387 ━━━━━━━━━━━━━━━━━━━━ 21:00:36\n",
      "Accuracy: 0.9973 - Precision: 0.8901 - Recall: 0.8697 - Specificity: 0.9990 - F1: 0.8708 - Loss: 0.1474\n",
      "\n",
      "Batch 115/387 ━━━━━━━━━━━━━━━━━━━━ 21:02:08\n",
      "Accuracy: 0.9974 - Precision: 0.8904 - Recall: 0.8702 - Specificity: 0.9990 - F1: 0.8713 - Loss: 0.1468\n",
      "\n",
      "Batch 116/387 ━━━━━━━━━━━━━━━━━━━━ 21:03:35\n",
      "Accuracy: 0.9973 - Precision: 0.8904 - Recall: 0.8704 - Specificity: 0.9990 - F1: 0.8715 - Loss: 0.1467\n",
      "\n",
      "Batch 117/387 ━━━━━━━━━━━━━━━━━━━━ 21:05:15\n",
      "Accuracy: 0.9974 - Precision: 0.8899 - Recall: 0.8713 - Specificity: 0.9990 - F1: 0.8717 - Loss: 0.1464\n",
      "\n",
      "Batch 118/387 ━━━━━━━━━━━━━━━━━━━━ 21:06:41\n",
      "Accuracy: 0.9974 - Precision: 0.8906 - Recall: 0.8716 - Specificity: 0.9990 - F1: 0.8723 - Loss: 0.1458\n",
      "\n",
      "Batch 119/387 ━━━━━━━━━━━━━━━━━━━━ 21:08:08\n",
      "Accuracy: 0.9974 - Precision: 0.8903 - Recall: 0.8725 - Specificity: 0.9990 - F1: 0.8726 - Loss: 0.1454\n",
      "\n",
      "Batch 120/387 ━━━━━━━━━━━━━━━━━━━━ 21:09:37\n",
      "Accuracy: 0.9974 - Precision: 0.8901 - Recall: 0.8727 - Specificity: 0.9990 - F1: 0.8727 - Loss: 0.1452\n",
      "\n",
      "Batch 121/387 ━━━━━━━━━━━━━━━━━━━━ 21:11:02\n",
      "Accuracy: 0.9974 - Precision: 0.8899 - Recall: 0.8714 - Specificity: 0.9990 - F1: 0.8720 - Loss: 0.1461\n",
      "\n",
      "Batch 122/387 ━━━━━━━━━━━━━━━━━━━━ 21:12:23\n",
      "Accuracy: 0.9973 - Precision: 0.8879 - Recall: 0.8706 - Specificity: 0.9990 - F1: 0.8706 - Loss: 0.1476\n",
      "\n",
      "Batch 123/387 ━━━━━━━━━━━━━━━━━━━━ 21:13:45\n",
      "Accuracy: 0.9973 - Precision: 0.8881 - Recall: 0.8709 - Specificity: 0.9990 - F1: 0.8709 - Loss: 0.1472\n",
      "\n",
      "Batch 124/387 ━━━━━━━━━━━━━━━━━━━━ 21:15:11\n",
      "Accuracy: 0.9974 - Precision: 0.8878 - Recall: 0.8704 - Specificity: 0.9990 - F1: 0.8706 - Loss: 0.1475\n",
      "\n",
      "Batch 125/387 ━━━━━━━━━━━━━━━━━━━━ 21:16:28\n",
      "Accuracy: 0.9974 - Precision: 0.8877 - Recall: 0.8712 - Specificity: 0.9990 - F1: 0.8710 - Loss: 0.1470\n",
      "\n",
      "Batch 126/387 ━━━━━━━━━━━━━━━━━━━━ 21:17:48\n",
      "Accuracy: 0.9974 - Precision: 0.8882 - Recall: 0.8718 - Specificity: 0.9990 - F1: 0.8716 - Loss: 0.1463\n",
      "\n",
      "Batch 127/387 ━━━━━━━━━━━━━━━━━━━━ 21:19:08\n",
      "Accuracy: 0.9974 - Precision: 0.8883 - Recall: 0.8723 - Specificity: 0.9990 - F1: 0.8719 - Loss: 0.1460\n",
      "\n",
      "Batch 128/387 ━━━━━━━━━━━━━━━━━━━━ 21:20:32\n",
      "Accuracy: 0.9974 - Precision: 0.8875 - Recall: 0.8730 - Specificity: 0.9990 - F1: 0.8719 - Loss: 0.1460\n",
      "\n",
      "Batch 129/387 ━━━━━━━━━━━━━━━━━━━━ 21:21:59\n",
      "Accuracy: 0.9974 - Precision: 0.8841 - Recall: 0.8727 - Specificity: 0.9990 - F1: 0.8696 - Loss: 0.1483\n",
      "\n",
      "Batch 130/387 ━━━━━━━━━━━━━━━━━━━━ 21:23:20\n",
      "Accuracy: 0.9974 - Precision: 0.8848 - Recall: 0.8730 - Specificity: 0.9990 - F1: 0.8702 - Loss: 0.1477\n",
      "\n",
      "Batch 131/387 ━━━━━━━━━━━━━━━━━━━━ 21:24:54\n",
      "Accuracy: 0.9974 - Precision: 0.8847 - Recall: 0.8734 - Specificity: 0.9990 - F1: 0.8705 - Loss: 0.1473\n",
      "\n",
      "Batch 132/387 ━━━━━━━━━━━━━━━━━━━━ 21:26:28\n",
      "Accuracy: 0.9974 - Precision: 0.8846 - Recall: 0.8740 - Specificity: 0.9990 - F1: 0.8707 - Loss: 0.1470\n",
      "\n",
      "Batch 133/387 ━━━━━━━━━━━━━━━━━━━━ 21:27:49\n",
      "Accuracy: 0.9974 - Precision: 0.8848 - Recall: 0.8738 - Specificity: 0.9990 - F1: 0.8708 - Loss: 0.1469\n",
      "\n",
      "Batch 134/387 ━━━━━━━━━━━━━━━━━━━━ 21:29:18\n",
      "Accuracy: 0.9974 - Precision: 0.8855 - Recall: 0.8722 - Specificity: 0.9990 - F1: 0.8701 - Loss: 0.1477\n",
      "\n",
      "Batch 135/387 ━━━━━━━━━━━━━━━━━━━━ 21:30:54\n",
      "Accuracy: 0.9974 - Precision: 0.8862 - Recall: 0.8708 - Specificity: 0.9990 - F1: 0.8697 - Loss: 0.1482\n",
      "\n",
      "Batch 136/387 ━━━━━━━━━━━━━━━━━━━━ 21:32:19\n",
      "Accuracy: 0.9973 - Precision: 0.8869 - Recall: 0.8686 - Specificity: 0.9990 - F1: 0.8686 - Loss: 0.1495\n",
      "\n",
      "Batch 137/387 ━━━━━━━━━━━━━━━━━━━━ 21:33:41\n",
      "Accuracy: 0.9974 - Precision: 0.8873 - Recall: 0.8687 - Specificity: 0.9990 - F1: 0.8689 - Loss: 0.1491\n",
      "\n",
      "Batch 138/387 ━━━━━━━━━━━━━━━━━━━━ 21:35:11\n",
      "Accuracy: 0.9974 - Precision: 0.8870 - Recall: 0.8682 - Specificity: 0.9990 - F1: 0.8686 - Loss: 0.1494\n",
      "\n",
      "Batch 139/387 ━━━━━━━━━━━━━━━━━━━━ 21:36:32\n",
      "Accuracy: 0.9974 - Precision: 0.8854 - Recall: 0.8689 - Specificity: 0.9990 - F1: 0.8680 - Loss: 0.1500\n",
      "\n",
      "Batch 140/387 ━━━━━━━━━━━━━━━━━━━━ 21:37:56\n",
      "Accuracy: 0.9973 - Precision: 0.8856 - Recall: 0.8662 - Specificity: 0.9990 - F1: 0.8663 - Loss: 0.1519\n",
      "\n",
      "Batch 141/387 ━━━━━━━━━━━━━━━━━━━━ 21:39:30\n",
      "Accuracy: 0.9973 - Precision: 0.8821 - Recall: 0.8664 - Specificity: 0.9990 - F1: 0.8640 - Loss: 0.1542\n",
      "\n",
      "Batch 142/387 ━━━━━━━━━━━━━━━━━━━━ 21:40:54\n",
      "Accuracy: 0.9973 - Precision: 0.8809 - Recall: 0.8671 - Specificity: 0.9990 - F1: 0.8638 - Loss: 0.1545\n",
      "\n",
      "Batch 143/387 ━━━━━━━━━━━━━━━━━━━━ 21:42:15\n",
      "Accuracy: 0.9973 - Precision: 0.8813 - Recall: 0.8677 - Specificity: 0.9990 - F1: 0.8643 - Loss: 0.1539\n",
      "\n",
      "Batch 144/387 ━━━━━━━━━━━━━━━━━━━━ 21:43:45\n",
      "Accuracy: 0.9973 - Precision: 0.8810 - Recall: 0.8679 - Specificity: 0.9990 - F1: 0.8643 - Loss: 0.1539\n",
      "\n",
      "Batch 145/387 ━━━━━━━━━━━━━━━━━━━━ 21:45:11\n",
      "Accuracy: 0.9973 - Precision: 0.8814 - Recall: 0.8683 - Specificity: 0.9990 - F1: 0.8648 - Loss: 0.1534\n",
      "\n",
      "Batch 146/387 ━━━━━━━━━━━━━━━━━━━━ 21:46:28\n",
      "Accuracy: 0.9973 - Precision: 0.8818 - Recall: 0.8687 - Specificity: 0.9990 - F1: 0.8653 - Loss: 0.1529\n",
      "\n",
      "Batch 147/387 ━━━━━━━━━━━━━━━━━━━━ 21:47:46\n",
      "Accuracy: 0.9973 - Precision: 0.8804 - Recall: 0.8682 - Specificity: 0.9990 - F1: 0.8643 - Loss: 0.1538\n",
      "\n",
      "Batch 148/387 ━━━━━━━━━━━━━━━━━━━━ 21:49:16\n",
      "Accuracy: 0.9973 - Precision: 0.8805 - Recall: 0.8676 - Specificity: 0.9990 - F1: 0.8642 - Loss: 0.1540\n",
      "\n",
      "Batch 149/387 ━━━━━━━━━━━━━━━━━━━━ 21:50:33\n",
      "Accuracy: 0.9973 - Precision: 0.8803 - Recall: 0.8682 - Specificity: 0.9989 - F1: 0.8644 - Loss: 0.1537\n",
      "\n",
      "Batch 150/387 ━━━━━━━━━━━━━━━━━━━━ 21:52:06\n",
      "Accuracy: 0.9973 - Precision: 0.8809 - Recall: 0.8688 - Specificity: 0.9989 - F1: 0.8651 - Loss: 0.1530\n",
      "\n",
      "Batch 151/387 ━━━━━━━━━━━━━━━━━━━━ 21:53:29\n",
      "Accuracy: 0.9973 - Precision: 0.8769 - Recall: 0.8686 - Specificity: 0.9989 - F1: 0.8621 - Loss: 0.1561\n",
      "\n",
      "Batch 152/387 ━━━━━━━━━━━━━━━━━━━━ 21:54:48\n",
      "Accuracy: 0.9973 - Precision: 0.8770 - Recall: 0.8690 - Specificity: 0.9989 - F1: 0.8624 - Loss: 0.1557\n",
      "\n",
      "Batch 153/387 ━━━━━━━━━━━━━━━━━━━━ 21:56:13\n",
      "Accuracy: 0.9973 - Precision: 0.8776 - Recall: 0.8691 - Specificity: 0.9989 - F1: 0.8628 - Loss: 0.1553\n",
      "\n",
      "Batch 154/387 ━━━━━━━━━━━━━━━━━━━━ 21:57:46\n",
      "Accuracy: 0.9973 - Precision: 0.8779 - Recall: 0.8685 - Specificity: 0.9989 - F1: 0.8627 - Loss: 0.1554\n",
      "\n",
      "Batch 155/387 ━━━━━━━━━━━━━━━━━━━━ 21:59:06\n",
      "Accuracy: 0.9973 - Precision: 0.8787 - Recall: 0.8666 - Specificity: 0.9990 - F1: 0.8619 - Loss: 0.1564\n",
      "\n",
      "Batch 156/387 ━━━━━━━━━━━━━━━━━━━━ 22:00:30\n",
      "Accuracy: 0.9973 - Precision: 0.8789 - Recall: 0.8671 - Specificity: 0.9990 - F1: 0.8623 - Loss: 0.1560\n",
      "\n",
      "Batch 157/387 ━━━━━━━━━━━━━━━━━━━━ 22:01:51\n",
      "Accuracy: 0.9973 - Precision: 0.8795 - Recall: 0.8673 - Specificity: 0.9990 - F1: 0.8627 - Loss: 0.1555\n",
      "\n",
      "Batch 158/387 ━━━━━━━━━━━━━━━━━━━━ 22:03:27\n",
      "Accuracy: 0.9973 - Precision: 0.8793 - Recall: 0.8680 - Specificity: 0.9990 - F1: 0.8630 - Loss: 0.1551\n",
      "\n",
      "Batch 159/387 ━━━━━━━━━━━━━━━━━━━━ 22:04:48\n",
      "Accuracy: 0.9973 - Precision: 0.8798 - Recall: 0.8685 - Specificity: 0.9990 - F1: 0.8636 - Loss: 0.1545\n",
      "\n",
      "Batch 160/387 ━━━━━━━━━━━━━━━━━━━━ 22:06:06\n",
      "Accuracy: 0.9974 - Precision: 0.8804 - Recall: 0.8686 - Specificity: 0.9990 - F1: 0.8640 - Loss: 0.1540\n",
      "\n",
      "Batch 161/387 ━━━━━━━━━━━━━━━━━━━━ 22:07:25\n",
      "Accuracy: 0.9974 - Precision: 0.8811 - Recall: 0.8678 - Specificity: 0.9990 - F1: 0.8639 - Loss: 0.1541\n",
      "\n",
      "Batch 162/387 ━━━━━━━━━━━━━━━━━━━━ 22:08:49\n",
      "Accuracy: 0.9974 - Precision: 0.8817 - Recall: 0.8674 - Specificity: 0.9990 - F1: 0.8640 - Loss: 0.1539\n",
      "\n",
      "Batch 163/387 ━━━━━━━━━━━━━━━━━━━━ 22:10:11\n",
      "Accuracy: 0.9974 - Precision: 0.8822 - Recall: 0.8680 - Specificity: 0.9990 - F1: 0.8646 - Loss: 0.1533\n",
      "\n",
      "Batch 164/387 ━━━━━━━━━━━━━━━━━━━━ 22:11:37\n",
      "Accuracy: 0.9974 - Precision: 0.8827 - Recall: 0.8685 - Specificity: 0.9990 - F1: 0.8652 - Loss: 0.1527\n",
      "\n",
      "Batch 165/387 ━━━━━━━━━━━━━━━━━━━━ 22:12:57\n",
      "Accuracy: 0.9974 - Precision: 0.8818 - Recall: 0.8692 - Specificity: 0.9990 - F1: 0.8650 - Loss: 0.1528\n",
      "\n",
      "Batch 166/387 ━━━━━━━━━━━━━━━━━━━━ 22:14:22\n",
      "Accuracy: 0.9974 - Precision: 0.8806 - Recall: 0.8694 - Specificity: 0.9990 - F1: 0.8645 - Loss: 0.1534\n",
      "\n",
      "Batch 167/387 ━━━━━━━━━━━━━━━━━━━━ 22:15:50\n",
      "Accuracy: 0.9974 - Precision: 0.8811 - Recall: 0.8696 - Specificity: 0.9990 - F1: 0.8649 - Loss: 0.1530\n",
      "\n",
      "Batch 168/387 ━━━━━━━━━━━━━━━━━━━━ 22:17:17\n",
      "Accuracy: 0.9974 - Precision: 0.8815 - Recall: 0.8700 - Specificity: 0.9990 - F1: 0.8654 - Loss: 0.1525\n",
      "\n",
      "Batch 169/387 ━━━━━━━━━━━━━━━━━━━━ 22:18:31\n",
      "Accuracy: 0.9974 - Precision: 0.8815 - Recall: 0.8706 - Specificity: 0.9990 - F1: 0.8657 - Loss: 0.1521\n",
      "\n",
      "Batch 170/387 ━━━━━━━━━━━━━━━━━━━━ 22:20:02\n",
      "Accuracy: 0.9974 - Precision: 0.8803 - Recall: 0.8694 - Specificity: 0.9990 - F1: 0.8646 - Loss: 0.1532\n",
      "\n",
      "Batch 171/387 ━━━━━━━━━━━━━━━━━━━━ 22:21:35\n",
      "Accuracy: 0.9974 - Precision: 0.8798 - Recall: 0.8696 - Specificity: 0.9990 - F1: 0.8645 - Loss: 0.1533\n",
      "\n",
      "Batch 172/387 ━━━━━━━━━━━━━━━━━━━━ 22:23:07\n",
      "Accuracy: 0.9974 - Precision: 0.8790 - Recall: 0.8683 - Specificity: 0.9990 - F1: 0.8634 - Loss: 0.1546\n",
      "\n",
      "Batch 173/387 ━━━━━━━━━━━━━━━━━━━━ 22:24:21\n",
      "Accuracy: 0.9974 - Precision: 0.8779 - Recall: 0.8689 - Specificity: 0.9989 - F1: 0.8631 - Loss: 0.1549\n",
      "\n",
      "Batch 174/387 ━━━━━━━━━━━━━━━━━━━━ 22:25:53\n",
      "Accuracy: 0.9974 - Precision: 0.8783 - Recall: 0.8692 - Specificity: 0.9989 - F1: 0.8636 - Loss: 0.1544\n",
      "\n",
      "Batch 175/387 ━━━━━━━━━━━━━━━━━━━━ 22:27:31\n",
      "Accuracy: 0.9974 - Precision: 0.8787 - Recall: 0.8698 - Specificity: 0.9989 - F1: 0.8641 - Loss: 0.1539\n",
      "\n",
      "Batch 176/387 ━━━━━━━━━━━━━━━━━━━━ 22:28:56\n",
      "Accuracy: 0.9974 - Precision: 0.8791 - Recall: 0.8703 - Specificity: 0.9989 - F1: 0.8646 - Loss: 0.1533\n",
      "\n",
      "Batch 177/387 ━━━━━━━━━━━━━━━━━━━━ 22:30:20\n",
      "Accuracy: 0.9974 - Precision: 0.8795 - Recall: 0.8704 - Specificity: 0.9990 - F1: 0.8649 - Loss: 0.1529\n",
      "\n",
      "Batch 178/387 ━━━━━━━━━━━━━━━━━━━━ 22:31:41\n",
      "Accuracy: 0.9974 - Precision: 0.8786 - Recall: 0.8710 - Specificity: 0.9989 - F1: 0.8647 - Loss: 0.1531\n",
      "\n",
      "Batch 179/387 ━━━━━━━━━━━━━━━━━━━━ 22:33:01\n",
      "Accuracy: 0.9974 - Precision: 0.8786 - Recall: 0.8713 - Specificity: 0.9989 - F1: 0.8650 - Loss: 0.1528\n",
      "\n",
      "Batch 180/387 ━━━━━━━━━━━━━━━━━━━━ 22:34:28\n",
      "Accuracy: 0.9974 - Precision: 0.8792 - Recall: 0.8713 - Specificity: 0.9990 - F1: 0.8652 - Loss: 0.1525\n",
      "\n",
      "Batch 181/387 ━━━━━━━━━━━━━━━━━━━━ 22:35:53\n",
      "Accuracy: 0.9974 - Precision: 0.8797 - Recall: 0.8710 - Specificity: 0.9990 - F1: 0.8654 - Loss: 0.1524\n",
      "\n",
      "Batch 182/387 ━━━━━━━━━━━━━━━━━━━━ 22:37:19\n",
      "Accuracy: 0.9974 - Precision: 0.8801 - Recall: 0.8714 - Specificity: 0.9990 - F1: 0.8658 - Loss: 0.1519\n",
      "\n",
      "Batch 183/387 ━━━━━━━━━━━━━━━━━━━━ 22:38:38\n",
      "Accuracy: 0.9974 - Precision: 0.8805 - Recall: 0.8715 - Specificity: 0.9990 - F1: 0.8662 - Loss: 0.1516\n",
      "\n",
      "Batch 184/387 ━━━━━━━━━━━━━━━━━━━━ 22:40:03\n",
      "Accuracy: 0.9974 - Precision: 0.8810 - Recall: 0.8708 - Specificity: 0.9990 - F1: 0.8660 - Loss: 0.1518\n",
      "\n",
      "Batch 185/387 ━━━━━━━━━━━━━━━━━━━━ 22:41:23\n",
      "Accuracy: 0.9974 - Precision: 0.8813 - Recall: 0.8713 - Specificity: 0.9990 - F1: 0.8664 - Loss: 0.1513\n",
      "\n",
      "Batch 186/387 ━━━━━━━━━━━━━━━━━━━━ 22:42:50\n",
      "Accuracy: 0.9974 - Precision: 0.8796 - Recall: 0.8711 - Specificity: 0.9990 - F1: 0.8655 - Loss: 0.1523\n",
      "\n",
      "Batch 187/387 ━━━━━━━━━━━━━━━━━━━━ 22:44:10\n",
      "Accuracy: 0.9974 - Precision: 0.8789 - Recall: 0.8717 - Specificity: 0.9990 - F1: 0.8653 - Loss: 0.1524\n",
      "\n",
      "Batch 188/387 ━━━━━━━━━━━━━━━━━━━━ 22:45:30\n",
      "Accuracy: 0.9974 - Precision: 0.8782 - Recall: 0.8721 - Specificity: 0.9989 - F1: 0.8652 - Loss: 0.1526\n",
      "\n",
      "Batch 189/387 ━━━━━━━━━━━━━━━━━━━━ 22:46:51\n",
      "Accuracy: 0.9974 - Precision: 0.8783 - Recall: 0.8726 - Specificity: 0.9989 - F1: 0.8655 - Loss: 0.1522\n",
      "\n",
      "Batch 190/387 ━━━━━━━━━━━━━━━━━━━━ 22:48:21\n",
      "Accuracy: 0.9974 - Precision: 0.8775 - Recall: 0.8720 - Specificity: 0.9989 - F1: 0.8649 - Loss: 0.1528\n",
      "\n",
      "Batch 191/387 ━━━━━━━━━━━━━━━━━━━━ 22:49:38\n",
      "Accuracy: 0.9974 - Precision: 0.8778 - Recall: 0.8723 - Specificity: 0.9989 - F1: 0.8652 - Loss: 0.1524\n",
      "\n",
      "Batch 192/387 ━━━━━━━━━━━━━━━━━━━━ 22:51:13\n",
      "Accuracy: 0.9974 - Precision: 0.8784 - Recall: 0.8721 - Specificity: 0.9989 - F1: 0.8655 - Loss: 0.1522\n",
      "\n",
      "Batch 193/387 ━━━━━━━━━━━━━━━━━━━━ 22:52:48\n",
      "Accuracy: 0.9974 - Precision: 0.8789 - Recall: 0.8723 - Specificity: 0.9990 - F1: 0.8659 - Loss: 0.1518\n",
      "\n",
      "Batch 194/387 ━━━━━━━━━━━━━━━━━━━━ 22:54:06\n",
      "Accuracy: 0.9974 - Precision: 0.8789 - Recall: 0.8726 - Specificity: 0.9989 - F1: 0.8661 - Loss: 0.1516\n",
      "\n",
      "Batch 195/387 ━━━━━━━━━━━━━━━━━━━━ 22:55:30\n",
      "Accuracy: 0.9974 - Precision: 0.8795 - Recall: 0.8728 - Specificity: 0.9990 - F1: 0.8665 - Loss: 0.1511\n",
      "\n",
      "Batch 196/387 ━━━━━━━━━━━━━━━━━━━━ 22:57:05\n",
      "Accuracy: 0.9974 - Precision: 0.8797 - Recall: 0.8721 - Specificity: 0.9990 - F1: 0.8663 - Loss: 0.1514\n",
      "\n",
      "Batch 197/387 ━━━━━━━━━━━━━━━━━━━━ 22:58:22\n",
      "Accuracy: 0.9974 - Precision: 0.8798 - Recall: 0.8724 - Specificity: 0.9990 - F1: 0.8665 - Loss: 0.1511\n",
      "\n",
      "Batch 198/387 ━━━━━━━━━━━━━━━━━━━━ 22:59:57\n",
      "Accuracy: 0.9974 - Precision: 0.8796 - Recall: 0.8729 - Specificity: 0.9990 - F1: 0.8667 - Loss: 0.1509\n",
      "\n",
      "Batch 199/387 ━━━━━━━━━━━━━━━━━━━━ 23:01:25\n",
      "Accuracy: 0.9974 - Precision: 0.8800 - Recall: 0.8730 - Specificity: 0.9990 - F1: 0.8670 - Loss: 0.1506\n",
      "\n",
      "Batch 200/387 ━━━━━━━━━━━━━━━━━━━━ 23:02:44\n",
      "Accuracy: 0.9974 - Precision: 0.8805 - Recall: 0.8731 - Specificity: 0.9990 - F1: 0.8673 - Loss: 0.1502\n",
      "\n",
      "Batch 201/387 ━━━━━━━━━━━━━━━━━━━━ 23:04:11\n",
      "Accuracy: 0.9974 - Precision: 0.8809 - Recall: 0.8736 - Specificity: 0.9990 - F1: 0.8677 - Loss: 0.1497\n",
      "\n",
      "Batch 202/387 ━━━━━━━━━━━━━━━━━━━━ 23:05:26\n",
      "Accuracy: 0.9975 - Precision: 0.8810 - Recall: 0.8737 - Specificity: 0.9990 - F1: 0.8679 - Loss: 0.1495\n",
      "\n",
      "Batch 203/387 ━━━━━━━━━━━━━━━━━━━━ 23:06:48\n",
      "Accuracy: 0.9975 - Precision: 0.8814 - Recall: 0.8741 - Specificity: 0.9990 - F1: 0.8684 - Loss: 0.1490\n",
      "\n",
      "Batch 204/387 ━━━━━━━━━━━━━━━━━━━━ 23:08:14\n",
      "Accuracy: 0.9975 - Precision: 0.8819 - Recall: 0.8739 - Specificity: 0.9990 - F1: 0.8685 - Loss: 0.1488\n",
      "\n",
      "Batch 205/387 ━━━━━━━━━━━━━━━━━━━━ 23:09:36\n",
      "Accuracy: 0.9975 - Precision: 0.8822 - Recall: 0.8742 - Specificity: 0.9990 - F1: 0.8689 - Loss: 0.1484\n",
      "\n",
      "Batch 206/387 ━━━━━━━━━━━━━━━━━━━━ 23:10:52\n",
      "Accuracy: 0.9975 - Precision: 0.8802 - Recall: 0.8747 - Specificity: 0.9990 - F1: 0.8678 - Loss: 0.1496\n",
      "\n",
      "Batch 207/387 ━━━━━━━━━━━━━━━━━━━━ 23:12:19\n",
      "Accuracy: 0.9975 - Precision: 0.8796 - Recall: 0.8737 - Specificity: 0.9990 - F1: 0.8670 - Loss: 0.1503\n",
      "\n",
      "Batch 208/387 ━━━━━━━━━━━━━━━━━━━━ 23:13:55\n",
      "Accuracy: 0.9975 - Precision: 0.8795 - Recall: 0.8728 - Specificity: 0.9990 - F1: 0.8665 - Loss: 0.1509\n",
      "\n",
      "Batch 209/387 ━━━━━━━━━━━━━━━━━━━━ 23:15:30\n",
      "Accuracy: 0.9975 - Precision: 0.8797 - Recall: 0.8732 - Specificity: 0.9990 - F1: 0.8669 - Loss: 0.1506\n",
      "\n",
      "Batch 210/387 ━━━━━━━━━━━━━━━━━━━━ 23:17:03\n",
      "Accuracy: 0.9975 - Precision: 0.8798 - Recall: 0.8738 - Specificity: 0.9990 - F1: 0.8672 - Loss: 0.1502\n",
      "\n",
      "Batch 211/387 ━━━━━━━━━━━━━━━━━━━━ 23:18:21\n",
      "Accuracy: 0.9975 - Precision: 0.8795 - Recall: 0.8742 - Specificity: 0.9990 - F1: 0.8673 - Loss: 0.1500\n",
      "\n",
      "Batch 212/387 ━━━━━━━━━━━━━━━━━━━━ 23:19:30\n",
      "Accuracy: 0.9974 - Precision: 0.8801 - Recall: 0.8728 - Specificity: 0.9990 - F1: 0.8667 - Loss: 0.1509\n",
      "\n",
      "Batch 213/387 ━━━━━━━━━━━━━━━━━━━━ 23:20:59\n",
      "Accuracy: 0.9975 - Precision: 0.8802 - Recall: 0.8730 - Specificity: 0.9990 - F1: 0.8669 - Loss: 0.1506\n",
      "\n",
      "Batch 214/387 ━━━━━━━━━━━━━━━━━━━━ 23:22:24\n",
      "Accuracy: 0.9975 - Precision: 0.8804 - Recall: 0.8717 - Specificity: 0.9990 - F1: 0.8662 - Loss: 0.1513\n",
      "\n",
      "Batch 215/387 ━━━━━━━━━━━━━━━━━━━━ 23:23:38\n",
      "Accuracy: 0.9975 - Precision: 0.8802 - Recall: 0.8719 - Specificity: 0.9990 - F1: 0.8662 - Loss: 0.1513\n",
      "\n",
      "Batch 216/387 ━━━━━━━━━━━━━━━━━━━━ 23:25:02\n",
      "Accuracy: 0.9975 - Precision: 0.8806 - Recall: 0.8721 - Specificity: 0.9990 - F1: 0.8666 - Loss: 0.1509\n",
      "\n",
      "Batch 217/387 ━━━━━━━━━━━━━━━━━━━━ 23:26:34\n",
      "Accuracy: 0.9975 - Precision: 0.8806 - Recall: 0.8724 - Specificity: 0.9990 - F1: 0.8668 - Loss: 0.1506\n",
      "\n",
      "Batch 218/387 ━━━━━━━━━━━━━━━━━━━━ 23:28:03\n",
      "Accuracy: 0.9975 - Precision: 0.8810 - Recall: 0.8725 - Specificity: 0.9990 - F1: 0.8670 - Loss: 0.1504\n",
      "\n",
      "Batch 219/387 ━━━━━━━━━━━━━━━━━━━━ 23:29:16\n",
      "Accuracy: 0.9975 - Precision: 0.8809 - Recall: 0.8723 - Specificity: 0.9990 - F1: 0.8669 - Loss: 0.1504\n",
      "\n",
      "Batch 220/387 ━━━━━━━━━━━━━━━━━━━━ 23:30:46\n",
      "Accuracy: 0.9975 - Precision: 0.8801 - Recall: 0.8720 - Specificity: 0.9990 - F1: 0.8664 - Loss: 0.1509\n",
      "\n",
      "Batch 221/387 ━━━━━━━━━━━━━━━━━━━━ 23:32:15\n",
      "Accuracy: 0.9975 - Precision: 0.8806 - Recall: 0.8718 - Specificity: 0.9990 - F1: 0.8666 - Loss: 0.1508\n",
      "\n",
      "Batch 222/387 ━━━━━━━━━━━━━━━━━━━━ 23:33:41\n",
      "Accuracy: 0.9975 - Precision: 0.8811 - Recall: 0.8716 - Specificity: 0.9990 - F1: 0.8668 - Loss: 0.1506\n",
      "\n",
      "Batch 223/387 ━━━━━━━━━━━━━━━━━━━━ 23:35:11\n",
      "Accuracy: 0.9975 - Precision: 0.8814 - Recall: 0.8714 - Specificity: 0.9990 - F1: 0.8668 - Loss: 0.1505\n",
      "\n",
      "Batch 224/387 ━━━━━━━━━━━━━━━━━━━━ 23:36:46\n",
      "Accuracy: 0.9975 - Precision: 0.8804 - Recall: 0.8717 - Specificity: 0.9990 - F1: 0.8664 - Loss: 0.1509\n",
      "\n",
      "Batch 225/387 ━━━━━━━━━━━━━━━━━━━━ 23:38:10\n",
      "Accuracy: 0.9975 - Precision: 0.8803 - Recall: 0.8716 - Specificity: 0.9990 - F1: 0.8664 - Loss: 0.1510\n",
      "\n",
      "Batch 226/387 ━━━━━━━━━━━━━━━━━━━━ 23:39:40\n",
      "Accuracy: 0.9975 - Precision: 0.8805 - Recall: 0.8716 - Specificity: 0.9990 - F1: 0.8665 - Loss: 0.1508\n",
      "\n",
      "Batch 227/387 ━━━━━━━━━━━━━━━━━━━━ 23:41:14\n",
      "Accuracy: 0.9975 - Precision: 0.8789 - Recall: 0.8722 - Specificity: 0.9990 - F1: 0.8657 - Loss: 0.1517\n",
      "\n",
      "Batch 228/387 ━━━━━━━━━━━━━━━━━━━━ 23:42:35\n",
      "Accuracy: 0.9975 - Precision: 0.8793 - Recall: 0.8715 - Specificity: 0.9990 - F1: 0.8655 - Loss: 0.1519\n",
      "\n",
      "Batch 229/387 ━━━━━━━━━━━━━━━━━━━━ 23:44:04\n",
      "Accuracy: 0.9974 - Precision: 0.8798 - Recall: 0.8709 - Specificity: 0.9990 - F1: 0.8654 - Loss: 0.1522\n",
      "\n",
      "Batch 230/387 ━━━━━━━━━━━━━━━━━━━━ 23:45:15\n",
      "Accuracy: 0.9974 - Precision: 0.8794 - Recall: 0.8711 - Specificity: 0.9990 - F1: 0.8653 - Loss: 0.1523\n",
      "\n",
      "Batch 231/387 ━━━━━━━━━━━━━━━━━━━━ 23:46:33\n",
      "Accuracy: 0.9974 - Precision: 0.8794 - Recall: 0.8711 - Specificity: 0.9990 - F1: 0.8654 - Loss: 0.1523\n",
      "\n",
      "Batch 232/387 ━━━━━━━━━━━━━━━━━━━━ 23:47:57\n",
      "Accuracy: 0.9974 - Precision: 0.8786 - Recall: 0.8716 - Specificity: 0.9990 - F1: 0.8652 - Loss: 0.1524\n",
      "\n",
      "Batch 233/387 ━━━━━━━━━━━━━━━━━━━━ 23:49:10\n",
      "Accuracy: 0.9975 - Precision: 0.8789 - Recall: 0.8718 - Specificity: 0.9990 - F1: 0.8655 - Loss: 0.1521\n",
      "\n",
      "Batch 234/387 ━━━━━━━━━━━━━━━━━━━━ 23:50:34\n",
      "Accuracy: 0.9975 - Precision: 0.8792 - Recall: 0.8721 - Specificity: 0.9990 - F1: 0.8658 - Loss: 0.1517\n",
      "\n",
      "Batch 235/387 ━━━━━━━━━━━━━━━━━━━━ 23:51:58\n",
      "Accuracy: 0.9975 - Precision: 0.8796 - Recall: 0.8722 - Specificity: 0.9990 - F1: 0.8660 - Loss: 0.1515\n",
      "\n",
      "Batch 236/387 ━━━━━━━━━━━━━━━━━━━━ 23:53:22\n",
      "Accuracy: 0.9975 - Precision: 0.8787 - Recall: 0.8727 - Specificity: 0.9990 - F1: 0.8658 - Loss: 0.1518\n",
      "\n",
      "Batch 237/387 ━━━━━━━━━━━━━━━━━━━━ 23:54:44\n",
      "Accuracy: 0.9974 - Precision: 0.8790 - Recall: 0.8721 - Specificity: 0.9990 - F1: 0.8656 - Loss: 0.1520\n",
      "\n",
      "Batch 238/387 ━━━━━━━━━━━━━━━━━━━━ 23:56:05\n",
      "Accuracy: 0.9974 - Precision: 0.8795 - Recall: 0.8724 - Specificity: 0.9990 - F1: 0.8660 - Loss: 0.1516\n",
      "\n",
      "Batch 239/387 ━━━━━━━━━━━━━━━━━━━━ 23:57:32\n",
      "Accuracy: 0.9974 - Precision: 0.8798 - Recall: 0.8719 - Specificity: 0.9990 - F1: 0.8659 - Loss: 0.1516\n",
      "\n",
      "Batch 240/387 ━━━━━━━━━━━━━━━━━━━━ 00:06:26\n",
      "Accuracy: 0.9974 - Precision: 0.8801 - Recall: 0.8722 - Specificity: 0.9990 - F1: 0.8663 - Loss: 0.1513\n",
      "\n",
      "Batch 241/387 ━━━━━━━━━━━━━━━━━━━━ 00:08:24\n",
      "Accuracy: 0.9974 - Precision: 0.8801 - Recall: 0.8724 - Specificity: 0.9990 - F1: 0.8664 - Loss: 0.1511\n",
      "\n",
      "Batch 242/387 ━━━━━━━━━━━━━━━━━━━━ 00:10:16\n",
      "Accuracy: 0.9974 - Precision: 0.8800 - Recall: 0.8725 - Specificity: 0.9990 - F1: 0.8664 - Loss: 0.1511\n",
      "\n",
      "Batch 243/387 ━━━━━━━━━━━━━━━━━━━━ 00:11:48\n",
      "Accuracy: 0.9974 - Precision: 0.8804 - Recall: 0.8719 - Specificity: 0.9990 - F1: 0.8663 - Loss: 0.1512\n",
      "\n",
      "Batch 244/387 ━━━━━━━━━━━━━━━━━━━━ 00:13:16\n",
      "Accuracy: 0.9974 - Precision: 0.8806 - Recall: 0.8722 - Specificity: 0.9990 - F1: 0.8666 - Loss: 0.1509\n",
      "\n",
      "Batch 245/387 ━━━━━━━━━━━━━━━━━━━━ 00:14:42\n",
      "Accuracy: 0.9974 - Precision: 0.8808 - Recall: 0.8718 - Specificity: 0.9990 - F1: 0.8666 - Loss: 0.1510\n",
      "\n",
      "Batch 246/387 ━━━━━━━━━━━━━━━━━━━━ 00:16:13\n",
      "Accuracy: 0.9974 - Precision: 0.8807 - Recall: 0.8721 - Specificity: 0.9990 - F1: 0.8667 - Loss: 0.1509\n",
      "\n",
      "Batch 247/387 ━━━━━━━━━━━━━━━━━━━━ 00:17:38\n",
      "Accuracy: 0.9974 - Precision: 0.8802 - Recall: 0.8725 - Specificity: 0.9990 - F1: 0.8666 - Loss: 0.1509\n",
      "\n",
      "Batch 248/387 ━━━━━━━━━━━━━━━━━━━━ 00:19:02\n",
      "Accuracy: 0.9974 - Precision: 0.8805 - Recall: 0.8730 - Specificity: 0.9990 - F1: 0.8670 - Loss: 0.1505\n",
      "\n",
      "Batch 249/387 ━━━━━━━━━━━━━━━━━━━━ 00:20:34\n",
      "Accuracy: 0.9974 - Precision: 0.8795 - Recall: 0.8711 - Specificity: 0.9990 - F1: 0.8655 - Loss: 0.1520\n",
      "\n",
      "Batch 250/387 ━━━━━━━━━━━━━━━━━━━━ 00:21:54\n",
      "Accuracy: 0.9974 - Precision: 0.8798 - Recall: 0.8704 - Specificity: 0.9990 - F1: 0.8653 - Loss: 0.1523\n",
      "\n",
      "Batch 251/387 ━━━━━━━━━━━━━━━━━━━━ 00:23:22\n",
      "Accuracy: 0.9974 - Precision: 0.8792 - Recall: 0.8698 - Specificity: 0.9990 - F1: 0.8648 - Loss: 0.1528\n",
      "\n",
      "Batch 252/387 ━━━━━━━━━━━━━━━━━━━━ 00:24:48\n",
      "Accuracy: 0.9974 - Precision: 0.8791 - Recall: 0.8699 - Specificity: 0.9990 - F1: 0.8648 - Loss: 0.1528\n",
      "\n",
      "Batch 253/387 ━━━━━━━━━━━━━━━━━━━━ 00:26:11\n",
      "Accuracy: 0.9974 - Precision: 0.8791 - Recall: 0.8703 - Specificity: 0.9990 - F1: 0.8650 - Loss: 0.1526\n",
      "\n",
      "Batch 254/387 ━━━━━━━━━━━━━━━━━━━━ 00:27:33\n",
      "Accuracy: 0.9974 - Precision: 0.8789 - Recall: 0.8700 - Specificity: 0.9990 - F1: 0.8648 - Loss: 0.1529\n",
      "\n",
      "Batch 255/387 ━━━━━━━━━━━━━━━━━━━━ 00:29:03\n",
      "Accuracy: 0.9974 - Precision: 0.8790 - Recall: 0.8696 - Specificity: 0.9990 - F1: 0.8647 - Loss: 0.1530\n",
      "\n",
      "Batch 256/387 ━━━━━━━━━━━━━━━━━━━━ 00:30:31\n",
      "Accuracy: 0.9974 - Precision: 0.8788 - Recall: 0.8701 - Specificity: 0.9990 - F1: 0.8648 - Loss: 0.1528\n",
      "\n",
      "Batch 257/387 ━━━━━━━━━━━━━━━━━━━━ 00:31:55\n",
      "Accuracy: 0.9974 - Precision: 0.8783 - Recall: 0.8701 - Specificity: 0.9990 - F1: 0.8646 - Loss: 0.1531\n",
      "\n",
      "Batch 258/387 ━━━━━━━━━━━━━━━━━━━━ 00:33:14\n",
      "Accuracy: 0.9974 - Precision: 0.8784 - Recall: 0.8705 - Specificity: 0.9990 - F1: 0.8649 - Loss: 0.1527\n",
      "\n",
      "Batch 259/387 ━━━━━━━━━━━━━━━━━━━━ 00:34:27\n",
      "Accuracy: 0.9974 - Precision: 0.8787 - Recall: 0.8704 - Specificity: 0.9990 - F1: 0.8650 - Loss: 0.1527\n",
      "\n",
      "Batch 260/387 ━━━━━━━━━━━━━━━━━━━━ 00:35:53\n",
      "Accuracy: 0.9974 - Precision: 0.8788 - Recall: 0.8705 - Specificity: 0.9990 - F1: 0.8652 - Loss: 0.1525\n",
      "\n",
      "Batch 261/387 ━━━━━━━━━━━━━━━━━━━━ 00:37:11\n",
      "Accuracy: 0.9974 - Precision: 0.8778 - Recall: 0.8704 - Specificity: 0.9990 - F1: 0.8645 - Loss: 0.1531\n",
      "\n",
      "Batch 262/387 ━━━━━━━━━━━━━━━━━━━━ 00:38:36\n",
      "Accuracy: 0.9974 - Precision: 0.8781 - Recall: 0.8705 - Specificity: 0.9990 - F1: 0.8648 - Loss: 0.1528\n",
      "\n",
      "Batch 263/387 ━━━━━━━━━━━━━━━━━━━━ 00:39:53\n",
      "Accuracy: 0.9974 - Precision: 0.8785 - Recall: 0.8703 - Specificity: 0.9990 - F1: 0.8649 - Loss: 0.1528\n",
      "\n",
      "Batch 264/387 ━━━━━━━━━━━━━━━━━━━━ 00:41:18\n",
      "Accuracy: 0.9974 - Precision: 0.8788 - Recall: 0.8705 - Specificity: 0.9990 - F1: 0.8651 - Loss: 0.1525\n",
      "\n",
      "Batch 265/387 ━━━━━━━━━━━━━━━━━━━━ 00:42:48\n",
      "Accuracy: 0.9974 - Precision: 0.8793 - Recall: 0.8706 - Specificity: 0.9990 - F1: 0.8654 - Loss: 0.1522\n",
      "\n",
      "Batch 266/387 ━━━━━━━━━━━━━━━━━━━━ 00:44:01\n",
      "Accuracy: 0.9974 - Precision: 0.8780 - Recall: 0.8708 - Specificity: 0.9990 - F1: 0.8648 - Loss: 0.1528\n",
      "\n",
      "Batch 267/387 ━━━━━━━━━━━━━━━━━━━━ 00:45:27\n",
      "Accuracy: 0.9974 - Precision: 0.8782 - Recall: 0.8710 - Specificity: 0.9990 - F1: 0.8651 - Loss: 0.1525\n",
      "\n",
      "Batch 268/387 ━━━━━━━━━━━━━━━━━━━━ 00:46:56\n",
      "Accuracy: 0.9974 - Precision: 0.8785 - Recall: 0.8711 - Specificity: 0.9990 - F1: 0.8653 - Loss: 0.1523\n",
      "\n",
      "Batch 269/387 ━━━━━━━━━━━━━━━━━━━━ 00:48:21\n",
      "Accuracy: 0.9974 - Precision: 0.8786 - Recall: 0.8706 - Specificity: 0.9990 - F1: 0.8651 - Loss: 0.1525\n",
      "\n",
      "Batch 270/387 ━━━━━━━━━━━━━━━━━━━━ 00:49:45\n",
      "Accuracy: 0.9974 - Precision: 0.8788 - Recall: 0.8698 - Specificity: 0.9990 - F1: 0.8647 - Loss: 0.1528\n",
      "\n",
      "Batch 271/387 ━━━━━━━━━━━━━━━━━━━━ 00:51:06\n",
      "Accuracy: 0.9974 - Precision: 0.8792 - Recall: 0.8696 - Specificity: 0.9990 - F1: 0.8648 - Loss: 0.1527\n",
      "\n",
      "Batch 272/387 ━━━━━━━━━━━━━━━━━━━━ 00:52:24\n",
      "Accuracy: 0.9974 - Precision: 0.8795 - Recall: 0.8695 - Specificity: 0.9990 - F1: 0.8649 - Loss: 0.1526\n",
      "\n",
      "Batch 273/387 ━━━━━━━━━━━━━━━━━━━━ 00:53:40\n",
      "Accuracy: 0.9974 - Precision: 0.8800 - Recall: 0.8692 - Specificity: 0.9990 - F1: 0.8650 - Loss: 0.1526\n",
      "\n",
      "Batch 274/387 ━━━━━━━━━━━━━━━━━━━━ 00:55:02\n",
      "Accuracy: 0.9974 - Precision: 0.8803 - Recall: 0.8693 - Specificity: 0.9990 - F1: 0.8653 - Loss: 0.1523\n",
      "\n",
      "Batch 275/387 ━━━━━━━━━━━━━━━━━━━━ 00:56:34\n",
      "Accuracy: 0.9974 - Precision: 0.8807 - Recall: 0.8689 - Specificity: 0.9990 - F1: 0.8652 - Loss: 0.1523\n",
      "\n",
      "Batch 276/387 ━━━━━━━━━━━━━━━━━━━━ 00:57:53\n",
      "Accuracy: 0.9974 - Precision: 0.8810 - Recall: 0.8688 - Specificity: 0.9990 - F1: 0.8654 - Loss: 0.1522\n",
      "\n",
      "Batch 277/387 ━━━━━━━━━━━━━━━━━━━━ 00:59:08\n",
      "Accuracy: 0.9974 - Precision: 0.8812 - Recall: 0.8680 - Specificity: 0.9990 - F1: 0.8650 - Loss: 0.1526\n",
      "\n",
      "Batch 278/387 ━━━━━━━━━━━━━━━━━━━━ 01:00:34\n",
      "Accuracy: 0.9974 - Precision: 0.8811 - Recall: 0.8684 - Specificity: 0.9990 - F1: 0.8652 - Loss: 0.1524\n",
      "\n",
      "Batch 279/387 ━━━━━━━━━━━━━━━━━━━━ 01:01:52\n",
      "Accuracy: 0.9974 - Precision: 0.8807 - Recall: 0.8686 - Specificity: 0.9990 - F1: 0.8651 - Loss: 0.1525\n",
      "\n",
      "Batch 280/387 ━━━━━━━━━━━━━━━━━━━━ 01:03:15\n",
      "Accuracy: 0.9974 - Precision: 0.8807 - Recall: 0.8689 - Specificity: 0.9990 - F1: 0.8653 - Loss: 0.1523\n",
      "\n",
      "Batch 281/387 ━━━━━━━━━━━━━━━━━━━━ 01:04:44\n",
      "Accuracy: 0.9974 - Precision: 0.8805 - Recall: 0.8692 - Specificity: 0.9990 - F1: 0.8654 - Loss: 0.1522\n",
      "\n",
      "Batch 282/387 ━━━━━━━━━━━━━━━━━━━━ 01:06:12\n",
      "Accuracy: 0.9974 - Precision: 0.8797 - Recall: 0.8696 - Specificity: 0.9989 - F1: 0.8650 - Loss: 0.1526\n",
      "\n",
      "Batch 283/387 ━━━━━━━━━━━━━━━━━━━━ 01:07:40\n",
      "Accuracy: 0.9974 - Precision: 0.8792 - Recall: 0.8699 - Specificity: 0.9989 - F1: 0.8649 - Loss: 0.1527\n",
      "\n",
      "Batch 284/387 ━━━━━━━━━━━━━━━━━━━━ 01:09:05\n",
      "Accuracy: 0.9974 - Precision: 0.8775 - Recall: 0.8704 - Specificity: 0.9989 - F1: 0.8639 - Loss: 0.1538\n",
      "\n",
      "Batch 285/387 ━━━━━━━━━━━━━━━━━━━━ 01:10:36\n",
      "Accuracy: 0.9974 - Precision: 0.8772 - Recall: 0.8708 - Specificity: 0.9989 - F1: 0.8640 - Loss: 0.1537\n",
      "\n",
      "Batch 286/387 ━━━━━━━━━━━━━━━━━━━━ 08:34:01\n",
      "Accuracy: 0.9974 - Precision: 0.8773 - Recall: 0.8711 - Specificity: 0.9989 - F1: 0.8642 - Loss: 0.1535\n",
      "\n",
      "Batch 287/387 ━━━━━━━━━━━━━━━━━━━━ 08:35:40\n",
      "Accuracy: 0.9974 - Precision: 0.8765 - Recall: 0.8716 - Specificity: 0.9989 - F1: 0.8640 - Loss: 0.1538\n",
      "\n",
      "Batch 288/387 ━━━━━━━━━━━━━━━━━━━━ 08:37:19\n",
      "Accuracy: 0.9974 - Precision: 0.8760 - Recall: 0.8719 - Specificity: 0.9989 - F1: 0.8639 - Loss: 0.1538\n",
      "\n",
      "Batch 289/387 ━━━━━━━━━━━━━━━━━━━━ 08:38:57\n",
      "Accuracy: 0.9974 - Precision: 0.8761 - Recall: 0.8717 - Specificity: 0.9989 - F1: 0.8639 - Loss: 0.1538\n",
      "\n",
      "Batch 290/387 ━━━━━━━━━━━━━━━━━━━━ 08:40:30\n",
      "Accuracy: 0.9974 - Precision: 0.8765 - Recall: 0.8718 - Specificity: 0.9989 - F1: 0.8641 - Loss: 0.1536\n",
      "\n",
      "Batch 291/387 ━━━━━━━━━━━━━━━━━━━━ 08:42:00\n",
      "Accuracy: 0.9974 - Precision: 0.8755 - Recall: 0.8719 - Specificity: 0.9989 - F1: 0.8636 - Loss: 0.1541\n",
      "\n",
      "Batch 292/387 ━━━━━━━━━━━━━━━━━━━━ 08:43:43\n",
      "Accuracy: 0.9974 - Precision: 0.8759 - Recall: 0.8714 - Specificity: 0.9989 - F1: 0.8635 - Loss: 0.1542\n",
      "\n",
      "Batch 293/387 ━━━━━━━━━━━━━━━━━━━━ 08:45:21\n",
      "Accuracy: 0.9974 - Precision: 0.8753 - Recall: 0.8710 - Specificity: 0.9989 - F1: 0.8631 - Loss: 0.1546\n",
      "\n",
      "Batch 294/387 ━━━━━━━━━━━━━━━━━━━━ 08:46:47\n",
      "Accuracy: 0.9974 - Precision: 0.8757 - Recall: 0.8708 - Specificity: 0.9989 - F1: 0.8632 - Loss: 0.1545\n",
      "\n",
      "Batch 295/387 ━━━━━━━━━━━━━━━━━━━━ 08:48:28\n",
      "Accuracy: 0.9974 - Precision: 0.8751 - Recall: 0.8702 - Specificity: 0.9989 - F1: 0.8626 - Loss: 0.1551\n",
      "\n",
      "Batch 296/387 ━━━━━━━━━━━━━━━━━━━━ 08:50:07\n",
      "Accuracy: 0.9974 - Precision: 0.8755 - Recall: 0.8702 - Specificity: 0.9989 - F1: 0.8628 - Loss: 0.1548\n",
      "\n",
      "Batch 297/387 ━━━━━━━━━━━━━━━━━━━━ 08:51:36\n",
      "Accuracy: 0.9974 - Precision: 0.8758 - Recall: 0.8704 - Specificity: 0.9989 - F1: 0.8631 - Loss: 0.1545\n",
      "\n",
      "Batch 298/387 ━━━━━━━━━━━━━━━━━━━━ 08:53:00\n",
      "Accuracy: 0.9974 - Precision: 0.8762 - Recall: 0.8699 - Specificity: 0.9989 - F1: 0.8630 - Loss: 0.1546\n",
      "\n",
      "Batch 299/387 ━━━━━━━━━━━━━━━━━━━━ 08:54:35\n",
      "Accuracy: 0.9974 - Precision: 0.8766 - Recall: 0.8698 - Specificity: 0.9989 - F1: 0.8632 - Loss: 0.1545\n",
      "\n",
      "Batch 300/387 ━━━━━━━━━━━━━━━━━━━━ 08:56:15\n",
      "Accuracy: 0.9974 - Precision: 0.8770 - Recall: 0.8696 - Specificity: 0.9989 - F1: 0.8633 - Loss: 0.1545\n",
      "\n",
      "Batch 301/387 ━━━━━━━━━━━━━━━━━━━━ 08:57:27\n",
      "Accuracy: 0.9974 - Precision: 0.8774 - Recall: 0.8694 - Specificity: 0.9989 - F1: 0.8634 - Loss: 0.1543\n",
      "\n",
      "Batch 302/387 ━━━━━━━━━━━━━━━━━━━━ 08:59:02\n",
      "Accuracy: 0.9974 - Precision: 0.8778 - Recall: 0.8694 - Specificity: 0.9989 - F1: 0.8636 - Loss: 0.1542\n",
      "\n",
      "Batch 303/387 ━━━━━━━━━━━━━━━━━━━━ 09:00:28\n",
      "Accuracy: 0.9974 - Precision: 0.8777 - Recall: 0.8697 - Specificity: 0.9989 - F1: 0.8637 - Loss: 0.1540\n",
      "\n",
      "Batch 304/387 ━━━━━━━━━━━━━━━━━━━━ 09:01:59\n",
      "Accuracy: 0.9974 - Precision: 0.8774 - Recall: 0.8695 - Specificity: 0.9989 - F1: 0.8635 - Loss: 0.1543\n",
      "\n",
      "Batch 305/387 ━━━━━━━━━━━━━━━━━━━━ 09:03:30\n",
      "Accuracy: 0.9974 - Precision: 0.8776 - Recall: 0.8695 - Specificity: 0.9989 - F1: 0.8637 - Loss: 0.1541\n",
      "\n",
      "Batch 306/387 ━━━━━━━━━━━━━━━━━━━━ 09:05:01\n",
      "Accuracy: 0.9974 - Precision: 0.8778 - Recall: 0.8697 - Specificity: 0.9989 - F1: 0.8639 - Loss: 0.1538\n",
      "\n",
      "Batch 307/387 ━━━━━━━━━━━━━━━━━━━━ 09:06:54\n",
      "Accuracy: 0.9974 - Precision: 0.8779 - Recall: 0.8689 - Specificity: 0.9989 - F1: 0.8635 - Loss: 0.1543\n",
      "\n",
      "Batch 308/387 ━━━━━━━━━━━━━━━━━━━━ 09:29:45\n",
      "Accuracy: 0.9974 - Precision: 0.8781 - Recall: 0.8691 - Specificity: 0.9989 - F1: 0.8637 - Loss: 0.1540\n",
      "\n",
      "Batch 309/387 ━━━━━━━━━━━━━━━━━━━━ 09:31:34\n",
      "Accuracy: 0.9974 - Precision: 0.8780 - Recall: 0.8694 - Specificity: 0.9989 - F1: 0.8638 - Loss: 0.1539\n",
      "\n",
      "Batch 310/387 ━━━━━━━━━━━━━━━━━━━━ 09:33:05\n",
      "Accuracy: 0.9974 - Precision: 0.8781 - Recall: 0.8692 - Specificity: 0.9989 - F1: 0.8638 - Loss: 0.1539\n",
      "\n",
      "Batch 311/387 ━━━━━━━━━━━━━━━━━━━━ 09:34:42\n",
      "Accuracy: 0.9974 - Precision: 0.8782 - Recall: 0.8695 - Specificity: 0.9989 - F1: 0.8640 - Loss: 0.1537\n",
      "\n",
      "Batch 312/387 ━━━━━━━━━━━━━━━━━━━━ 09:36:16\n",
      "Accuracy: 0.9974 - Precision: 0.8783 - Recall: 0.8696 - Specificity: 0.9989 - F1: 0.8641 - Loss: 0.1536\n",
      "\n",
      "Batch 313/387 ━━━━━━━━━━━━━━━━━━━━ 09:38:05\n",
      "Accuracy: 0.9974 - Precision: 0.8780 - Recall: 0.8699 - Specificity: 0.9989 - F1: 0.8641 - Loss: 0.1536\n",
      "\n",
      "Batch 314/387 ━━━━━━━━━━━━━━━━━━━━ 09:39:39\n",
      "Accuracy: 0.9974 - Precision: 0.8781 - Recall: 0.8702 - Specificity: 0.9989 - F1: 0.8644 - Loss: 0.1533\n",
      "\n",
      "Batch 315/387 ━━━━━━━━━━━━━━━━━━━━ 09:41:16\n",
      "Accuracy: 0.9974 - Precision: 0.8759 - Recall: 0.8706 - Specificity: 0.9989 - F1: 0.8627 - Loss: 0.1551\n",
      "\n",
      "Batch 316/387 ━━━━━━━━━━━━━━━━━━━━ 09:42:50\n",
      "Accuracy: 0.9974 - Precision: 0.8760 - Recall: 0.8707 - Specificity: 0.9989 - F1: 0.8628 - Loss: 0.1549\n",
      "\n",
      "Batch 317/387 ━━━━━━━━━━━━━━━━━━━━ 09:44:18\n",
      "Accuracy: 0.9974 - Precision: 0.8763 - Recall: 0.8710 - Specificity: 0.9989 - F1: 0.8632 - Loss: 0.1546\n",
      "\n",
      "Batch 318/387 ━━━━━━━━━━━━━━━━━━━━ 09:45:48\n",
      "Accuracy: 0.9974 - Precision: 0.8763 - Recall: 0.8701 - Specificity: 0.9989 - F1: 0.8626 - Loss: 0.1551\n",
      "\n",
      "Batch 319/387 ━━━━━━━━━━━━━━━━━━━━ 09:47:16\n",
      "Accuracy: 0.9974 - Precision: 0.8761 - Recall: 0.8704 - Specificity: 0.9989 - F1: 0.8627 - Loss: 0.1550\n",
      "\n",
      "Batch 320/387 ━━━━━━━━━━━━━━━━━━━━ 09:48:41\n",
      "Accuracy: 0.9974 - Precision: 0.8762 - Recall: 0.8706 - Specificity: 0.9989 - F1: 0.8629 - Loss: 0.1548\n",
      "\n",
      "Batch 321/387 ━━━━━━━━━━━━━━━━━━━━ 09:50:12\n",
      "Accuracy: 0.9974 - Precision: 0.8764 - Recall: 0.8709 - Specificity: 0.9989 - F1: 0.8632 - Loss: 0.1545\n",
      "\n",
      "Batch 322/387 ━━━━━━━━━━━━━━━━━━━━ 09:51:47\n",
      "Accuracy: 0.9974 - Precision: 0.8767 - Recall: 0.8709 - Specificity: 0.9989 - F1: 0.8633 - Loss: 0.1543\n",
      "\n",
      "Batch 323/387 ━━━━━━━━━━━━━━━━━━━━ 09:53:19\n",
      "Accuracy: 0.9974 - Precision: 0.8763 - Recall: 0.8692 - Specificity: 0.9989 - F1: 0.8621 - Loss: 0.1555\n",
      "\n",
      "Batch 324/387 ━━━━━━━━━━━━━━━━━━━━ 09:54:44\n",
      "Accuracy: 0.9974 - Precision: 0.8751 - Recall: 0.8693 - Specificity: 0.9989 - F1: 0.8614 - Loss: 0.1563\n",
      "\n",
      "Batch 325/387 ━━━━━━━━━━━━━━━━━━━━ 09:56:11\n",
      "Accuracy: 0.9974 - Precision: 0.8748 - Recall: 0.8695 - Specificity: 0.9989 - F1: 0.8613 - Loss: 0.1564\n",
      "\n",
      "Batch 326/387 ━━━━━━━━━━━━━━━━━━━━ 09:57:44\n",
      "Accuracy: 0.9974 - Precision: 0.8752 - Recall: 0.8691 - Specificity: 0.9989 - F1: 0.8613 - Loss: 0.1564\n",
      "\n",
      "Batch 327/387 ━━━━━━━━━━━━━━━━━━━━ 09:59:10\n",
      "Accuracy: 0.9974 - Precision: 0.8755 - Recall: 0.8693 - Specificity: 0.9989 - F1: 0.8616 - Loss: 0.1561\n",
      "\n",
      "Batch 328/387 ━━━━━━━━━━━━━━━━━━━━ 10:00:37\n",
      "Accuracy: 0.9974 - Precision: 0.8750 - Recall: 0.8690 - Specificity: 0.9989 - F1: 0.8612 - Loss: 0.1565\n",
      "\n",
      "Batch 329/387 ━━━━━━━━━━━━━━━━━━━━ 10:02:02\n",
      "Accuracy: 0.9974 - Precision: 0.8754 - Recall: 0.8687 - Specificity: 0.9989 - F1: 0.8612 - Loss: 0.1564\n",
      "\n",
      "Batch 330/387 ━━━━━━━━━━━━━━━━━━━━ 10:03:43\n",
      "Accuracy: 0.9974 - Precision: 0.8755 - Recall: 0.8687 - Specificity: 0.9989 - F1: 0.8613 - Loss: 0.1563\n",
      "\n",
      "Batch 331/387 ━━━━━━━━━━━━━━━━━━━━ 10:05:16\n",
      "Accuracy: 0.9974 - Precision: 0.8759 - Recall: 0.8678 - Specificity: 0.9989 - F1: 0.8610 - Loss: 0.1567\n",
      "\n",
      "Batch 332/387 ━━━━━━━━━━━━━━━━━━━━ 10:06:45\n",
      "Accuracy: 0.9974 - Precision: 0.8763 - Recall: 0.8675 - Specificity: 0.9989 - F1: 0.8610 - Loss: 0.1567\n",
      "\n",
      "Batch 333/387 ━━━━━━━━━━━━━━━━━━━━ 10:08:20\n",
      "Accuracy: 0.9974 - Precision: 0.8766 - Recall: 0.8669 - Specificity: 0.9989 - F1: 0.8608 - Loss: 0.1569\n",
      "\n",
      "Batch 334/387 ━━━━━━━━━━━━━━━━━━━━ 10:09:55\n",
      "Accuracy: 0.9974 - Precision: 0.8768 - Recall: 0.8669 - Specificity: 0.9989 - F1: 0.8609 - Loss: 0.1568\n",
      "\n",
      "Batch 335/387 ━━━━━━━━━━━━━━━━━━━━ 10:11:25\n",
      "Accuracy: 0.9974 - Precision: 0.8771 - Recall: 0.8671 - Specificity: 0.9989 - F1: 0.8612 - Loss: 0.1565\n",
      "\n",
      "Batch 336/387 ━━━━━━━━━━━━━━━━━━━━ 10:12:50\n",
      "Accuracy: 0.9974 - Precision: 0.8771 - Recall: 0.8674 - Specificity: 0.9989 - F1: 0.8614 - Loss: 0.1563\n",
      "\n",
      "Batch 337/387 ━━━━━━━━━━━━━━━━━━━━ 10:14:18\n",
      "Accuracy: 0.9974 - Precision: 0.8764 - Recall: 0.8674 - Specificity: 0.9989 - F1: 0.8610 - Loss: 0.1567\n",
      "\n",
      "Batch 338/387 ━━━━━━━━━━━━━━━━━━━━ 10:15:37\n",
      "Accuracy: 0.9974 - Precision: 0.8766 - Recall: 0.8674 - Specificity: 0.9989 - F1: 0.8611 - Loss: 0.1566\n",
      "\n",
      "Batch 339/387 ━━━━━━━━━━━━━━━━━━━━ 10:16:52\n",
      "Accuracy: 0.9974 - Precision: 0.8759 - Recall: 0.8677 - Specificity: 0.9989 - F1: 0.8609 - Loss: 0.1569\n",
      "\n",
      "Batch 340/387 ━━━━━━━━━━━━━━━━━━━━ 10:18:24\n",
      "Accuracy: 0.9974 - Precision: 0.8761 - Recall: 0.8675 - Specificity: 0.9989 - F1: 0.8609 - Loss: 0.1569\n",
      "\n",
      "Batch 341/387 ━━━━━━━━━━━━━━━━━━━━ 10:19:46\n",
      "Accuracy: 0.9974 - Precision: 0.8750 - Recall: 0.8678 - Specificity: 0.9989 - F1: 0.8603 - Loss: 0.1575\n",
      "\n",
      "Batch 342/387 ━━━━━━━━━━━━━━━━━━━━ 10:21:09\n",
      "Accuracy: 0.9974 - Precision: 0.8749 - Recall: 0.8678 - Specificity: 0.9989 - F1: 0.8603 - Loss: 0.1576\n",
      "\n",
      "Batch 343/387 ━━━━━━━━━━━━━━━━━━━━ 10:22:33\n",
      "Accuracy: 0.9974 - Precision: 0.8738 - Recall: 0.8682 - Specificity: 0.9989 - F1: 0.8597 - Loss: 0.1582\n",
      "\n",
      "Batch 344/387 ━━━━━━━━━━━━━━━━━━━━ 10:24:06\n",
      "Accuracy: 0.9974 - Precision: 0.8739 - Recall: 0.8678 - Specificity: 0.9989 - F1: 0.8596 - Loss: 0.1583\n",
      "\n",
      "Batch 345/387 ━━━━━━━━━━━━━━━━━━━━ 10:25:46\n",
      "Accuracy: 0.9974 - Precision: 0.8739 - Recall: 0.8681 - Specificity: 0.9989 - F1: 0.8598 - Loss: 0.1581\n",
      "\n",
      "Batch 346/387 ━━━━━━━━━━━━━━━━━━━━ 10:27:21\n",
      "Accuracy: 0.9974 - Precision: 0.8741 - Recall: 0.8680 - Specificity: 0.9989 - F1: 0.8598 - Loss: 0.1580\n",
      "\n",
      "Batch 347/387 ━━━━━━━━━━━━━━━━━━━━ 10:28:53\n",
      "Accuracy: 0.9974 - Precision: 0.8741 - Recall: 0.8683 - Specificity: 0.9989 - F1: 0.8600 - Loss: 0.1579\n",
      "\n",
      "Batch 348/387 ━━━━━━━━━━━━━━━━━━━━ 10:30:22\n",
      "Accuracy: 0.9974 - Precision: 0.8739 - Recall: 0.8677 - Specificity: 0.9989 - F1: 0.8596 - Loss: 0.1583\n",
      "\n",
      "Batch 349/387 ━━━━━━━━━━━━━━━━━━━━ 10:31:50\n",
      "Accuracy: 0.9974 - Precision: 0.8742 - Recall: 0.8676 - Specificity: 0.9989 - F1: 0.8597 - Loss: 0.1582\n",
      "\n",
      "Batch 350/387 ━━━━━━━━━━━━━━━━━━━━ 10:33:18\n",
      "Accuracy: 0.9974 - Precision: 0.8744 - Recall: 0.8678 - Specificity: 0.9989 - F1: 0.8600 - Loss: 0.1579\n",
      "\n",
      "Batch 351/387 ━━━━━━━━━━━━━━━━━━━━ 10:34:48\n",
      "Accuracy: 0.9974 - Precision: 0.8740 - Recall: 0.8681 - Specificity: 0.9989 - F1: 0.8599 - Loss: 0.1580\n",
      "\n",
      "Batch 352/387 ━━━━━━━━━━━━━━━━━━━━ 10:36:28\n",
      "Accuracy: 0.9974 - Precision: 0.8732 - Recall: 0.8684 - Specificity: 0.9989 - F1: 0.8596 - Loss: 0.1583\n",
      "\n",
      "Batch 353/387 ━━━━━━━━━━━━━━━━━━━━ 10:37:56\n",
      "Accuracy: 0.9974 - Precision: 0.8735 - Recall: 0.8684 - Specificity: 0.9989 - F1: 0.8598 - Loss: 0.1581\n",
      "\n",
      "Batch 354/387 ━━━━━━━━━━━━━━━━━━━━ 10:39:23\n",
      "Accuracy: 0.9974 - Precision: 0.8739 - Recall: 0.8680 - Specificity: 0.9989 - F1: 0.8597 - Loss: 0.1583\n",
      "\n",
      "Batch 355/387 ━━━━━━━━━━━━━━━━━━━━ 10:40:54\n",
      "Accuracy: 0.9974 - Precision: 0.8738 - Recall: 0.8679 - Specificity: 0.9989 - F1: 0.8596 - Loss: 0.1583\n",
      "\n",
      "Batch 356/387 ━━━━━━━━━━━━━━━━━━━━ 10:42:19\n",
      "Accuracy: 0.9974 - Precision: 0.8741 - Recall: 0.8679 - Specificity: 0.9989 - F1: 0.8598 - Loss: 0.1581\n",
      "\n",
      "Batch 357/387 ━━━━━━━━━━━━━━━━━━━━ 10:43:49\n",
      "Accuracy: 0.9974 - Precision: 0.8740 - Recall: 0.8678 - Specificity: 0.9989 - F1: 0.8598 - Loss: 0.1582\n",
      "\n",
      "Batch 358/387 ━━━━━━━━━━━━━━━━━━━━ 10:45:15\n",
      "Accuracy: 0.9974 - Precision: 0.8742 - Recall: 0.8678 - Specificity: 0.9989 - F1: 0.8599 - Loss: 0.1580\n",
      "\n",
      "Batch 359/387 ━━━━━━━━━━━━━━━━━━━━ 10:46:37\n",
      "Accuracy: 0.9974 - Precision: 0.8745 - Recall: 0.8674 - Specificity: 0.9989 - F1: 0.8598 - Loss: 0.1583\n",
      "\n",
      "Batch 360/387 ━━━━━━━━━━━━━━━━━━━━ 10:48:05\n",
      "Accuracy: 0.9974 - Precision: 0.8748 - Recall: 0.8672 - Specificity: 0.9989 - F1: 0.8598 - Loss: 0.1582\n",
      "\n",
      "Batch 361/387 ━━━━━━━━━━━━━━━━━━━━ 10:49:39\n",
      "Accuracy: 0.9974 - Precision: 0.8748 - Recall: 0.8671 - Specificity: 0.9989 - F1: 0.8598 - Loss: 0.1582\n",
      "\n",
      "Batch 362/387 ━━━━━━━━━━━━━━━━━━━━ 10:51:07\n",
      "Accuracy: 0.9974 - Precision: 0.8746 - Recall: 0.8666 - Specificity: 0.9989 - F1: 0.8595 - Loss: 0.1586\n",
      "\n",
      "Batch 363/387 ━━━━━━━━━━━━━━━━━━━━ 10:52:33\n",
      "Accuracy: 0.9973 - Precision: 0.8743 - Recall: 0.8669 - Specificity: 0.9989 - F1: 0.8594 - Loss: 0.1587\n",
      "\n",
      "Batch 364/387 ━━━━━━━━━━━━━━━━━━━━ 10:53:58\n",
      "Accuracy: 0.9974 - Precision: 0.8745 - Recall: 0.8672 - Specificity: 0.9989 - F1: 0.8597 - Loss: 0.1583\n",
      "\n",
      "Batch 365/387 ━━━━━━━━━━━━━━━━━━━━ 10:55:24\n",
      "Accuracy: 0.9974 - Precision: 0.8747 - Recall: 0.8675 - Specificity: 0.9989 - F1: 0.8600 - Loss: 0.1581\n",
      "\n",
      "Batch 366/387 ━━━━━━━━━━━━━━━━━━━━ 10:56:45\n",
      "Accuracy: 0.9974 - Precision: 0.8743 - Recall: 0.8678 - Specificity: 0.9989 - F1: 0.8600 - Loss: 0.1581\n",
      "\n",
      "Batch 367/387 ━━━━━━━━━━━━━━━━━━━━ 10:58:13\n",
      "Accuracy: 0.9974 - Precision: 0.8744 - Recall: 0.8680 - Specificity: 0.9989 - F1: 0.8602 - Loss: 0.1579\n",
      "\n",
      "Batch 368/387 ━━━━━━━━━━━━━━━━━━━━ 10:59:33\n",
      "Accuracy: 0.9974 - Precision: 0.8746 - Recall: 0.8682 - Specificity: 0.9989 - F1: 0.8604 - Loss: 0.1576\n",
      "\n",
      "Batch 369/387 ━━━━━━━━━━━━━━━━━━━━ 11:00:57\n",
      "Accuracy: 0.9974 - Precision: 0.8745 - Recall: 0.8685 - Specificity: 0.9989 - F1: 0.8605 - Loss: 0.1575\n",
      "\n",
      "Batch 370/387 ━━━━━━━━━━━━━━━━━━━━ 11:02:27\n",
      "Accuracy: 0.9974 - Precision: 0.8741 - Recall: 0.8685 - Specificity: 0.9989 - F1: 0.8603 - Loss: 0.1577\n",
      "\n",
      "Batch 371/387 ━━━━━━━━━━━━━━━━━━━━ 11:04:07\n",
      "Accuracy: 0.9974 - Precision: 0.8742 - Recall: 0.8686 - Specificity: 0.9989 - F1: 0.8604 - Loss: 0.1576\n",
      "\n",
      "Batch 372/387 ━━━━━━━━━━━━━━━━━━━━ 11:05:39\n",
      "Accuracy: 0.9974 - Precision: 0.8743 - Recall: 0.8683 - Specificity: 0.9989 - F1: 0.8603 - Loss: 0.1577\n",
      "\n",
      "Batch 373/387 ━━━━━━━━━━━━━━━━━━━━ 11:07:08\n",
      "Accuracy: 0.9974 - Precision: 0.8742 - Recall: 0.8684 - Specificity: 0.9989 - F1: 0.8604 - Loss: 0.1576\n",
      "\n",
      "Batch 374/387 ━━━━━━━━━━━━━━━━━━━━ 11:08:43\n",
      "Accuracy: 0.9974 - Precision: 0.8744 - Recall: 0.8685 - Specificity: 0.9989 - F1: 0.8606 - Loss: 0.1575\n",
      "\n",
      "Batch 375/387 ━━━━━━━━━━━━━━━━━━━━ 11:10:25\n",
      "Accuracy: 0.9974 - Precision: 0.8747 - Recall: 0.8688 - Specificity: 0.9989 - F1: 0.8609 - Loss: 0.1571\n",
      "\n",
      "Batch 376/387 ━━━━━━━━━━━━━━━━━━━━ 11:11:53\n",
      "Accuracy: 0.9974 - Precision: 0.8747 - Recall: 0.8689 - Specificity: 0.9989 - F1: 0.8610 - Loss: 0.1570\n",
      "\n",
      "Batch 377/387 ━━━━━━━━━━━━━━━━━━━━ 11:13:15\n",
      "Accuracy: 0.9974 - Precision: 0.8748 - Recall: 0.8687 - Specificity: 0.9989 - F1: 0.8609 - Loss: 0.1571\n",
      "\n",
      "Batch 378/387 ━━━━━━━━━━━━━━━━━━━━ 11:14:42\n",
      "Accuracy: 0.9974 - Precision: 0.8751 - Recall: 0.8688 - Specificity: 0.9989 - F1: 0.8611 - Loss: 0.1569\n",
      "\n",
      "Batch 379/387 ━━━━━━━━━━━━━━━━━━━━ 11:16:13\n",
      "Accuracy: 0.9973 - Precision: 0.8754 - Recall: 0.8682 - Specificity: 0.9989 - F1: 0.8609 - Loss: 0.1571\n",
      "\n",
      "Batch 380/387 ━━━━━━━━━━━━━━━━━━━━ 11:17:42\n",
      "Accuracy: 0.9974 - Precision: 0.8750 - Recall: 0.8686 - Specificity: 0.9989 - F1: 0.8609 - Loss: 0.1571\n",
      "\n",
      "Batch 381/387 ━━━━━━━━━━━━━━━━━━━━ 11:19:06\n",
      "Accuracy: 0.9973 - Precision: 0.8752 - Recall: 0.8686 - Specificity: 0.9989 - F1: 0.8610 - Loss: 0.1570\n",
      "\n",
      "Batch 382/387 ━━━━━━━━━━━━━━━━━━━━ 11:20:35\n",
      "Accuracy: 0.9974 - Precision: 0.8754 - Recall: 0.8689 - Specificity: 0.9989 - F1: 0.8613 - Loss: 0.1567\n",
      "\n",
      "Batch 383/387 ━━━━━━━━━━━━━━━━━━━━ 11:21:59\n",
      "Accuracy: 0.9974 - Precision: 0.8754 - Recall: 0.8687 - Specificity: 0.9989 - F1: 0.8612 - Loss: 0.1568\n",
      "\n",
      "Batch 384/387 ━━━━━━━━━━━━━━━━━━━━ 11:23:28\n",
      "Accuracy: 0.9974 - Precision: 0.8748 - Recall: 0.8683 - Specificity: 0.9989 - F1: 0.8607 - Loss: 0.1573\n",
      "\n",
      "Batch 385/387 ━━━━━━━━━━━━━━━━━━━━ 11:24:47\n",
      "Accuracy: 0.9974 - Precision: 0.8751 - Recall: 0.8684 - Specificity: 0.9989 - F1: 0.8610 - Loss: 0.1570\n",
      "\n",
      "Batch 386/387 ━━━━━━━━━━━━━━━━━━━━ 11:26:14\n",
      "Accuracy: 0.9974 - Precision: 0.8746 - Recall: 0.8687 - Specificity: 0.9989 - F1: 0.8608 - Loss: 0.1572\n",
      "\n",
      "Batch 387/387 ━━━━━━━━━━━━━━━━━━━━ 11:27:37\n",
      "Accuracy: 0.9974 - Precision: 0.8747 - Recall: 0.8687 - Specificity: 0.9989 - F1: 0.8609 - Loss: 0.1571\n",
      "\n",
      "End of Epoch 4\n",
      "\n",
      "Epoch 5/50\n",
      "Batch 1/387 ━━━━━━━━━━━━━━━━━━━━ 11:50:09\n",
      "Accuracy: 0.9970 - Precision: 0.9867 - Recall: 0.8562 - Specificity: 0.9998 - F1: 0.9168 - Loss: 0.1019\n",
      "\n",
      "Batch 2/387 ━━━━━━━━━━━━━━━━━━━━ 11:51:47\n",
      "Accuracy: 0.9977 - Precision: 0.9709 - Recall: 0.8577 - Specificity: 0.9997 - F1: 0.9107 - Loss: 0.1081\n",
      "\n",
      "Batch 3/387 ━━━━━━━━━━━━━━━━━━━━ 11:53:16\n",
      "Accuracy: 0.9981 - Precision: 0.9161 - Recall: 0.8544 - Specificity: 0.9996 - F1: 0.8827 - Loss: 0.1359\n",
      "\n",
      "Batch 4/387 ━━━━━━━━━━━━━━━━━━━━ 11:54:43\n",
      "Accuracy: 0.9980 - Precision: 0.9192 - Recall: 0.8726 - Specificity: 0.9994 - F1: 0.8940 - Loss: 0.1231\n",
      "\n",
      "Batch 5/387 ━━━━━━━━━━━━━━━━━━━━ 11:56:16\n",
      "Accuracy: 0.9982 - Precision: 0.9281 - Recall: 0.8728 - Specificity: 0.9995 - F1: 0.8985 - Loss: 0.1177\n",
      "\n",
      "Batch 6/387 ━━━━━━━━━━━━━━━━━━━━ 11:57:56\n",
      "Accuracy: 0.9981 - Precision: 0.9240 - Recall: 0.8864 - Specificity: 0.9993 - F1: 0.9034 - Loss: 0.1120\n",
      "\n",
      "Batch 7/387 ━━━━━━━━━━━━━━━━━━━━ 11:59:26\n",
      "Accuracy: 0.9981 - Precision: 0.8950 - Recall: 0.8842 - Specificity: 0.9992 - F1: 0.8871 - Loss: 0.1284\n",
      "\n",
      "Batch 8/387 ━━━━━━━━━━━━━━━━━━━━ 12:00:58\n",
      "Accuracy: 0.9981 - Precision: 0.9044 - Recall: 0.8899 - Specificity: 0.9992 - F1: 0.8949 - Loss: 0.1200\n",
      "\n",
      "Batch 9/387 ━━━━━━━━━━━━━━━━━━━━ 12:02:36\n",
      "Accuracy: 0.9982 - Precision: 0.9089 - Recall: 0.8950 - Specificity: 0.9992 - F1: 0.9000 - Loss: 0.1142\n",
      "\n",
      "Batch 10/387 ━━━━━━━━━━━━━━━━━━━━ 12:04:03\n",
      "Accuracy: 0.9981 - Precision: 0.9048 - Recall: 0.8991 - Specificity: 0.9991 - F1: 0.9000 - Loss: 0.1141\n",
      "\n",
      "Batch 11/387 ━━━━━━━━━━━━━━━━━━━━ 12:05:28\n",
      "Accuracy: 0.9980 - Precision: 0.9085 - Recall: 0.8788 - Specificity: 0.9992 - F1: 0.8898 - Loss: 0.1244\n",
      "\n",
      "Batch 12/387 ━━━━━━━━━━━━━━━━━━━━ 12:06:55\n",
      "Accuracy: 0.9982 - Precision: 0.9053 - Recall: 0.8837 - Specificity: 0.9992 - F1: 0.8909 - Loss: 0.1230\n",
      "\n",
      "Batch 13/387 ━━━━━━━━━━━━━━━━━━━━ 12:08:19\n",
      "Accuracy: 0.9981 - Precision: 0.9117 - Recall: 0.8835 - Specificity: 0.9993 - F1: 0.8940 - Loss: 0.1198\n",
      "\n",
      "Batch 14/387 ━━━━━━━━━━━━━━━━━━━━ 12:09:42\n",
      "Accuracy: 0.9982 - Precision: 0.9138 - Recall: 0.8893 - Specificity: 0.9993 - F1: 0.8983 - Loss: 0.1151\n",
      "\n",
      "Batch 15/387 ━━━━━━━━━━━━━━━━━━━━ 12:11:02\n",
      "Accuracy: 0.9981 - Precision: 0.9074 - Recall: 0.8942 - Specificity: 0.9991 - F1: 0.8973 - Loss: 0.1164\n",
      "\n",
      "Batch 16/387 ━━━━━━━━━━━━━━━━━━━━ 12:12:30\n",
      "Accuracy: 0.9979 - Precision: 0.9125 - Recall: 0.8912 - Specificity: 0.9992 - F1: 0.8982 - Loss: 0.1162\n",
      "\n",
      "Batch 17/387 ━━━━━━━━━━━━━━━━━━━━ 12:13:57\n",
      "Accuracy: 0.9980 - Precision: 0.9155 - Recall: 0.8945 - Specificity: 0.9992 - F1: 0.9016 - Loss: 0.1124\n",
      "\n",
      "Batch 18/387 ━━━━━━━━━━━━━━━━━━━━ 12:15:20\n",
      "Accuracy: 0.9979 - Precision: 0.9088 - Recall: 0.8997 - Specificity: 0.9990 - F1: 0.9004 - Loss: 0.1138\n",
      "\n",
      "Batch 19/387 ━━━━━━━━━━━━━━━━━━━━ 12:16:44\n",
      "Accuracy: 0.9977 - Precision: 0.9020 - Recall: 0.8974 - Specificity: 0.9989 - F1: 0.8960 - Loss: 0.1194\n",
      "\n",
      "Batch 20/387 ━━━━━━━━━━━━━━━━━━━━ 12:18:15\n",
      "Accuracy: 0.9975 - Precision: 0.9061 - Recall: 0.8894 - Specificity: 0.9989 - F1: 0.8934 - Loss: 0.1234\n",
      "\n",
      "Batch 21/387 ━━━━━━━━━━━━━━━━━━━━ 12:19:47\n",
      "Accuracy: 0.9974 - Precision: 0.9019 - Recall: 0.8787 - Specificity: 0.9989 - F1: 0.8857 - Loss: 0.1317\n",
      "\n",
      "Batch 22/387 ━━━━━━━━━━━━━━━━━━━━ 12:21:16\n",
      "Accuracy: 0.9975 - Precision: 0.9008 - Recall: 0.8769 - Specificity: 0.9990 - F1: 0.8845 - Loss: 0.1327\n",
      "\n",
      "Batch 23/387 ━━━━━━━━━━━━━━━━━━━━ 12:22:43\n",
      "Accuracy: 0.9976 - Precision: 0.9000 - Recall: 0.8820 - Specificity: 0.9989 - F1: 0.8867 - Loss: 0.1301\n",
      "\n",
      "Batch 24/387 ━━━━━━━━━━━━━━━━━━━━ 12:24:04\n",
      "Accuracy: 0.9975 - Precision: 0.9037 - Recall: 0.8807 - Specificity: 0.9990 - F1: 0.8879 - Loss: 0.1288\n",
      "\n",
      "Batch 25/387 ━━━━━━━━━━━━━━━━━━━━ 12:25:24\n",
      "Accuracy: 0.9975 - Precision: 0.9038 - Recall: 0.8818 - Specificity: 0.9990 - F1: 0.8886 - Loss: 0.1282\n",
      "\n",
      "Batch 26/387 ━━━━━━━━━━━━━━━━━━━━ 12:26:55\n",
      "Accuracy: 0.9976 - Precision: 0.9025 - Recall: 0.8844 - Specificity: 0.9990 - F1: 0.8894 - Loss: 0.1272\n",
      "\n",
      "Batch 27/387 ━━━━━━━━━━━━━━━━━━━━ 12:28:28\n",
      "Accuracy: 0.9975 - Precision: 0.9046 - Recall: 0.8835 - Specificity: 0.9990 - F1: 0.8900 - Loss: 0.1269\n",
      "\n",
      "Batch 28/387 ━━━━━━━━━━━━━━━━━━━━ 12:29:52\n",
      "Accuracy: 0.9976 - Precision: 0.9047 - Recall: 0.8869 - Specificity: 0.9990 - F1: 0.8918 - Loss: 0.1248\n",
      "\n",
      "Batch 29/387 ━━━━━━━━━━━━━━━━━━━━ 12:31:23\n",
      "Accuracy: 0.9976 - Precision: 0.8972 - Recall: 0.8878 - Specificity: 0.9990 - F1: 0.8882 - Loss: 0.1285\n",
      "\n",
      "Batch 30/387 ━━━━━━━━━━━━━━━━━━━━ 12:32:45\n",
      "Accuracy: 0.9976 - Precision: 0.8943 - Recall: 0.8891 - Specificity: 0.9990 - F1: 0.8873 - Loss: 0.1291\n",
      "\n",
      "Batch 31/387 ━━━━━━━━━━━━━━━━━━━━ 12:34:19\n",
      "Accuracy: 0.9976 - Precision: 0.8972 - Recall: 0.8886 - Specificity: 0.9990 - F1: 0.8886 - Loss: 0.1276\n",
      "\n",
      "Batch 32/387 ━━━━━━━━━━━━━━━━━━━━ 12:35:49\n",
      "Accuracy: 0.9977 - Precision: 0.8968 - Recall: 0.8893 - Specificity: 0.9990 - F1: 0.8889 - Loss: 0.1271\n",
      "\n",
      "Batch 33/387 ━━━━━━━━━━━━━━━━━━━━ 12:37:12\n",
      "Accuracy: 0.9977 - Precision: 0.8977 - Recall: 0.8910 - Specificity: 0.9990 - F1: 0.8903 - Loss: 0.1255\n",
      "\n",
      "Batch 34/387 ━━━━━━━━━━━━━━━━━━━━ 12:38:37\n",
      "Accuracy: 0.9978 - Precision: 0.8988 - Recall: 0.8879 - Specificity: 0.9990 - F1: 0.8892 - Loss: 0.1265\n",
      "\n",
      "Batch 35/387 ━━━━━━━━━━━━━━━━━━━━ 12:40:06\n",
      "Accuracy: 0.9978 - Precision: 0.9009 - Recall: 0.8862 - Specificity: 0.9991 - F1: 0.8894 - Loss: 0.1262\n",
      "\n",
      "Batch 36/387 ━━━━━━━━━━━━━━━━━━━━ 12:41:36\n",
      "Accuracy: 0.9978 - Precision: 0.8958 - Recall: 0.8871 - Specificity: 0.9990 - F1: 0.8871 - Loss: 0.1286\n",
      "\n",
      "Batch 37/387 ━━━━━━━━━━━━━━━━━━━━ 12:43:12\n",
      "Accuracy: 0.9978 - Precision: 0.8976 - Recall: 0.8874 - Specificity: 0.9991 - F1: 0.8882 - Loss: 0.1274\n",
      "\n",
      "Batch 38/387 ━━━━━━━━━━━━━━━━━━━━ 12:44:41\n",
      "Accuracy: 0.9978 - Precision: 0.8985 - Recall: 0.8890 - Specificity: 0.9991 - F1: 0.8895 - Loss: 0.1258\n",
      "\n",
      "Batch 39/387 ━━━━━━━━━━━━━━━━━━━━ 12:46:12\n",
      "Accuracy: 0.9978 - Precision: 0.8998 - Recall: 0.8883 - Specificity: 0.9991 - F1: 0.8899 - Loss: 0.1255\n",
      "\n",
      "Batch 40/387 ━━━━━━━━━━━━━━━━━━━━ 12:47:39\n",
      "Accuracy: 0.9978 - Precision: 0.9001 - Recall: 0.8893 - Specificity: 0.9991 - F1: 0.8907 - Loss: 0.1247\n",
      "\n",
      "Batch 41/387 ━━━━━━━━━━━━━━━━━━━━ 12:49:06\n",
      "Accuracy: 0.9978 - Precision: 0.9012 - Recall: 0.8896 - Specificity: 0.9991 - F1: 0.8914 - Loss: 0.1237\n",
      "\n",
      "Batch 42/387 ━━━━━━━━━━━━━━━━━━━━ 12:50:26\n",
      "Accuracy: 0.9979 - Precision: 0.9027 - Recall: 0.8854 - Specificity: 0.9991 - F1: 0.8897 - Loss: 0.1253\n",
      "\n",
      "Batch 43/387 ━━━━━━━━━━━━━━━━━━━━ 12:51:53\n",
      "Accuracy: 0.9979 - Precision: 0.9043 - Recall: 0.8848 - Specificity: 0.9991 - F1: 0.8902 - Loss: 0.1246\n",
      "\n",
      "Batch 44/387 ━━━━━━━━━━━━━━━━━━━━ 12:53:09\n",
      "Accuracy: 0.9979 - Precision: 0.9052 - Recall: 0.8858 - Specificity: 0.9991 - F1: 0.8913 - Loss: 0.1235\n",
      "\n",
      "Batch 45/387 ━━━━━━━━━━━━━━━━━━━━ 12:54:37\n",
      "Accuracy: 0.9979 - Precision: 0.9062 - Recall: 0.8872 - Specificity: 0.9991 - F1: 0.8926 - Loss: 0.1221\n",
      "\n",
      "Batch 46/387 ━━━━━━━━━━━━━━━━━━━━ 12:56:01\n",
      "Accuracy: 0.9978 - Precision: 0.9063 - Recall: 0.8867 - Specificity: 0.9991 - F1: 0.8924 - Loss: 0.1224\n",
      "\n",
      "Batch 47/387 ━━━━━━━━━━━━━━━━━━━━ 12:57:36\n",
      "Accuracy: 0.9978 - Precision: 0.9072 - Recall: 0.8857 - Specificity: 0.9991 - F1: 0.8924 - Loss: 0.1226\n",
      "\n",
      "Batch 48/387 ━━━━━━━━━━━━━━━━━━━━ 12:59:04\n",
      "Accuracy: 0.9978 - Precision: 0.9080 - Recall: 0.8851 - Specificity: 0.9991 - F1: 0.8926 - Loss: 0.1223\n",
      "\n",
      "Batch 49/387 ━━━━━━━━━━━━━━━━━━━━ 13:00:25\n",
      "Accuracy: 0.9977 - Precision: 0.9076 - Recall: 0.8809 - Specificity: 0.9991 - F1: 0.8901 - Loss: 0.1254\n",
      "\n",
      "Batch 50/387 ━━━━━━━━━━━━━━━━━━━━ 13:01:45\n",
      "Accuracy: 0.9977 - Precision: 0.9074 - Recall: 0.8828 - Specificity: 0.9991 - F1: 0.8910 - Loss: 0.1243\n",
      "\n",
      "Batch 51/387 ━━━━━━━━━━━━━━━━━━━━ 13:03:13\n",
      "Accuracy: 0.9977 - Precision: 0.8964 - Recall: 0.8844 - Specificity: 0.9990 - F1: 0.8835 - Loss: 0.1322\n",
      "\n",
      "Batch 52/387 ━━━━━━━━━━━━━━━━━━━━ 13:04:47\n",
      "Accuracy: 0.9977 - Precision: 0.8913 - Recall: 0.8860 - Specificity: 0.9990 - F1: 0.8812 - Loss: 0.1347\n",
      "\n",
      "Batch 53/387 ━━━━━━━━━━━━━━━━━━━━ 13:06:15\n",
      "Accuracy: 0.9976 - Precision: 0.8884 - Recall: 0.8868 - Specificity: 0.9989 - F1: 0.8800 - Loss: 0.1363\n",
      "\n",
      "Batch 54/387 ━━━━━━━━━━━━━━━━━━━━ 13:07:39\n",
      "Accuracy: 0.9975 - Precision: 0.8891 - Recall: 0.8874 - Specificity: 0.9989 - F1: 0.8808 - Loss: 0.1354\n",
      "\n",
      "Batch 55/387 ━━━━━━━━━━━━━━━━━━━━ 13:09:03\n",
      "Accuracy: 0.9976 - Precision: 0.8903 - Recall: 0.8880 - Specificity: 0.9989 - F1: 0.8818 - Loss: 0.1344\n",
      "\n",
      "Batch 56/387 ━━━━━━━━━━━━━━━━━━━━ 13:10:27\n",
      "Accuracy: 0.9976 - Precision: 0.8914 - Recall: 0.8889 - Specificity: 0.9989 - F1: 0.8830 - Loss: 0.1331\n",
      "\n",
      "Batch 57/387 ━━━━━━━━━━━━━━━━━━━━ 13:11:58\n",
      "Accuracy: 0.9975 - Precision: 0.8793 - Recall: 0.8903 - Specificity: 0.9988 - F1: 0.8734 - Loss: 0.1430\n",
      "\n",
      "Batch 58/387 ━━━━━━━━━━━━━━━━━━━━ 13:13:20\n",
      "Accuracy: 0.9976 - Precision: 0.8801 - Recall: 0.8909 - Specificity: 0.9988 - F1: 0.8743 - Loss: 0.1421\n",
      "\n",
      "Batch 59/387 ━━━━━━━━━━━━━━━━━━━━ 13:14:50\n",
      "Accuracy: 0.9975 - Precision: 0.8820 - Recall: 0.8907 - Specificity: 0.9988 - F1: 0.8753 - Loss: 0.1411\n",
      "\n",
      "Batch 60/387 ━━━━━━━━━━━━━━━━━━━━ 13:16:23\n",
      "Accuracy: 0.9976 - Precision: 0.8829 - Recall: 0.8905 - Specificity: 0.9989 - F1: 0.8758 - Loss: 0.1405\n",
      "\n",
      "Batch 61/387 ━━━━━━━━━━━━━━━━━━━━ 13:17:47\n",
      "Accuracy: 0.9976 - Precision: 0.8847 - Recall: 0.8879 - Specificity: 0.9989 - F1: 0.8752 - Loss: 0.1409\n",
      "\n",
      "Batch 62/387 ━━━━━━━━━━━━━━━━━━━━ 13:19:08\n",
      "Accuracy: 0.9976 - Precision: 0.8858 - Recall: 0.8883 - Specificity: 0.9989 - F1: 0.8762 - Loss: 0.1399\n",
      "\n",
      "Batch 63/387 ━━━━━━━━━━━━━━━━━━━━ 13:20:41\n",
      "Accuracy: 0.9976 - Precision: 0.8871 - Recall: 0.8890 - Specificity: 0.9989 - F1: 0.8773 - Loss: 0.1386\n",
      "\n",
      "Batch 64/387 ━━━━━━━━━━━━━━━━━━━━ 13:22:16\n",
      "Accuracy: 0.9976 - Precision: 0.8846 - Recall: 0.8900 - Specificity: 0.9989 - F1: 0.8765 - Loss: 0.1394\n",
      "\n",
      "Batch 65/387 ━━━━━━━━━━━━━━━━━━━━ 13:23:32\n",
      "Accuracy: 0.9976 - Precision: 0.8858 - Recall: 0.8883 - Specificity: 0.9989 - F1: 0.8763 - Loss: 0.1398\n",
      "\n",
      "Batch 66/387 ━━━━━━━━━━━━━━━━━━━━ 13:24:56\n",
      "Accuracy: 0.9976 - Precision: 0.8871 - Recall: 0.8875 - Specificity: 0.9989 - F1: 0.8767 - Loss: 0.1396\n",
      "\n",
      "Batch 67/387 ━━━━━━━━━━━━━━━━━━━━ 13:26:25\n",
      "Accuracy: 0.9975 - Precision: 0.8888 - Recall: 0.8840 - Specificity: 0.9989 - F1: 0.8754 - Loss: 0.1415\n",
      "\n",
      "Batch 68/387 ━━━━━━━━━━━━━━━━━━━━ 13:27:56\n",
      "Accuracy: 0.9975 - Precision: 0.8876 - Recall: 0.8855 - Specificity: 0.9989 - F1: 0.8755 - Loss: 0.1412\n",
      "\n",
      "Batch 69/387 ━━━━━━━━━━━━━━━━━━━━ 13:29:15\n",
      "Accuracy: 0.9975 - Precision: 0.8855 - Recall: 0.8849 - Specificity: 0.9989 - F1: 0.8743 - Loss: 0.1424\n",
      "\n",
      "Batch 70/387 ━━━━━━━━━━━━━━━━━━━━ 13:30:50\n",
      "Accuracy: 0.9975 - Precision: 0.8843 - Recall: 0.8860 - Specificity: 0.9989 - F1: 0.8743 - Loss: 0.1423\n",
      "\n",
      "Batch 71/387 ━━━━━━━━━━━━━━━━━━━━ 13:32:19\n",
      "Accuracy: 0.9975 - Precision: 0.8859 - Recall: 0.8839 - Specificity: 0.9989 - F1: 0.8739 - Loss: 0.1428\n",
      "\n",
      "Batch 72/387 ━━━━━━━━━━━━━━━━━━━━ 13:33:41\n",
      "Accuracy: 0.9974 - Precision: 0.8811 - Recall: 0.8855 - Specificity: 0.9989 - F1: 0.8715 - Loss: 0.1455\n",
      "\n",
      "Batch 73/387 ━━━━━━━━━━━━━━━━━━━━ 13:35:05\n",
      "Accuracy: 0.9974 - Precision: 0.8820 - Recall: 0.8860 - Specificity: 0.9989 - F1: 0.8724 - Loss: 0.1445\n",
      "\n",
      "Batch 74/387 ━━━━━━━━━━━━━━━━━━━━ 13:36:37\n",
      "Accuracy: 0.9975 - Precision: 0.8798 - Recall: 0.8860 - Specificity: 0.9989 - F1: 0.8713 - Loss: 0.1455\n",
      "\n",
      "Batch 75/387 ━━━━━━━━━━━━━━━━━━━━ 13:38:07\n",
      "Accuracy: 0.9974 - Precision: 0.8808 - Recall: 0.8835 - Specificity: 0.9989 - F1: 0.8705 - Loss: 0.1464\n",
      "\n",
      "Batch 76/387 ━━━━━━━━━━━━━━━━━━━━ 13:39:27\n",
      "Accuracy: 0.9974 - Precision: 0.8820 - Recall: 0.8838 - Specificity: 0.9989 - F1: 0.8714 - Loss: 0.1454\n",
      "\n",
      "Batch 77/387 ━━━━━━━━━━━━━━━━━━━━ 13:41:00\n",
      "Accuracy: 0.9974 - Precision: 0.8832 - Recall: 0.8837 - Specificity: 0.9989 - F1: 0.8721 - Loss: 0.1447\n",
      "\n",
      "Batch 78/387 ━━━━━━━━━━━━━━━━━━━━ 13:42:24\n",
      "Accuracy: 0.9974 - Precision: 0.8832 - Recall: 0.8845 - Specificity: 0.9989 - F1: 0.8726 - Loss: 0.1443\n",
      "\n",
      "Batch 79/387 ━━━━━━━━━━━━━━━━━━━━ 13:43:53\n",
      "Accuracy: 0.9974 - Precision: 0.8832 - Recall: 0.8799 - Specificity: 0.9989 - F1: 0.8698 - Loss: 0.1472\n",
      "\n",
      "Batch 80/387 ━━━━━━━━━━━━━━━━━━━━ 13:45:18\n",
      "Accuracy: 0.9974 - Precision: 0.8838 - Recall: 0.8799 - Specificity: 0.9989 - F1: 0.8702 - Loss: 0.1467\n",
      "\n",
      "Batch 81/387 ━━━━━━━━━━━━━━━━━━━━ 13:46:44\n",
      "Accuracy: 0.9974 - Precision: 0.8848 - Recall: 0.8796 - Specificity: 0.9989 - F1: 0.8707 - Loss: 0.1462\n",
      "\n",
      "Batch 82/387 ━━━━━━━━━━━━━━━━━━━━ 13:48:14\n",
      "Accuracy: 0.9974 - Precision: 0.8851 - Recall: 0.8798 - Specificity: 0.9989 - F1: 0.8711 - Loss: 0.1459\n",
      "\n",
      "Batch 83/387 ━━━━━━━━━━━━━━━━━━━━ 13:49:48\n",
      "Accuracy: 0.9974 - Precision: 0.8839 - Recall: 0.8807 - Specificity: 0.9989 - F1: 0.8710 - Loss: 0.1460\n",
      "\n",
      "Batch 84/387 ━━━━━━━━━━━━━━━━━━━━ 13:51:12\n",
      "Accuracy: 0.9974 - Precision: 0.8850 - Recall: 0.8816 - Specificity: 0.9989 - F1: 0.8721 - Loss: 0.1447\n",
      "\n",
      "Batch 85/387 ━━━━━━━━━━━━━━━━━━━━ 13:52:36\n",
      "Accuracy: 0.9974 - Precision: 0.8857 - Recall: 0.8825 - Specificity: 0.9989 - F1: 0.8731 - Loss: 0.1437\n",
      "\n",
      "Batch 86/387 ━━━━━━━━━━━━━━━━━━━━ 13:54:02\n",
      "Accuracy: 0.9974 - Precision: 0.8865 - Recall: 0.8834 - Specificity: 0.9989 - F1: 0.8741 - Loss: 0.1426\n",
      "\n",
      "Batch 87/387 ━━━━━━━━━━━━━━━━━━━━ 13:55:32\n",
      "Accuracy: 0.9974 - Precision: 0.8864 - Recall: 0.8847 - Specificity: 0.9989 - F1: 0.8747 - Loss: 0.1419\n",
      "\n",
      "Batch 88/387 ━━━━━━━━━━━━━━━━━━━━ 13:57:00\n",
      "Accuracy: 0.9974 - Precision: 0.8837 - Recall: 0.8858 - Specificity: 0.9989 - F1: 0.8737 - Loss: 0.1429\n",
      "\n",
      "Batch 89/387 ━━━━━━━━━━━━━━━━━━━━ 13:58:26\n",
      "Accuracy: 0.9974 - Precision: 0.8836 - Recall: 0.8865 - Specificity: 0.9989 - F1: 0.8740 - Loss: 0.1426\n",
      "\n",
      "Batch 90/387 ━━━━━━━━━━━━━━━━━━━━ 13:59:45\n",
      "Accuracy: 0.9974 - Precision: 0.8794 - Recall: 0.8874 - Specificity: 0.9988 - F1: 0.8718 - Loss: 0.1449\n",
      "\n",
      "Batch 91/387 ━━━━━━━━━━━━━━━━━━━━ 14:01:13\n",
      "Accuracy: 0.9974 - Precision: 0.8781 - Recall: 0.8884 - Specificity: 0.9988 - F1: 0.8716 - Loss: 0.1452\n",
      "\n",
      "Batch 92/387 ━━━━━━━━━━━━━━━━━━━━ 14:02:39\n",
      "Accuracy: 0.9974 - Precision: 0.8724 - Recall: 0.8874 - Specificity: 0.9988 - F1: 0.8674 - Loss: 0.1496\n",
      "\n",
      "Batch 93/387 ━━━━━━━━━━━━━━━━━━━━ 14:04:10\n",
      "Accuracy: 0.9974 - Precision: 0.8737 - Recall: 0.8873 - Specificity: 0.9988 - F1: 0.8681 - Loss: 0.1488\n",
      "\n",
      "Batch 94/387 ━━━━━━━━━━━━━━━━━━━━ 14:05:36\n",
      "Accuracy: 0.9974 - Precision: 0.8748 - Recall: 0.8874 - Specificity: 0.9988 - F1: 0.8689 - Loss: 0.1480\n",
      "\n",
      "Batch 95/387 ━━━━━━━━━━━━━━━━━━━━ 14:06:58\n",
      "Accuracy: 0.9974 - Precision: 0.8757 - Recall: 0.8874 - Specificity: 0.9988 - F1: 0.8694 - Loss: 0.1474\n",
      "\n",
      "Batch 96/387 ━━━━━━━━━━━━━━━━━━━━ 14:08:31\n",
      "Accuracy: 0.9974 - Precision: 0.8765 - Recall: 0.8878 - Specificity: 0.9988 - F1: 0.8701 - Loss: 0.1467\n",
      "\n",
      "Batch 97/387 ━━━━━━━━━━━━━━━━━━━━ 14:09:50\n",
      "Accuracy: 0.9974 - Precision: 0.8767 - Recall: 0.8883 - Specificity: 0.9988 - F1: 0.8706 - Loss: 0.1461\n",
      "\n",
      "Batch 98/387 ━━━━━━━━━━━━━━━━━━━━ 14:11:17\n",
      "Accuracy: 0.9973 - Precision: 0.8780 - Recall: 0.8836 - Specificity: 0.9988 - F1: 0.8679 - Loss: 0.1496\n",
      "\n",
      "Batch 99/387 ━━━━━━━━━━━━━━━━━━━━ 14:12:52\n",
      "Accuracy: 0.9973 - Precision: 0.8764 - Recall: 0.8815 - Specificity: 0.9988 - F1: 0.8661 - Loss: 0.1513\n",
      "\n",
      "Batch 100/387 ━━━━━━━━━━━━━━━━━━━━ 14:14:19\n",
      "Accuracy: 0.9973 - Precision: 0.8766 - Recall: 0.8772 - Specificity: 0.9988 - F1: 0.8634 - Loss: 0.1539\n",
      "\n",
      "Batch 101/387 ━━━━━━━━━━━━━━━━━━━━ 14:15:49\n",
      "Accuracy: 0.9973 - Precision: 0.8777 - Recall: 0.8753 - Specificity: 0.9988 - F1: 0.8629 - Loss: 0.1544\n",
      "\n",
      "Batch 102/387 ━━━━━━━━━━━━━━━━━━━━ 14:17:19\n",
      "Accuracy: 0.9973 - Precision: 0.8788 - Recall: 0.8752 - Specificity: 0.9989 - F1: 0.8635 - Loss: 0.1538\n",
      "\n",
      "Batch 103/387 ━━━━━━━━━━━━━━━━━━━━ 14:18:38\n",
      "Accuracy: 0.9973 - Precision: 0.8797 - Recall: 0.8746 - Specificity: 0.9989 - F1: 0.8637 - Loss: 0.1535\n",
      "\n",
      "Batch 104/387 ━━━━━━━━━━━━━━━━━━━━ 14:20:05\n",
      "Accuracy: 0.9973 - Precision: 0.8807 - Recall: 0.8736 - Specificity: 0.9989 - F1: 0.8637 - Loss: 0.1535\n",
      "\n",
      "Batch 105/387 ━━━━━━━━━━━━━━━━━━━━ 14:21:37\n",
      "Accuracy: 0.9974 - Precision: 0.8812 - Recall: 0.8742 - Specificity: 0.9989 - F1: 0.8644 - Loss: 0.1527\n",
      "\n",
      "Batch 106/387 ━━━━━━━━━━━━━━━━━━━━ 14:23:04\n",
      "Accuracy: 0.9974 - Precision: 0.8772 - Recall: 0.8751 - Specificity: 0.9989 - F1: 0.8621 - Loss: 0.1555\n",
      "\n",
      "Batch 107/387 ━━━━━━━━━━━━━━━━━━━━ 14:24:33\n",
      "Accuracy: 0.9974 - Precision: 0.8781 - Recall: 0.8750 - Specificity: 0.9989 - F1: 0.8626 - Loss: 0.1550\n",
      "\n",
      "Batch 108/387 ━━━━━━━━━━━━━━━━━━━━ 14:25:54\n",
      "Accuracy: 0.9973 - Precision: 0.8787 - Recall: 0.8748 - Specificity: 0.9989 - F1: 0.8629 - Loss: 0.1547\n",
      "\n",
      "Batch 109/387 ━━━━━━━━━━━━━━━━━━━━ 14:27:26\n",
      "Accuracy: 0.9973 - Precision: 0.8777 - Recall: 0.8755 - Specificity: 0.9989 - F1: 0.8628 - Loss: 0.1548\n",
      "\n",
      "Batch 110/387 ━━━━━━━━━━━━━━━━━━━━ 14:28:59\n",
      "Accuracy: 0.9973 - Precision: 0.8784 - Recall: 0.8763 - Specificity: 0.9989 - F1: 0.8637 - Loss: 0.1539\n",
      "\n",
      "Batch 111/387 ━━━━━━━━━━━━━━━━━━━━ 14:30:31\n",
      "Accuracy: 0.9973 - Precision: 0.8775 - Recall: 0.8771 - Specificity: 0.9989 - F1: 0.8636 - Loss: 0.1540\n",
      "\n",
      "Batch 112/387 ━━━━━━━━━━━━━━━━━━━━ 14:31:55\n",
      "Accuracy: 0.9973 - Precision: 0.8770 - Recall: 0.8773 - Specificity: 0.9989 - F1: 0.8636 - Loss: 0.1540\n",
      "\n",
      "Batch 113/387 ━━━━━━━━━━━━━━━━━━━━ 14:33:18\n",
      "Accuracy: 0.9973 - Precision: 0.8753 - Recall: 0.8784 - Specificity: 0.9988 - F1: 0.8632 - Loss: 0.1544\n",
      "\n",
      "Batch 114/387 ━━━━━━━━━━━━━━━━━━━━ 14:34:40\n",
      "Accuracy: 0.9973 - Precision: 0.8732 - Recall: 0.8784 - Specificity: 0.9988 - F1: 0.8620 - Loss: 0.1557\n",
      "\n",
      "Batch 115/387 ━━━━━━━━━━━━━━━━━━━━ 14:35:57\n",
      "Accuracy: 0.9973 - Precision: 0.8740 - Recall: 0.8789 - Specificity: 0.9988 - F1: 0.8628 - Loss: 0.1549\n",
      "\n",
      "Batch 116/387 ━━━━━━━━━━━━━━━━━━━━ 14:37:25\n",
      "Accuracy: 0.9973 - Precision: 0.8746 - Recall: 0.8792 - Specificity: 0.9988 - F1: 0.8634 - Loss: 0.1543\n",
      "\n",
      "Batch 117/387 ━━━━━━━━━━━━━━━━━━━━ 14:38:55\n",
      "Accuracy: 0.9973 - Precision: 0.8739 - Recall: 0.8800 - Specificity: 0.9988 - F1: 0.8635 - Loss: 0.1542\n",
      "\n",
      "Batch 118/387 ━━━━━━━━━━━━━━━━━━━━ 14:40:18\n",
      "Accuracy: 0.9973 - Precision: 0.8734 - Recall: 0.8802 - Specificity: 0.9988 - F1: 0.8634 - Loss: 0.1542\n",
      "\n",
      "Batch 119/387 ━━━━━━━━━━━━━━━━━━━━ 14:41:46\n",
      "Accuracy: 0.9973 - Precision: 0.8736 - Recall: 0.8808 - Specificity: 0.9988 - F1: 0.8639 - Loss: 0.1537\n",
      "\n",
      "Batch 120/387 ━━━━━━━━━━━━━━━━━━━━ 14:43:12\n",
      "Accuracy: 0.9973 - Precision: 0.8744 - Recall: 0.8813 - Specificity: 0.9988 - F1: 0.8647 - Loss: 0.1529\n",
      "\n",
      "Batch 121/387 ━━━━━━━━━━━━━━━━━━━━ 14:44:48\n",
      "Accuracy: 0.9973 - Precision: 0.8746 - Recall: 0.8820 - Specificity: 0.9988 - F1: 0.8652 - Loss: 0.1523\n",
      "\n",
      "Batch 122/387 ━━━━━━━━━━━━━━━━━━━━ 14:46:10\n",
      "Accuracy: 0.9973 - Precision: 0.8744 - Recall: 0.8797 - Specificity: 0.9988 - F1: 0.8639 - Loss: 0.1535\n",
      "\n",
      "Batch 123/387 ━━━━━━━━━━━━━━━━━━━━ 14:47:34\n",
      "Accuracy: 0.9974 - Precision: 0.8730 - Recall: 0.8795 - Specificity: 0.9988 - F1: 0.8632 - Loss: 0.1543\n",
      "\n",
      "Batch 124/387 ━━━━━━━━━━━━━━━━━━━━ 14:48:58\n",
      "Accuracy: 0.9973 - Precision: 0.8737 - Recall: 0.8792 - Specificity: 0.9988 - F1: 0.8635 - Loss: 0.1540\n",
      "\n",
      "Batch 125/387 ━━━━━━━━━━━━━━━━━━━━ 14:50:21\n",
      "Accuracy: 0.9973 - Precision: 0.8740 - Recall: 0.8779 - Specificity: 0.9988 - F1: 0.8629 - Loss: 0.1546\n",
      "\n",
      "Batch 126/387 ━━━━━━━━━━━━━━━━━━━━ 14:51:46\n",
      "Accuracy: 0.9973 - Precision: 0.8746 - Recall: 0.8779 - Specificity: 0.9988 - F1: 0.8633 - Loss: 0.1542\n",
      "\n",
      "Batch 127/387 ━━━━━━━━━━━━━━━━━━━━ 14:53:07\n",
      "Accuracy: 0.9973 - Precision: 0.8746 - Recall: 0.8788 - Specificity: 0.9988 - F1: 0.8639 - Loss: 0.1535\n",
      "\n",
      "Batch 128/387 ━━━━━━━━━━━━━━━━━━━━ 14:54:25\n",
      "Accuracy: 0.9974 - Precision: 0.8750 - Recall: 0.8782 - Specificity: 0.9988 - F1: 0.8638 - Loss: 0.1535\n",
      "\n",
      "Batch 129/387 ━━━━━━━━━━━━━━━━━━━━ 14:55:52\n",
      "Accuracy: 0.9974 - Precision: 0.8756 - Recall: 0.8786 - Specificity: 0.9988 - F1: 0.8645 - Loss: 0.1529\n",
      "\n",
      "Batch 130/387 ━━━━━━━━━━━━━━━━━━━━ 14:57:16\n",
      "Accuracy: 0.9974 - Precision: 0.8762 - Recall: 0.8774 - Specificity: 0.9988 - F1: 0.8641 - Loss: 0.1532\n",
      "\n",
      "Batch 131/387 ━━━━━━━━━━━━━━━━━━━━ 14:58:37\n",
      "Accuracy: 0.9974 - Precision: 0.8758 - Recall: 0.8780 - Specificity: 0.9988 - F1: 0.8643 - Loss: 0.1530\n",
      "\n",
      "Batch 132/387 ━━━━━━━━━━━━━━━━━━━━ 14:59:54\n",
      "Accuracy: 0.9974 - Precision: 0.8764 - Recall: 0.8783 - Specificity: 0.9988 - F1: 0.8648 - Loss: 0.1524\n",
      "\n",
      "Batch 133/387 ━━━━━━━━━━━━━━━━━━━━ 15:01:27\n",
      "Accuracy: 0.9974 - Precision: 0.8738 - Recall: 0.8792 - Specificity: 0.9988 - F1: 0.8635 - Loss: 0.1537\n",
      "\n",
      "Batch 134/387 ━━━━━━━━━━━━━━━━━━━━ 15:03:01\n",
      "Accuracy: 0.9974 - Precision: 0.8744 - Recall: 0.8796 - Specificity: 0.9988 - F1: 0.8641 - Loss: 0.1530\n",
      "\n",
      "Batch 135/387 ━━━━━━━━━━━━━━━━━━━━ 15:04:24\n",
      "Accuracy: 0.9974 - Precision: 0.8752 - Recall: 0.8800 - Specificity: 0.9988 - F1: 0.8648 - Loss: 0.1523\n",
      "\n",
      "Batch 136/387 ━━━━━━━━━━━━━━━━━━━━ 15:05:51\n",
      "Accuracy: 0.9974 - Precision: 0.8755 - Recall: 0.8794 - Specificity: 0.9988 - F1: 0.8647 - Loss: 0.1524\n",
      "\n",
      "Batch 137/387 ━━━━━━━━━━━━━━━━━━━━ 15:07:09\n",
      "Accuracy: 0.9974 - Precision: 0.8758 - Recall: 0.8775 - Specificity: 0.9988 - F1: 0.8638 - Loss: 0.1535\n",
      "\n",
      "Batch 138/387 ━━━━━━━━━━━━━━━━━━━━ 15:08:30\n",
      "Accuracy: 0.9974 - Precision: 0.8766 - Recall: 0.8776 - Specificity: 0.9988 - F1: 0.8643 - Loss: 0.1529\n",
      "\n",
      "Batch 139/387 ━━━━━━━━━━━━━━━━━━━━ 15:09:49\n",
      "Accuracy: 0.9974 - Precision: 0.8753 - Recall: 0.8778 - Specificity: 0.9988 - F1: 0.8638 - Loss: 0.1535\n",
      "\n",
      "Batch 140/387 ━━━━━━━━━━━━━━━━━━━━ 15:11:22\n",
      "Accuracy: 0.9974 - Precision: 0.8759 - Recall: 0.8777 - Specificity: 0.9988 - F1: 0.8641 - Loss: 0.1532\n",
      "\n",
      "Batch 141/387 ━━━━━━━━━━━━━━━━━━━━ 15:12:46\n",
      "Accuracy: 0.9974 - Precision: 0.8748 - Recall: 0.8774 - Specificity: 0.9988 - F1: 0.8635 - Loss: 0.1538\n",
      "\n",
      "Batch 142/387 ━━━━━━━━━━━━━━━━━━━━ 15:14:09\n",
      "Accuracy: 0.9974 - Precision: 0.8748 - Recall: 0.8769 - Specificity: 0.9989 - F1: 0.8633 - Loss: 0.1540\n",
      "\n",
      "Batch 143/387 ━━━━━━━━━━━━━━━━━━━━ 15:15:28\n",
      "Accuracy: 0.9974 - Precision: 0.8732 - Recall: 0.8777 - Specificity: 0.9988 - F1: 0.8628 - Loss: 0.1544\n",
      "\n",
      "Batch 144/387 ━━━━━━━━━━━━━━━━━━━━ 15:16:52\n",
      "Accuracy: 0.9974 - Precision: 0.8737 - Recall: 0.8783 - Specificity: 0.9989 - F1: 0.8634 - Loss: 0.1538\n",
      "\n",
      "Batch 145/387 ━━━━━━━━━━━━━━━━━━━━ 15:18:16\n",
      "Accuracy: 0.9974 - Precision: 0.8741 - Recall: 0.8787 - Specificity: 0.9989 - F1: 0.8639 - Loss: 0.1532\n",
      "\n",
      "Batch 146/387 ━━━━━━━━━━━━━━━━━━━━ 15:19:38\n",
      "Accuracy: 0.9974 - Precision: 0.8746 - Recall: 0.8787 - Specificity: 0.9989 - F1: 0.8642 - Loss: 0.1530\n",
      "\n",
      "Batch 147/387 ━━━━━━━━━━━━━━━━━━━━ 15:21:03\n",
      "Accuracy: 0.9974 - Precision: 0.8751 - Recall: 0.8793 - Specificity: 0.9989 - F1: 0.8648 - Loss: 0.1523\n",
      "\n",
      "Batch 148/387 ━━━━━━━━━━━━━━━━━━━━ 15:22:22\n",
      "Accuracy: 0.9974 - Precision: 0.8758 - Recall: 0.8794 - Specificity: 0.9989 - F1: 0.8653 - Loss: 0.1518\n",
      "\n",
      "Batch 149/387 ━━━━━━━━━━━━━━━━━━━━ 15:23:58\n",
      "Accuracy: 0.9974 - Precision: 0.8765 - Recall: 0.8797 - Specificity: 0.9989 - F1: 0.8659 - Loss: 0.1511\n",
      "\n",
      "Batch 150/387 ━━━━━━━━━━━━━━━━━━━━ 15:25:27\n",
      "Accuracy: 0.9975 - Precision: 0.8772 - Recall: 0.8799 - Specificity: 0.9989 - F1: 0.8664 - Loss: 0.1506\n",
      "\n",
      "Batch 151/387 ━━━━━━━━━━━━━━━━━━━━ 15:26:47\n",
      "Accuracy: 0.9975 - Precision: 0.8779 - Recall: 0.8803 - Specificity: 0.9989 - F1: 0.8670 - Loss: 0.1499\n",
      "\n",
      "Batch 152/387 ━━━━━━━━━━━━━━━━━━━━ 15:28:11\n",
      "Accuracy: 0.9975 - Precision: 0.8772 - Recall: 0.8808 - Specificity: 0.9989 - F1: 0.8669 - Loss: 0.1499\n",
      "\n",
      "Batch 153/387 ━━━━━━━━━━━━━━━━━━━━ 15:29:41\n",
      "Accuracy: 0.9975 - Precision: 0.8773 - Recall: 0.8812 - Specificity: 0.9989 - F1: 0.8673 - Loss: 0.1495\n",
      "\n",
      "Batch 154/387 ━━━━━━━━━━━━━━━━━━━━ 15:31:11\n",
      "Accuracy: 0.9975 - Precision: 0.8754 - Recall: 0.8819 - Specificity: 0.9989 - F1: 0.8664 - Loss: 0.1504\n",
      "\n",
      "Batch 155/387 ━━━━━━━━━━━━━━━━━━━━ 15:32:32\n",
      "Accuracy: 0.9975 - Precision: 0.8759 - Recall: 0.8810 - Specificity: 0.9989 - F1: 0.8662 - Loss: 0.1506\n",
      "\n",
      "Batch 156/387 ━━━━━━━━━━━━━━━━━━━━ 15:34:09\n",
      "Accuracy: 0.9975 - Precision: 0.8757 - Recall: 0.8814 - Specificity: 0.9989 - F1: 0.8664 - Loss: 0.1503\n",
      "\n",
      "Batch 157/387 ━━━━━━━━━━━━━━━━━━━━ 15:35:53\n",
      "Accuracy: 0.9975 - Precision: 0.8750 - Recall: 0.8801 - Specificity: 0.9989 - F1: 0.8654 - Loss: 0.1514\n",
      "\n",
      "Batch 158/387 ━━━━━━━━━━━━━━━━━━━━ 15:37:22\n",
      "Accuracy: 0.9975 - Precision: 0.8757 - Recall: 0.8804 - Specificity: 0.9989 - F1: 0.8660 - Loss: 0.1508\n",
      "\n",
      "Batch 159/387 ━━━━━━━━━━━━━━━━━━━━ 15:38:54\n",
      "Accuracy: 0.9975 - Precision: 0.8763 - Recall: 0.8805 - Specificity: 0.9989 - F1: 0.8665 - Loss: 0.1503\n",
      "\n",
      "Batch 160/387 ━━━━━━━━━━━━━━━━━━━━ 15:40:33\n",
      "Accuracy: 0.9975 - Precision: 0.8768 - Recall: 0.8795 - Specificity: 0.9989 - F1: 0.8661 - Loss: 0.1507\n",
      "\n",
      "Batch 161/387 ━━━━━━━━━━━━━━━━━━━━ 15:42:08\n",
      "Accuracy: 0.9975 - Precision: 0.8773 - Recall: 0.8798 - Specificity: 0.9989 - F1: 0.8666 - Loss: 0.1502\n",
      "\n",
      "Batch 162/387 ━━━━━━━━━━━━━━━━━━━━ 15:43:24\n",
      "Accuracy: 0.9975 - Precision: 0.8773 - Recall: 0.8794 - Specificity: 0.9989 - F1: 0.8664 - Loss: 0.1503\n",
      "\n",
      "Batch 163/387 ━━━━━━━━━━━━━━━━━━━━ 15:44:46\n",
      "Accuracy: 0.9975 - Precision: 0.8752 - Recall: 0.8773 - Specificity: 0.9989 - F1: 0.8645 - Loss: 0.1523\n",
      "\n",
      "Batch 164/387 ━━━━━━━━━━━━━━━━━━━━ 15:46:07\n",
      "Accuracy: 0.9975 - Precision: 0.8756 - Recall: 0.8779 - Specificity: 0.9989 - F1: 0.8650 - Loss: 0.1517\n",
      "\n",
      "Batch 165/387 ━━━━━━━━━━━━━━━━━━━━ 15:47:36\n",
      "Accuracy: 0.9975 - Precision: 0.8762 - Recall: 0.8784 - Specificity: 0.9989 - F1: 0.8656 - Loss: 0.1510\n",
      "\n",
      "Batch 166/387 ━━━━━━━━━━━━━━━━━━━━ 15:49:13\n",
      "Accuracy: 0.9975 - Precision: 0.8768 - Recall: 0.8789 - Specificity: 0.9989 - F1: 0.8662 - Loss: 0.1504\n",
      "\n",
      "Batch 167/387 ━━━━━━━━━━━━━━━━━━━━ 15:50:44\n",
      "Accuracy: 0.9975 - Precision: 0.8768 - Recall: 0.8788 - Specificity: 0.9989 - F1: 0.8662 - Loss: 0.1504\n",
      "\n",
      "Batch 168/387 ━━━━━━━━━━━━━━━━━━━━ 15:52:20\n",
      "Accuracy: 0.9975 - Precision: 0.8764 - Recall: 0.8791 - Specificity: 0.9989 - F1: 0.8663 - Loss: 0.1503\n",
      "\n",
      "Batch 169/387 ━━━━━━━━━━━━━━━━━━━━ 15:53:49\n",
      "Accuracy: 0.9975 - Precision: 0.8770 - Recall: 0.8795 - Specificity: 0.9989 - F1: 0.8668 - Loss: 0.1498\n",
      "\n",
      "Batch 170/387 ━━━━━━━━━━━━━━━━━━━━ 15:55:26\n",
      "Accuracy: 0.9975 - Precision: 0.8771 - Recall: 0.8794 - Specificity: 0.9989 - F1: 0.8669 - Loss: 0.1496\n",
      "\n",
      "Batch 171/387 ━━━━━━━━━━━━━━━━━━━━ 15:56:57\n",
      "Accuracy: 0.9975 - Precision: 0.8771 - Recall: 0.8800 - Specificity: 0.9989 - F1: 0.8672 - Loss: 0.1493\n",
      "\n",
      "Batch 172/387 ━━━━━━━━━━━━━━━━━━━━ 15:58:30\n",
      "Accuracy: 0.9975 - Precision: 0.8773 - Recall: 0.8800 - Specificity: 0.9989 - F1: 0.8674 - Loss: 0.1491\n",
      "\n",
      "Batch 173/387 ━━━━━━━━━━━━━━━━━━━━ 16:00:05\n",
      "Accuracy: 0.9975 - Precision: 0.8763 - Recall: 0.8796 - Specificity: 0.9989 - F1: 0.8667 - Loss: 0.1497\n",
      "\n",
      "Batch 174/387 ━━━━━━━━━━━━━━━━━━━━ 16:01:26\n",
      "Accuracy: 0.9976 - Precision: 0.8769 - Recall: 0.8800 - Specificity: 0.9989 - F1: 0.8673 - Loss: 0.1491\n",
      "\n",
      "Batch 175/387 ━━━━━━━━━━━━━━━━━━━━ 16:02:55\n",
      "Accuracy: 0.9976 - Precision: 0.8766 - Recall: 0.8799 - Specificity: 0.9989 - F1: 0.8671 - Loss: 0.1493\n",
      "\n",
      "Batch 176/387 ━━━━━━━━━━━━━━━━━━━━ 16:04:20\n",
      "Accuracy: 0.9975 - Precision: 0.8771 - Recall: 0.8801 - Specificity: 0.9989 - F1: 0.8675 - Loss: 0.1489\n",
      "\n",
      "Batch 177/387 ━━━━━━━━━━━━━━━━━━━━ 16:05:39\n",
      "Accuracy: 0.9976 - Precision: 0.8774 - Recall: 0.8804 - Specificity: 0.9989 - F1: 0.8679 - Loss: 0.1485\n",
      "\n",
      "Batch 178/387 ━━━━━━━━━━━━━━━━━━━━ 16:07:00\n",
      "Accuracy: 0.9975 - Precision: 0.8780 - Recall: 0.8797 - Specificity: 0.9989 - F1: 0.8679 - Loss: 0.1486\n",
      "\n",
      "Batch 179/387 ━━━━━━━━━━━━━━━━━━━━ 16:08:27\n",
      "Accuracy: 0.9975 - Precision: 0.8777 - Recall: 0.8796 - Specificity: 0.9989 - F1: 0.8677 - Loss: 0.1488\n",
      "\n",
      "Batch 180/387 ━━━━━━━━━━━━━━━━━━━━ 16:09:52\n",
      "Accuracy: 0.9975 - Precision: 0.8774 - Recall: 0.8799 - Specificity: 0.9989 - F1: 0.8677 - Loss: 0.1488\n",
      "\n",
      "Batch 181/387 ━━━━━━━━━━━━━━━━━━━━ 16:11:16\n",
      "Accuracy: 0.9975 - Precision: 0.8777 - Recall: 0.8797 - Specificity: 0.9989 - F1: 0.8679 - Loss: 0.1486\n",
      "\n",
      "Batch 182/387 ━━━━━━━━━━━━━━━━━━━━ 16:12:50\n",
      "Accuracy: 0.9975 - Precision: 0.8783 - Recall: 0.8796 - Specificity: 0.9989 - F1: 0.8682 - Loss: 0.1483\n",
      "\n",
      "Batch 183/387 ━━━━━━━━━━━━━━━━━━━━ 16:14:19\n",
      "Accuracy: 0.9975 - Precision: 0.8784 - Recall: 0.8799 - Specificity: 0.9989 - F1: 0.8684 - Loss: 0.1480\n",
      "\n",
      "Batch 184/387 ━━━━━━━━━━━━━━━━━━━━ 16:15:40\n",
      "Accuracy: 0.9975 - Precision: 0.8789 - Recall: 0.8790 - Specificity: 0.9989 - F1: 0.8681 - Loss: 0.1484\n",
      "\n",
      "Batch 185/387 ━━━━━━━━━━━━━━━━━━━━ 16:17:08\n",
      "Accuracy: 0.9975 - Precision: 0.8793 - Recall: 0.8792 - Specificity: 0.9989 - F1: 0.8685 - Loss: 0.1480\n",
      "\n",
      "Batch 186/387 ━━━━━━━━━━━━━━━━━━━━ 16:18:28\n",
      "Accuracy: 0.9975 - Precision: 0.8785 - Recall: 0.8789 - Specificity: 0.9989 - F1: 0.8680 - Loss: 0.1486\n",
      "\n",
      "Batch 187/387 ━━━━━━━━━━━━━━━━━━━━ 16:20:01\n",
      "Accuracy: 0.9975 - Precision: 0.8779 - Recall: 0.8794 - Specificity: 0.9989 - F1: 0.8679 - Loss: 0.1486\n",
      "\n",
      "Batch 188/387 ━━━━━━━━━━━━━━━━━━━━ 16:21:39\n",
      "Accuracy: 0.9975 - Precision: 0.8775 - Recall: 0.8795 - Specificity: 0.9989 - F1: 0.8678 - Loss: 0.1486\n",
      "\n",
      "Batch 189/387 ━━━━━━━━━━━━━━━━━━━━ 16:23:15\n",
      "Accuracy: 0.9975 - Precision: 0.8775 - Recall: 0.8799 - Specificity: 0.9989 - F1: 0.8681 - Loss: 0.1483\n",
      "\n",
      "Batch 190/387 ━━━━━━━━━━━━━━━━━━━━ 16:24:44\n",
      "Accuracy: 0.9975 - Precision: 0.8768 - Recall: 0.8805 - Specificity: 0.9989 - F1: 0.8680 - Loss: 0.1485\n",
      "\n",
      "Batch 191/387 ━━━━━━━━━━━━━━━━━━━━ 16:26:08\n",
      "Accuracy: 0.9975 - Precision: 0.8773 - Recall: 0.8804 - Specificity: 0.9989 - F1: 0.8683 - Loss: 0.1482\n",
      "\n",
      "Batch 192/387 ━━━━━━━━━━━━━━━━━━━━ 16:27:35\n",
      "Accuracy: 0.9975 - Precision: 0.8779 - Recall: 0.8792 - Specificity: 0.9989 - F1: 0.8678 - Loss: 0.1487\n",
      "\n",
      "Batch 193/387 ━━━━━━━━━━━━━━━━━━━━ 16:29:10\n",
      "Accuracy: 0.9975 - Precision: 0.8785 - Recall: 0.8789 - Specificity: 0.9989 - F1: 0.8680 - Loss: 0.1486\n",
      "\n",
      "Batch 194/387 ━━━━━━━━━━━━━━━━━━━━ 16:30:37\n",
      "Accuracy: 0.9975 - Precision: 0.8785 - Recall: 0.8793 - Specificity: 0.9989 - F1: 0.8682 - Loss: 0.1484\n",
      "\n",
      "Batch 195/387 ━━━━━━━━━━━━━━━━━━━━ 16:32:01\n",
      "Accuracy: 0.9975 - Precision: 0.8778 - Recall: 0.8797 - Specificity: 0.9989 - F1: 0.8681 - Loss: 0.1484\n",
      "\n",
      "Batch 196/387 ━━━━━━━━━━━━━━━━━━━━ 16:33:37\n",
      "Accuracy: 0.9975 - Precision: 0.8778 - Recall: 0.8802 - Specificity: 0.9989 - F1: 0.8684 - Loss: 0.1481\n",
      "\n",
      "Batch 197/387 ━━━━━━━━━━━━━━━━━━━━ 16:35:13\n",
      "Accuracy: 0.9975 - Precision: 0.8773 - Recall: 0.8803 - Specificity: 0.9989 - F1: 0.8682 - Loss: 0.1483\n",
      "\n",
      "Batch 198/387 ━━━━━━━━━━━━━━━━━━━━ 16:36:38\n",
      "Accuracy: 0.9975 - Precision: 0.8772 - Recall: 0.8802 - Specificity: 0.9989 - F1: 0.8682 - Loss: 0.1483\n",
      "\n",
      "Batch 199/387 ━━━━━━━━━━━━━━━━━━━━ 16:38:06\n",
      "Accuracy: 0.9975 - Precision: 0.8775 - Recall: 0.8803 - Specificity: 0.9989 - F1: 0.8684 - Loss: 0.1481\n",
      "\n",
      "Batch 200/387 ━━━━━━━━━━━━━━━━━━━━ 16:39:36\n",
      "Accuracy: 0.9975 - Precision: 0.8779 - Recall: 0.8804 - Specificity: 0.9989 - F1: 0.8687 - Loss: 0.1477\n",
      "\n",
      "Batch 201/387 ━━━━━━━━━━━━━━━━━━━━ 16:41:14\n",
      "Accuracy: 0.9975 - Precision: 0.8783 - Recall: 0.8802 - Specificity: 0.9989 - F1: 0.8688 - Loss: 0.1475\n",
      "\n",
      "Batch 202/387 ━━━━━━━━━━━━━━━━━━━━ 16:43:03\n",
      "Accuracy: 0.9975 - Precision: 0.8788 - Recall: 0.8794 - Specificity: 0.9989 - F1: 0.8686 - Loss: 0.1478\n",
      "\n",
      "Batch 203/387 ━━━━━━━━━━━━━━━━━━━━ 16:44:39\n",
      "Accuracy: 0.9975 - Precision: 0.8792 - Recall: 0.8798 - Specificity: 0.9989 - F1: 0.8691 - Loss: 0.1473\n",
      "\n",
      "Batch 204/387 ━━━━━━━━━━━━━━━━━━━━ 16:46:03\n",
      "Accuracy: 0.9975 - Precision: 0.8793 - Recall: 0.8801 - Specificity: 0.9989 - F1: 0.8693 - Loss: 0.1470\n",
      "\n",
      "Batch 205/387 ━━━━━━━━━━━━━━━━━━━━ 16:47:39\n",
      "Accuracy: 0.9975 - Precision: 0.8792 - Recall: 0.8797 - Specificity: 0.9989 - F1: 0.8691 - Loss: 0.1472\n",
      "\n",
      "Batch 206/387 ━━━━━━━━━━━━━━━━━━━━ 16:49:06\n",
      "Accuracy: 0.9975 - Precision: 0.8797 - Recall: 0.8795 - Specificity: 0.9989 - F1: 0.8693 - Loss: 0.1471\n",
      "\n",
      "Batch 207/387 ━━━━━━━━━━━━━━━━━━━━ 16:50:27\n",
      "Accuracy: 0.9975 - Precision: 0.8786 - Recall: 0.8800 - Specificity: 0.9989 - F1: 0.8690 - Loss: 0.1474\n",
      "\n",
      "Batch 208/387 ━━━━━━━━━━━━━━━━━━━━ 16:51:59\n",
      "Accuracy: 0.9975 - Precision: 0.8782 - Recall: 0.8805 - Specificity: 0.9989 - F1: 0.8690 - Loss: 0.1474\n",
      "\n",
      "Batch 209/387 ━━━━━━━━━━━━━━━━━━━━ 16:53:20\n",
      "Accuracy: 0.9975 - Precision: 0.8778 - Recall: 0.8809 - Specificity: 0.9989 - F1: 0.8690 - Loss: 0.1473\n",
      "\n",
      "Batch 210/387 ━━━━━━━━━━━━━━━━━━━━ 16:54:43\n",
      "Accuracy: 0.9976 - Precision: 0.8783 - Recall: 0.8806 - Specificity: 0.9989 - F1: 0.8691 - Loss: 0.1472\n",
      "\n",
      "Batch 211/387 ━━━━━━━━━━━━━━━━━━━━ 16:56:12\n",
      "Accuracy: 0.9975 - Precision: 0.8785 - Recall: 0.8806 - Specificity: 0.9989 - F1: 0.8693 - Loss: 0.1471\n",
      "\n",
      "Batch 212/387 ━━━━━━━━━━━━━━━━━━━━ 16:57:36\n",
      "Accuracy: 0.9975 - Precision: 0.8789 - Recall: 0.8800 - Specificity: 0.9989 - F1: 0.8691 - Loss: 0.1473\n",
      "\n",
      "Batch 213/387 ━━━━━━━━━━━━━━━━━━━━ 16:59:09\n",
      "Accuracy: 0.9975 - Precision: 0.8793 - Recall: 0.8793 - Specificity: 0.9989 - F1: 0.8690 - Loss: 0.1475\n",
      "\n",
      "Batch 214/387 ━━━━━━━━━━━━━━━━━━━━ 17:00:36\n",
      "Accuracy: 0.9975 - Precision: 0.8794 - Recall: 0.8795 - Specificity: 0.9989 - F1: 0.8691 - Loss: 0.1473\n",
      "\n",
      "Batch 215/387 ━━━━━━━━━━━━━━━━━━━━ 17:02:13\n",
      "Accuracy: 0.9975 - Precision: 0.8798 - Recall: 0.8795 - Specificity: 0.9989 - F1: 0.8694 - Loss: 0.1471\n",
      "\n",
      "Batch 216/387 ━━━━━━━━━━━━━━━━━━━━ 17:03:45\n",
      "Accuracy: 0.9975 - Precision: 0.8799 - Recall: 0.8799 - Specificity: 0.9989 - F1: 0.8697 - Loss: 0.1467\n",
      "\n",
      "Batch 217/387 ━━━━━━━━━━━━━━━━━━━━ 17:05:08\n",
      "Accuracy: 0.9975 - Precision: 0.8804 - Recall: 0.8801 - Specificity: 0.9989 - F1: 0.8701 - Loss: 0.1463\n",
      "\n",
      "Batch 218/387 ━━━━━━━━━━━━━━━━━━━━ 17:06:37\n",
      "Accuracy: 0.9975 - Precision: 0.8809 - Recall: 0.8799 - Specificity: 0.9989 - F1: 0.8703 - Loss: 0.1461\n",
      "\n",
      "Batch 219/387 ━━━━━━━━━━━━━━━━━━━━ 17:08:01\n",
      "Accuracy: 0.9975 - Precision: 0.8810 - Recall: 0.8804 - Specificity: 0.9990 - F1: 0.8706 - Loss: 0.1458\n",
      "\n",
      "Batch 220/387 ━━━━━━━━━━━━━━━━━━━━ 17:09:26\n",
      "Accuracy: 0.9976 - Precision: 0.8814 - Recall: 0.8806 - Specificity: 0.9990 - F1: 0.8710 - Loss: 0.1454\n",
      "\n",
      "Batch 221/387 ━━━━━━━━━━━━━━━━━━━━ 17:11:00\n",
      "Accuracy: 0.9975 - Precision: 0.8815 - Recall: 0.8809 - Specificity: 0.9989 - F1: 0.8712 - Loss: 0.1451\n",
      "\n",
      "Batch 222/387 ━━━━━━━━━━━━━━━━━━━━ 17:12:24\n",
      "Accuracy: 0.9975 - Precision: 0.8816 - Recall: 0.8808 - Specificity: 0.9989 - F1: 0.8713 - Loss: 0.1450\n",
      "\n",
      "Batch 223/387 ━━━━━━━━━━━━━━━━━━━━ 17:13:52\n",
      "Accuracy: 0.9976 - Precision: 0.8819 - Recall: 0.8811 - Specificity: 0.9990 - F1: 0.8716 - Loss: 0.1447\n",
      "\n",
      "Batch 224/387 ━━━━━━━━━━━━━━━━━━━━ 17:15:13\n",
      "Accuracy: 0.9976 - Precision: 0.8820 - Recall: 0.8814 - Specificity: 0.9990 - F1: 0.8718 - Loss: 0.1444\n",
      "\n",
      "Batch 225/387 ━━━━━━━━━━━━━━━━━━━━ 17:16:38\n",
      "Accuracy: 0.9976 - Precision: 0.8810 - Recall: 0.8811 - Specificity: 0.9989 - F1: 0.8712 - Loss: 0.1451\n",
      "\n",
      "Batch 226/387 ━━━━━━━━━━━━━━━━━━━━ 17:17:58\n",
      "Accuracy: 0.9976 - Precision: 0.8813 - Recall: 0.8815 - Specificity: 0.9989 - F1: 0.8715 - Loss: 0.1447\n",
      "\n",
      "Batch 227/387 ━━━━━━━━━━━━━━━━━━━━ 17:19:28\n",
      "Accuracy: 0.9976 - Precision: 0.8813 - Recall: 0.8810 - Specificity: 0.9989 - F1: 0.8714 - Loss: 0.1449\n",
      "\n",
      "Batch 228/387 ━━━━━━━━━━━━━━━━━━━━ 17:20:57\n",
      "Accuracy: 0.9976 - Precision: 0.8816 - Recall: 0.8808 - Specificity: 0.9990 - F1: 0.8714 - Loss: 0.1449\n",
      "\n",
      "Batch 229/387 ━━━━━━━━━━━━━━━━━━━━ 17:22:31\n",
      "Accuracy: 0.9976 - Precision: 0.8816 - Recall: 0.8812 - Specificity: 0.9990 - F1: 0.8716 - Loss: 0.1446\n",
      "\n",
      "Batch 230/387 ━━━━━━━━━━━━━━━━━━━━ 17:23:53\n",
      "Accuracy: 0.9976 - Precision: 0.8818 - Recall: 0.8807 - Specificity: 0.9990 - F1: 0.8715 - Loss: 0.1447\n",
      "\n",
      "Batch 231/387 ━━━━━━━━━━━━━━━━━━━━ 17:25:14\n",
      "Accuracy: 0.9976 - Precision: 0.8821 - Recall: 0.8811 - Specificity: 0.9990 - F1: 0.8719 - Loss: 0.1443\n",
      "\n",
      "Batch 232/387 ━━━━━━━━━━━━━━━━━━━━ 17:26:37\n",
      "Accuracy: 0.9976 - Precision: 0.8824 - Recall: 0.8800 - Specificity: 0.9990 - F1: 0.8714 - Loss: 0.1449\n",
      "\n",
      "Batch 233/387 ━━━━━━━━━━━━━━━━━━━━ 17:28:00\n",
      "Accuracy: 0.9976 - Precision: 0.8828 - Recall: 0.8798 - Specificity: 0.9990 - F1: 0.8716 - Loss: 0.1447\n",
      "\n",
      "Batch 234/387 ━━━━━━━━━━━━━━━━━━━━ 17:29:19\n",
      "Accuracy: 0.9976 - Precision: 0.8828 - Recall: 0.8801 - Specificity: 0.9990 - F1: 0.8717 - Loss: 0.1445\n",
      "\n",
      "Batch 235/387 ━━━━━━━━━━━━━━━━━━━━ 17:30:41\n",
      "Accuracy: 0.9976 - Precision: 0.8818 - Recall: 0.8805 - Specificity: 0.9990 - F1: 0.8713 - Loss: 0.1449\n",
      "\n",
      "Batch 236/387 ━━━━━━━━━━━━━━━━━━━━ 17:32:12\n",
      "Accuracy: 0.9976 - Precision: 0.8817 - Recall: 0.8810 - Specificity: 0.9990 - F1: 0.8715 - Loss: 0.1447\n",
      "\n",
      "Batch 237/387 ━━━━━━━━━━━━━━━━━━━━ 17:33:33\n",
      "Accuracy: 0.9976 - Precision: 0.8803 - Recall: 0.8810 - Specificity: 0.9990 - F1: 0.8707 - Loss: 0.1455\n",
      "\n",
      "Batch 238/387 ━━━━━━━━━━━━━━━━━━━━ 17:34:55\n",
      "Accuracy: 0.9976 - Precision: 0.8787 - Recall: 0.8814 - Specificity: 0.9989 - F1: 0.8698 - Loss: 0.1465\n",
      "\n",
      "Batch 239/387 ━━━━━━━━━━━━━━━━━━━━ 17:36:50\n",
      "Accuracy: 0.9976 - Precision: 0.8786 - Recall: 0.8817 - Specificity: 0.9990 - F1: 0.8699 - Loss: 0.1463\n",
      "\n",
      "Batch 240/387 ━━━━━━━━━━━━━━━━━━━━ 17:38:28\n",
      "Accuracy: 0.9976 - Precision: 0.8787 - Recall: 0.8818 - Specificity: 0.9989 - F1: 0.8701 - Loss: 0.1462\n",
      "\n",
      "Batch 241/387 ━━━━━━━━━━━━━━━━━━━━ 17:39:54\n",
      "Accuracy: 0.9976 - Precision: 0.8787 - Recall: 0.8818 - Specificity: 0.9989 - F1: 0.8701 - Loss: 0.1461\n",
      "\n",
      "Batch 242/387 ━━━━━━━━━━━━━━━━━━━━ 17:41:25\n",
      "Accuracy: 0.9976 - Precision: 0.8790 - Recall: 0.8820 - Specificity: 0.9989 - F1: 0.8704 - Loss: 0.1458\n",
      "\n",
      "Batch 243/387 ━━━━━━━━━━━━━━━━━━━━ 17:42:46\n",
      "Accuracy: 0.9976 - Precision: 0.8792 - Recall: 0.8823 - Specificity: 0.9990 - F1: 0.8707 - Loss: 0.1455\n",
      "\n",
      "Batch 244/387 ━━━━━━━━━━━━━━━━━━━━ 17:44:10\n",
      "Accuracy: 0.9976 - Precision: 0.8795 - Recall: 0.8822 - Specificity: 0.9990 - F1: 0.8708 - Loss: 0.1454\n",
      "\n",
      "Batch 245/387 ━━━━━━━━━━━━━━━━━━━━ 17:45:29\n",
      "Accuracy: 0.9976 - Precision: 0.8800 - Recall: 0.8823 - Specificity: 0.9990 - F1: 0.8711 - Loss: 0.1450\n",
      "\n",
      "Batch 246/387 ━━━━━━━━━━━━━━━━━━━━ 17:46:52\n",
      "Accuracy: 0.9976 - Precision: 0.8800 - Recall: 0.8817 - Specificity: 0.9990 - F1: 0.8709 - Loss: 0.1453\n",
      "\n",
      "Batch 247/387 ━━━━━━━━━━━━━━━━━━━━ 17:48:25\n",
      "Accuracy: 0.9976 - Precision: 0.8802 - Recall: 0.8815 - Specificity: 0.9990 - F1: 0.8709 - Loss: 0.1452\n",
      "\n",
      "Batch 248/387 ━━━━━━━━━━━━━━━━━━━━ 17:49:48\n",
      "Accuracy: 0.9976 - Precision: 0.8807 - Recall: 0.8806 - Specificity: 0.9990 - F1: 0.8706 - Loss: 0.1456\n",
      "\n",
      "Batch 249/387 ━━━━━━━━━━━━━━━━━━━━ 17:51:17\n",
      "Accuracy: 0.9976 - Precision: 0.8809 - Recall: 0.8797 - Specificity: 0.9990 - F1: 0.8702 - Loss: 0.1459\n",
      "\n",
      "Batch 250/387 ━━━━━━━━━━━━━━━━━━━━ 17:52:29\n",
      "Accuracy: 0.9976 - Precision: 0.8812 - Recall: 0.8798 - Specificity: 0.9990 - F1: 0.8705 - Loss: 0.1457\n",
      "\n",
      "Batch 251/387 ━━━━━━━━━━━━━━━━━━━━ 17:54:02\n",
      "Accuracy: 0.9976 - Precision: 0.8802 - Recall: 0.8802 - Specificity: 0.9990 - F1: 0.8700 - Loss: 0.1461\n",
      "\n",
      "Batch 252/387 ━━━━━━━━━━━━━━━━━━━━ 17:55:32\n",
      "Accuracy: 0.9976 - Precision: 0.8805 - Recall: 0.8803 - Specificity: 0.9990 - F1: 0.8703 - Loss: 0.1458\n",
      "\n",
      "Batch 253/387 ━━━━━━━━━━━━━━━━━━━━ 17:56:55\n",
      "Accuracy: 0.9976 - Precision: 0.8801 - Recall: 0.8807 - Specificity: 0.9990 - F1: 0.8702 - Loss: 0.1459\n",
      "\n",
      "Batch 254/387 ━━━━━━━━━━━━━━━━━━━━ 17:58:21\n",
      "Accuracy: 0.9976 - Precision: 0.8802 - Recall: 0.8796 - Specificity: 0.9990 - F1: 0.8697 - Loss: 0.1464\n",
      "\n",
      "Batch 255/387 ━━━━━━━━━━━━━━━━━━━━ 17:59:55\n",
      "Accuracy: 0.9976 - Precision: 0.8803 - Recall: 0.8798 - Specificity: 0.9990 - F1: 0.8699 - Loss: 0.1463\n",
      "\n",
      "Batch 256/387 ━━━━━━━━━━━━━━━━━━━━ 18:01:30\n",
      "Accuracy: 0.9976 - Precision: 0.8807 - Recall: 0.8797 - Specificity: 0.9990 - F1: 0.8700 - Loss: 0.1462\n",
      "\n",
      "Batch 257/387 ━━━━━━━━━━━━━━━━━━━━ 18:02:57\n",
      "Accuracy: 0.9976 - Precision: 0.8809 - Recall: 0.8796 - Specificity: 0.9990 - F1: 0.8701 - Loss: 0.1460\n",
      "\n",
      "Batch 258/387 ━━━━━━━━━━━━━━━━━━━━ 18:04:14\n",
      "Accuracy: 0.9976 - Precision: 0.8807 - Recall: 0.8793 - Specificity: 0.9990 - F1: 0.8699 - Loss: 0.1462\n",
      "\n",
      "Batch 259/387 ━━━━━━━━━━━━━━━━━━━━ 18:05:31\n",
      "Accuracy: 0.9976 - Precision: 0.8800 - Recall: 0.8797 - Specificity: 0.9990 - F1: 0.8697 - Loss: 0.1464\n",
      "\n",
      "Batch 260/387 ━━━━━━━━━━━━━━━━━━━━ 18:07:03\n",
      "Accuracy: 0.9976 - Precision: 0.8798 - Recall: 0.8795 - Specificity: 0.9990 - F1: 0.8695 - Loss: 0.1466\n",
      "\n",
      "Batch 261/387 ━━━━━━━━━━━━━━━━━━━━ 18:08:31\n",
      "Accuracy: 0.9976 - Precision: 0.8790 - Recall: 0.8797 - Specificity: 0.9990 - F1: 0.8692 - Loss: 0.1470\n",
      "\n",
      "Batch 262/387 ━━━━━━━━━━━━━━━━━━━━ 18:09:56\n",
      "Accuracy: 0.9976 - Precision: 0.8791 - Recall: 0.8797 - Specificity: 0.9990 - F1: 0.8693 - Loss: 0.1470\n",
      "\n",
      "Batch 263/387 ━━━━━━━━━━━━━━━━━━━━ 18:11:26\n",
      "Accuracy: 0.9976 - Precision: 0.8789 - Recall: 0.8799 - Specificity: 0.9989 - F1: 0.8693 - Loss: 0.1469\n",
      "\n",
      "Batch 264/387 ━━━━━━━━━━━━━━━━━━━━ 18:12:46\n",
      "Accuracy: 0.9976 - Precision: 0.8782 - Recall: 0.8796 - Specificity: 0.9989 - F1: 0.8688 - Loss: 0.1474\n",
      "\n",
      "Batch 265/387 ━━━━━━━━━━━━━━━━━━━━ 18:14:13\n",
      "Accuracy: 0.9976 - Precision: 0.8785 - Recall: 0.8799 - Specificity: 0.9989 - F1: 0.8692 - Loss: 0.1470\n",
      "\n",
      "Batch 266/387 ━━━━━━━━━━━━━━━━━━━━ 18:15:36\n",
      "Accuracy: 0.9976 - Precision: 0.8785 - Recall: 0.8799 - Specificity: 0.9989 - F1: 0.8692 - Loss: 0.1470\n",
      "\n",
      "Batch 267/387 ━━━━━━━━━━━━━━━━━━━━ 18:16:58\n",
      "Accuracy: 0.9976 - Precision: 0.8785 - Recall: 0.8801 - Specificity: 0.9989 - F1: 0.8693 - Loss: 0.1469\n",
      "\n",
      "Batch 268/387 ━━━━━━━━━━━━━━━━━━━━ 18:18:11\n",
      "Accuracy: 0.9976 - Precision: 0.8788 - Recall: 0.8799 - Specificity: 0.9989 - F1: 0.8694 - Loss: 0.1469\n",
      "\n",
      "Batch 269/387 ━━━━━━━━━━━━━━━━━━━━ 18:19:49\n",
      "Accuracy: 0.9975 - Precision: 0.8791 - Recall: 0.8799 - Specificity: 0.9989 - F1: 0.8696 - Loss: 0.1467\n",
      "\n",
      "Batch 270/387 ━━━━━━━━━━━━━━━━━━━━ 18:21:12\n",
      "Accuracy: 0.9975 - Precision: 0.8774 - Recall: 0.8800 - Specificity: 0.9989 - F1: 0.8685 - Loss: 0.1479\n",
      "\n",
      "Batch 271/387 ━━━━━━━━━━━━━━━━━━━━ 18:22:33\n",
      "Accuracy: 0.9975 - Precision: 0.8774 - Recall: 0.8801 - Specificity: 0.9989 - F1: 0.8686 - Loss: 0.1478\n",
      "\n",
      "Batch 272/387 ━━━━━━━━━━━━━━━━━━━━ 18:23:57\n",
      "Accuracy: 0.9975 - Precision: 0.8777 - Recall: 0.8803 - Specificity: 0.9989 - F1: 0.8688 - Loss: 0.1475\n",
      "\n",
      "Batch 273/387 ━━━━━━━━━━━━━━━━━━━━ 18:25:25\n",
      "Accuracy: 0.9975 - Precision: 0.8775 - Recall: 0.8805 - Specificity: 0.9989 - F1: 0.8689 - Loss: 0.1474\n",
      "\n",
      "Batch 274/387 ━━━━━━━━━━━━━━━━━━━━ 18:26:58\n",
      "Accuracy: 0.9976 - Precision: 0.8776 - Recall: 0.8807 - Specificity: 0.9989 - F1: 0.8690 - Loss: 0.1473\n",
      "\n",
      "Batch 275/387 ━━━━━━━━━━━━━━━━━━━━ 18:28:21\n",
      "Accuracy: 0.9976 - Precision: 0.8779 - Recall: 0.8808 - Specificity: 0.9989 - F1: 0.8693 - Loss: 0.1469\n",
      "\n",
      "Batch 276/387 ━━━━━━━━━━━━━━━━━━━━ 18:29:47\n",
      "Accuracy: 0.9976 - Precision: 0.8780 - Recall: 0.8804 - Specificity: 0.9989 - F1: 0.8692 - Loss: 0.1471\n",
      "\n",
      "Batch 277/387 ━━━━━━━━━━━━━━━━━━━━ 18:31:17\n",
      "Accuracy: 0.9976 - Precision: 0.8784 - Recall: 0.8799 - Specificity: 0.9989 - F1: 0.8691 - Loss: 0.1472\n",
      "\n",
      "Batch 278/387 ━━━━━━━━━━━━━━━━━━━━ 18:32:38\n",
      "Accuracy: 0.9975 - Precision: 0.8788 - Recall: 0.8799 - Specificity: 0.9989 - F1: 0.8693 - Loss: 0.1470\n",
      "\n",
      "Batch 279/387 ━━━━━━━━━━━━━━━━━━━━ 18:33:59\n",
      "Accuracy: 0.9975 - Precision: 0.8790 - Recall: 0.8796 - Specificity: 0.9989 - F1: 0.8692 - Loss: 0.1471\n",
      "\n",
      "Batch 280/387 ━━━━━━━━━━━━━━━━━━━━ 18:35:26\n",
      "Accuracy: 0.9975 - Precision: 0.8793 - Recall: 0.8797 - Specificity: 0.9989 - F1: 0.8695 - Loss: 0.1468\n",
      "\n",
      "Batch 281/387 ━━━━━━━━━━━━━━━━━━━━ 18:36:45\n",
      "Accuracy: 0.9975 - Precision: 0.8789 - Recall: 0.8800 - Specificity: 0.9989 - F1: 0.8695 - Loss: 0.1469\n",
      "\n",
      "Batch 282/387 ━━━━━━━━━━━━━━━━━━━━ 18:38:13\n",
      "Accuracy: 0.9975 - Precision: 0.8793 - Recall: 0.8796 - Specificity: 0.9989 - F1: 0.8694 - Loss: 0.1469\n",
      "\n",
      "Batch 283/387 ━━━━━━━━━━━━━━━━━━━━ 18:39:40\n",
      "Accuracy: 0.9975 - Precision: 0.8792 - Recall: 0.8799 - Specificity: 0.9989 - F1: 0.8695 - Loss: 0.1468\n",
      "\n",
      "Batch 284/387 ━━━━━━━━━━━━━━━━━━━━ 18:41:06\n",
      "Accuracy: 0.9975 - Precision: 0.8796 - Recall: 0.8799 - Specificity: 0.9989 - F1: 0.8698 - Loss: 0.1466\n",
      "\n",
      "Batch 285/387 ━━━━━━━━━━━━━━━━━━━━ 18:42:37\n",
      "Accuracy: 0.9975 - Precision: 0.8795 - Recall: 0.8799 - Specificity: 0.9989 - F1: 0.8698 - Loss: 0.1466\n",
      "\n",
      "Batch 286/387 ━━━━━━━━━━━━━━━━━━━━ 18:44:00\n",
      "Accuracy: 0.9975 - Precision: 0.8798 - Recall: 0.8799 - Specificity: 0.9989 - F1: 0.8699 - Loss: 0.1464\n",
      "\n",
      "Batch 287/387 ━━━━━━━━━━━━━━━━━━━━ 18:45:23\n",
      "Accuracy: 0.9975 - Precision: 0.8800 - Recall: 0.8800 - Specificity: 0.9989 - F1: 0.8701 - Loss: 0.1463\n",
      "\n",
      "Batch 288/387 ━━━━━━━━━━━━━━━━━━━━ 18:46:59\n",
      "Accuracy: 0.9975 - Precision: 0.8800 - Recall: 0.8802 - Specificity: 0.9989 - F1: 0.8702 - Loss: 0.1461\n",
      "\n",
      "Batch 289/387 ━━━━━━━━━━━━━━━━━━━━ 18:48:35\n",
      "Accuracy: 0.9975 - Precision: 0.8790 - Recall: 0.8805 - Specificity: 0.9989 - F1: 0.8697 - Loss: 0.1467\n",
      "\n",
      "Batch 290/387 ━━━━━━━━━━━━━━━━━━━━ 18:50:01\n",
      "Accuracy: 0.9975 - Precision: 0.8784 - Recall: 0.8801 - Specificity: 0.9989 - F1: 0.8693 - Loss: 0.1472\n",
      "\n",
      "Batch 291/387 ━━━━━━━━━━━━━━━━━━━━ 18:51:33\n",
      "Accuracy: 0.9975 - Precision: 0.8788 - Recall: 0.8796 - Specificity: 0.9989 - F1: 0.8693 - Loss: 0.1473\n",
      "\n",
      "Batch 292/387 ━━━━━━━━━━━━━━━━━━━━ 18:53:23\n",
      "Accuracy: 0.9975 - Precision: 0.8790 - Recall: 0.8798 - Specificity: 0.9989 - F1: 0.8695 - Loss: 0.1470\n",
      "\n",
      "Batch 293/387 ━━━━━━━━━━━━━━━━━━━━ 18:54:55\n",
      "Accuracy: 0.9975 - Precision: 0.8792 - Recall: 0.8800 - Specificity: 0.9989 - F1: 0.8697 - Loss: 0.1468\n",
      "\n",
      "Batch 294/387 ━━━━━━━━━━━━━━━━━━━━ 18:56:29\n",
      "Accuracy: 0.9975 - Precision: 0.8792 - Recall: 0.8803 - Specificity: 0.9989 - F1: 0.8699 - Loss: 0.1466\n",
      "\n",
      "Batch 295/387 ━━━━━━━━━━━━━━━━━━━━ 18:58:10\n",
      "Accuracy: 0.9975 - Precision: 0.8791 - Recall: 0.8805 - Specificity: 0.9989 - F1: 0.8700 - Loss: 0.1464\n",
      "\n",
      "Batch 296/387 ━━━━━━━━━━━━━━━━━━━━ 18:59:46\n",
      "Accuracy: 0.9975 - Precision: 0.8785 - Recall: 0.8807 - Specificity: 0.9989 - F1: 0.8697 - Loss: 0.1467\n",
      "\n",
      "Batch 297/387 ━━━━━━━━━━━━━━━━━━━━ 19:01:07\n",
      "Accuracy: 0.9975 - Precision: 0.8789 - Recall: 0.8806 - Specificity: 0.9989 - F1: 0.8699 - Loss: 0.1465\n",
      "\n",
      "Batch 298/387 ━━━━━━━━━━━━━━━━━━━━ 19:02:43\n",
      "Accuracy: 0.9975 - Precision: 0.8792 - Recall: 0.8806 - Specificity: 0.9989 - F1: 0.8701 - Loss: 0.1463\n",
      "\n",
      "Batch 299/387 ━━━━━━━━━━━━━━━━━━━━ 19:04:04\n",
      "Accuracy: 0.9975 - Precision: 0.8796 - Recall: 0.8804 - Specificity: 0.9989 - F1: 0.8702 - Loss: 0.1462\n",
      "\n",
      "Batch 300/387 ━━━━━━━━━━━━━━━━━━━━ 19:05:36\n",
      "Accuracy: 0.9975 - Precision: 0.8797 - Recall: 0.8806 - Specificity: 0.9989 - F1: 0.8703 - Loss: 0.1461\n",
      "\n",
      "Batch 301/387 ━━━━━━━━━━━━━━━━━━━━ 19:07:04\n",
      "Accuracy: 0.9975 - Precision: 0.8800 - Recall: 0.8794 - Specificity: 0.9989 - F1: 0.8697 - Loss: 0.1468\n",
      "\n",
      "Batch 302/387 ━━━━━━━━━━━━━━━━━━━━ 19:08:40\n",
      "Accuracy: 0.9975 - Precision: 0.8799 - Recall: 0.8796 - Specificity: 0.9990 - F1: 0.8698 - Loss: 0.1467\n",
      "\n",
      "Batch 303/387 ━━━━━━━━━━━━━━━━━━━━ 19:10:09\n",
      "Accuracy: 0.9975 - Precision: 0.8801 - Recall: 0.8778 - Specificity: 0.9990 - F1: 0.8686 - Loss: 0.1480\n",
      "\n",
      "Batch 304/387 ━━━━━━━━━━━━━━━━━━━━ 19:11:38\n",
      "Accuracy: 0.9975 - Precision: 0.8805 - Recall: 0.8771 - Specificity: 0.9990 - F1: 0.8684 - Loss: 0.1482\n",
      "\n",
      "Batch 305/387 ━━━━━━━━━━━━━━━━━━━━ 19:13:04\n",
      "Accuracy: 0.9975 - Precision: 0.8806 - Recall: 0.8759 - Specificity: 0.9990 - F1: 0.8676 - Loss: 0.1490\n",
      "\n",
      "Batch 306/387 ━━━━━━━━━━━━━━━━━━━━ 19:14:38\n",
      "Accuracy: 0.9975 - Precision: 0.8808 - Recall: 0.8744 - Specificity: 0.9990 - F1: 0.8667 - Loss: 0.1501\n",
      "\n",
      "Batch 307/387 ━━━━━━━━━━━━━━━━━━━━ 19:16:20\n",
      "Accuracy: 0.9975 - Precision: 0.8809 - Recall: 0.8746 - Specificity: 0.9990 - F1: 0.8669 - Loss: 0.1499\n",
      "\n",
      "Batch 308/387 ━━━━━━━━━━━━━━━━━━━━ 19:17:52\n",
      "Accuracy: 0.9975 - Precision: 0.8812 - Recall: 0.8745 - Specificity: 0.9990 - F1: 0.8670 - Loss: 0.1498\n",
      "\n",
      "Batch 309/387 ━━━━━━━━━━━━━━━━━━━━ 19:19:16\n",
      "Accuracy: 0.9975 - Precision: 0.8812 - Recall: 0.8748 - Specificity: 0.9990 - F1: 0.8672 - Loss: 0.1496\n",
      "\n",
      "Batch 310/387 ━━━━━━━━━━━━━━━━━━━━ 19:20:51\n",
      "Accuracy: 0.9975 - Precision: 0.8811 - Recall: 0.8752 - Specificity: 0.9990 - F1: 0.8674 - Loss: 0.1494\n",
      "\n",
      "Batch 311/387 ━━━━━━━━━━━━━━━━━━━━ 19:22:18\n",
      "Accuracy: 0.9975 - Precision: 0.8812 - Recall: 0.8756 - Specificity: 0.9989 - F1: 0.8676 - Loss: 0.1491\n",
      "\n",
      "Batch 312/387 ━━━━━━━━━━━━━━━━━━━━ 19:23:46\n",
      "Accuracy: 0.9975 - Precision: 0.8813 - Recall: 0.8756 - Specificity: 0.9989 - F1: 0.8677 - Loss: 0.1491\n",
      "\n",
      "Batch 313/387 ━━━━━━━━━━━━━━━━━━━━ 19:25:09\n",
      "Accuracy: 0.9975 - Precision: 0.8808 - Recall: 0.8759 - Specificity: 0.9989 - F1: 0.8676 - Loss: 0.1492\n",
      "\n",
      "Batch 314/387 ━━━━━━━━━━━━━━━━━━━━ 19:26:34\n",
      "Accuracy: 0.9975 - Precision: 0.8805 - Recall: 0.8763 - Specificity: 0.9989 - F1: 0.8676 - Loss: 0.1492\n",
      "\n",
      "Batch 315/387 ━━━━━━━━━━━━━━━━━━━━ 19:27:59\n",
      "Accuracy: 0.9975 - Precision: 0.8800 - Recall: 0.8766 - Specificity: 0.9989 - F1: 0.8675 - Loss: 0.1494\n",
      "\n",
      "Batch 316/387 ━━━━━━━━━━━━━━━━━━━━ 19:29:32\n",
      "Accuracy: 0.9975 - Precision: 0.8795 - Recall: 0.8769 - Specificity: 0.9989 - F1: 0.8674 - Loss: 0.1495\n",
      "\n",
      "Batch 317/387 ━━━━━━━━━━━━━━━━━━━━ 19:31:03\n",
      "Accuracy: 0.9975 - Precision: 0.8796 - Recall: 0.8770 - Specificity: 0.9989 - F1: 0.8675 - Loss: 0.1494\n",
      "\n",
      "Batch 318/387 ━━━━━━━━━━━━━━━━━━━━ 19:32:33\n",
      "Accuracy: 0.9975 - Precision: 0.8798 - Recall: 0.8773 - Specificity: 0.9989 - F1: 0.8678 - Loss: 0.1491\n",
      "\n",
      "Batch 319/387 ━━━━━━━━━━━━━━━━━━━━ 19:34:01\n",
      "Accuracy: 0.9975 - Precision: 0.8786 - Recall: 0.8775 - Specificity: 0.9989 - F1: 0.8671 - Loss: 0.1498\n",
      "\n",
      "Batch 320/387 ━━━━━━━━━━━━━━━━━━━━ 19:35:30\n",
      "Accuracy: 0.9975 - Precision: 0.8782 - Recall: 0.8777 - Specificity: 0.9989 - F1: 0.8670 - Loss: 0.1499\n",
      "\n",
      "Batch 321/387 ━━━━━━━━━━━━━━━━━━━━ 19:36:46\n",
      "Accuracy: 0.9975 - Precision: 0.8785 - Recall: 0.8779 - Specificity: 0.9989 - F1: 0.8673 - Loss: 0.1496\n",
      "\n",
      "Batch 322/387 ━━━━━━━━━━━━━━━━━━━━ 19:38:20\n",
      "Accuracy: 0.9975 - Precision: 0.8786 - Recall: 0.8781 - Specificity: 0.9989 - F1: 0.8674 - Loss: 0.1494\n",
      "\n",
      "Batch 323/387 ━━━━━━━━━━━━━━━━━━━━ 19:39:42\n",
      "Accuracy: 0.9975 - Precision: 0.8785 - Recall: 0.8784 - Specificity: 0.9989 - F1: 0.8676 - Loss: 0.1492\n",
      "\n",
      "Batch 324/387 ━━━━━━━━━━━━━━━━━━━━ 19:41:13\n",
      "Accuracy: 0.9975 - Precision: 0.8780 - Recall: 0.8781 - Specificity: 0.9989 - F1: 0.8672 - Loss: 0.1496\n",
      "\n",
      "Batch 325/387 ━━━━━━━━━━━━━━━━━━━━ 19:42:36\n",
      "Accuracy: 0.9975 - Precision: 0.8784 - Recall: 0.8782 - Specificity: 0.9989 - F1: 0.8675 - Loss: 0.1493\n",
      "\n",
      "Batch 326/387 ━━━━━━━━━━━━━━━━━━━━ 19:44:12\n",
      "Accuracy: 0.9975 - Precision: 0.8779 - Recall: 0.8780 - Specificity: 0.9989 - F1: 0.8672 - Loss: 0.1496\n",
      "\n",
      "Batch 327/387 ━━━━━━━━━━━━━━━━━━━━ 19:45:38\n",
      "Accuracy: 0.9975 - Precision: 0.8781 - Recall: 0.8778 - Specificity: 0.9989 - F1: 0.8672 - Loss: 0.1496\n",
      "\n",
      "Batch 328/387 ━━━━━━━━━━━━━━━━━━━━ 19:47:03\n",
      "Accuracy: 0.9975 - Precision: 0.8784 - Recall: 0.8776 - Specificity: 0.9989 - F1: 0.8672 - Loss: 0.1496\n",
      "\n",
      "Batch 329/387 ━━━━━━━━━━━━━━━━━━━━ 19:48:24\n",
      "Accuracy: 0.9975 - Precision: 0.8786 - Recall: 0.8775 - Specificity: 0.9989 - F1: 0.8673 - Loss: 0.1495\n",
      "\n",
      "Batch 330/387 ━━━━━━━━━━━━━━━━━━━━ 19:49:46\n",
      "Accuracy: 0.9975 - Precision: 0.8788 - Recall: 0.8763 - Specificity: 0.9989 - F1: 0.8666 - Loss: 0.1502\n",
      "\n",
      "Batch 331/387 ━━━━━━━━━━━━━━━━━━━━ 19:51:47\n",
      "Accuracy: 0.9975 - Precision: 0.8783 - Recall: 0.8753 - Specificity: 0.9989 - F1: 0.8659 - Loss: 0.1510\n",
      "\n",
      "Batch 332/387 ━━━━━━━━━━━━━━━━━━━━ 19:53:10\n",
      "Accuracy: 0.9975 - Precision: 0.8787 - Recall: 0.8752 - Specificity: 0.9989 - F1: 0.8660 - Loss: 0.1509\n",
      "\n",
      "Batch 333/387 ━━━━━━━━━━━━━━━━━━━━ 19:54:34\n",
      "Accuracy: 0.9975 - Precision: 0.8790 - Recall: 0.8750 - Specificity: 0.9989 - F1: 0.8660 - Loss: 0.1509\n",
      "\n",
      "Batch 334/387 ━━━━━━━━━━━━━━━━━━━━ 19:56:00\n",
      "Accuracy: 0.9975 - Precision: 0.8793 - Recall: 0.8748 - Specificity: 0.9989 - F1: 0.8661 - Loss: 0.1508\n",
      "\n",
      "Batch 335/387 ━━━━━━━━━━━━━━━━━━━━ 19:57:24\n",
      "Accuracy: 0.9975 - Precision: 0.8793 - Recall: 0.8748 - Specificity: 0.9989 - F1: 0.8662 - Loss: 0.1507\n",
      "\n",
      "Batch 336/387 ━━━━━━━━━━━━━━━━━━━━ 19:58:45\n",
      "Accuracy: 0.9975 - Precision: 0.8792 - Recall: 0.8750 - Specificity: 0.9989 - F1: 0.8662 - Loss: 0.1506\n",
      "\n",
      "Batch 337/387 ━━━━━━━━━━━━━━━━━━━━ 20:00:05\n",
      "Accuracy: 0.9975 - Precision: 0.8787 - Recall: 0.8748 - Specificity: 0.9989 - F1: 0.8659 - Loss: 0.1510\n",
      "\n",
      "Batch 338/387 ━━━━━━━━━━━━━━━━━━━━ 20:01:48\n",
      "Accuracy: 0.9975 - Precision: 0.8790 - Recall: 0.8748 - Specificity: 0.9989 - F1: 0.8661 - Loss: 0.1508\n",
      "\n",
      "Batch 339/387 ━━━━━━━━━━━━━━━━━━━━ 20:03:31\n",
      "Accuracy: 0.9975 - Precision: 0.8792 - Recall: 0.8750 - Specificity: 0.9989 - F1: 0.8663 - Loss: 0.1505\n",
      "\n",
      "Batch 340/387 ━━━━━━━━━━━━━━━━━━━━ 20:04:59\n",
      "Accuracy: 0.9975 - Precision: 0.8795 - Recall: 0.8749 - Specificity: 0.9989 - F1: 0.8664 - Loss: 0.1505\n",
      "\n",
      "Batch 341/387 ━━━━━━━━━━━━━━━━━━━━ 20:06:29\n",
      "Accuracy: 0.9975 - Precision: 0.8787 - Recall: 0.8752 - Specificity: 0.9989 - F1: 0.8661 - Loss: 0.1508\n",
      "\n",
      "Batch 342/387 ━━━━━━━━━━━━━━━━━━━━ 20:07:56\n",
      "Accuracy: 0.9975 - Precision: 0.8789 - Recall: 0.8754 - Specificity: 0.9989 - F1: 0.8663 - Loss: 0.1505\n",
      "\n",
      "Batch 343/387 ━━━━━━━━━━━━━━━━━━━━ 20:09:31\n",
      "Accuracy: 0.9975 - Precision: 0.8791 - Recall: 0.8747 - Specificity: 0.9989 - F1: 0.8660 - Loss: 0.1509\n",
      "\n",
      "Batch 344/387 ━━━━━━━━━━━━━━━━━━━━ 20:10:46\n",
      "Accuracy: 0.9975 - Precision: 0.8793 - Recall: 0.8749 - Specificity: 0.9989 - F1: 0.8663 - Loss: 0.1506\n",
      "\n",
      "Batch 345/387 ━━━━━━━━━━━━━━━━━━━━ 20:12:19\n",
      "Accuracy: 0.9975 - Precision: 0.8788 - Recall: 0.8752 - Specificity: 0.9989 - F1: 0.8662 - Loss: 0.1507\n",
      "\n",
      "Batch 346/387 ━━━━━━━━━━━━━━━━━━━━ 20:13:53\n",
      "Accuracy: 0.9975 - Precision: 0.8790 - Recall: 0.8753 - Specificity: 0.9989 - F1: 0.8663 - Loss: 0.1505\n",
      "\n",
      "Batch 347/387 ━━━━━━━━━━━━━━━━━━━━ 20:15:13\n",
      "Accuracy: 0.9975 - Precision: 0.8784 - Recall: 0.8757 - Specificity: 0.9989 - F1: 0.8661 - Loss: 0.1507\n",
      "\n",
      "Batch 348/387 ━━━━━━━━━━━━━━━━━━━━ 20:16:37\n",
      "Accuracy: 0.9975 - Precision: 0.8786 - Recall: 0.8759 - Specificity: 0.9989 - F1: 0.8664 - Loss: 0.1505\n",
      "\n",
      "Batch 349/387 ━━━━━━━━━━━━━━━━━━━━ 20:18:10\n",
      "Accuracy: 0.9975 - Precision: 0.8788 - Recall: 0.8759 - Specificity: 0.9989 - F1: 0.8665 - Loss: 0.1503\n",
      "\n",
      "Batch 350/387 ━━━━━━━━━━━━━━━━━━━━ 20:19:45\n",
      "Accuracy: 0.9975 - Precision: 0.8791 - Recall: 0.8760 - Specificity: 0.9989 - F1: 0.8667 - Loss: 0.1501\n",
      "\n",
      "Batch 351/387 ━━━━━━━━━━━━━━━━━━━━ 20:21:13\n",
      "Accuracy: 0.9975 - Precision: 0.8790 - Recall: 0.8762 - Specificity: 0.9989 - F1: 0.8668 - Loss: 0.1499\n",
      "\n",
      "Batch 352/387 ━━━━━━━━━━━━━━━━━━━━ 20:22:56\n",
      "Accuracy: 0.9975 - Precision: 0.8793 - Recall: 0.8759 - Specificity: 0.9989 - F1: 0.8668 - Loss: 0.1500\n",
      "\n",
      "Batch 353/387 ━━━━━━━━━━━━━━━━━━━━ 20:24:35\n",
      "Accuracy: 0.9975 - Precision: 0.8796 - Recall: 0.8753 - Specificity: 0.9989 - F1: 0.8666 - Loss: 0.1502\n",
      "\n",
      "Batch 354/387 ━━━━━━━━━━━━━━━━━━━━ 20:26:17\n",
      "Accuracy: 0.9975 - Precision: 0.8777 - Recall: 0.8755 - Specificity: 0.9989 - F1: 0.8652 - Loss: 0.1517\n",
      "\n",
      "Batch 355/387 ━━━━━━━━━━━━━━━━━━━━ 20:27:50\n",
      "Accuracy: 0.9975 - Precision: 0.8776 - Recall: 0.8756 - Specificity: 0.9989 - F1: 0.8652 - Loss: 0.1517\n",
      "\n",
      "Batch 356/387 ━━━━━━━━━━━━━━━━━━━━ 20:29:23\n",
      "Accuracy: 0.9975 - Precision: 0.8773 - Recall: 0.8754 - Specificity: 0.9989 - F1: 0.8649 - Loss: 0.1519\n",
      "\n",
      "Batch 357/387 ━━━━━━━━━━━━━━━━━━━━ 20:30:46\n",
      "Accuracy: 0.9975 - Precision: 0.8774 - Recall: 0.8756 - Specificity: 0.9989 - F1: 0.8651 - Loss: 0.1517\n",
      "\n",
      "Batch 358/387 ━━━━━━━━━━━━━━━━━━━━ 20:32:16\n",
      "Accuracy: 0.9975 - Precision: 0.8775 - Recall: 0.8750 - Specificity: 0.9989 - F1: 0.8649 - Loss: 0.1520\n",
      "\n",
      "Batch 359/387 ━━━━━━━━━━━━━━━━━━━━ 20:34:03\n",
      "Accuracy: 0.9975 - Precision: 0.8772 - Recall: 0.8753 - Specificity: 0.9989 - F1: 0.8649 - Loss: 0.1519\n",
      "\n",
      "Batch 360/387 ━━━━━━━━━━━━━━━━━━━━ 20:35:30\n",
      "Accuracy: 0.9975 - Precision: 0.8775 - Recall: 0.8744 - Specificity: 0.9989 - F1: 0.8645 - Loss: 0.1525\n",
      "\n",
      "Batch 361/387 ━━━━━━━━━━━━━━━━━━━━ 20:37:04\n",
      "Accuracy: 0.9975 - Precision: 0.8778 - Recall: 0.8744 - Specificity: 0.9989 - F1: 0.8646 - Loss: 0.1523\n",
      "\n",
      "Batch 362/387 ━━━━━━━━━━━━━━━━━━━━ 20:38:28\n",
      "Accuracy: 0.9975 - Precision: 0.8781 - Recall: 0.8743 - Specificity: 0.9989 - F1: 0.8647 - Loss: 0.1522\n",
      "\n",
      "Batch 363/387 ━━━━━━━━━━━━━━━━━━━━ 20:39:52\n",
      "Accuracy: 0.9975 - Precision: 0.8778 - Recall: 0.8746 - Specificity: 0.9989 - F1: 0.8647 - Loss: 0.1522\n",
      "\n",
      "Batch 364/387 ━━━━━━━━━━━━━━━━━━━━ 20:41:20\n",
      "Accuracy: 0.9975 - Precision: 0.8781 - Recall: 0.8746 - Specificity: 0.9989 - F1: 0.8649 - Loss: 0.1520\n",
      "\n",
      "Batch 365/387 ━━━━━━━━━━━━━━━━━━━━ 20:42:48\n",
      "Accuracy: 0.9975 - Precision: 0.8783 - Recall: 0.8749 - Specificity: 0.9989 - F1: 0.8652 - Loss: 0.1517\n",
      "\n",
      "Batch 366/387 ━━━━━━━━━━━━━━━━━━━━ 20:44:15\n",
      "Accuracy: 0.9975 - Precision: 0.8784 - Recall: 0.8751 - Specificity: 0.9989 - F1: 0.8654 - Loss: 0.1515\n",
      "\n",
      "Batch 367/387 ━━━━━━━━━━━━━━━━━━━━ 20:45:40\n",
      "Accuracy: 0.9975 - Precision: 0.8770 - Recall: 0.8754 - Specificity: 0.9989 - F1: 0.8644 - Loss: 0.1525\n",
      "\n",
      "Batch 368/387 ━━━━━━━━━━━━━━━━━━━━ 20:47:05\n",
      "Accuracy: 0.9975 - Precision: 0.8770 - Recall: 0.8747 - Specificity: 0.9989 - F1: 0.8641 - Loss: 0.1529\n",
      "\n",
      "Batch 369/387 ━━━━━━━━━━━━━━━━━━━━ 20:48:34\n",
      "Accuracy: 0.9975 - Precision: 0.8773 - Recall: 0.8748 - Specificity: 0.9989 - F1: 0.8643 - Loss: 0.1527\n",
      "\n",
      "Batch 370/387 ━━━━━━━━━━━━━━━━━━━━ 20:50:11\n",
      "Accuracy: 0.9975 - Precision: 0.8775 - Recall: 0.8751 - Specificity: 0.9989 - F1: 0.8645 - Loss: 0.1524\n",
      "\n",
      "Batch 371/387 ━━━━━━━━━━━━━━━━━━━━ 20:51:37\n",
      "Accuracy: 0.9975 - Precision: 0.8772 - Recall: 0.8751 - Specificity: 0.9989 - F1: 0.8644 - Loss: 0.1525\n",
      "\n",
      "Batch 372/387 ━━━━━━━━━━━━━━━━━━━━ 20:52:52\n",
      "Accuracy: 0.9975 - Precision: 0.8774 - Recall: 0.8753 - Specificity: 0.9989 - F1: 0.8647 - Loss: 0.1523\n",
      "\n",
      "Batch 373/387 ━━━━━━━━━━━━━━━━━━━━ 20:54:03\n",
      "Accuracy: 0.9975 - Precision: 0.8776 - Recall: 0.8751 - Specificity: 0.9989 - F1: 0.8647 - Loss: 0.1522\n",
      "\n",
      "Batch 374/387 ━━━━━━━━━━━━━━━━━━━━ 20:55:38\n",
      "Accuracy: 0.9975 - Precision: 0.8779 - Recall: 0.8752 - Specificity: 0.9989 - F1: 0.8649 - Loss: 0.1520\n",
      "\n",
      "Batch 375/387 ━━━━━━━━━━━━━━━━━━━━ 20:57:01\n",
      "Accuracy: 0.9975 - Precision: 0.8779 - Recall: 0.8752 - Specificity: 0.9989 - F1: 0.8650 - Loss: 0.1520\n",
      "\n",
      "Batch 376/387 ━━━━━━━━━━━━━━━━━━━━ 20:58:28\n",
      "Accuracy: 0.9975 - Precision: 0.8781 - Recall: 0.8751 - Specificity: 0.9989 - F1: 0.8650 - Loss: 0.1519\n",
      "\n",
      "Batch 377/387 ━━━━━━━━━━━━━━━━━━━━ 21:00:00\n",
      "Accuracy: 0.9975 - Precision: 0.8783 - Recall: 0.8752 - Specificity: 0.9989 - F1: 0.8652 - Loss: 0.1517\n",
      "\n",
      "Batch 378/387 ━━━━━━━━━━━━━━━━━━━━ 21:01:26\n",
      "Accuracy: 0.9975 - Precision: 0.8785 - Recall: 0.8753 - Specificity: 0.9989 - F1: 0.8654 - Loss: 0.1515\n",
      "\n",
      "Batch 379/387 ━━━━━━━━━━━━━━━━━━━━ 21:02:46\n",
      "Accuracy: 0.9975 - Precision: 0.8787 - Recall: 0.8755 - Specificity: 0.9989 - F1: 0.8656 - Loss: 0.1513\n",
      "\n",
      "Batch 380/387 ━━━━━━━━━━━━━━━━━━━━ 21:04:19\n",
      "Accuracy: 0.9975 - Precision: 0.8790 - Recall: 0.8755 - Specificity: 0.9989 - F1: 0.8658 - Loss: 0.1510\n",
      "\n",
      "Batch 381/387 ━━━━━━━━━━━━━━━━━━━━ 21:05:45\n",
      "Accuracy: 0.9975 - Precision: 0.8793 - Recall: 0.8752 - Specificity: 0.9989 - F1: 0.8657 - Loss: 0.1511\n",
      "\n",
      "Batch 382/387 ━━━━━━━━━━━━━━━━━━━━ 21:07:13\n",
      "Accuracy: 0.9975 - Precision: 0.8794 - Recall: 0.8747 - Specificity: 0.9989 - F1: 0.8655 - Loss: 0.1514\n",
      "\n",
      "Batch 383/387 ━━━━━━━━━━━━━━━━━━━━ 21:08:40\n",
      "Accuracy: 0.9975 - Precision: 0.8793 - Recall: 0.8750 - Specificity: 0.9989 - F1: 0.8656 - Loss: 0.1512\n",
      "\n",
      "Batch 384/387 ━━━━━━━━━━━━━━━━━━━━ 21:10:12\n",
      "Accuracy: 0.9975 - Precision: 0.8789 - Recall: 0.8750 - Specificity: 0.9989 - F1: 0.8655 - Loss: 0.1514\n",
      "\n",
      "Batch 385/387 ━━━━━━━━━━━━━━━━━━━━ 21:11:39\n",
      "Accuracy: 0.9975 - Precision: 0.8790 - Recall: 0.8752 - Specificity: 0.9989 - F1: 0.8657 - Loss: 0.1512\n",
      "\n",
      "Batch 386/387 ━━━━━━━━━━━━━━━━━━━━ 21:13:01\n",
      "Accuracy: 0.9975 - Precision: 0.8787 - Recall: 0.8754 - Specificity: 0.9989 - F1: 0.8656 - Loss: 0.1513\n",
      "\n",
      "Batch 387/387 ━━━━━━━━━━━━━━━━━━━━ 21:14:19\n",
      "Accuracy: 0.9975 - Precision: 0.8788 - Recall: 0.8757 - Specificity: 0.9989 - F1: 0.8658 - Loss: 0.1511\n",
      "\n",
      "End of Epoch 5\n",
      "\n",
      "Epoch 6/50\n",
      "Batch 1/387 ━━━━━━━━━━━━━━━━━━━━ 21:36:41\n",
      "Accuracy: 0.9961 - Precision: 0.9457 - Recall: 0.8681 - Specificity: 0.9989 - F1: 0.9052 - Loss: 0.1169\n",
      "\n",
      "Batch 2/387 ━━━━━━━━━━━━━━━━━━━━ 21:38:17\n",
      "Accuracy: 0.9974 - Precision: 0.9501 - Recall: 0.9255 - Specificity: 0.9990 - F1: 0.9369 - Loss: 0.0775\n",
      "\n",
      "Batch 3/387 ━━━━━━━━━━━━━━━━━━━━ 21:39:50\n",
      "Accuracy: 0.9964 - Precision: 0.9609 - Recall: 0.8796 - Specificity: 0.9992 - F1: 0.9161 - Loss: 0.1026\n",
      "\n",
      "Batch 4/387 ━━━━━━━━━━━━━━━━━━━━ 21:41:19\n",
      "Accuracy: 0.9971 - Precision: 0.9502 - Recall: 0.8984 - Specificity: 0.9993 - F1: 0.9211 - Loss: 0.0946\n",
      "\n",
      "Batch 5/387 ━━━━━━━━━━━━━━━━━━━━ 21:42:43\n",
      "Accuracy: 0.9974 - Precision: 0.9263 - Recall: 0.8839 - Specificity: 0.9993 - F1: 0.9025 - Loss: 0.1130\n",
      "\n",
      "Batch 6/387 ━━━━━━━━━━━━━━━━━━━━ 21:44:07\n",
      "Accuracy: 0.9973 - Precision: 0.9318 - Recall: 0.8923 - Specificity: 0.9992 - F1: 0.9098 - Loss: 0.1055\n",
      "\n",
      "Batch 7/387 ━━━━━━━━━━━━━━━━━━━━ 21:45:31\n",
      "Accuracy: 0.9974 - Precision: 0.9359 - Recall: 0.9003 - Specificity: 0.9992 - F1: 0.9162 - Loss: 0.0985\n",
      "\n",
      "Batch 8/387 ━━━━━━━━━━━━━━━━━━━━ 21:46:56\n",
      "Accuracy: 0.9975 - Precision: 0.9377 - Recall: 0.9057 - Specificity: 0.9992 - F1: 0.9201 - Loss: 0.0941\n",
      "\n",
      "Batch 9/387 ━━━━━━━━━━━━━━━━━━━━ 21:48:17\n",
      "Accuracy: 0.9975 - Precision: 0.9254 - Recall: 0.9106 - Specificity: 0.9991 - F1: 0.9161 - Loss: 0.0982\n",
      "\n",
      "Batch 10/387 ━━━━━━━━━━━━━━━━━━━━ 21:49:41\n",
      "Accuracy: 0.9975 - Precision: 0.8988 - Recall: 0.9101 - Specificity: 0.9990 - F1: 0.9008 - Loss: 0.1138\n",
      "\n",
      "Batch 11/387 ━━━━━━━━━━━━━━━━━━━━ 21:51:14\n",
      "Accuracy: 0.9977 - Precision: 0.8942 - Recall: 0.9169 - Specificity: 0.9990 - F1: 0.9017 - Loss: 0.1125\n",
      "\n",
      "Batch 12/387 ━━━━━━━━━━━━━━━━━━━━ 21:52:37\n",
      "Accuracy: 0.9978 - Precision: 0.8951 - Recall: 0.9038 - Specificity: 0.9991 - F1: 0.8954 - Loss: 0.1187\n",
      "\n",
      "Batch 13/387 ━━━━━━━━━━━━━━━━━━━━ 21:53:58\n",
      "Accuracy: 0.9978 - Precision: 0.8848 - Recall: 0.8893 - Specificity: 0.9991 - F1: 0.8833 - Loss: 0.1310\n",
      "\n",
      "Batch 14/387 ━━━━━━━━━━━━━━━━━━━━ 21:55:25\n",
      "Accuracy: 0.9978 - Precision: 0.8910 - Recall: 0.8909 - Specificity: 0.9991 - F1: 0.8874 - Loss: 0.1268\n",
      "\n",
      "Batch 15/387 ━━━━━━━━━━━━━━━━━━━━ 21:56:51\n",
      "Accuracy: 0.9974 - Precision: 0.8978 - Recall: 0.8763 - Specificity: 0.9992 - F1: 0.8817 - Loss: 0.1349\n",
      "\n",
      "Batch 16/387 ━━━━━━━━━━━━━━━━━━━━ 21:58:20\n",
      "Accuracy: 0.9975 - Precision: 0.9023 - Recall: 0.8798 - Specificity: 0.9992 - F1: 0.8860 - Loss: 0.1303\n",
      "\n",
      "Batch 17/387 ━━━━━━━━━━━━━━━━━━━━ 21:59:47\n",
      "Accuracy: 0.9973 - Precision: 0.9043 - Recall: 0.8745 - Specificity: 0.9991 - F1: 0.8843 - Loss: 0.1326\n",
      "\n",
      "Batch 18/387 ━━━━━━━━━━━━━━━━━━━━ 22:01:22\n",
      "Accuracy: 0.9974 - Precision: 0.9042 - Recall: 0.8791 - Specificity: 0.9991 - F1: 0.8868 - Loss: 0.1297\n",
      "\n",
      "Batch 19/387 ━━━━━━━━━━━━━━━━━━━━ 22:02:52\n",
      "Accuracy: 0.9972 - Precision: 0.9057 - Recall: 0.8798 - Specificity: 0.9991 - F1: 0.8881 - Loss: 0.1289\n",
      "\n",
      "Batch 20/387 ━━━━━━━━━━━━━━━━━━━━ 22:04:29\n",
      "Accuracy: 0.9973 - Precision: 0.9008 - Recall: 0.8844 - Specificity: 0.9990 - F1: 0.8878 - Loss: 0.1289\n",
      "\n",
      "Batch 21/387 ━━━━━━━━━━━━━━━━━━━━ 22:05:59\n",
      "Accuracy: 0.9974 - Precision: 0.9022 - Recall: 0.8890 - Specificity: 0.9990 - F1: 0.8910 - Loss: 0.1253\n",
      "\n",
      "Batch 22/387 ━━━━━━━━━━━━━━━━━━━━ 22:07:20\n",
      "Accuracy: 0.9975 - Precision: 0.8992 - Recall: 0.8919 - Specificity: 0.9991 - F1: 0.8910 - Loss: 0.1251\n",
      "\n",
      "Batch 23/387 ━━━━━━━━━━━━━━━━━━━━ 22:08:54\n",
      "Accuracy: 0.9975 - Precision: 0.8854 - Recall: 0.8928 - Specificity: 0.9991 - F1: 0.8831 - Loss: 0.1332\n",
      "\n",
      "Batch 24/387 ━━━━━━━━━━━━━━━━━━━━ 22:10:17\n",
      "Accuracy: 0.9974 - Precision: 0.8895 - Recall: 0.8791 - Specificity: 0.9991 - F1: 0.8762 - Loss: 0.1405\n",
      "\n",
      "Batch 25/387 ━━━━━━━━━━━━━━━━━━━━ 22:11:34\n",
      "Accuracy: 0.9975 - Precision: 0.8925 - Recall: 0.8704 - Specificity: 0.9991 - F1: 0.8725 - Loss: 0.1438\n",
      "\n",
      "Batch 26/387 ━━━━━━━━━━━━━━━━━━━━ 22:13:01\n",
      "Accuracy: 0.9976 - Precision: 0.8952 - Recall: 0.8701 - Specificity: 0.9992 - F1: 0.8740 - Loss: 0.1422\n",
      "\n",
      "Batch 27/387 ━━━━━━━━━━━━━━━━━━━━ 22:14:35\n",
      "Accuracy: 0.9975 - Precision: 0.8975 - Recall: 0.8667 - Specificity: 0.9992 - F1: 0.8734 - Loss: 0.1428\n",
      "\n",
      "Batch 28/387 ━━━━━━━━━━━━━━━━━━━━ 22:16:04\n",
      "Accuracy: 0.9976 - Precision: 0.8997 - Recall: 0.8693 - Specificity: 0.9992 - F1: 0.8761 - Loss: 0.1398\n",
      "\n",
      "Batch 29/387 ━━━━━━━━━━━━━━━━━━━━ 22:17:35\n",
      "Accuracy: 0.9976 - Precision: 0.8925 - Recall: 0.8733 - Specificity: 0.9991 - F1: 0.8739 - Loss: 0.1420\n",
      "\n",
      "Batch 30/387 ━━━━━━━━━━━━━━━━━━━━ 22:19:02\n",
      "Accuracy: 0.9977 - Precision: 0.8910 - Recall: 0.8759 - Specificity: 0.9992 - F1: 0.8746 - Loss: 0.1412\n",
      "\n",
      "Batch 31/387 ━━━━━━━━━━━━━━━━━━━━ 22:20:34\n",
      "Accuracy: 0.9977 - Precision: 0.8917 - Recall: 0.8788 - Specificity: 0.9992 - F1: 0.8767 - Loss: 0.1390\n",
      "\n",
      "Batch 32/387 ━━━━━━━━━━━━━━━━━━━━ 22:22:19\n",
      "Accuracy: 0.9976 - Precision: 0.8941 - Recall: 0.8732 - Specificity: 0.9992 - F1: 0.8747 - Loss: 0.1410\n",
      "\n",
      "Batch 33/387 ━━━━━━━━━━━━━━━━━━━━ 22:23:56\n",
      "Accuracy: 0.9976 - Precision: 0.8949 - Recall: 0.8741 - Specificity: 0.9992 - F1: 0.8759 - Loss: 0.1399\n",
      "\n",
      "Batch 34/387 ━━━━━━━━━━━━━━━━━━━━ 22:25:30\n",
      "Accuracy: 0.9976 - Precision: 0.8971 - Recall: 0.8729 - Specificity: 0.9992 - F1: 0.8765 - Loss: 0.1391\n",
      "\n",
      "Batch 35/387 ━━━━━━━━━━━━━━━━━━━━ 22:27:03\n",
      "Accuracy: 0.9976 - Precision: 0.8947 - Recall: 0.8755 - Specificity: 0.9991 - F1: 0.8766 - Loss: 0.1389\n",
      "\n",
      "Batch 36/387 ━━━━━━━━━━━━━━━━━━━━ 22:28:28\n",
      "Accuracy: 0.9977 - Precision: 0.8929 - Recall: 0.8774 - Specificity: 0.9991 - F1: 0.8768 - Loss: 0.1388\n",
      "\n",
      "Batch 37/387 ━━━━━━━━━━━━━━━━━━━━ 22:30:05\n",
      "Accuracy: 0.9977 - Precision: 0.8931 - Recall: 0.8799 - Specificity: 0.9991 - F1: 0.8783 - Loss: 0.1372\n",
      "\n",
      "Batch 38/387 ━━━━━━━━━━━━━━━━━━━━ 22:31:24\n",
      "Accuracy: 0.9976 - Precision: 0.8948 - Recall: 0.8797 - Specificity: 0.9991 - F1: 0.8792 - Loss: 0.1365\n",
      "\n",
      "Batch 39/387 ━━━━━━━━━━━━━━━━━━━━ 22:32:44\n",
      "Accuracy: 0.9977 - Precision: 0.8940 - Recall: 0.8820 - Specificity: 0.9991 - F1: 0.8801 - Loss: 0.1358\n",
      "\n",
      "Batch 40/387 ━━━━━━━━━━━━━━━━━━━━ 22:33:58\n",
      "Accuracy: 0.9977 - Precision: 0.8948 - Recall: 0.8837 - Specificity: 0.9991 - F1: 0.8815 - Loss: 0.1342\n",
      "\n",
      "Batch 41/387 ━━━━━━━━━━━━━━━━━━━━ 22:35:26\n",
      "Accuracy: 0.9977 - Precision: 0.8945 - Recall: 0.8836 - Specificity: 0.9991 - F1: 0.8816 - Loss: 0.1342\n",
      "\n",
      "Batch 42/387 ━━━━━━━━━━━━━━━━━━━━ 22:36:59\n",
      "Accuracy: 0.9977 - Precision: 0.8951 - Recall: 0.8833 - Specificity: 0.9991 - F1: 0.8819 - Loss: 0.1338\n",
      "\n",
      "Batch 43/387 ━━━━━━━━━━━━━━━━━━━━ 22:38:37\n",
      "Accuracy: 0.9977 - Precision: 0.8894 - Recall: 0.8856 - Specificity: 0.9991 - F1: 0.8795 - Loss: 0.1361\n",
      "\n",
      "Batch 44/387 ━━━━━━━━━━━━━━━━━━━━ 22:40:04\n",
      "Accuracy: 0.9977 - Precision: 0.8900 - Recall: 0.8877 - Specificity: 0.9991 - F1: 0.8811 - Loss: 0.1344\n",
      "\n",
      "Batch 45/387 ━━━━━━━━━━━━━━━━━━━━ 22:41:36\n",
      "Accuracy: 0.9977 - Precision: 0.8922 - Recall: 0.8881 - Specificity: 0.9991 - F1: 0.8825 - Loss: 0.1329\n",
      "\n",
      "Batch 46/387 ━━━━━━━━━━━━━━━━━━━━ 22:43:07\n",
      "Accuracy: 0.9978 - Precision: 0.8935 - Recall: 0.8894 - Specificity: 0.9991 - F1: 0.8840 - Loss: 0.1312\n",
      "\n",
      "Batch 47/387 ━━━━━━━━━━━━━━━━━━━━ 22:44:27\n",
      "Accuracy: 0.9976 - Precision: 0.8850 - Recall: 0.8804 - Specificity: 0.9990 - F1: 0.8753 - Loss: 0.1408\n",
      "\n",
      "Batch 48/387 ━━━━━━━━━━━━━━━━━━━━ 22:45:57\n",
      "Accuracy: 0.9976 - Precision: 0.8868 - Recall: 0.8814 - Specificity: 0.9990 - F1: 0.8769 - Loss: 0.1390\n",
      "\n",
      "Batch 49/387 ━━━━━━━━━━━━━━━━━━━━ 22:47:22\n",
      "Accuracy: 0.9976 - Precision: 0.8881 - Recall: 0.8769 - Specificity: 0.9991 - F1: 0.8749 - Loss: 0.1410\n",
      "\n",
      "Batch 50/387 ━━━━━━━━━━━━━━━━━━━━ 22:48:49\n",
      "Accuracy: 0.9976 - Precision: 0.8895 - Recall: 0.8763 - Specificity: 0.9991 - F1: 0.8754 - Loss: 0.1405\n",
      "\n",
      "Batch 51/387 ━━━━━━━━━━━━━━━━━━━━ 22:50:19\n",
      "Accuracy: 0.9976 - Precision: 0.8888 - Recall: 0.8773 - Specificity: 0.9991 - F1: 0.8756 - Loss: 0.1402\n",
      "\n",
      "Batch 52/387 ━━━━━━━━━━━━━━━━━━━━ 22:51:33\n",
      "Accuracy: 0.9976 - Precision: 0.8907 - Recall: 0.8767 - Specificity: 0.9991 - F1: 0.8764 - Loss: 0.1393\n",
      "\n",
      "Batch 53/387 ━━━━━━━━━━━━━━━━━━━━ 22:52:58\n",
      "Accuracy: 0.9977 - Precision: 0.8926 - Recall: 0.8777 - Specificity: 0.9991 - F1: 0.8779 - Loss: 0.1376\n",
      "\n",
      "Batch 54/387 ━━━━━━━━━━━━━━━━━━━━ 22:54:31\n",
      "Accuracy: 0.9977 - Precision: 0.8944 - Recall: 0.8777 - Specificity: 0.9991 - F1: 0.8789 - Loss: 0.1366\n",
      "\n",
      "Batch 55/387 ━━━━━━━━━━━━━━━━━━━━ 22:56:07\n",
      "Accuracy: 0.9977 - Precision: 0.8955 - Recall: 0.8769 - Specificity: 0.9991 - F1: 0.8791 - Loss: 0.1364\n",
      "\n",
      "Batch 56/387 ━━━━━━━━━━━━━━━━━━━━ 22:57:38\n",
      "Accuracy: 0.9977 - Precision: 0.8906 - Recall: 0.8789 - Specificity: 0.9991 - F1: 0.8770 - Loss: 0.1385\n",
      "\n",
      "Batch 57/387 ━━━━━━━━━━━━━━━━━━━━ 22:59:06\n",
      "Accuracy: 0.9977 - Precision: 0.8880 - Recall: 0.8794 - Specificity: 0.9991 - F1: 0.8760 - Loss: 0.1396\n",
      "\n",
      "Batch 58/387 ━━━━━━━━━━━━━━━━━━━━ 23:00:34\n",
      "Accuracy: 0.9977 - Precision: 0.8886 - Recall: 0.8804 - Specificity: 0.9991 - F1: 0.8769 - Loss: 0.1386\n",
      "\n",
      "Batch 59/387 ━━━━━━━━━━━━━━━━━━━━ 23:02:10\n",
      "Accuracy: 0.9977 - Precision: 0.8899 - Recall: 0.8816 - Specificity: 0.9991 - F1: 0.8783 - Loss: 0.1371\n",
      "\n",
      "Batch 60/387 ━━━━━━━━━━━━━━━━━━━━ 23:03:39\n",
      "Accuracy: 0.9977 - Precision: 0.8875 - Recall: 0.8832 - Specificity: 0.9991 - F1: 0.8777 - Loss: 0.1376\n",
      "\n",
      "Batch 61/387 ━━━━━━━━━━━━━━━━━━━━ 23:05:03\n",
      "Accuracy: 0.9977 - Precision: 0.8840 - Recall: 0.8794 - Specificity: 0.9991 - F1: 0.8742 - Loss: 0.1414\n",
      "\n",
      "Batch 62/387 ━━━━━━━━━━━━━━━━━━━━ 23:06:27\n",
      "Accuracy: 0.9977 - Precision: 0.8854 - Recall: 0.8794 - Specificity: 0.9991 - F1: 0.8750 - Loss: 0.1406\n",
      "\n",
      "Batch 63/387 ━━━━━━━━━━━━━━━━━━━━ 23:07:46\n",
      "Accuracy: 0.9977 - Precision: 0.8854 - Recall: 0.8771 - Specificity: 0.9991 - F1: 0.8739 - Loss: 0.1419\n",
      "\n",
      "Batch 64/387 ━━━━━━━━━━━━━━━━━━━━ 23:09:10\n",
      "Accuracy: 0.9977 - Precision: 0.8868 - Recall: 0.8781 - Specificity: 0.9991 - F1: 0.8752 - Loss: 0.1404\n",
      "\n",
      "Batch 65/387 ━━━━━━━━━━━━━━━━━━━━ 23:10:29\n",
      "Accuracy: 0.9977 - Precision: 0.8878 - Recall: 0.8764 - Specificity: 0.9991 - F1: 0.8748 - Loss: 0.1408\n",
      "\n",
      "Batch 66/387 ━━━━━━━━━━━━━━━━━━━━ 23:12:00\n",
      "Accuracy: 0.9977 - Precision: 0.8880 - Recall: 0.8764 - Specificity: 0.9991 - F1: 0.8750 - Loss: 0.1408\n",
      "\n",
      "Batch 67/387 ━━━━━━━━━━━━━━━━━━━━ 23:13:36\n",
      "Accuracy: 0.9976 - Precision: 0.8890 - Recall: 0.8754 - Specificity: 0.9991 - F1: 0.8750 - Loss: 0.1410\n",
      "\n",
      "Batch 68/387 ━━━━━━━━━━━━━━━━━━━━ 23:14:59\n",
      "Accuracy: 0.9976 - Precision: 0.8904 - Recall: 0.8757 - Specificity: 0.9991 - F1: 0.8759 - Loss: 0.1400\n",
      "\n",
      "Batch 69/387 ━━━━━━━━━━━━━━━━━━━━ 23:16:26\n",
      "Accuracy: 0.9976 - Precision: 0.8910 - Recall: 0.8747 - Specificity: 0.9991 - F1: 0.8758 - Loss: 0.1403\n",
      "\n",
      "Batch 70/387 ━━━━━━━━━━━━━━━━━━━━ 23:17:46\n",
      "Accuracy: 0.9976 - Precision: 0.8917 - Recall: 0.8758 - Specificity: 0.9991 - F1: 0.8767 - Loss: 0.1392\n",
      "\n",
      "Batch 71/387 ━━━━━━━━━━━━━━━━━━━━ 23:19:18\n",
      "Accuracy: 0.9976 - Precision: 0.8916 - Recall: 0.8738 - Specificity: 0.9991 - F1: 0.8757 - Loss: 0.1404\n",
      "\n",
      "Batch 72/387 ━━━━━━━━━━━━━━━━━━━━ 23:20:47\n",
      "Accuracy: 0.9976 - Precision: 0.8923 - Recall: 0.8751 - Specificity: 0.9991 - F1: 0.8768 - Loss: 0.1392\n",
      "\n",
      "Batch 73/387 ━━━━━━━━━━━━━━━━━━━━ 23:22:26\n",
      "Accuracy: 0.9976 - Precision: 0.8926 - Recall: 0.8764 - Specificity: 0.9991 - F1: 0.8777 - Loss: 0.1382\n",
      "\n",
      "Batch 74/387 ━━━━━━━━━━━━━━━━━━━━ 23:23:40\n",
      "Accuracy: 0.9976 - Precision: 0.8927 - Recall: 0.8754 - Specificity: 0.9991 - F1: 0.8773 - Loss: 0.1387\n",
      "\n",
      "Batch 75/387 ━━━━━━━━━━━━━━━━━━━━ 23:24:55\n",
      "Accuracy: 0.9976 - Precision: 0.8900 - Recall: 0.8770 - Specificity: 0.9991 - F1: 0.8765 - Loss: 0.1395\n",
      "\n",
      "Batch 76/387 ━━━━━━━━━━━━━━━━━━━━ 23:26:18\n",
      "Accuracy: 0.9976 - Precision: 0.8896 - Recall: 0.8777 - Specificity: 0.9990 - F1: 0.8767 - Loss: 0.1392\n",
      "\n",
      "Batch 77/387 ━━━━━━━━━━━━━━━━━━━━ 23:27:52\n",
      "Accuracy: 0.9976 - Precision: 0.8903 - Recall: 0.8789 - Specificity: 0.9990 - F1: 0.8778 - Loss: 0.1381\n",
      "\n",
      "Batch 78/387 ━━━━━━━━━━━━━━━━━━━━ 23:29:22\n",
      "Accuracy: 0.9976 - Precision: 0.8885 - Recall: 0.8800 - Specificity: 0.9990 - F1: 0.8773 - Loss: 0.1386\n",
      "\n",
      "Batch 79/387 ━━━━━━━━━━━━━━━━━━━━ 23:30:55\n",
      "Accuracy: 0.9976 - Precision: 0.8879 - Recall: 0.8812 - Specificity: 0.9990 - F1: 0.8776 - Loss: 0.1383\n",
      "\n",
      "Batch 80/387 ━━━━━━━━━━━━━━━━━━━━ 23:32:18\n",
      "Accuracy: 0.9976 - Precision: 0.8879 - Recall: 0.8811 - Specificity: 0.9990 - F1: 0.8777 - Loss: 0.1382\n",
      "\n",
      "Batch 81/387 ━━━━━━━━━━━━━━━━━━━━ 23:33:41\n",
      "Accuracy: 0.9976 - Precision: 0.8886 - Recall: 0.8805 - Specificity: 0.9990 - F1: 0.8777 - Loss: 0.1383\n",
      "\n",
      "Batch 82/387 ━━━━━━━━━━━━━━━━━━━━ 23:35:07\n",
      "Accuracy: 0.9976 - Precision: 0.8866 - Recall: 0.8812 - Specificity: 0.9990 - F1: 0.8770 - Loss: 0.1389\n",
      "\n",
      "Batch 83/387 ━━━━━━━━━━━━━━━━━━━━ 23:36:24\n",
      "Accuracy: 0.9976 - Precision: 0.8865 - Recall: 0.8788 - Specificity: 0.9990 - F1: 0.8756 - Loss: 0.1403\n",
      "\n",
      "Batch 84/387 ━━━━━━━━━━━━━━━━━━━━ 23:37:53\n",
      "Accuracy: 0.9976 - Precision: 0.8871 - Recall: 0.8800 - Specificity: 0.9990 - F1: 0.8767 - Loss: 0.1392\n",
      "\n",
      "Batch 85/387 ━━━━━━━━━━━━━━━━━━━━ 23:39:15\n",
      "Accuracy: 0.9976 - Precision: 0.8879 - Recall: 0.8797 - Specificity: 0.9990 - F1: 0.8770 - Loss: 0.1389\n",
      "\n",
      "Batch 86/387 ━━━━━━━━━━━━━━━━━━━━ 23:40:42\n",
      "Accuracy: 0.9976 - Precision: 0.8891 - Recall: 0.8793 - Specificity: 0.9990 - F1: 0.8773 - Loss: 0.1385\n",
      "\n",
      "Batch 87/387 ━━━━━━━━━━━━━━━━━━━━ 23:42:12\n",
      "Accuracy: 0.9976 - Precision: 0.8901 - Recall: 0.8800 - Specificity: 0.9990 - F1: 0.8783 - Loss: 0.1375\n",
      "\n",
      "Batch 88/387 ━━━━━━━━━━━━━━━━━━━━ 23:43:42\n",
      "Accuracy: 0.9976 - Precision: 0.8913 - Recall: 0.8788 - Specificity: 0.9990 - F1: 0.8782 - Loss: 0.1378\n",
      "\n",
      "Batch 89/387 ━━━━━━━━━━━━━━━━━━━━ 23:45:09\n",
      "Accuracy: 0.9976 - Precision: 0.8923 - Recall: 0.8776 - Specificity: 0.9990 - F1: 0.8780 - Loss: 0.1379\n",
      "\n",
      "Batch 90/387 ━━━━━━━━━━━━━━━━━━━━ 23:46:38\n",
      "Accuracy: 0.9976 - Precision: 0.8923 - Recall: 0.8781 - Specificity: 0.9990 - F1: 0.8783 - Loss: 0.1375\n",
      "\n",
      "Batch 91/387 ━━━━━━━━━━━━━━━━━━━━ 23:47:57\n",
      "Accuracy: 0.9976 - Precision: 0.8933 - Recall: 0.8785 - Specificity: 0.9990 - F1: 0.8791 - Loss: 0.1367\n",
      "\n",
      "Batch 92/387 ━━━━━━━━━━━━━━━━━━━━ 23:49:21\n",
      "Accuracy: 0.9976 - Precision: 0.8926 - Recall: 0.8779 - Specificity: 0.9990 - F1: 0.8785 - Loss: 0.1372\n",
      "\n",
      "Batch 93/387 ━━━━━━━━━━━━━━━━━━━━ 23:50:47\n",
      "Accuracy: 0.9976 - Precision: 0.8913 - Recall: 0.8791 - Specificity: 0.9990 - F1: 0.8784 - Loss: 0.1373\n",
      "\n",
      "Batch 94/387 ━━━━━━━━━━━━━━━━━━━━ 23:52:17\n",
      "Accuracy: 0.9976 - Precision: 0.8891 - Recall: 0.8801 - Specificity: 0.9990 - F1: 0.8776 - Loss: 0.1380\n",
      "\n",
      "Batch 95/387 ━━━━━━━━━━━━━━━━━━━━ 23:53:44\n",
      "Accuracy: 0.9976 - Precision: 0.8903 - Recall: 0.8788 - Specificity: 0.9990 - F1: 0.8775 - Loss: 0.1383\n",
      "\n",
      "Batch 96/387 ━━━━━━━━━━━━━━━━━━━━ 23:55:10\n",
      "Accuracy: 0.9976 - Precision: 0.8906 - Recall: 0.8784 - Specificity: 0.9990 - F1: 0.8775 - Loss: 0.1384\n",
      "\n",
      "Batch 97/387 ━━━━━━━━━━━━━━━━━━━━ 23:56:41\n",
      "Accuracy: 0.9976 - Precision: 0.8914 - Recall: 0.8792 - Specificity: 0.9990 - F1: 0.8784 - Loss: 0.1374\n",
      "\n",
      "Batch 98/387 ━━━━━━━━━━━━━━━━━━━━ 23:58:24\n",
      "Accuracy: 0.9976 - Precision: 0.8913 - Recall: 0.8767 - Specificity: 0.9990 - F1: 0.8770 - Loss: 0.1390\n",
      "\n",
      "Batch 99/387 ━━━━━━━━━━━━━━━━━━━━ 00:00:03\n",
      "Accuracy: 0.9975 - Precision: 0.8905 - Recall: 0.8771 - Specificity: 0.9990 - F1: 0.8768 - Loss: 0.1392\n",
      "\n",
      "Batch 100/387 ━━━━━━━━━━━━━━━━━━━━ 00:01:24\n",
      "Accuracy: 0.9975 - Precision: 0.8882 - Recall: 0.8783 - Specificity: 0.9990 - F1: 0.8759 - Loss: 0.1401\n",
      "\n",
      "Batch 101/387 ━━━━━━━━━━━━━━━━━━━━ 00:02:46\n",
      "Accuracy: 0.9976 - Precision: 0.8886 - Recall: 0.8784 - Specificity: 0.9990 - F1: 0.8762 - Loss: 0.1397\n",
      "\n",
      "Batch 102/387 ━━━━━━━━━━━━━━━━━━━━ 00:04:14\n",
      "Accuracy: 0.9976 - Precision: 0.8883 - Recall: 0.8792 - Specificity: 0.9990 - F1: 0.8766 - Loss: 0.1393\n",
      "\n",
      "Batch 103/387 ━━━━━━━━━━━━━━━━━━━━ 00:05:43\n",
      "Accuracy: 0.9976 - Precision: 0.8880 - Recall: 0.8791 - Specificity: 0.9990 - F1: 0.8764 - Loss: 0.1394\n",
      "\n",
      "Batch 104/387 ━━━━━━━━━━━━━━━━━━━━ 00:07:06\n",
      "Accuracy: 0.9976 - Precision: 0.8886 - Recall: 0.8797 - Specificity: 0.9990 - F1: 0.8771 - Loss: 0.1388\n",
      "\n",
      "Batch 105/387 ━━━━━━━━━━━━━━━━━━━━ 00:08:38\n",
      "Accuracy: 0.9976 - Precision: 0.8890 - Recall: 0.8800 - Specificity: 0.9990 - F1: 0.8775 - Loss: 0.1382\n",
      "\n",
      "Batch 106/387 ━━━━━━━━━━━━━━━━━━━━ 00:10:07\n",
      "Accuracy: 0.9976 - Precision: 0.8899 - Recall: 0.8787 - Specificity: 0.9990 - F1: 0.8772 - Loss: 0.1387\n",
      "\n",
      "Batch 107/387 ━━━━━━━━━━━━━━━━━━━━ 00:11:46\n",
      "Accuracy: 0.9976 - Precision: 0.8897 - Recall: 0.8798 - Specificity: 0.9990 - F1: 0.8777 - Loss: 0.1381\n",
      "\n",
      "Batch 108/387 ━━━━━━━━━━━━━━━━━━━━ 00:13:10\n",
      "Accuracy: 0.9976 - Precision: 0.8893 - Recall: 0.8801 - Specificity: 0.9990 - F1: 0.8777 - Loss: 0.1382\n",
      "\n",
      "Batch 109/387 ━━━━━━━━━━━━━━━━━━━━ 00:14:39\n",
      "Accuracy: 0.9976 - Precision: 0.8897 - Recall: 0.8806 - Specificity: 0.9990 - F1: 0.8782 - Loss: 0.1376\n",
      "\n",
      "Batch 110/387 ━━━━━━━━━━━━━━━━━━━━ 00:16:03\n",
      "Accuracy: 0.9976 - Precision: 0.8856 - Recall: 0.8808 - Specificity: 0.9990 - F1: 0.8755 - Loss: 0.1403\n",
      "\n",
      "Batch 111/387 ━━━━━━━━━━━━━━━━━━━━ 00:17:39\n",
      "Accuracy: 0.9976 - Precision: 0.8864 - Recall: 0.8797 - Specificity: 0.9990 - F1: 0.8754 - Loss: 0.1405\n",
      "\n",
      "Batch 112/387 ━━━━━━━━━━━━━━━━━━━━ 00:19:21\n",
      "Accuracy: 0.9976 - Precision: 0.8869 - Recall: 0.8779 - Specificity: 0.9990 - F1: 0.8746 - Loss: 0.1412\n",
      "\n",
      "Batch 113/387 ━━━━━━━━━━━━━━━━━━━━ 00:21:15\n",
      "Accuracy: 0.9976 - Precision: 0.8871 - Recall: 0.8784 - Specificity: 0.9990 - F1: 0.8750 - Loss: 0.1408\n",
      "\n",
      "Batch 114/387 ━━━━━━━━━━━━━━━━━━━━ 00:22:52\n",
      "Accuracy: 0.9976 - Precision: 0.8880 - Recall: 0.8785 - Specificity: 0.9990 - F1: 0.8756 - Loss: 0.1402\n",
      "\n",
      "Batch 115/387 ━━━━━━━━━━━━━━━━━━━━ 00:24:26\n",
      "Accuracy: 0.9976 - Precision: 0.8889 - Recall: 0.8767 - Specificity: 0.9990 - F1: 0.8750 - Loss: 0.1408\n",
      "\n",
      "Batch 116/387 ━━━━━━━━━━━━━━━━━━━━ 00:26:01\n",
      "Accuracy: 0.9976 - Precision: 0.8898 - Recall: 0.8769 - Specificity: 0.9990 - F1: 0.8755 - Loss: 0.1401\n",
      "\n",
      "Batch 117/387 ━━━━━━━━━━━━━━━━━━━━ 00:27:25\n",
      "Accuracy: 0.9976 - Precision: 0.8899 - Recall: 0.8776 - Specificity: 0.9990 - F1: 0.8760 - Loss: 0.1396\n",
      "\n",
      "Batch 118/387 ━━━━━━━━━━━━━━━━━━━━ 00:29:00\n",
      "Accuracy: 0.9976 - Precision: 0.8906 - Recall: 0.8784 - Specificity: 0.9990 - F1: 0.8768 - Loss: 0.1388\n",
      "\n",
      "Batch 119/387 ━━━━━━━━━━━━━━━━━━━━ 00:30:34\n",
      "Accuracy: 0.9976 - Precision: 0.8910 - Recall: 0.8786 - Specificity: 0.9990 - F1: 0.8772 - Loss: 0.1384\n",
      "\n",
      "Batch 120/387 ━━━━━━━━━━━━━━━━━━━━ 00:31:59\n",
      "Accuracy: 0.9976 - Precision: 0.8892 - Recall: 0.8790 - Specificity: 0.9990 - F1: 0.8764 - Loss: 0.1392\n",
      "\n",
      "Batch 121/387 ━━━━━━━━━━━━━━━━━━━━ 00:33:28\n",
      "Accuracy: 0.9976 - Precision: 0.8895 - Recall: 0.8768 - Specificity: 0.9990 - F1: 0.8752 - Loss: 0.1405\n",
      "\n",
      "Batch 122/387 ━━━━━━━━━━━━━━━━━━━━ 00:34:56\n",
      "Accuracy: 0.9976 - Precision: 0.8894 - Recall: 0.8763 - Specificity: 0.9990 - F1: 0.8750 - Loss: 0.1407\n",
      "\n",
      "Batch 123/387 ━━━━━━━━━━━━━━━━━━━━ 00:36:27\n",
      "Accuracy: 0.9976 - Precision: 0.8884 - Recall: 0.8772 - Specificity: 0.9990 - F1: 0.8749 - Loss: 0.1409\n",
      "\n",
      "Batch 124/387 ━━━━━━━━━━━━━━━━━━━━ 00:38:04\n",
      "Accuracy: 0.9976 - Precision: 0.8889 - Recall: 0.8778 - Specificity: 0.9990 - F1: 0.8755 - Loss: 0.1402\n",
      "\n",
      "Batch 125/387 ━━━━━━━━━━━━━━━━━━━━ 00:39:39\n",
      "Accuracy: 0.9976 - Precision: 0.8884 - Recall: 0.8786 - Specificity: 0.9990 - F1: 0.8757 - Loss: 0.1400\n",
      "\n",
      "Batch 126/387 ━━━━━━━━━━━━━━━━━━━━ 00:41:02\n",
      "Accuracy: 0.9976 - Precision: 0.8892 - Recall: 0.8785 - Specificity: 0.9990 - F1: 0.8760 - Loss: 0.1397\n",
      "\n",
      "Batch 127/387 ━━━━━━━━━━━━━━━━━━━━ 00:42:32\n",
      "Accuracy: 0.9976 - Precision: 0.8894 - Recall: 0.8784 - Specificity: 0.9990 - F1: 0.8762 - Loss: 0.1396\n",
      "\n",
      "Batch 128/387 ━━━━━━━━━━━━━━━━━━━━ 00:44:09\n",
      "Accuracy: 0.9976 - Precision: 0.8890 - Recall: 0.8791 - Specificity: 0.9990 - F1: 0.8763 - Loss: 0.1394\n",
      "\n",
      "Batch 129/387 ━━━━━━━━━━━━━━━━━━━━ 00:45:44\n",
      "Accuracy: 0.9976 - Precision: 0.8891 - Recall: 0.8795 - Specificity: 0.9990 - F1: 0.8766 - Loss: 0.1391\n",
      "\n",
      "Batch 130/387 ━━━━━━━━━━━━━━━━━━━━ 00:47:20\n",
      "Accuracy: 0.9975 - Precision: 0.8854 - Recall: 0.8796 - Specificity: 0.9990 - F1: 0.8742 - Loss: 0.1416\n",
      "\n",
      "Batch 131/387 ━━━━━━━━━━━━━━━━━━━━ 00:48:47\n",
      "Accuracy: 0.9976 - Precision: 0.8847 - Recall: 0.8802 - Specificity: 0.9990 - F1: 0.8741 - Loss: 0.1416\n",
      "\n",
      "Batch 132/387 ━━━━━━━━━━━━━━━━━━━━ 00:50:26\n",
      "Accuracy: 0.9976 - Precision: 0.8850 - Recall: 0.8809 - Specificity: 0.9990 - F1: 0.8747 - Loss: 0.1411\n",
      "\n",
      "Batch 133/387 ━━━━━━━━━━━━━━━━━━━━ 00:51:42\n",
      "Accuracy: 0.9975 - Precision: 0.8856 - Recall: 0.8788 - Specificity: 0.9990 - F1: 0.8737 - Loss: 0.1422\n",
      "\n",
      "Batch 134/387 ━━━━━━━━━━━━━━━━━━━━ 00:53:04\n",
      "Accuracy: 0.9975 - Precision: 0.8860 - Recall: 0.8793 - Specificity: 0.9990 - F1: 0.8742 - Loss: 0.1417\n",
      "\n",
      "Batch 135/387 ━━━━━━━━━━━━━━━━━━━━ 00:54:35\n",
      "Accuracy: 0.9975 - Precision: 0.8868 - Recall: 0.8793 - Specificity: 0.9990 - F1: 0.8746 - Loss: 0.1413\n",
      "\n",
      "Batch 136/387 ━━━━━━━━━━━━━━━━━━━━ 00:56:08\n",
      "Accuracy: 0.9976 - Precision: 0.8871 - Recall: 0.8798 - Specificity: 0.9990 - F1: 0.8751 - Loss: 0.1407\n",
      "\n",
      "Batch 137/387 ━━━━━━━━━━━━━━━━━━━━ 00:57:36\n",
      "Accuracy: 0.9975 - Precision: 0.8879 - Recall: 0.8789 - Specificity: 0.9990 - F1: 0.8750 - Loss: 0.1409\n",
      "\n",
      "Batch 138/387 ━━━━━━━━━━━━━━━━━━━━ 00:59:07\n",
      "Accuracy: 0.9975 - Precision: 0.8874 - Recall: 0.8790 - Specificity: 0.9990 - F1: 0.8749 - Loss: 0.1410\n",
      "\n",
      "Batch 139/387 ━━━━━━━━━━━━━━━━━━━━ 01:00:41\n",
      "Accuracy: 0.9976 - Precision: 0.8882 - Recall: 0.8792 - Specificity: 0.9990 - F1: 0.8754 - Loss: 0.1404\n",
      "\n",
      "Batch 140/387 ━━━━━━━━━━━━━━━━━━━━ 01:02:10\n",
      "Accuracy: 0.9976 - Precision: 0.8870 - Recall: 0.8791 - Specificity: 0.9990 - F1: 0.8748 - Loss: 0.1411\n",
      "\n",
      "Batch 141/387 ━━━━━━━━━━━━━━━━━━━━ 01:03:43\n",
      "Accuracy: 0.9975 - Precision: 0.8849 - Recall: 0.8793 - Specificity: 0.9990 - F1: 0.8737 - Loss: 0.1423\n",
      "\n",
      "Batch 142/387 ━━━━━━━━━━━━━━━━━━━━ 01:05:19\n",
      "Accuracy: 0.9976 - Precision: 0.8851 - Recall: 0.8799 - Specificity: 0.9990 - F1: 0.8741 - Loss: 0.1418\n",
      "\n",
      "Batch 143/387 ━━━━━━━━━━━━━━━━━━━━ 01:06:46\n",
      "Accuracy: 0.9975 - Precision: 0.8846 - Recall: 0.8776 - Specificity: 0.9990 - F1: 0.8726 - Loss: 0.1434\n",
      "\n",
      "Batch 144/387 ━━━━━━━━━━━━━━━━━━━━ 01:08:23\n",
      "Accuracy: 0.9975 - Precision: 0.8843 - Recall: 0.8776 - Specificity: 0.9990 - F1: 0.8725 - Loss: 0.1435\n",
      "\n",
      "Batch 145/387 ━━━━━━━━━━━━━━━━━━━━ 01:09:56\n",
      "Accuracy: 0.9975 - Precision: 0.8849 - Recall: 0.8779 - Specificity: 0.9990 - F1: 0.8730 - Loss: 0.1429\n",
      "\n",
      "Batch 146/387 ━━━━━━━━━━━━━━━━━━━━ 01:11:22\n",
      "Accuracy: 0.9976 - Precision: 0.8848 - Recall: 0.8785 - Specificity: 0.9990 - F1: 0.8733 - Loss: 0.1426\n",
      "\n",
      "Batch 147/387 ━━━━━━━━━━━━━━━━━━━━ 01:12:52\n",
      "Accuracy: 0.9976 - Precision: 0.8853 - Recall: 0.8790 - Specificity: 0.9990 - F1: 0.8738 - Loss: 0.1420\n",
      "\n",
      "Batch 148/387 ━━━━━━━━━━━━━━━━━━━━ 01:14:26\n",
      "Accuracy: 0.9976 - Precision: 0.8859 - Recall: 0.8792 - Specificity: 0.9990 - F1: 0.8743 - Loss: 0.1415\n",
      "\n",
      "Batch 149/387 ━━━━━━━━━━━━━━━━━━━━ 01:15:53\n",
      "Accuracy: 0.9976 - Precision: 0.8862 - Recall: 0.8795 - Specificity: 0.9990 - F1: 0.8746 - Loss: 0.1411\n",
      "\n",
      "Batch 150/387 ━━━━━━━━━━━━━━━━━━━━ 01:17:30\n",
      "Accuracy: 0.9976 - Precision: 0.8852 - Recall: 0.8787 - Specificity: 0.9990 - F1: 0.8738 - Loss: 0.1419\n",
      "\n",
      "Batch 151/387 ━━━━━━━━━━━━━━━━━━━━ 01:18:56\n",
      "Accuracy: 0.9976 - Precision: 0.8846 - Recall: 0.8793 - Specificity: 0.9990 - F1: 0.8738 - Loss: 0.1419\n",
      "\n",
      "Batch 152/387 ━━━━━━━━━━━━━━━━━━━━ 01:20:25\n",
      "Accuracy: 0.9976 - Precision: 0.8847 - Recall: 0.8797 - Specificity: 0.9990 - F1: 0.8741 - Loss: 0.1416\n",
      "\n",
      "Batch 153/387 ━━━━━━━━━━━━━━━━━━━━ 01:21:56\n",
      "Accuracy: 0.9976 - Precision: 0.8836 - Recall: 0.8802 - Specificity: 0.9990 - F1: 0.8737 - Loss: 0.1419\n",
      "\n",
      "Batch 154/387 ━━━━━━━━━━━━━━━━━━━━ 01:23:24\n",
      "Accuracy: 0.9976 - Precision: 0.8843 - Recall: 0.8797 - Specificity: 0.9990 - F1: 0.8739 - Loss: 0.1418\n",
      "\n",
      "Batch 155/387 ━━━━━━━━━━━━━━━━━━━━ 01:24:53\n",
      "Accuracy: 0.9976 - Precision: 0.8842 - Recall: 0.8802 - Specificity: 0.9990 - F1: 0.8741 - Loss: 0.1415\n",
      "\n",
      "Batch 156/387 ━━━━━━━━━━━━━━━━━━━━ 01:26:20\n",
      "Accuracy: 0.9976 - Precision: 0.8845 - Recall: 0.8807 - Specificity: 0.9990 - F1: 0.8745 - Loss: 0.1410\n",
      "\n",
      "Batch 157/387 ━━━━━━━━━━━━━━━━━━━━ 01:27:49\n",
      "Accuracy: 0.9976 - Precision: 0.8850 - Recall: 0.8806 - Specificity: 0.9990 - F1: 0.8748 - Loss: 0.1407\n",
      "\n",
      "Batch 158/387 ━━━━━━━━━━━━━━━━━━━━ 01:29:16\n",
      "Accuracy: 0.9976 - Precision: 0.8846 - Recall: 0.8807 - Specificity: 0.9990 - F1: 0.8746 - Loss: 0.1408\n",
      "\n",
      "Batch 159/387 ━━━━━━━━━━━━━━━━━━━━ 01:30:42\n",
      "Accuracy: 0.9976 - Precision: 0.8851 - Recall: 0.8807 - Specificity: 0.9990 - F1: 0.8749 - Loss: 0.1405\n",
      "\n",
      "Batch 160/387 ━━━━━━━━━━━━━━━━━━━━ 01:32:07\n",
      "Accuracy: 0.9976 - Precision: 0.8857 - Recall: 0.8799 - Specificity: 0.9990 - F1: 0.8748 - Loss: 0.1407\n",
      "\n",
      "Batch 161/387 ━━━━━━━━━━━━━━━━━━━━ 01:33:39\n",
      "Accuracy: 0.9976 - Precision: 0.8856 - Recall: 0.8801 - Specificity: 0.9990 - F1: 0.8749 - Loss: 0.1406\n",
      "\n",
      "Batch 162/387 ━━━━━━━━━━━━━━━━━━━━ 01:35:07\n",
      "Accuracy: 0.9976 - Precision: 0.8859 - Recall: 0.8801 - Specificity: 0.9990 - F1: 0.8751 - Loss: 0.1404\n",
      "\n",
      "Batch 163/387 ━━━━━━━━━━━━━━━━━━━━ 01:36:39\n",
      "Accuracy: 0.9976 - Precision: 0.8865 - Recall: 0.8801 - Specificity: 0.9990 - F1: 0.8754 - Loss: 0.1401\n",
      "\n",
      "Batch 164/387 ━━━━━━━━━━━━━━━━━━━━ 01:38:09\n",
      "Accuracy: 0.9976 - Precision: 0.8862 - Recall: 0.8797 - Specificity: 0.9990 - F1: 0.8751 - Loss: 0.1404\n",
      "\n",
      "Batch 165/387 ━━━━━━━━━━━━━━━━━━━━ 01:39:33\n",
      "Accuracy: 0.9976 - Precision: 0.8866 - Recall: 0.8798 - Specificity: 0.9990 - F1: 0.8754 - Loss: 0.1401\n",
      "\n",
      "Batch 166/387 ━━━━━━━━━━━━━━━━━━━━ 01:40:51\n",
      "Accuracy: 0.9976 - Precision: 0.8872 - Recall: 0.8799 - Specificity: 0.9990 - F1: 0.8758 - Loss: 0.1396\n",
      "\n",
      "Batch 167/387 ━━━━━━━━━━━━━━━━━━━━ 01:42:30\n",
      "Accuracy: 0.9976 - Precision: 0.8863 - Recall: 0.8805 - Specificity: 0.9990 - F1: 0.8756 - Loss: 0.1398\n",
      "\n",
      "Batch 168/387 ━━━━━━━━━━━━━━━━━━━━ 01:44:05\n",
      "Accuracy: 0.9976 - Precision: 0.8862 - Recall: 0.8812 - Specificity: 0.9990 - F1: 0.8759 - Loss: 0.1395\n",
      "\n",
      "Batch 169/387 ━━━━━━━━━━━━━━━━━━━━ 01:45:29\n",
      "Accuracy: 0.9977 - Precision: 0.8867 - Recall: 0.8816 - Specificity: 0.9990 - F1: 0.8764 - Loss: 0.1389\n",
      "\n",
      "Batch 170/387 ━━━━━━━━━━━━━━━━━━━━ 01:46:54\n",
      "Accuracy: 0.9977 - Precision: 0.8868 - Recall: 0.8815 - Specificity: 0.9990 - F1: 0.8764 - Loss: 0.1389\n",
      "\n",
      "Batch 171/387 ━━━━━━━━━━━━━━━━━━━━ 01:48:20\n",
      "Accuracy: 0.9976 - Precision: 0.8860 - Recall: 0.8820 - Specificity: 0.9990 - F1: 0.8762 - Loss: 0.1391\n",
      "\n",
      "Batch 172/387 ━━━━━━━━━━━━━━━━━━━━ 01:49:41\n",
      "Accuracy: 0.9976 - Precision: 0.8863 - Recall: 0.8823 - Specificity: 0.9990 - F1: 0.8766 - Loss: 0.1387\n",
      "\n",
      "Batch 173/387 ━━━━━━━━━━━━━━━━━━━━ 01:51:11\n",
      "Accuracy: 0.9977 - Precision: 0.8864 - Recall: 0.8824 - Specificity: 0.9990 - F1: 0.8767 - Loss: 0.1386\n",
      "\n",
      "Batch 174/387 ━━━━━━━━━━━━━━━━━━━━ 01:52:36\n",
      "Accuracy: 0.9976 - Precision: 0.8866 - Recall: 0.8829 - Specificity: 0.9990 - F1: 0.8771 - Loss: 0.1382\n",
      "\n",
      "Batch 175/387 ━━━━━━━━━━━━━━━━━━━━ 01:54:03\n",
      "Accuracy: 0.9976 - Precision: 0.8858 - Recall: 0.8834 - Specificity: 0.9990 - F1: 0.8769 - Loss: 0.1384\n",
      "\n",
      "Batch 176/387 ━━━━━━━━━━━━━━━━━━━━ 01:55:36\n",
      "Accuracy: 0.9976 - Precision: 0.8844 - Recall: 0.8834 - Specificity: 0.9990 - F1: 0.8761 - Loss: 0.1393\n",
      "\n",
      "Batch 177/387 ━━━━━━━━━━━━━━━━━━━━ 01:57:15\n",
      "Accuracy: 0.9976 - Precision: 0.8829 - Recall: 0.8839 - Specificity: 0.9990 - F1: 0.8755 - Loss: 0.1400\n",
      "\n",
      "Batch 178/387 ━━━━━━━━━━━━━━━━━━━━ 01:58:48\n",
      "Accuracy: 0.9976 - Precision: 0.8812 - Recall: 0.8837 - Specificity: 0.9990 - F1: 0.8744 - Loss: 0.1411\n",
      "\n",
      "Batch 179/387 ━━━━━━━━━━━━━━━━━━━━ 02:00:17\n",
      "Accuracy: 0.9976 - Precision: 0.8815 - Recall: 0.8827 - Specificity: 0.9990 - F1: 0.8740 - Loss: 0.1414\n",
      "\n",
      "Batch 180/387 ━━━━━━━━━━━━━━━━━━━━ 02:01:46\n",
      "Accuracy: 0.9976 - Precision: 0.8821 - Recall: 0.8822 - Specificity: 0.9990 - F1: 0.8741 - Loss: 0.1414\n",
      "\n",
      "Batch 181/387 ━━━━━━━━━━━━━━━━━━━━ 02:03:17\n",
      "Accuracy: 0.9976 - Precision: 0.8826 - Recall: 0.8820 - Specificity: 0.9990 - F1: 0.8742 - Loss: 0.1412\n",
      "\n",
      "Batch 182/387 ━━━━━━━━━━━━━━━━━━━━ 02:04:43\n",
      "Accuracy: 0.9976 - Precision: 0.8818 - Recall: 0.8823 - Specificity: 0.9990 - F1: 0.8739 - Loss: 0.1414\n",
      "\n",
      "Batch 183/387 ━━━━━━━━━━━━━━━━━━━━ 02:06:16\n",
      "Accuracy: 0.9977 - Precision: 0.8820 - Recall: 0.8826 - Specificity: 0.9990 - F1: 0.8743 - Loss: 0.1411\n",
      "\n",
      "Batch 184/387 ━━━━━━━━━━━━━━━━━━━━ 02:07:37\n",
      "Accuracy: 0.9976 - Precision: 0.8826 - Recall: 0.8819 - Specificity: 0.9990 - F1: 0.8741 - Loss: 0.1412\n",
      "\n",
      "Batch 185/387 ━━━━━━━━━━━━━━━━━━━━ 02:09:06\n",
      "Accuracy: 0.9977 - Precision: 0.8822 - Recall: 0.8816 - Specificity: 0.9990 - F1: 0.8738 - Loss: 0.1415\n",
      "\n",
      "Batch 186/387 ━━━━━━━━━━━━━━━━━━━━ 02:10:37\n",
      "Accuracy: 0.9977 - Precision: 0.8820 - Recall: 0.8799 - Specificity: 0.9990 - F1: 0.8728 - Loss: 0.1425\n",
      "\n",
      "Batch 187/387 ━━━━━━━━━━━━━━━━━━━━ 02:11:56\n",
      "Accuracy: 0.9977 - Precision: 0.8825 - Recall: 0.8799 - Specificity: 0.9990 - F1: 0.8730 - Loss: 0.1423\n",
      "\n",
      "Batch 188/387 ━━━━━━━━━━━━━━━━━━━━ 02:13:25\n",
      "Accuracy: 0.9976 - Precision: 0.8827 - Recall: 0.8791 - Specificity: 0.9990 - F1: 0.8727 - Loss: 0.1427\n",
      "\n",
      "Batch 189/387 ━━━━━━━━━━━━━━━━━━━━ 02:14:45\n",
      "Accuracy: 0.9976 - Precision: 0.8833 - Recall: 0.8791 - Specificity: 0.9990 - F1: 0.8731 - Loss: 0.1423\n",
      "\n",
      "Batch 190/387 ━━━━━━━━━━━━━━━━━━━━ 02:16:19\n",
      "Accuracy: 0.9977 - Precision: 0.8832 - Recall: 0.8794 - Specificity: 0.9990 - F1: 0.8732 - Loss: 0.1421\n",
      "\n",
      "Batch 191/387 ━━━━━━━━━━━━━━━━━━━━ 02:17:53\n",
      "Accuracy: 0.9977 - Precision: 0.8828 - Recall: 0.8800 - Specificity: 0.9990 - F1: 0.8733 - Loss: 0.1419\n",
      "\n",
      "Batch 192/387 ━━━━━━━━━━━━━━━━━━━━ 02:19:18\n",
      "Accuracy: 0.9977 - Precision: 0.8831 - Recall: 0.8804 - Specificity: 0.9990 - F1: 0.8737 - Loss: 0.1415\n",
      "\n",
      "Batch 193/387 ━━━━━━━━━━━━━━━━━━━━ 02:20:49\n",
      "Accuracy: 0.9977 - Precision: 0.8835 - Recall: 0.8806 - Specificity: 0.9990 - F1: 0.8740 - Loss: 0.1412\n",
      "\n",
      "Batch 194/387 ━━━━━━━━━━━━━━━━━━━━ 02:22:07\n",
      "Accuracy: 0.9977 - Precision: 0.8835 - Recall: 0.8803 - Specificity: 0.9990 - F1: 0.8739 - Loss: 0.1412\n",
      "\n",
      "Batch 195/387 ━━━━━━━━━━━━━━━━━━━━ 02:23:35\n",
      "Accuracy: 0.9977 - Precision: 0.8836 - Recall: 0.8805 - Specificity: 0.9990 - F1: 0.8741 - Loss: 0.1411\n",
      "\n",
      "Batch 196/387 ━━━━━━━━━━━━━━━━━━━━ 02:25:08\n",
      "Accuracy: 0.9977 - Precision: 0.8840 - Recall: 0.8802 - Specificity: 0.9990 - F1: 0.8742 - Loss: 0.1410\n",
      "\n",
      "Batch 197/387 ━━━━━━━━━━━━━━━━━━━━ 02:26:44\n",
      "Accuracy: 0.9977 - Precision: 0.8844 - Recall: 0.8802 - Specificity: 0.9990 - F1: 0.8744 - Loss: 0.1408\n",
      "\n",
      "Batch 198/387 ━━━━━━━━━━━━━━━━━━━━ 02:28:20\n",
      "Accuracy: 0.9977 - Precision: 0.8844 - Recall: 0.8802 - Specificity: 0.9990 - F1: 0.8744 - Loss: 0.1408\n",
      "\n",
      "Batch 199/387 ━━━━━━━━━━━━━━━━━━━━ 02:29:56\n",
      "Accuracy: 0.9977 - Precision: 0.8845 - Recall: 0.8806 - Specificity: 0.9990 - F1: 0.8747 - Loss: 0.1404\n",
      "\n",
      "Batch 200/387 ━━━━━━━━━━━━━━━━━━━━ 02:31:10\n",
      "Accuracy: 0.9977 - Precision: 0.8832 - Recall: 0.8809 - Specificity: 0.9990 - F1: 0.8741 - Loss: 0.1411\n",
      "\n",
      "Batch 201/387 ━━━━━━━━━━━━━━━━━━━━ 02:32:50\n",
      "Accuracy: 0.9977 - Precision: 0.8835 - Recall: 0.8808 - Specificity: 0.9990 - F1: 0.8742 - Loss: 0.1410\n",
      "\n",
      "Batch 202/387 ━━━━━━━━━━━━━━━━━━━━ 02:34:14\n",
      "Accuracy: 0.9977 - Precision: 0.8834 - Recall: 0.8810 - Specificity: 0.9990 - F1: 0.8743 - Loss: 0.1408\n",
      "\n",
      "Batch 203/387 ━━━━━━━━━━━━━━━━━━━━ 02:35:38\n",
      "Accuracy: 0.9977 - Precision: 0.8838 - Recall: 0.8799 - Specificity: 0.9990 - F1: 0.8738 - Loss: 0.1414\n",
      "\n",
      "Batch 204/387 ━━━━━━━━━━━━━━━━━━━━ 02:37:01\n",
      "Accuracy: 0.9977 - Precision: 0.8824 - Recall: 0.8802 - Specificity: 0.9990 - F1: 0.8732 - Loss: 0.1421\n",
      "\n",
      "Batch 205/387 ━━━━━━━━━━━━━━━━━━━━ 02:38:25\n",
      "Accuracy: 0.9977 - Precision: 0.8825 - Recall: 0.8802 - Specificity: 0.9990 - F1: 0.8733 - Loss: 0.1420\n",
      "\n",
      "Batch 206/387 ━━━━━━━━━━━━━━━━━━━━ 02:40:09\n",
      "Accuracy: 0.9977 - Precision: 0.8827 - Recall: 0.8800 - Specificity: 0.9990 - F1: 0.8733 - Loss: 0.1420\n",
      "\n",
      "Batch 207/387 ━━━━━━━━━━━━━━━━━━━━ 02:41:37\n",
      "Accuracy: 0.9976 - Precision: 0.8826 - Recall: 0.8800 - Specificity: 0.9990 - F1: 0.8733 - Loss: 0.1420\n",
      "\n",
      "Batch 208/387 ━━━━━━━━━━━━━━━━━━━━ 02:43:11\n",
      "Accuracy: 0.9976 - Precision: 0.8822 - Recall: 0.8804 - Specificity: 0.9990 - F1: 0.8733 - Loss: 0.1420\n",
      "\n",
      "Batch 209/387 ━━━━━━━━━━━━━━━━━━━━ 02:44:50\n",
      "Accuracy: 0.9976 - Precision: 0.8826 - Recall: 0.8808 - Specificity: 0.9990 - F1: 0.8737 - Loss: 0.1416\n",
      "\n",
      "Batch 210/387 ━━━━━━━━━━━━━━━━━━━━ 02:46:20\n",
      "Accuracy: 0.9977 - Precision: 0.8824 - Recall: 0.8813 - Specificity: 0.9990 - F1: 0.8739 - Loss: 0.1414\n",
      "\n",
      "Batch 211/387 ━━━━━━━━━━━━━━━━━━━━ 02:47:55\n",
      "Accuracy: 0.9976 - Precision: 0.8827 - Recall: 0.8814 - Specificity: 0.9990 - F1: 0.8741 - Loss: 0.1412\n",
      "\n",
      "Batch 212/387 ━━━━━━━━━━━━━━━━━━━━ 02:49:28\n",
      "Accuracy: 0.9976 - Precision: 0.8832 - Recall: 0.8813 - Specificity: 0.9990 - F1: 0.8744 - Loss: 0.1409\n",
      "\n",
      "Batch 213/387 ━━━━━━━━━━━━━━━━━━━━ 02:50:54\n",
      "Accuracy: 0.9976 - Precision: 0.8832 - Recall: 0.8811 - Specificity: 0.9990 - F1: 0.8742 - Loss: 0.1410\n",
      "\n",
      "Batch 214/387 ━━━━━━━━━━━━━━━━━━━━ 02:52:20\n",
      "Accuracy: 0.9976 - Precision: 0.8834 - Recall: 0.8807 - Specificity: 0.9990 - F1: 0.8742 - Loss: 0.1411\n",
      "\n",
      "Batch 215/387 ━━━━━━━━━━━━━━━━━━━━ 02:53:35\n",
      "Accuracy: 0.9976 - Precision: 0.8813 - Recall: 0.8809 - Specificity: 0.9990 - F1: 0.8729 - Loss: 0.1424\n",
      "\n",
      "Batch 216/387 ━━━━━━━━━━━━━━━━━━━━ 02:55:05\n",
      "Accuracy: 0.9976 - Precision: 0.8817 - Recall: 0.8808 - Specificity: 0.9990 - F1: 0.8730 - Loss: 0.1423\n",
      "\n",
      "Batch 217/387 ━━━━━━━━━━━━━━━━━━━━ 02:56:27\n",
      "Accuracy: 0.9976 - Precision: 0.8808 - Recall: 0.8810 - Specificity: 0.9990 - F1: 0.8726 - Loss: 0.1427\n",
      "\n",
      "Batch 218/387 ━━━━━━━━━━━━━━━━━━━━ 02:58:00\n",
      "Accuracy: 0.9976 - Precision: 0.8807 - Recall: 0.8813 - Specificity: 0.9990 - F1: 0.8728 - Loss: 0.1425\n",
      "\n",
      "Batch 219/387 ━━━━━━━━━━━━━━━━━━━━ 02:59:17\n",
      "Accuracy: 0.9976 - Precision: 0.8798 - Recall: 0.8809 - Specificity: 0.9990 - F1: 0.8722 - Loss: 0.1432\n",
      "\n",
      "Batch 220/387 ━━━━━━━━━━━━━━━━━━━━ 03:00:46\n",
      "Accuracy: 0.9976 - Precision: 0.8797 - Recall: 0.8810 - Specificity: 0.9990 - F1: 0.8722 - Loss: 0.1431\n",
      "\n",
      "Batch 221/387 ━━━━━━━━━━━━━━━━━━━━ 03:02:31\n",
      "Accuracy: 0.9976 - Precision: 0.8800 - Recall: 0.8815 - Specificity: 0.9990 - F1: 0.8726 - Loss: 0.1427\n",
      "\n",
      "Batch 222/387 ━━━━━━━━━━━━━━━━━━━━ 03:04:03\n",
      "Accuracy: 0.9976 - Precision: 0.8804 - Recall: 0.8816 - Specificity: 0.9990 - F1: 0.8729 - Loss: 0.1423\n",
      "\n",
      "Batch 223/387 ━━━━━━━━━━━━━━━━━━━━ 03:05:32\n",
      "Accuracy: 0.9977 - Precision: 0.8808 - Recall: 0.8818 - Specificity: 0.9990 - F1: 0.8732 - Loss: 0.1420\n",
      "\n",
      "Batch 224/387 ━━━━━━━━━━━━━━━━━━━━ 03:06:55\n",
      "Accuracy: 0.9977 - Precision: 0.8807 - Recall: 0.8821 - Specificity: 0.9990 - F1: 0.8733 - Loss: 0.1419\n",
      "\n",
      "Batch 225/387 ━━━━━━━━━━━━━━━━━━━━ 03:08:31\n",
      "Accuracy: 0.9976 - Precision: 0.8812 - Recall: 0.8814 - Specificity: 0.9990 - F1: 0.8732 - Loss: 0.1420\n",
      "\n",
      "Batch 226/387 ━━━━━━━━━━━━━━━━━━━━ 03:10:10\n",
      "Accuracy: 0.9976 - Precision: 0.8807 - Recall: 0.8817 - Specificity: 0.9990 - F1: 0.8731 - Loss: 0.1421\n",
      "\n",
      "Batch 227/387 ━━━━━━━━━━━━━━━━━━━━ 03:11:30\n",
      "Accuracy: 0.9977 - Precision: 0.8809 - Recall: 0.8820 - Specificity: 0.9990 - F1: 0.8734 - Loss: 0.1418\n",
      "\n",
      "Batch 228/387 ━━━━━━━━━━━━━━━━━━━━ 03:12:53\n",
      "Accuracy: 0.9976 - Precision: 0.8814 - Recall: 0.8814 - Specificity: 0.9990 - F1: 0.8733 - Loss: 0.1420\n",
      "\n",
      "Batch 229/387 ━━━━━━━━━━━━━━━━━━━━ 03:14:21\n",
      "Accuracy: 0.9976 - Precision: 0.8819 - Recall: 0.8814 - Specificity: 0.9990 - F1: 0.8735 - Loss: 0.1417\n",
      "\n",
      "Batch 230/387 ━━━━━━━━━━━━━━━━━━━━ 03:15:41\n",
      "Accuracy: 0.9976 - Precision: 0.8824 - Recall: 0.8810 - Specificity: 0.9990 - F1: 0.8736 - Loss: 0.1417\n",
      "\n",
      "Batch 231/387 ━━━━━━━━━━━━━━━━━━━━ 03:17:06\n",
      "Accuracy: 0.9976 - Precision: 0.8828 - Recall: 0.8809 - Specificity: 0.9990 - F1: 0.8737 - Loss: 0.1415\n",
      "\n",
      "Batch 232/387 ━━━━━━━━━━━━━━━━━━━━ 03:18:40\n",
      "Accuracy: 0.9976 - Precision: 0.8832 - Recall: 0.8805 - Specificity: 0.9990 - F1: 0.8737 - Loss: 0.1415\n",
      "\n",
      "Batch 233/387 ━━━━━━━━━━━━━━━━━━━━ 03:20:11\n",
      "Accuracy: 0.9976 - Precision: 0.8833 - Recall: 0.8790 - Specificity: 0.9990 - F1: 0.8729 - Loss: 0.1423\n",
      "\n",
      "Batch 234/387 ━━━━━━━━━━━━━━━━━━━━ 03:21:54\n",
      "Accuracy: 0.9976 - Precision: 0.8834 - Recall: 0.8793 - Specificity: 0.9990 - F1: 0.8731 - Loss: 0.1420\n",
      "\n",
      "Batch 235/387 ━━━━━━━━━━━━━━━━━━━━ 03:23:18\n",
      "Accuracy: 0.9976 - Precision: 0.8836 - Recall: 0.8793 - Specificity: 0.9990 - F1: 0.8733 - Loss: 0.1419\n",
      "\n",
      "Batch 236/387 ━━━━━━━━━━━━━━━━━━━━ 03:24:39\n",
      "Accuracy: 0.9976 - Precision: 0.8841 - Recall: 0.8794 - Specificity: 0.9990 - F1: 0.8735 - Loss: 0.1417\n",
      "\n",
      "Batch 237/387 ━━━━━━━━━━━━━━━━━━━━ 03:26:09\n",
      "Accuracy: 0.9976 - Precision: 0.8842 - Recall: 0.8795 - Specificity: 0.9990 - F1: 0.8737 - Loss: 0.1415\n",
      "\n",
      "Batch 238/387 ━━━━━━━━━━━━━━━━━━━━ 03:27:43\n",
      "Accuracy: 0.9976 - Precision: 0.8841 - Recall: 0.8798 - Specificity: 0.9990 - F1: 0.8739 - Loss: 0.1413\n",
      "\n",
      "Batch 239/387 ━━━━━━━━━━━━━━━━━━━━ 03:29:12\n",
      "Accuracy: 0.9976 - Precision: 0.8834 - Recall: 0.8799 - Specificity: 0.9990 - F1: 0.8735 - Loss: 0.1417\n",
      "\n",
      "Batch 240/387 ━━━━━━━━━━━━━━━━━━━━ 03:30:35\n",
      "Accuracy: 0.9977 - Precision: 0.8830 - Recall: 0.8803 - Specificity: 0.9990 - F1: 0.8735 - Loss: 0.1417\n",
      "\n",
      "Batch 241/387 ━━━━━━━━━━━━━━━━━━━━ 03:31:58\n",
      "Accuracy: 0.9977 - Precision: 0.8830 - Recall: 0.8806 - Specificity: 0.9990 - F1: 0.8737 - Loss: 0.1415\n",
      "\n",
      "Batch 242/387 ━━━━━━━━━━━━━━━━━━━━ 03:33:32\n",
      "Accuracy: 0.9977 - Precision: 0.8833 - Recall: 0.8809 - Specificity: 0.9990 - F1: 0.8740 - Loss: 0.1412\n",
      "\n",
      "Batch 243/387 ━━━━━━━━━━━━━━━━━━━━ 03:34:56\n",
      "Accuracy: 0.9977 - Precision: 0.8821 - Recall: 0.8813 - Specificity: 0.9990 - F1: 0.8735 - Loss: 0.1417\n",
      "\n",
      "Batch 244/387 ━━━━━━━━━━━━━━━━━━━━ 03:36:27\n",
      "Accuracy: 0.9977 - Precision: 0.8809 - Recall: 0.8816 - Specificity: 0.9990 - F1: 0.8729 - Loss: 0.1423\n",
      "\n",
      "Batch 245/387 ━━━━━━━━━━━━━━━━━━━━ 03:38:05\n",
      "Accuracy: 0.9977 - Precision: 0.8813 - Recall: 0.8818 - Specificity: 0.9990 - F1: 0.8732 - Loss: 0.1420\n",
      "\n",
      "Batch 246/387 ━━━━━━━━━━━━━━━━━━━━ 03:39:28\n",
      "Accuracy: 0.9976 - Precision: 0.8817 - Recall: 0.8806 - Specificity: 0.9990 - F1: 0.8726 - Loss: 0.1427\n",
      "\n",
      "Batch 247/387 ━━━━━━━━━━━━━━━━━━━━ 03:40:50\n",
      "Accuracy: 0.9976 - Precision: 0.8818 - Recall: 0.8792 - Specificity: 0.9990 - F1: 0.8718 - Loss: 0.1435\n",
      "\n",
      "Batch 248/387 ━━━━━━━━━━━━━━━━━━━━ 03:42:18\n",
      "Accuracy: 0.9976 - Precision: 0.8816 - Recall: 0.8783 - Specificity: 0.9990 - F1: 0.8712 - Loss: 0.1442\n",
      "\n",
      "Batch 249/387 ━━━━━━━━━━━━━━━━━━━━ 03:43:40\n",
      "Accuracy: 0.9976 - Precision: 0.8812 - Recall: 0.8786 - Specificity: 0.9990 - F1: 0.8712 - Loss: 0.1442\n",
      "\n",
      "Batch 250/387 ━━━━━━━━━━━━━━━━━━━━ 03:45:03\n",
      "Accuracy: 0.9976 - Precision: 0.8806 - Recall: 0.8783 - Specificity: 0.9990 - F1: 0.8708 - Loss: 0.1446\n",
      "\n",
      "Batch 251/387 ━━━━━━━━━━━━━━━━━━━━ 03:46:34\n",
      "Accuracy: 0.9976 - Precision: 0.8811 - Recall: 0.8785 - Specificity: 0.9990 - F1: 0.8712 - Loss: 0.1442\n",
      "\n",
      "Batch 252/387 ━━━━━━━━━━━━━━━━━━━━ 03:47:56\n",
      "Accuracy: 0.9976 - Precision: 0.8814 - Recall: 0.8787 - Specificity: 0.9990 - F1: 0.8715 - Loss: 0.1439\n",
      "\n",
      "Batch 253/387 ━━━━━━━━━━━━━━━━━━━━ 03:49:39\n",
      "Accuracy: 0.9977 - Precision: 0.8811 - Recall: 0.8789 - Specificity: 0.9990 - F1: 0.8714 - Loss: 0.1439\n",
      "\n",
      "Batch 254/387 ━━━━━━━━━━━━━━━━━━━━ 03:51:08\n",
      "Accuracy: 0.9976 - Precision: 0.8813 - Recall: 0.8788 - Specificity: 0.9990 - F1: 0.8715 - Loss: 0.1439\n",
      "\n",
      "Batch 255/387 ━━━━━━━━━━━━━━━━━━━━ 03:52:30\n",
      "Accuracy: 0.9976 - Precision: 0.8808 - Recall: 0.8783 - Specificity: 0.9990 - F1: 0.8710 - Loss: 0.1443\n",
      "\n",
      "Batch 256/387 ━━━━━━━━━━━━━━━━━━━━ 03:53:59\n",
      "Accuracy: 0.9976 - Precision: 0.8799 - Recall: 0.8786 - Specificity: 0.9990 - F1: 0.8707 - Loss: 0.1447\n",
      "\n",
      "Batch 257/387 ━━━━━━━━━━━━━━━━━━━━ 03:55:29\n",
      "Accuracy: 0.9976 - Precision: 0.8803 - Recall: 0.8787 - Specificity: 0.9990 - F1: 0.8709 - Loss: 0.1444\n",
      "\n",
      "Batch 258/387 ━━━━━━━━━━━━━━━━━━━━ 03:57:02\n",
      "Accuracy: 0.9976 - Precision: 0.8806 - Recall: 0.8786 - Specificity: 0.9990 - F1: 0.8710 - Loss: 0.1444\n",
      "\n",
      "Batch 259/387 ━━━━━━━━━━━━━━━━━━━━ 03:58:32\n",
      "Accuracy: 0.9976 - Precision: 0.8807 - Recall: 0.8788 - Specificity: 0.9990 - F1: 0.8712 - Loss: 0.1441\n",
      "\n",
      "Batch 260/387 ━━━━━━━━━━━━━━━━━━━━ 04:00:10\n",
      "Accuracy: 0.9976 - Precision: 0.8810 - Recall: 0.8789 - Specificity: 0.9990 - F1: 0.8714 - Loss: 0.1438\n",
      "\n",
      "Batch 261/387 ━━━━━━━━━━━━━━━━━━━━ 04:01:28\n",
      "Accuracy: 0.9976 - Precision: 0.8812 - Recall: 0.8792 - Specificity: 0.9990 - F1: 0.8717 - Loss: 0.1436\n",
      "\n",
      "Batch 262/387 ━━━━━━━━━━━━━━━━━━━━ 04:03:13\n",
      "Accuracy: 0.9977 - Precision: 0.8812 - Recall: 0.8795 - Specificity: 0.9990 - F1: 0.8719 - Loss: 0.1433\n",
      "\n",
      "Batch 263/387 ━━━━━━━━━━━━━━━━━━━━ 04:04:49\n",
      "Accuracy: 0.9977 - Precision: 0.8814 - Recall: 0.8798 - Specificity: 0.9990 - F1: 0.8722 - Loss: 0.1430\n",
      "\n",
      "Batch 264/387 ━━━━━━━━━━━━━━━━━━━━ 04:06:10\n",
      "Accuracy: 0.9977 - Precision: 0.8813 - Recall: 0.8796 - Specificity: 0.9990 - F1: 0.8721 - Loss: 0.1431\n",
      "\n",
      "Batch 265/387 ━━━━━━━━━━━━━━━━━━━━ 04:07:41\n",
      "Accuracy: 0.9977 - Precision: 0.8815 - Recall: 0.8799 - Specificity: 0.9990 - F1: 0.8724 - Loss: 0.1428\n",
      "\n",
      "Batch 266/387 ━━━━━━━━━━━━━━━━━━━━ 04:09:20\n",
      "Accuracy: 0.9977 - Precision: 0.8818 - Recall: 0.8801 - Specificity: 0.9990 - F1: 0.8727 - Loss: 0.1425\n",
      "\n",
      "Batch 267/387 ━━━━━━━━━━━━━━━━━━━━ 04:10:50\n",
      "Accuracy: 0.9977 - Precision: 0.8818 - Recall: 0.8804 - Specificity: 0.9990 - F1: 0.8728 - Loss: 0.1423\n",
      "\n",
      "Batch 268/387 ━━━━━━━━━━━━━━━━━━━━ 04:12:39\n",
      "Accuracy: 0.9977 - Precision: 0.8818 - Recall: 0.8804 - Specificity: 0.9990 - F1: 0.8728 - Loss: 0.1423\n",
      "\n",
      "Batch 269/387 ━━━━━━━━━━━━━━━━━━━━ 04:14:07\n",
      "Accuracy: 0.9977 - Precision: 0.8817 - Recall: 0.8806 - Specificity: 0.9990 - F1: 0.8729 - Loss: 0.1422\n",
      "\n",
      "Batch 270/387 ━━━━━━━━━━━━━━━━━━━━ 04:15:40\n",
      "Accuracy: 0.9977 - Precision: 0.8817 - Recall: 0.8800 - Specificity: 0.9990 - F1: 0.8726 - Loss: 0.1425\n",
      "\n",
      "Batch 271/387 ━━━━━━━━━━━━━━━━━━━━ 04:17:04\n",
      "Accuracy: 0.9977 - Precision: 0.8817 - Recall: 0.8802 - Specificity: 0.9990 - F1: 0.8728 - Loss: 0.1424\n",
      "\n",
      "Batch 272/387 ━━━━━━━━━━━━━━━━━━━━ 04:18:27\n",
      "Accuracy: 0.9977 - Precision: 0.8820 - Recall: 0.8804 - Specificity: 0.9990 - F1: 0.8730 - Loss: 0.1421\n",
      "\n",
      "Batch 273/387 ━━━━━━━━━━━━━━━━━━━━ 04:20:02\n",
      "Accuracy: 0.9977 - Precision: 0.8823 - Recall: 0.8806 - Specificity: 0.9990 - F1: 0.8733 - Loss: 0.1418\n",
      "\n",
      "Batch 274/387 ━━━━━━━━━━━━━━━━━━━━ 04:21:33\n",
      "Accuracy: 0.9977 - Precision: 0.8826 - Recall: 0.8807 - Specificity: 0.9990 - F1: 0.8735 - Loss: 0.1415\n",
      "\n",
      "Batch 275/387 ━━━━━━━━━━━━━━━━━━━━ 04:22:55\n",
      "Accuracy: 0.9977 - Precision: 0.8824 - Recall: 0.8806 - Specificity: 0.9990 - F1: 0.8734 - Loss: 0.1417\n",
      "\n",
      "Batch 276/387 ━━━━━━━━━━━━━━━━━━━━ 04:24:25\n",
      "Accuracy: 0.9977 - Precision: 0.8826 - Recall: 0.8806 - Specificity: 0.9990 - F1: 0.8735 - Loss: 0.1416\n",
      "\n",
      "Batch 277/387 ━━━━━━━━━━━━━━━━━━━━ 04:25:45\n",
      "Accuracy: 0.9977 - Precision: 0.8830 - Recall: 0.8804 - Specificity: 0.9990 - F1: 0.8736 - Loss: 0.1415\n",
      "\n",
      "Batch 278/387 ━━━━━━━━━━━━━━━━━━━━ 04:27:08\n",
      "Accuracy: 0.9977 - Precision: 0.8831 - Recall: 0.8802 - Specificity: 0.9990 - F1: 0.8736 - Loss: 0.1416\n",
      "\n",
      "Batch 279/387 ━━━━━━━━━━━━━━━━━━━━ 04:28:45\n",
      "Accuracy: 0.9977 - Precision: 0.8832 - Recall: 0.8804 - Specificity: 0.9990 - F1: 0.8738 - Loss: 0.1413\n",
      "\n",
      "Batch 280/387 ━━━━━━━━━━━━━━━━━━━━ 04:30:31\n",
      "Accuracy: 0.9977 - Precision: 0.8828 - Recall: 0.8808 - Specificity: 0.9990 - F1: 0.8737 - Loss: 0.1414\n",
      "\n",
      "Batch 281/387 ━━━━━━━━━━━━━━━━━━━━ 04:32:04\n",
      "Accuracy: 0.9977 - Precision: 0.8828 - Recall: 0.8809 - Specificity: 0.9990 - F1: 0.8738 - Loss: 0.1412\n",
      "\n",
      "Batch 282/387 ━━━━━━━━━━━━━━━━━━━━ 04:33:33\n",
      "Accuracy: 0.9977 - Precision: 0.8831 - Recall: 0.8808 - Specificity: 0.9990 - F1: 0.8740 - Loss: 0.1411\n",
      "\n",
      "Batch 283/387 ━━━━━━━━━━━━━━━━━━━━ 04:35:11\n",
      "Accuracy: 0.9977 - Precision: 0.8826 - Recall: 0.8811 - Specificity: 0.9990 - F1: 0.8738 - Loss: 0.1413\n",
      "\n",
      "Batch 284/387 ━━━━━━━━━━━━━━━━━━━━ 04:36:41\n",
      "Accuracy: 0.9977 - Precision: 0.8819 - Recall: 0.8815 - Specificity: 0.9990 - F1: 0.8736 - Loss: 0.1415\n",
      "\n",
      "Batch 285/387 ━━━━━━━━━━━━━━━━━━━━ 04:38:08\n",
      "Accuracy: 0.9977 - Precision: 0.8815 - Recall: 0.8816 - Specificity: 0.9990 - F1: 0.8734 - Loss: 0.1417\n",
      "\n",
      "Batch 286/387 ━━━━━━━━━━━━━━━━━━━━ 04:39:41\n",
      "Accuracy: 0.9976 - Precision: 0.8817 - Recall: 0.8813 - Specificity: 0.9990 - F1: 0.8734 - Loss: 0.1418\n",
      "\n",
      "Batch 287/387 ━━━━━━━━━━━━━━━━━━━━ 04:41:01\n",
      "Accuracy: 0.9976 - Precision: 0.8821 - Recall: 0.8807 - Specificity: 0.9990 - F1: 0.8732 - Loss: 0.1421\n",
      "\n",
      "Batch 288/387 ━━━━━━━━━━━━━━━━━━━━ 04:42:26\n",
      "Accuracy: 0.9976 - Precision: 0.8823 - Recall: 0.8809 - Specificity: 0.9990 - F1: 0.8735 - Loss: 0.1418\n",
      "\n",
      "Batch 289/387 ━━━━━━━━━━━━━━━━━━━━ 04:43:58\n",
      "Accuracy: 0.9976 - Precision: 0.8825 - Recall: 0.8811 - Specificity: 0.9990 - F1: 0.8738 - Loss: 0.1415\n",
      "\n",
      "Batch 290/387 ━━━━━━━━━━━━━━━━━━━━ 04:45:23\n",
      "Accuracy: 0.9976 - Precision: 0.8828 - Recall: 0.8803 - Specificity: 0.9990 - F1: 0.8733 - Loss: 0.1419\n",
      "\n",
      "Batch 291/387 ━━━━━━━━━━━━━━━━━━━━ 04:46:56\n",
      "Accuracy: 0.9976 - Precision: 0.8821 - Recall: 0.8790 - Specificity: 0.9990 - F1: 0.8723 - Loss: 0.1430\n",
      "\n",
      "Batch 292/387 ━━━━━━━━━━━━━━━━━━━━ 04:48:41\n",
      "Accuracy: 0.9976 - Precision: 0.8823 - Recall: 0.8792 - Specificity: 0.9990 - F1: 0.8726 - Loss: 0.1427\n",
      "\n",
      "Batch 293/387 ━━━━━━━━━━━━━━━━━━━━ 04:50:18\n",
      "Accuracy: 0.9976 - Precision: 0.8826 - Recall: 0.8794 - Specificity: 0.9990 - F1: 0.8729 - Loss: 0.1424\n",
      "\n",
      "Batch 294/387 ━━━━━━━━━━━━━━━━━━━━ 04:51:50\n",
      "Accuracy: 0.9976 - Precision: 0.8824 - Recall: 0.8796 - Specificity: 0.9990 - F1: 0.8729 - Loss: 0.1423\n",
      "\n",
      "Batch 295/387 ━━━━━━━━━━━━━━━━━━━━ 04:53:19\n",
      "Accuracy: 0.9976 - Precision: 0.8818 - Recall: 0.8797 - Specificity: 0.9990 - F1: 0.8726 - Loss: 0.1427\n",
      "\n",
      "Batch 296/387 ━━━━━━━━━━━━━━━━━━━━ 04:54:42\n",
      "Accuracy: 0.9976 - Precision: 0.8810 - Recall: 0.8794 - Specificity: 0.9990 - F1: 0.8721 - Loss: 0.1433\n",
      "\n",
      "Batch 297/387 ━━━━━━━━━━━━━━━━━━━━ 04:56:09\n",
      "Accuracy: 0.9976 - Precision: 0.8809 - Recall: 0.8798 - Specificity: 0.9990 - F1: 0.8722 - Loss: 0.1431\n",
      "\n",
      "Batch 298/387 ━━━━━━━━━━━━━━━━━━━━ 04:57:44\n",
      "Accuracy: 0.9976 - Precision: 0.8812 - Recall: 0.8801 - Specificity: 0.9990 - F1: 0.8725 - Loss: 0.1428\n",
      "\n",
      "Batch 299/387 ━━━━━━━━━━━━━━━━━━━━ 04:59:03\n",
      "Accuracy: 0.9976 - Precision: 0.8814 - Recall: 0.8799 - Specificity: 0.9990 - F1: 0.8726 - Loss: 0.1428\n",
      "\n",
      "Batch 300/387 ━━━━━━━━━━━━━━━━━━━━ 05:00:28\n",
      "Accuracy: 0.9976 - Precision: 0.8817 - Recall: 0.8795 - Specificity: 0.9990 - F1: 0.8725 - Loss: 0.1429\n",
      "\n",
      "Batch 301/387 ━━━━━━━━━━━━━━━━━━━━ 05:01:54\n",
      "Accuracy: 0.9976 - Precision: 0.8818 - Recall: 0.8798 - Specificity: 0.9990 - F1: 0.8727 - Loss: 0.1426\n",
      "\n",
      "Batch 302/387 ━━━━━━━━━━━━━━━━━━━━ 05:03:22\n",
      "Accuracy: 0.9976 - Precision: 0.8819 - Recall: 0.8799 - Specificity: 0.9990 - F1: 0.8728 - Loss: 0.1425\n",
      "\n",
      "Batch 303/387 ━━━━━━━━━━━━━━━━━━━━ 05:04:50\n",
      "Accuracy: 0.9976 - Precision: 0.8819 - Recall: 0.8801 - Specificity: 0.9990 - F1: 0.8730 - Loss: 0.1423\n",
      "\n",
      "Batch 304/387 ━━━━━━━━━━━━━━━━━━━━ 05:06:20\n",
      "Accuracy: 0.9976 - Precision: 0.8821 - Recall: 0.8799 - Specificity: 0.9990 - F1: 0.8730 - Loss: 0.1424\n",
      "\n",
      "Batch 305/387 ━━━━━━━━━━━━━━━━━━━━ 05:07:51\n",
      "Accuracy: 0.9976 - Precision: 0.8820 - Recall: 0.8801 - Specificity: 0.9990 - F1: 0.8731 - Loss: 0.1422\n",
      "\n",
      "Batch 306/387 ━━━━━━━━━━━━━━━━━━━━ 05:09:20\n",
      "Accuracy: 0.9976 - Precision: 0.8821 - Recall: 0.8803 - Specificity: 0.9990 - F1: 0.8732 - Loss: 0.1421\n",
      "\n",
      "Batch 307/387 ━━━━━━━━━━━━━━━━━━━━ 05:10:48\n",
      "Accuracy: 0.9976 - Precision: 0.8822 - Recall: 0.8806 - Specificity: 0.9990 - F1: 0.8734 - Loss: 0.1418\n",
      "\n",
      "Batch 308/387 ━━━━━━━━━━━━━━━━━━━━ 05:12:19\n",
      "Accuracy: 0.9976 - Precision: 0.8824 - Recall: 0.8808 - Specificity: 0.9990 - F1: 0.8737 - Loss: 0.1416\n",
      "\n",
      "Batch 309/387 ━━━━━━━━━━━━━━━━━━━━ 05:13:42\n",
      "Accuracy: 0.9976 - Precision: 0.8825 - Recall: 0.8809 - Specificity: 0.9990 - F1: 0.8738 - Loss: 0.1415\n",
      "\n",
      "Batch 310/387 ━━━━━━━━━━━━━━━━━━━━ 05:15:04\n",
      "Accuracy: 0.9976 - Precision: 0.8826 - Recall: 0.8810 - Specificity: 0.9990 - F1: 0.8739 - Loss: 0.1413\n",
      "\n",
      "Batch 311/387 ━━━━━━━━━━━━━━━━━━━━ 05:16:37\n",
      "Accuracy: 0.9976 - Precision: 0.8825 - Recall: 0.8814 - Specificity: 0.9990 - F1: 0.8741 - Loss: 0.1411\n",
      "\n",
      "Batch 312/387 ━━━━━━━━━━━━━━━━━━━━ 05:18:18\n",
      "Accuracy: 0.9976 - Precision: 0.8823 - Recall: 0.8814 - Specificity: 0.9990 - F1: 0.8740 - Loss: 0.1412\n",
      "\n",
      "Batch 313/387 ━━━━━━━━━━━━━━━━━━━━ 05:19:49\n",
      "Accuracy: 0.9976 - Precision: 0.8822 - Recall: 0.8817 - Specificity: 0.9990 - F1: 0.8741 - Loss: 0.1411\n",
      "\n",
      "Batch 314/387 ━━━━━━━━━━━━━━━━━━━━ 05:21:15\n",
      "Accuracy: 0.9976 - Precision: 0.8818 - Recall: 0.8820 - Specificity: 0.9990 - F1: 0.8740 - Loss: 0.1412\n",
      "\n",
      "Batch 315/387 ━━━━━━━━━━━━━━━━━━━━ 05:22:47\n",
      "Accuracy: 0.9976 - Precision: 0.8820 - Recall: 0.8814 - Specificity: 0.9990 - F1: 0.8738 - Loss: 0.1414\n",
      "\n",
      "Batch 316/387 ━━━━━━━━━━━━━━━━━━━━ 05:24:20\n",
      "Accuracy: 0.9976 - Precision: 0.8822 - Recall: 0.8816 - Specificity: 0.9990 - F1: 0.8741 - Loss: 0.1411\n",
      "\n",
      "Batch 317/387 ━━━━━━━━━━━━━━━━━━━━ 05:25:52\n",
      "Accuracy: 0.9976 - Precision: 0.8825 - Recall: 0.8814 - Specificity: 0.9990 - F1: 0.8741 - Loss: 0.1411\n",
      "\n",
      "Batch 318/387 ━━━━━━━━━━━━━━━━━━━━ 05:27:25\n",
      "Accuracy: 0.9976 - Precision: 0.8827 - Recall: 0.8814 - Specificity: 0.9990 - F1: 0.8742 - Loss: 0.1410\n",
      "\n",
      "Batch 319/387 ━━━━━━━━━━━━━━━━━━━━ 05:28:52\n",
      "Accuracy: 0.9976 - Precision: 0.8829 - Recall: 0.8812 - Specificity: 0.9990 - F1: 0.8742 - Loss: 0.1410\n",
      "\n",
      "Batch 320/387 ━━━━━━━━━━━━━━━━━━━━ 05:30:20\n",
      "Accuracy: 0.9976 - Precision: 0.8829 - Recall: 0.8809 - Specificity: 0.9990 - F1: 0.8741 - Loss: 0.1411\n",
      "\n",
      "Batch 321/387 ━━━━━━━━━━━━━━━━━━━━ 05:31:46\n",
      "Accuracy: 0.9976 - Precision: 0.8832 - Recall: 0.8807 - Specificity: 0.9990 - F1: 0.8741 - Loss: 0.1411\n",
      "\n",
      "Batch 322/387 ━━━━━━━━━━━━━━━━━━━━ 05:33:05\n",
      "Accuracy: 0.9976 - Precision: 0.8821 - Recall: 0.8805 - Specificity: 0.9990 - F1: 0.8734 - Loss: 0.1418\n",
      "\n",
      "Batch 323/387 ━━━━━━━━━━━━━━━━━━━━ 05:34:24\n",
      "Accuracy: 0.9976 - Precision: 0.8823 - Recall: 0.8807 - Specificity: 0.9990 - F1: 0.8736 - Loss: 0.1416\n",
      "\n",
      "Batch 324/387 ━━━━━━━━━━━━━━━━━━━━ 05:35:49\n",
      "Accuracy: 0.9976 - Precision: 0.8825 - Recall: 0.8810 - Specificity: 0.9990 - F1: 0.8739 - Loss: 0.1413\n",
      "\n",
      "Batch 325/387 ━━━━━━━━━━━━━━━━━━━━ 05:37:13\n",
      "Accuracy: 0.9977 - Precision: 0.8827 - Recall: 0.8812 - Specificity: 0.9990 - F1: 0.8741 - Loss: 0.1410\n",
      "\n",
      "Batch 326/387 ━━━━━━━━━━━━━━━━━━━━ 05:38:48\n",
      "Accuracy: 0.9977 - Precision: 0.8823 - Recall: 0.8814 - Specificity: 0.9990 - F1: 0.8741 - Loss: 0.1411\n",
      "\n",
      "Batch 327/387 ━━━━━━━━━━━━━━━━━━━━ 05:40:20\n",
      "Accuracy: 0.9977 - Precision: 0.8819 - Recall: 0.8814 - Specificity: 0.9990 - F1: 0.8738 - Loss: 0.1413\n",
      "\n",
      "Batch 328/387 ━━━━━━━━━━━━━━━━━━━━ 05:41:50\n",
      "Accuracy: 0.9977 - Precision: 0.8822 - Recall: 0.8815 - Specificity: 0.9990 - F1: 0.8741 - Loss: 0.1411\n",
      "\n",
      "Batch 329/387 ━━━━━━━━━━━━━━━━━━━━ 05:43:10\n",
      "Accuracy: 0.9977 - Precision: 0.8823 - Recall: 0.8815 - Specificity: 0.9990 - F1: 0.8742 - Loss: 0.1410\n",
      "\n",
      "Batch 330/387 ━━━━━━━━━━━━━━━━━━━━ 05:44:29\n",
      "Accuracy: 0.9977 - Precision: 0.8826 - Recall: 0.8817 - Specificity: 0.9990 - F1: 0.8744 - Loss: 0.1407\n",
      "\n",
      "Batch 331/387 ━━━━━━━━━━━━━━━━━━━━ 05:45:52\n",
      "Accuracy: 0.9977 - Precision: 0.8827 - Recall: 0.8818 - Specificity: 0.9990 - F1: 0.8746 - Loss: 0.1406\n",
      "\n",
      "Batch 332/387 ━━━━━━━━━━━━━━━━━━━━ 05:47:16\n",
      "Accuracy: 0.9977 - Precision: 0.8831 - Recall: 0.8816 - Specificity: 0.9990 - F1: 0.8746 - Loss: 0.1405\n",
      "\n",
      "Batch 333/387 ━━━━━━━━━━━━━━━━━━━━ 05:48:43\n",
      "Accuracy: 0.9977 - Precision: 0.8833 - Recall: 0.8818 - Specificity: 0.9990 - F1: 0.8749 - Loss: 0.1402\n",
      "\n",
      "Batch 334/387 ━━━━━━━━━━━━━━━━━━━━ 05:50:06\n",
      "Accuracy: 0.9977 - Precision: 0.8837 - Recall: 0.8816 - Specificity: 0.9990 - F1: 0.8749 - Loss: 0.1402\n",
      "\n",
      "Batch 335/387 ━━━━━━━━━━━━━━━━━━━━ 05:51:45\n",
      "Accuracy: 0.9977 - Precision: 0.8839 - Recall: 0.8816 - Specificity: 0.9990 - F1: 0.8751 - Loss: 0.1400\n",
      "\n",
      "Batch 336/387 ━━━━━━━━━━━━━━━━━━━━ 05:53:16\n",
      "Accuracy: 0.9977 - Precision: 0.8842 - Recall: 0.8817 - Specificity: 0.9990 - F1: 0.8753 - Loss: 0.1398\n",
      "\n",
      "Batch 337/387 ━━━━━━━━━━━━━━━━━━━━ 05:54:44\n",
      "Accuracy: 0.9977 - Precision: 0.8837 - Recall: 0.8819 - Specificity: 0.9990 - F1: 0.8751 - Loss: 0.1399\n",
      "\n",
      "Batch 338/387 ━━━━━━━━━━━━━━━━━━━━ 05:56:14\n",
      "Accuracy: 0.9977 - Precision: 0.8832 - Recall: 0.8822 - Specificity: 0.9990 - F1: 0.8749 - Loss: 0.1401\n",
      "\n",
      "Batch 339/387 ━━━━━━━━━━━━━━━━━━━━ 05:57:37\n",
      "Accuracy: 0.9977 - Precision: 0.8829 - Recall: 0.8822 - Specificity: 0.9990 - F1: 0.8748 - Loss: 0.1403\n",
      "\n",
      "Batch 340/387 ━━━━━━━━━━━━━━━━━━━━ 05:59:05\n",
      "Accuracy: 0.9977 - Precision: 0.8831 - Recall: 0.8822 - Specificity: 0.9990 - F1: 0.8749 - Loss: 0.1402\n",
      "\n",
      "Batch 341/387 ━━━━━━━━━━━━━━━━━━━━ 06:00:29\n",
      "Accuracy: 0.9977 - Precision: 0.8833 - Recall: 0.8824 - Specificity: 0.9990 - F1: 0.8752 - Loss: 0.1399\n",
      "\n",
      "Batch 342/387 ━━━━━━━━━━━━━━━━━━━━ 06:02:07\n",
      "Accuracy: 0.9977 - Precision: 0.8832 - Recall: 0.8820 - Specificity: 0.9990 - F1: 0.8749 - Loss: 0.1401\n",
      "\n",
      "Batch 343/387 ━━━━━━━━━━━━━━━━━━━━ 06:03:36\n",
      "Accuracy: 0.9977 - Precision: 0.8835 - Recall: 0.8822 - Specificity: 0.9990 - F1: 0.8752 - Loss: 0.1398\n",
      "\n",
      "Batch 344/387 ━━━━━━━━━━━━━━━━━━━━ 06:04:57\n",
      "Accuracy: 0.9977 - Precision: 0.8837 - Recall: 0.8824 - Specificity: 0.9990 - F1: 0.8754 - Loss: 0.1396\n",
      "\n",
      "Batch 345/387 ━━━━━━━━━━━━━━━━━━━━ 06:06:14\n",
      "Accuracy: 0.9977 - Precision: 0.8837 - Recall: 0.8820 - Specificity: 0.9990 - F1: 0.8752 - Loss: 0.1398\n",
      "\n",
      "Batch 346/387 ━━━━━━━━━━━━━━━━━━━━ 06:07:47\n",
      "Accuracy: 0.9977 - Precision: 0.8839 - Recall: 0.8821 - Specificity: 0.9990 - F1: 0.8754 - Loss: 0.1396\n",
      "\n",
      "Batch 347/387 ━━━━━━━━━━━━━━━━━━━━ 06:09:18\n",
      "Accuracy: 0.9977 - Precision: 0.8841 - Recall: 0.8822 - Specificity: 0.9990 - F1: 0.8756 - Loss: 0.1394\n",
      "\n",
      "Batch 348/387 ━━━━━━━━━━━━━━━━━━━━ 06:10:49\n",
      "Accuracy: 0.9977 - Precision: 0.8841 - Recall: 0.8822 - Specificity: 0.9990 - F1: 0.8756 - Loss: 0.1394\n",
      "\n",
      "Batch 349/387 ━━━━━━━━━━━━━━━━━━━━ 06:12:22\n",
      "Accuracy: 0.9977 - Precision: 0.8842 - Recall: 0.8813 - Specificity: 0.9990 - F1: 0.8751 - Loss: 0.1398\n",
      "\n",
      "Batch 350/387 ━━━━━━━━━━━━━━━━━━━━ 06:13:48\n",
      "Accuracy: 0.9977 - Precision: 0.8845 - Recall: 0.8815 - Specificity: 0.9990 - F1: 0.8754 - Loss: 0.1396\n",
      "\n",
      "Batch 351/387 ━━━━━━━━━━━━━━━━━━━━ 06:15:16\n",
      "Accuracy: 0.9977 - Precision: 0.8847 - Recall: 0.8818 - Specificity: 0.9990 - F1: 0.8756 - Loss: 0.1393\n",
      "\n",
      "Batch 352/387 ━━━━━━━━━━━━━━━━━━━━ 06:16:47\n",
      "Accuracy: 0.9977 - Precision: 0.8847 - Recall: 0.8819 - Specificity: 0.9990 - F1: 0.8757 - Loss: 0.1392\n",
      "\n",
      "Batch 353/387 ━━━━━━━━━━━━━━━━━━━━ 06:18:27\n",
      "Accuracy: 0.9977 - Precision: 0.8848 - Recall: 0.8821 - Specificity: 0.9990 - F1: 0.8759 - Loss: 0.1390\n",
      "\n",
      "Batch 354/387 ━━━━━━━━━━━━━━━━━━━━ 06:19:51\n",
      "Accuracy: 0.9977 - Precision: 0.8842 - Recall: 0.8821 - Specificity: 0.9990 - F1: 0.8756 - Loss: 0.1394\n",
      "\n",
      "Batch 355/387 ━━━━━━━━━━━━━━━━━━━━ 06:21:46\n",
      "Accuracy: 0.9977 - Precision: 0.8842 - Recall: 0.8823 - Specificity: 0.9990 - F1: 0.8757 - Loss: 0.1392\n",
      "\n",
      "Batch 356/387 ━━━━━━━━━━━━━━━━━━━━ 06:23:25\n",
      "Accuracy: 0.9977 - Precision: 0.8845 - Recall: 0.8823 - Specificity: 0.9990 - F1: 0.8758 - Loss: 0.1391\n",
      "\n",
      "Batch 357/387 ━━━━━━━━━━━━━━━━━━━━ 06:24:58\n",
      "Accuracy: 0.9977 - Precision: 0.8846 - Recall: 0.8824 - Specificity: 0.9990 - F1: 0.8759 - Loss: 0.1390\n",
      "\n",
      "Batch 358/387 ━━━━━━━━━━━━━━━━━━━━ 06:26:22\n",
      "Accuracy: 0.9977 - Precision: 0.8848 - Recall: 0.8823 - Specificity: 0.9990 - F1: 0.8761 - Loss: 0.1389\n",
      "\n",
      "Batch 359/387 ━━━━━━━━━━━━━━━━━━━━ 06:27:42\n",
      "Accuracy: 0.9977 - Precision: 0.8847 - Recall: 0.8824 - Specificity: 0.9990 - F1: 0.8760 - Loss: 0.1389\n",
      "\n",
      "Batch 360/387 ━━━━━━━━━━━━━━━━━━━━ 06:29:13\n",
      "Accuracy: 0.9977 - Precision: 0.8836 - Recall: 0.8827 - Specificity: 0.9990 - F1: 0.8754 - Loss: 0.1396\n",
      "\n",
      "Batch 361/387 ━━━━━━━━━━━━━━━━━━━━ 06:30:37\n",
      "Accuracy: 0.9977 - Precision: 0.8837 - Recall: 0.8821 - Specificity: 0.9990 - F1: 0.8751 - Loss: 0.1400\n",
      "\n",
      "Batch 362/387 ━━━━━━━━━━━━━━━━━━━━ 06:32:12\n",
      "Accuracy: 0.9977 - Precision: 0.8839 - Recall: 0.8822 - Specificity: 0.9990 - F1: 0.8753 - Loss: 0.1398\n",
      "\n",
      "Batch 363/387 ━━━━━━━━━━━━━━━━━━━━ 06:33:45\n",
      "Accuracy: 0.9977 - Precision: 0.8840 - Recall: 0.8824 - Specificity: 0.9990 - F1: 0.8755 - Loss: 0.1396\n",
      "\n",
      "Batch 364/387 ━━━━━━━━━━━━━━━━━━━━ 06:35:11\n",
      "Accuracy: 0.9977 - Precision: 0.8839 - Recall: 0.8825 - Specificity: 0.9990 - F1: 0.8754 - Loss: 0.1397\n",
      "\n",
      "Batch 365/387 ━━━━━━━━━━━━━━━━━━━━ 06:36:43\n",
      "Accuracy: 0.9977 - Precision: 0.8841 - Recall: 0.8826 - Specificity: 0.9990 - F1: 0.8756 - Loss: 0.1394\n",
      "\n",
      "Batch 366/387 ━━━━━━━━━━━━━━━━━━━━ 06:38:15\n",
      "Accuracy: 0.9977 - Precision: 0.8842 - Recall: 0.8827 - Specificity: 0.9990 - F1: 0.8758 - Loss: 0.1393\n",
      "\n",
      "Batch 367/387 ━━━━━━━━━━━━━━━━━━━━ 06:39:39\n",
      "Accuracy: 0.9977 - Precision: 0.8842 - Recall: 0.8828 - Specificity: 0.9990 - F1: 0.8758 - Loss: 0.1392\n",
      "\n",
      "Batch 368/387 ━━━━━━━━━━━━━━━━━━━━ 06:41:13\n",
      "Accuracy: 0.9977 - Precision: 0.8842 - Recall: 0.8830 - Specificity: 0.9990 - F1: 0.8760 - Loss: 0.1391\n",
      "\n",
      "Batch 369/387 ━━━━━━━━━━━━━━━━━━━━ 06:42:39\n",
      "Accuracy: 0.9977 - Precision: 0.8837 - Recall: 0.8826 - Specificity: 0.9990 - F1: 0.8755 - Loss: 0.1395\n",
      "\n",
      "Batch 370/387 ━━━━━━━━━━━━━━━━━━━━ 06:44:12\n",
      "Accuracy: 0.9977 - Precision: 0.8840 - Recall: 0.8824 - Specificity: 0.9990 - F1: 0.8756 - Loss: 0.1395\n",
      "\n",
      "Batch 371/387 ━━━━━━━━━━━━━━━━━━━━ 06:45:49\n",
      "Accuracy: 0.9977 - Precision: 0.8842 - Recall: 0.8824 - Specificity: 0.9990 - F1: 0.8757 - Loss: 0.1393\n",
      "\n",
      "Batch 372/387 ━━━━━━━━━━━━━━━━━━━━ 06:47:16\n",
      "Accuracy: 0.9977 - Precision: 0.8845 - Recall: 0.8822 - Specificity: 0.9990 - F1: 0.8758 - Loss: 0.1393\n",
      "\n",
      "Batch 373/387 ━━━━━━━━━━━━━━━━━━━━ 06:48:44\n",
      "Accuracy: 0.9977 - Precision: 0.8848 - Recall: 0.8821 - Specificity: 0.9990 - F1: 0.8758 - Loss: 0.1392\n",
      "\n",
      "Batch 374/387 ━━━━━━━━━━━━━━━━━━━━ 06:50:17\n",
      "Accuracy: 0.9977 - Precision: 0.8848 - Recall: 0.8822 - Specificity: 0.9990 - F1: 0.8759 - Loss: 0.1391\n",
      "\n",
      "Batch 375/387 ━━━━━━━━━━━━━━━━━━━━ 06:51:37\n",
      "Accuracy: 0.9977 - Precision: 0.8850 - Recall: 0.8822 - Specificity: 0.9990 - F1: 0.8760 - Loss: 0.1391\n",
      "\n",
      "Batch 376/387 ━━━━━━━━━━━━━━━━━━━━ 06:53:05\n",
      "Accuracy: 0.9977 - Precision: 0.8851 - Recall: 0.8823 - Specificity: 0.9990 - F1: 0.8762 - Loss: 0.1389\n",
      "\n",
      "Batch 377/387 ━━━━━━━━━━━━━━━━━━━━ 06:54:38\n",
      "Accuracy: 0.9977 - Precision: 0.8852 - Recall: 0.8824 - Specificity: 0.9990 - F1: 0.8763 - Loss: 0.1388\n",
      "\n",
      "Batch 378/387 ━━━━━━━━━━━━━━━━━━━━ 06:56:05\n",
      "Accuracy: 0.9977 - Precision: 0.8849 - Recall: 0.8825 - Specificity: 0.9990 - F1: 0.8762 - Loss: 0.1389\n",
      "\n",
      "Batch 379/387 ━━━━━━━━━━━━━━━━━━━━ 06:57:42\n",
      "Accuracy: 0.9977 - Precision: 0.8850 - Recall: 0.8827 - Specificity: 0.9990 - F1: 0.8763 - Loss: 0.1387\n",
      "\n",
      "Batch 380/387 ━━━━━━━━━━━━━━━━━━━━ 06:59:07\n",
      "Accuracy: 0.9977 - Precision: 0.8848 - Recall: 0.8822 - Specificity: 0.9990 - F1: 0.8760 - Loss: 0.1391\n",
      "\n",
      "Batch 381/387 ━━━━━━━━━━━━━━━━━━━━ 07:00:46\n",
      "Accuracy: 0.9977 - Precision: 0.8851 - Recall: 0.8824 - Specificity: 0.9990 - F1: 0.8763 - Loss: 0.1388\n",
      "\n",
      "Batch 382/387 ━━━━━━━━━━━━━━━━━━━━ 07:02:19\n",
      "Accuracy: 0.9977 - Precision: 0.8854 - Recall: 0.8820 - Specificity: 0.9990 - F1: 0.8762 - Loss: 0.1390\n",
      "\n",
      "Batch 383/387 ━━━━━━━━━━━━━━━━━━━━ 07:03:53\n",
      "Accuracy: 0.9977 - Precision: 0.8854 - Recall: 0.8821 - Specificity: 0.9990 - F1: 0.8763 - Loss: 0.1388\n",
      "\n",
      "Batch 384/387 ━━━━━━━━━━━━━━━━━━━━ 07:05:25\n",
      "Accuracy: 0.9977 - Precision: 0.8854 - Recall: 0.8821 - Specificity: 0.9990 - F1: 0.8763 - Loss: 0.1388\n",
      "\n",
      "Batch 385/387 ━━━━━━━━━━━━━━━━━━━━ 07:07:03\n",
      "Accuracy: 0.9977 - Precision: 0.8855 - Recall: 0.8822 - Specificity: 0.9990 - F1: 0.8764 - Loss: 0.1387\n",
      "\n",
      "Batch 386/387 ━━━━━━━━━━━━━━━━━━━━ 07:08:27\n",
      "Accuracy: 0.9977 - Precision: 0.8856 - Recall: 0.8822 - Specificity: 0.9990 - F1: 0.8764 - Loss: 0.1387\n",
      "\n",
      "Batch 387/387 ━━━━━━━━━━━━━━━━━━━━ 07:09:58\n",
      "Accuracy: 0.9977 - Precision: 0.8856 - Recall: 0.8824 - Specificity: 0.9990 - F1: 0.8766 - Loss: 0.1385\n",
      "\n",
      "End of Epoch 6\n",
      "\n",
      "Epoch 7/50\n",
      "Batch 1/387 ━━━━━━━━━━━━━━━━━━━━ 08:55:10\n",
      "Accuracy: 0.9990 - Precision: 0.8580 - Recall: 0.9559 - Specificity: 0.9992 - F1: 0.9043 - Loss: 0.1047\n",
      "\n",
      "Batch 2/387 ━━━━━━━━━━━━━━━━━━━━ 08:56:55\n",
      "Accuracy: 0.9985 - Precision: 0.8760 - Recall: 0.9643 - Specificity: 0.9988 - F1: 0.9180 - Loss: 0.0918\n",
      "\n",
      "Batch 3/387 ━━━━━━━━━━━━━━━━━━━━ 08:58:38\n",
      "Accuracy: 0.9987 - Precision: 0.8467 - Recall: 0.9057 - Specificity: 0.9990 - F1: 0.8748 - Loss: 0.1354\n",
      "\n",
      "Batch 4/387 ━━━━━━━━━━━━━━━━━━━━ 09:00:11\n",
      "Accuracy: 0.9988 - Precision: 0.8779 - Recall: 0.9137 - Specificity: 0.9992 - F1: 0.8946 - Loss: 0.1148\n",
      "\n",
      "Batch 5/387 ━━━━━━━━━━━━━━━━━━━━ 09:01:45\n",
      "Accuracy: 0.9988 - Precision: 0.8942 - Recall: 0.9038 - Specificity: 0.9993 - F1: 0.8976 - Loss: 0.1117\n",
      "\n",
      "Batch 6/387 ━━━━━━━━━━━━━━━━━━━━ 09:03:17\n",
      "Accuracy: 0.9980 - Precision: 0.9048 - Recall: 0.8778 - Specificity: 0.9993 - F1: 0.8880 - Loss: 0.1257\n",
      "\n",
      "Batch 7/387 ━━━━━━━━━━━━━━━━━━━━ 09:04:50\n",
      "Accuracy: 0.9980 - Precision: 0.9019 - Recall: 0.8868 - Specificity: 0.9992 - F1: 0.8914 - Loss: 0.1221\n",
      "\n",
      "Batch 8/387 ━━━━━━━━━━━━━━━━━━━━ 09:06:24\n",
      "Accuracy: 0.9978 - Precision: 0.9115 - Recall: 0.8819 - Specificity: 0.9992 - F1: 0.8935 - Loss: 0.1205\n",
      "\n",
      "Batch 9/387 ━━━━━━━━━━━━━━━━━━━━ 09:08:02\n",
      "Accuracy: 0.9976 - Precision: 0.9057 - Recall: 0.8549 - Specificity: 0.9992 - F1: 0.8756 - Loss: 0.1393\n",
      "\n",
      "Batch 10/387 ━━━━━━━━━━━━━━━━━━━━ 09:09:35\n",
      "Accuracy: 0.9977 - Precision: 0.9049 - Recall: 0.8473 - Specificity: 0.9993 - F1: 0.8715 - Loss: 0.1436\n",
      "\n",
      "Batch 11/387 ━━━━━━━━━━━━━━━━━━━━ 09:11:12\n",
      "Accuracy: 0.9976 - Precision: 0.9119 - Recall: 0.8500 - Specificity: 0.9993 - F1: 0.8765 - Loss: 0.1387\n",
      "\n",
      "Batch 12/387 ━━━━━━━━━━━━━━━━━━━━ 09:12:44\n",
      "Accuracy: 0.9975 - Precision: 0.9146 - Recall: 0.8466 - Specificity: 0.9993 - F1: 0.8761 - Loss: 0.1396\n",
      "\n",
      "Batch 13/387 ━━━━━━━━━━━━━━━━━━━━ 09:14:12\n",
      "Accuracy: 0.9975 - Precision: 0.9140 - Recall: 0.8349 - Specificity: 0.9993 - F1: 0.8692 - Loss: 0.1470\n",
      "\n",
      "Batch 14/387 ━━━━━━━━━━━━━━━━━━━━ 09:15:48\n",
      "Accuracy: 0.9975 - Precision: 0.9130 - Recall: 0.8464 - Specificity: 0.9992 - F1: 0.8746 - Loss: 0.1410\n",
      "\n",
      "Batch 15/387 ━━━━━━━━━━━━━━━━━━━━ 09:17:09\n",
      "Accuracy: 0.9977 - Precision: 0.9082 - Recall: 0.8549 - Specificity: 0.9992 - F1: 0.8765 - Loss: 0.1386\n",
      "\n",
      "Batch 16/387 ━━━━━━━━━━━━━━━━━━━━ 09:18:49\n",
      "Accuracy: 0.9978 - Precision: 0.8992 - Recall: 0.8619 - Specificity: 0.9992 - F1: 0.8751 - Loss: 0.1400\n",
      "\n",
      "Batch 17/387 ━━━━━━━━━━━━━━━━━━━━ 09:20:24\n",
      "Accuracy: 0.9978 - Precision: 0.9029 - Recall: 0.8675 - Specificity: 0.9992 - F1: 0.8801 - Loss: 0.1346\n",
      "\n",
      "Batch 18/387 ━━━━━━━━━━━━━━━━━━━━ 09:21:50\n",
      "Accuracy: 0.9978 - Precision: 0.9041 - Recall: 0.8724 - Specificity: 0.9992 - F1: 0.8834 - Loss: 0.1311\n",
      "\n",
      "Batch 19/387 ━━━━━━━━━━━━━━━━━━━━ 09:23:24\n",
      "Accuracy: 0.9979 - Precision: 0.9044 - Recall: 0.8785 - Specificity: 0.9992 - F1: 0.8867 - Loss: 0.1274\n",
      "\n",
      "Batch 20/387 ━━━━━━━━━━━━━━━━━━━━ 09:24:52\n",
      "Accuracy: 0.9978 - Precision: 0.8892 - Recall: 0.8804 - Specificity: 0.9991 - F1: 0.8787 - Loss: 0.1355\n",
      "\n",
      "Batch 21/387 ━━━━━━━━━━━━━━━━━━━━ 09:26:14\n",
      "Accuracy: 0.9979 - Precision: 0.8830 - Recall: 0.8830 - Specificity: 0.9991 - F1: 0.8767 - Loss: 0.1373\n",
      "\n",
      "Batch 22/387 ━━━━━━━━━━━━━━━━━━━━ 09:27:36\n",
      "Accuracy: 0.9979 - Precision: 0.8864 - Recall: 0.8862 - Specificity: 0.9991 - F1: 0.8804 - Loss: 0.1334\n",
      "\n",
      "Batch 23/387 ━━━━━━━━━━━━━━━━━━━━ 09:29:10\n",
      "Accuracy: 0.9979 - Precision: 0.8781 - Recall: 0.8889 - Specificity: 0.9991 - F1: 0.8770 - Loss: 0.1370\n",
      "\n",
      "Batch 24/387 ━━━━━━━━━━━━━━━━━━━━ 09:30:43\n",
      "Accuracy: 0.9980 - Precision: 0.8825 - Recall: 0.8887 - Specificity: 0.9991 - F1: 0.8793 - Loss: 0.1346\n",
      "\n",
      "Batch 25/387 ━━━━━━━━━━━━━━━━━━━━ 09:31:58\n",
      "Accuracy: 0.9979 - Precision: 0.8801 - Recall: 0.8915 - Specificity: 0.9991 - F1: 0.8794 - Loss: 0.1345\n",
      "\n",
      "Batch 26/387 ━━━━━━━━━━━━━━━━━━━━ 09:33:26\n",
      "Accuracy: 0.9979 - Precision: 0.8721 - Recall: 0.8932 - Specificity: 0.9990 - F1: 0.8757 - Loss: 0.1384\n",
      "\n",
      "Batch 27/387 ━━━━━━━━━━━━━━━━━━━━ 09:34:56\n",
      "Accuracy: 0.9979 - Precision: 0.8756 - Recall: 0.8934 - Specificity: 0.9990 - F1: 0.8778 - Loss: 0.1361\n",
      "\n",
      "Batch 28/387 ━━━━━━━━━━━━━━━━━━━━ 09:36:27\n",
      "Accuracy: 0.9979 - Precision: 0.8776 - Recall: 0.8838 - Specificity: 0.9990 - F1: 0.8731 - Loss: 0.1406\n",
      "\n",
      "Batch 29/387 ━━━━━━━━━━━━━━━━━━━━ 09:37:59\n",
      "Accuracy: 0.9979 - Precision: 0.8813 - Recall: 0.8842 - Specificity: 0.9990 - F1: 0.8754 - Loss: 0.1382\n",
      "\n",
      "Batch 30/387 ━━━━━━━━━━━━━━━━━━━━ 09:39:38\n",
      "Accuracy: 0.9980 - Precision: 0.8830 - Recall: 0.8833 - Specificity: 0.9991 - F1: 0.8760 - Loss: 0.1374\n",
      "\n",
      "Batch 31/387 ━━━━━━━━━━━━━━━━━━━━ 09:41:12\n",
      "Accuracy: 0.9980 - Precision: 0.8865 - Recall: 0.8824 - Specificity: 0.9991 - F1: 0.8773 - Loss: 0.1360\n",
      "\n",
      "Batch 32/387 ━━━━━━━━━━━━━━━━━━━━ 09:42:42\n",
      "Accuracy: 0.9980 - Precision: 0.8867 - Recall: 0.8824 - Specificity: 0.9991 - F1: 0.8777 - Loss: 0.1356\n",
      "\n",
      "Batch 33/387 ━━━━━━━━━━━━━━━━━━━━ 09:44:27\n",
      "Accuracy: 0.9980 - Precision: 0.8895 - Recall: 0.8804 - Specificity: 0.9991 - F1: 0.8781 - Loss: 0.1351\n",
      "\n",
      "Batch 34/387 ━━━━━━━━━━━━━━━━━━━━ 09:45:53\n",
      "Accuracy: 0.9980 - Precision: 0.8926 - Recall: 0.8782 - Specificity: 0.9991 - F1: 0.8784 - Loss: 0.1346\n",
      "\n",
      "Batch 35/387 ━━━━━━━━━━━━━━━━━━━━ 09:47:26\n",
      "Accuracy: 0.9980 - Precision: 0.8943 - Recall: 0.8726 - Specificity: 0.9992 - F1: 0.8761 - Loss: 0.1370\n",
      "\n",
      "Batch 36/387 ━━━━━━━━━━━━━━━━━━━━ 09:49:01\n",
      "Accuracy: 0.9979 - Precision: 0.8973 - Recall: 0.8688 - Specificity: 0.9992 - F1: 0.8753 - Loss: 0.1384\n",
      "\n",
      "Batch 37/387 ━━━━━━━━━━━━━━━━━━━━ 09:50:26\n",
      "Accuracy: 0.9979 - Precision: 0.8967 - Recall: 0.8681 - Specificity: 0.9992 - F1: 0.8748 - Loss: 0.1389\n",
      "\n",
      "Batch 38/387 ━━━━━━━━━━━━━━━━━━━━ 09:51:50\n",
      "Accuracy: 0.9979 - Precision: 0.8988 - Recall: 0.8696 - Specificity: 0.9992 - F1: 0.8768 - Loss: 0.1368\n",
      "\n",
      "Batch 39/387 ━━━━━━━━━━━━━━━━━━━━ 09:53:16\n",
      "Accuracy: 0.9980 - Precision: 0.9002 - Recall: 0.8686 - Specificity: 0.9992 - F1: 0.8771 - Loss: 0.1365\n",
      "\n",
      "Batch 40/387 ━━━━━━━━━━━━━━━━━━━━ 09:54:40\n",
      "Accuracy: 0.9979 - Precision: 0.8993 - Recall: 0.8712 - Specificity: 0.9992 - F1: 0.8780 - Loss: 0.1355\n",
      "\n",
      "Batch 41/387 ━━━━━━━━━━━━━━━━━━━━ 09:56:05\n",
      "Accuracy: 0.9980 - Precision: 0.8994 - Recall: 0.8736 - Specificity: 0.9992 - F1: 0.8794 - Loss: 0.1340\n",
      "\n",
      "Batch 42/387 ━━━━━━━━━━━━━━━━━━━━ 09:57:46\n",
      "Accuracy: 0.9980 - Precision: 0.9012 - Recall: 0.8754 - Specificity: 0.9992 - F1: 0.8814 - Loss: 0.1319\n",
      "\n",
      "Batch 43/387 ━━━━━━━━━━━━━━━━━━━━ 09:59:20\n",
      "Accuracy: 0.9980 - Precision: 0.9016 - Recall: 0.8759 - Specificity: 0.9992 - F1: 0.8820 - Loss: 0.1312\n",
      "\n",
      "Batch 44/387 ━━━━━━━━━━━━━━━━━━━━ 10:00:47\n",
      "Accuracy: 0.9980 - Precision: 0.9017 - Recall: 0.8778 - Specificity: 0.9992 - F1: 0.8831 - Loss: 0.1301\n",
      "\n",
      "Batch 45/387 ━━━━━━━━━━━━━━━━━━━━ 10:02:14\n",
      "Accuracy: 0.9980 - Precision: 0.9033 - Recall: 0.8786 - Specificity: 0.9992 - F1: 0.8845 - Loss: 0.1287\n",
      "\n",
      "Batch 46/387 ━━━━━━━━━━━━━━━━━━━━ 10:03:43\n",
      "Accuracy: 0.9980 - Precision: 0.9039 - Recall: 0.8798 - Specificity: 0.9992 - F1: 0.8855 - Loss: 0.1277\n",
      "\n",
      "Batch 47/387 ━━━━━━━━━━━━━━━━━━━━ 10:05:17\n",
      "Accuracy: 0.9979 - Precision: 0.9038 - Recall: 0.8803 - Specificity: 0.9991 - F1: 0.8859 - Loss: 0.1275\n",
      "\n",
      "Batch 48/387 ━━━━━━━━━━━━━━━━━━━━ 10:06:40\n",
      "Accuracy: 0.9979 - Precision: 0.9038 - Recall: 0.8812 - Specificity: 0.9991 - F1: 0.8864 - Loss: 0.1270\n",
      "\n",
      "Batch 49/387 ━━━━━━━━━━━━━━━━━━━━ 10:08:09\n",
      "Accuracy: 0.9979 - Precision: 0.9044 - Recall: 0.8830 - Specificity: 0.9991 - F1: 0.8877 - Loss: 0.1256\n",
      "\n",
      "Batch 50/387 ━━━━━━━━━━━━━━━━━━━━ 10:09:41\n",
      "Accuracy: 0.9979 - Precision: 0.9024 - Recall: 0.8840 - Specificity: 0.9991 - F1: 0.8872 - Loss: 0.1262\n",
      "\n",
      "Batch 51/387 ━━━━━━━━━━━━━━━━━━━━ 10:11:08\n",
      "Accuracy: 0.9979 - Precision: 0.9034 - Recall: 0.8852 - Specificity: 0.9991 - F1: 0.8885 - Loss: 0.1249\n",
      "\n",
      "Batch 52/387 ━━━━━━━━━━━━━━━━━━━━ 10:12:39\n",
      "Accuracy: 0.9979 - Precision: 0.9028 - Recall: 0.8847 - Specificity: 0.9991 - F1: 0.8880 - Loss: 0.1255\n",
      "\n",
      "Batch 53/387 ━━━━━━━━━━━━━━━━━━━━ 10:14:02\n",
      "Accuracy: 0.9979 - Precision: 0.9042 - Recall: 0.8858 - Specificity: 0.9991 - F1: 0.8894 - Loss: 0.1241\n",
      "\n",
      "Batch 54/387 ━━━━━━━━━━━━━━━━━━━━ 10:15:30\n",
      "Accuracy: 0.9979 - Precision: 0.9050 - Recall: 0.8876 - Specificity: 0.9991 - F1: 0.8908 - Loss: 0.1226\n",
      "\n",
      "Batch 55/387 ━━━━━━━━━━━━━━━━━━━━ 10:17:04\n",
      "Accuracy: 0.9979 - Precision: 0.9047 - Recall: 0.8883 - Specificity: 0.9991 - F1: 0.8911 - Loss: 0.1223\n",
      "\n",
      "Batch 56/387 ━━━━━━━━━━━━━━━━━━━━ 10:18:37\n",
      "Accuracy: 0.9979 - Precision: 0.9060 - Recall: 0.8893 - Specificity: 0.9991 - F1: 0.8923 - Loss: 0.1209\n",
      "\n",
      "Batch 57/387 ━━━━━━━━━━━━━━━━━━━━ 10:20:06\n",
      "Accuracy: 0.9979 - Precision: 0.9063 - Recall: 0.8904 - Specificity: 0.9991 - F1: 0.8931 - Loss: 0.1201\n",
      "\n",
      "Batch 58/387 ━━━━━━━━━━━━━━━━━━━━ 10:21:40\n",
      "Accuracy: 0.9979 - Precision: 0.9072 - Recall: 0.8920 - Specificity: 0.9991 - F1: 0.8945 - Loss: 0.1186\n",
      "\n",
      "Batch 59/387 ━━━━━━━━━━━━━━━━━━━━ 10:23:09\n",
      "Accuracy: 0.9979 - Precision: 0.9057 - Recall: 0.8921 - Specificity: 0.9990 - F1: 0.8938 - Loss: 0.1194\n",
      "\n",
      "Batch 60/387 ━━━━━━━━━━━━━━━━━━━━ 10:24:36\n",
      "Accuracy: 0.9979 - Precision: 0.9063 - Recall: 0.8921 - Specificity: 0.9990 - F1: 0.8942 - Loss: 0.1191\n",
      "\n",
      "Batch 61/387 ━━━━━━━━━━━━━━━━━━━━ 10:26:08\n",
      "Accuracy: 0.9979 - Precision: 0.9057 - Recall: 0.8933 - Specificity: 0.9990 - F1: 0.8945 - Loss: 0.1187\n",
      "\n",
      "Batch 62/387 ━━━━━━━━━━━━━━━━━━━━ 10:27:28\n",
      "Accuracy: 0.9979 - Precision: 0.9058 - Recall: 0.8941 - Specificity: 0.9990 - F1: 0.8951 - Loss: 0.1181\n",
      "\n",
      "Batch 63/387 ━━━━━━━━━━━━━━━━━━━━ 10:28:44\n",
      "Accuracy: 0.9979 - Precision: 0.9027 - Recall: 0.8941 - Specificity: 0.9990 - F1: 0.8934 - Loss: 0.1199\n",
      "\n",
      "Batch 64/387 ━━━━━━━━━━━━━━━━━━━━ 10:30:08\n",
      "Accuracy: 0.9979 - Precision: 0.9036 - Recall: 0.8947 - Specificity: 0.9990 - F1: 0.8942 - Loss: 0.1190\n",
      "\n",
      "Batch 65/387 ━━━━━━━━━━━━━━━━━━━━ 10:31:37\n",
      "Accuracy: 0.9979 - Precision: 0.9029 - Recall: 0.8940 - Specificity: 0.9990 - F1: 0.8936 - Loss: 0.1196\n",
      "\n",
      "Batch 66/387 ━━━━━━━━━━━━━━━━━━━━ 10:32:54\n",
      "Accuracy: 0.9979 - Precision: 0.9022 - Recall: 0.8928 - Specificity: 0.9990 - F1: 0.8927 - Loss: 0.1205\n",
      "\n",
      "Batch 67/387 ━━━━━━━━━━━━━━━━━━━━ 10:34:08\n",
      "Accuracy: 0.9979 - Precision: 0.9018 - Recall: 0.8922 - Specificity: 0.9990 - F1: 0.8923 - Loss: 0.1209\n",
      "\n",
      "Batch 68/387 ━━━━━━━━━━━━━━━━━━━━ 10:35:41\n",
      "Accuracy: 0.9980 - Precision: 0.8996 - Recall: 0.8922 - Specificity: 0.9991 - F1: 0.8912 - Loss: 0.1220\n",
      "\n",
      "Batch 69/387 ━━━━━━━━━━━━━━━━━━━━ 10:37:12\n",
      "Accuracy: 0.9979 - Precision: 0.8975 - Recall: 0.8900 - Specificity: 0.9990 - F1: 0.8891 - Loss: 0.1244\n",
      "\n",
      "Batch 70/387 ━━━━━━━━━━━━━━━━━━━━ 10:38:51\n",
      "Accuracy: 0.9979 - Precision: 0.8984 - Recall: 0.8897 - Specificity: 0.9990 - F1: 0.8894 - Loss: 0.1242\n",
      "\n",
      "Batch 71/387 ━━━━━━━━━━━━━━━━━━━━ 10:40:11\n",
      "Accuracy: 0.9979 - Precision: 0.8994 - Recall: 0.8894 - Specificity: 0.9990 - F1: 0.8898 - Loss: 0.1237\n",
      "\n",
      "Batch 72/387 ━━━━━━━━━━━━━━━━━━━━ 10:41:31\n",
      "Accuracy: 0.9979 - Precision: 0.9008 - Recall: 0.8889 - Specificity: 0.9991 - F1: 0.8902 - Loss: 0.1232\n",
      "\n",
      "Batch 73/387 ━━━━━━━━━━━━━━━━━━━━ 10:43:09\n",
      "Accuracy: 0.9979 - Precision: 0.9020 - Recall: 0.8853 - Specificity: 0.9991 - F1: 0.8885 - Loss: 0.1254\n",
      "\n",
      "Batch 74/387 ━━━━━━━━━━━━━━━━━━━━ 10:44:37\n",
      "Accuracy: 0.9978 - Precision: 0.9032 - Recall: 0.8848 - Specificity: 0.9991 - F1: 0.8889 - Loss: 0.1251\n",
      "\n",
      "Batch 75/387 ━━━━━━━━━━━━━━━━━━━━ 10:46:03\n",
      "Accuracy: 0.9978 - Precision: 0.9043 - Recall: 0.8850 - Specificity: 0.9991 - F1: 0.8896 - Loss: 0.1244\n",
      "\n",
      "Batch 76/387 ━━━━━━━━━━━━━━━━━━━━ 10:47:46\n",
      "Accuracy: 0.9978 - Precision: 0.9029 - Recall: 0.8860 - Specificity: 0.9991 - F1: 0.8893 - Loss: 0.1246\n",
      "\n",
      "Batch 77/387 ━━━━━━━━━━━━━━━━━━━━ 10:49:27\n",
      "Accuracy: 0.9978 - Precision: 0.9039 - Recall: 0.8840 - Specificity: 0.9991 - F1: 0.8887 - Loss: 0.1256\n",
      "\n",
      "Batch 78/387 ━━━━━━━━━━━━━━━━━━━━ 10:50:52\n",
      "Accuracy: 0.9978 - Precision: 0.9022 - Recall: 0.8790 - Specificity: 0.9991 - F1: 0.8850 - Loss: 0.1294\n",
      "\n",
      "Batch 79/387 ━━━━━━━━━━━━━━━━━━━━ 10:52:20\n",
      "Accuracy: 0.9978 - Precision: 0.9015 - Recall: 0.8801 - Specificity: 0.9991 - F1: 0.8852 - Loss: 0.1292\n",
      "\n",
      "Batch 80/387 ━━━━━━━━━━━━━━━━━━━━ 10:54:01\n",
      "Accuracy: 0.9978 - Precision: 0.9021 - Recall: 0.8811 - Specificity: 0.9991 - F1: 0.8861 - Loss: 0.1282\n",
      "\n",
      "Batch 81/387 ━━━━━━━━━━━━━━━━━━━━ 10:55:37\n",
      "Accuracy: 0.9978 - Precision: 0.9014 - Recall: 0.8823 - Specificity: 0.9990 - F1: 0.8864 - Loss: 0.1279\n",
      "\n",
      "Batch 82/387 ━━━━━━━━━━━━━━━━━━━━ 10:57:05\n",
      "Accuracy: 0.9978 - Precision: 0.8968 - Recall: 0.8836 - Specificity: 0.9990 - F1: 0.8839 - Loss: 0.1305\n",
      "\n",
      "Batch 83/387 ━━━━━━━━━━━━━━━━━━━━ 10:58:29\n",
      "Accuracy: 0.9978 - Precision: 0.8977 - Recall: 0.8840 - Specificity: 0.9990 - F1: 0.8846 - Loss: 0.1297\n",
      "\n",
      "Batch 84/387 ━━━━━━━━━━━━━━━━━━━━ 10:59:57\n",
      "Accuracy: 0.9978 - Precision: 0.8986 - Recall: 0.8840 - Specificity: 0.9990 - F1: 0.8851 - Loss: 0.1293\n",
      "\n",
      "Batch 85/387 ━━━━━━━━━━━━━━━━━━━━ 11:01:24\n",
      "Accuracy: 0.9978 - Precision: 0.8971 - Recall: 0.8846 - Specificity: 0.9990 - F1: 0.8846 - Loss: 0.1297\n",
      "\n",
      "Batch 86/387 ━━━━━━━━━━━━━━━━━━━━ 11:02:47\n",
      "Accuracy: 0.9977 - Precision: 0.8927 - Recall: 0.8852 - Specificity: 0.9990 - F1: 0.8821 - Loss: 0.1324\n",
      "\n",
      "Batch 87/387 ━━━━━━━━━━━━━━━━━━━━ 11:04:20\n",
      "Accuracy: 0.9977 - Precision: 0.8929 - Recall: 0.8862 - Specificity: 0.9990 - F1: 0.8828 - Loss: 0.1317\n",
      "\n",
      "Batch 88/387 ━━━━━━━━━━━━━━━━━━━━ 11:05:45\n",
      "Accuracy: 0.9977 - Precision: 0.8902 - Recall: 0.8857 - Specificity: 0.9990 - F1: 0.8811 - Loss: 0.1334\n",
      "\n",
      "Batch 89/387 ━━━━━━━━━━━━━━━━━━━━ 11:07:07\n",
      "Accuracy: 0.9977 - Precision: 0.8876 - Recall: 0.8838 - Specificity: 0.9990 - F1: 0.8789 - Loss: 0.1355\n",
      "\n",
      "Batch 90/387 ━━━━━━━━━━━━━━━━━━━━ 11:08:33\n",
      "Accuracy: 0.9977 - Precision: 0.8865 - Recall: 0.8830 - Specificity: 0.9989 - F1: 0.8781 - Loss: 0.1365\n",
      "\n",
      "Batch 91/387 ━━━━━━━━━━━━━━━━━━━━ 11:09:56\n",
      "Accuracy: 0.9977 - Precision: 0.8871 - Recall: 0.8826 - Specificity: 0.9990 - F1: 0.8782 - Loss: 0.1364\n",
      "\n",
      "Batch 92/387 ━━━━━━━━━━━━━━━━━━━━ 11:11:25\n",
      "Accuracy: 0.9977 - Precision: 0.8879 - Recall: 0.8825 - Specificity: 0.9990 - F1: 0.8786 - Loss: 0.1359\n",
      "\n",
      "Batch 93/387 ━━━━━━━━━━━━━━━━━━━━ 11:12:39\n",
      "Accuracy: 0.9977 - Precision: 0.8879 - Recall: 0.8830 - Specificity: 0.9990 - F1: 0.8789 - Loss: 0.1356\n",
      "\n",
      "Batch 94/387 ━━━━━━━━━━━━━━━━━━━━ 11:14:16\n",
      "Accuracy: 0.9977 - Precision: 0.8887 - Recall: 0.8835 - Specificity: 0.9990 - F1: 0.8796 - Loss: 0.1348\n",
      "\n",
      "Batch 95/387 ━━━━━━━━━━━━━━━━━━━━ 11:15:47\n",
      "Accuracy: 0.9978 - Precision: 0.8885 - Recall: 0.8837 - Specificity: 0.9990 - F1: 0.8797 - Loss: 0.1347\n",
      "\n",
      "Batch 96/387 ━━━━━━━━━━━━━━━━━━━━ 11:17:18\n",
      "Accuracy: 0.9978 - Precision: 0.8883 - Recall: 0.8840 - Specificity: 0.9990 - F1: 0.8798 - Loss: 0.1346\n",
      "\n",
      "Batch 97/387 ━━━━━━━━━━━━━━━━━━━━ 11:18:49\n",
      "Accuracy: 0.9978 - Precision: 0.8889 - Recall: 0.8848 - Specificity: 0.9990 - F1: 0.8806 - Loss: 0.1337\n",
      "\n",
      "Batch 98/387 ━━━━━━━━━━━━━━━━━━━━ 11:20:11\n",
      "Accuracy: 0.9978 - Precision: 0.8899 - Recall: 0.8852 - Specificity: 0.9990 - F1: 0.8813 - Loss: 0.1330\n",
      "\n",
      "Batch 99/387 ━━━━━━━━━━━━━━━━━━━━ 11:21:45\n",
      "Accuracy: 0.9978 - Precision: 0.8878 - Recall: 0.8858 - Specificity: 0.9990 - F1: 0.8804 - Loss: 0.1339\n",
      "\n",
      "Batch 100/387 ━━━━━━━━━━━━━━━━━━━━ 11:23:09\n",
      "Accuracy: 0.9978 - Precision: 0.8879 - Recall: 0.8860 - Specificity: 0.9990 - F1: 0.8807 - Loss: 0.1336\n",
      "\n",
      "Batch 101/387 ━━━━━━━━━━━━━━━━━━━━ 11:24:28\n",
      "Accuracy: 0.9978 - Precision: 0.8868 - Recall: 0.8867 - Specificity: 0.9990 - F1: 0.8804 - Loss: 0.1339\n",
      "\n",
      "Batch 102/387 ━━━━━━━━━━━━━━━━━━━━ 11:25:51\n",
      "Accuracy: 0.9978 - Precision: 0.8870 - Recall: 0.8846 - Specificity: 0.9990 - F1: 0.8794 - Loss: 0.1349\n",
      "\n",
      "Batch 103/387 ━━━━━━━━━━━━━━━━━━━━ 11:27:21\n",
      "Accuracy: 0.9978 - Precision: 0.8874 - Recall: 0.8852 - Specificity: 0.9990 - F1: 0.8799 - Loss: 0.1343\n",
      "\n",
      "Batch 104/387 ━━━━━━━━━━━━━━━━━━━━ 11:28:33\n",
      "Accuracy: 0.9978 - Precision: 0.8882 - Recall: 0.8853 - Specificity: 0.9990 - F1: 0.8804 - Loss: 0.1337\n",
      "\n",
      "Batch 105/387 ━━━━━━━━━━━━━━━━━━━━ 11:29:55\n",
      "Accuracy: 0.9978 - Precision: 0.8890 - Recall: 0.8856 - Specificity: 0.9990 - F1: 0.8810 - Loss: 0.1331\n",
      "\n",
      "Batch 106/387 ━━━━━━━━━━━━━━━━━━━━ 11:31:22\n",
      "Accuracy: 0.9978 - Precision: 0.8898 - Recall: 0.8860 - Specificity: 0.9990 - F1: 0.8817 - Loss: 0.1324\n",
      "\n",
      "Batch 107/387 ━━━━━━━━━━━━━━━━━━━━ 11:32:47\n",
      "Accuracy: 0.9979 - Precision: 0.8907 - Recall: 0.8860 - Specificity: 0.9990 - F1: 0.8822 - Loss: 0.1318\n",
      "\n",
      "Batch 108/387 ━━━━━━━━━━━━━━━━━━━━ 11:34:04\n",
      "Accuracy: 0.9978 - Precision: 0.8915 - Recall: 0.8856 - Specificity: 0.9990 - F1: 0.8823 - Loss: 0.1318\n",
      "\n",
      "Batch 109/387 ━━━━━━━━━━━━━━━━━━━━ 11:35:23\n",
      "Accuracy: 0.9978 - Precision: 0.8917 - Recall: 0.8863 - Specificity: 0.9990 - F1: 0.8829 - Loss: 0.1312\n",
      "\n",
      "Batch 110/387 ━━━━━━━━━━━━━━━━━━━━ 11:36:50\n",
      "Accuracy: 0.9978 - Precision: 0.8925 - Recall: 0.8865 - Specificity: 0.9990 - F1: 0.8834 - Loss: 0.1307\n",
      "\n",
      "Batch 111/387 ━━━━━━━━━━━━━━━━━━━━ 11:38:20\n",
      "Accuracy: 0.9978 - Precision: 0.8918 - Recall: 0.8873 - Specificity: 0.9990 - F1: 0.8834 - Loss: 0.1306\n",
      "\n",
      "Batch 112/387 ━━━━━━━━━━━━━━━━━━━━ 11:39:48\n",
      "Accuracy: 0.9978 - Precision: 0.8923 - Recall: 0.8879 - Specificity: 0.9990 - F1: 0.8840 - Loss: 0.1300\n",
      "\n",
      "Batch 113/387 ━━━━━━━━━━━━━━━━━━━━ 11:41:23\n",
      "Accuracy: 0.9978 - Precision: 0.8928 - Recall: 0.8866 - Specificity: 0.9990 - F1: 0.8836 - Loss: 0.1304\n",
      "\n",
      "Batch 114/387 ━━━━━━━━━━━━━━━━━━━━ 11:42:48\n",
      "Accuracy: 0.9978 - Precision: 0.8928 - Recall: 0.8873 - Specificity: 0.9990 - F1: 0.8840 - Loss: 0.1301\n",
      "\n",
      "Batch 115/387 ━━━━━━━━━━━━━━━━━━━━ 11:44:17\n",
      "Accuracy: 0.9978 - Precision: 0.8929 - Recall: 0.8874 - Specificity: 0.9990 - F1: 0.8841 - Loss: 0.1300\n",
      "\n",
      "Batch 116/387 ━━━━━━━━━━━━━━━━━━━━ 11:45:37\n",
      "Accuracy: 0.9978 - Precision: 0.8934 - Recall: 0.8875 - Specificity: 0.9990 - F1: 0.8845 - Loss: 0.1296\n",
      "\n",
      "Batch 117/387 ━━━━━━━━━━━━━━━━━━━━ 11:47:07\n",
      "Accuracy: 0.9978 - Precision: 0.8913 - Recall: 0.8884 - Specificity: 0.9990 - F1: 0.8837 - Loss: 0.1304\n",
      "\n",
      "Batch 118/387 ━━━━━━━━━━━━━━━━━━━━ 11:48:28\n",
      "Accuracy: 0.9978 - Precision: 0.8920 - Recall: 0.8875 - Specificity: 0.9990 - F1: 0.8835 - Loss: 0.1306\n",
      "\n",
      "Batch 119/387 ━━━━━━━━━━━━━━━━━━━━ 11:49:55\n",
      "Accuracy: 0.9978 - Precision: 0.8900 - Recall: 0.8883 - Specificity: 0.9990 - F1: 0.8827 - Loss: 0.1314\n",
      "\n",
      "Batch 120/387 ━━━━━━━━━━━━━━━━━━━━ 11:51:07\n",
      "Accuracy: 0.9979 - Precision: 0.8905 - Recall: 0.8880 - Specificity: 0.9990 - F1: 0.8828 - Loss: 0.1312\n",
      "\n",
      "Batch 121/387 ━━━━━━━━━━━━━━━━━━━━ 11:52:34\n",
      "Accuracy: 0.9978 - Precision: 0.8906 - Recall: 0.8878 - Specificity: 0.9990 - F1: 0.8828 - Loss: 0.1313\n",
      "\n",
      "Batch 122/387 ━━━━━━━━━━━━━━━━━━━━ 11:54:01\n",
      "Accuracy: 0.9979 - Precision: 0.8905 - Recall: 0.8882 - Specificity: 0.9990 - F1: 0.8830 - Loss: 0.1311\n",
      "\n",
      "Batch 123/387 ━━━━━━━━━━━━━━━━━━━━ 11:55:15\n",
      "Accuracy: 0.9979 - Precision: 0.8909 - Recall: 0.8887 - Specificity: 0.9990 - F1: 0.8835 - Loss: 0.1306\n",
      "\n",
      "Batch 124/387 ━━━━━━━━━━━━━━━━━━━━ 11:56:30\n",
      "Accuracy: 0.9978 - Precision: 0.8916 - Recall: 0.8862 - Specificity: 0.9990 - F1: 0.8823 - Loss: 0.1321\n",
      "\n",
      "Batch 125/387 ━━━━━━━━━━━━━━━━━━━━ 11:58:02\n",
      "Accuracy: 0.9978 - Precision: 0.8923 - Recall: 0.8855 - Specificity: 0.9990 - F1: 0.8822 - Loss: 0.1321\n",
      "\n",
      "Batch 126/387 ━━━━━━━━━━━━━━━━━━━━ 11:59:27\n",
      "Accuracy: 0.9978 - Precision: 0.8929 - Recall: 0.8856 - Specificity: 0.9991 - F1: 0.8826 - Loss: 0.1317\n",
      "\n",
      "Batch 127/387 ━━━━━━━━━━━━━━━━━━━━ 12:00:58\n",
      "Accuracy: 0.9978 - Precision: 0.8934 - Recall: 0.8860 - Specificity: 0.9991 - F1: 0.8832 - Loss: 0.1311\n",
      "\n",
      "Batch 128/387 ━━━━━━━━━━━━━━━━━━━━ 12:02:30\n",
      "Accuracy: 0.9978 - Precision: 0.8941 - Recall: 0.8838 - Specificity: 0.9991 - F1: 0.8821 - Loss: 0.1323\n",
      "\n",
      "Batch 129/387 ━━━━━━━━━━━━━━━━━━━━ 12:04:10\n",
      "Accuracy: 0.9978 - Precision: 0.8941 - Recall: 0.8833 - Specificity: 0.9991 - F1: 0.8818 - Loss: 0.1326\n",
      "\n",
      "Batch 130/387 ━━━━━━━━━━━━━━━━━━━━ 12:05:43\n",
      "Accuracy: 0.9978 - Precision: 0.8926 - Recall: 0.8839 - Specificity: 0.9991 - F1: 0.8812 - Loss: 0.1332\n",
      "\n",
      "Batch 131/387 ━━━━━━━━━━━━━━━━━━━━ 12:07:15\n",
      "Accuracy: 0.9978 - Precision: 0.8928 - Recall: 0.8836 - Specificity: 0.9991 - F1: 0.8813 - Loss: 0.1333\n",
      "\n",
      "Batch 132/387 ━━━━━━━━━━━━━━━━━━━━ 12:08:55\n",
      "Accuracy: 0.9978 - Precision: 0.8926 - Recall: 0.8840 - Specificity: 0.9991 - F1: 0.8814 - Loss: 0.1330\n",
      "\n",
      "Batch 133/387 ━━━━━━━━━━━━━━━━━━━━ 12:10:29\n",
      "Accuracy: 0.9978 - Precision: 0.8921 - Recall: 0.8831 - Specificity: 0.9990 - F1: 0.8807 - Loss: 0.1339\n",
      "\n",
      "Batch 134/387 ━━━━━━━━━━━━━━━━━━━━ 12:11:59\n",
      "Accuracy: 0.9978 - Precision: 0.8907 - Recall: 0.8837 - Specificity: 0.9990 - F1: 0.8802 - Loss: 0.1346\n",
      "\n",
      "Batch 135/387 ━━━━━━━━━━━━━━━━━━━━ 12:13:16\n",
      "Accuracy: 0.9978 - Precision: 0.8904 - Recall: 0.8843 - Specificity: 0.9990 - F1: 0.8804 - Loss: 0.1344\n",
      "\n",
      "Batch 136/387 ━━━━━━━━━━━━━━━━━━━━ 12:14:41\n",
      "Accuracy: 0.9978 - Precision: 0.8907 - Recall: 0.8833 - Specificity: 0.9990 - F1: 0.8801 - Loss: 0.1347\n",
      "\n",
      "Batch 137/387 ━━━━━━━━━━━━━━━━━━━━ 12:16:14\n",
      "Accuracy: 0.9978 - Precision: 0.8903 - Recall: 0.8840 - Specificity: 0.9990 - F1: 0.8802 - Loss: 0.1345\n",
      "\n",
      "Batch 138/387 ━━━━━━━━━━━━━━━━━━━━ 12:17:42\n",
      "Accuracy: 0.9978 - Precision: 0.8907 - Recall: 0.8846 - Specificity: 0.9990 - F1: 0.8808 - Loss: 0.1339\n",
      "\n",
      "Batch 139/387 ━━━━━━━━━━━━━━━━━━━━ 12:19:14\n",
      "Accuracy: 0.9978 - Precision: 0.8895 - Recall: 0.8844 - Specificity: 0.9990 - F1: 0.8801 - Loss: 0.1346\n",
      "\n",
      "Batch 140/387 ━━━━━━━━━━━━━━━━━━━━ 12:20:36\n",
      "Accuracy: 0.9978 - Precision: 0.8890 - Recall: 0.8849 - Specificity: 0.9990 - F1: 0.8801 - Loss: 0.1346\n",
      "\n",
      "Batch 141/387 ━━━━━━━━━━━━━━━━━━━━ 12:21:53\n",
      "Accuracy: 0.9978 - Precision: 0.8892 - Recall: 0.8845 - Specificity: 0.9990 - F1: 0.8800 - Loss: 0.1346\n",
      "\n",
      "Batch 142/387 ━━━━━━━━━━━━━━━━━━━━ 12:23:21\n",
      "Accuracy: 0.9978 - Precision: 0.8888 - Recall: 0.8847 - Specificity: 0.9990 - F1: 0.8799 - Loss: 0.1347\n",
      "\n",
      "Batch 143/387 ━━━━━━━━━━━━━━━━━━━━ 12:24:55\n",
      "Accuracy: 0.9978 - Precision: 0.8890 - Recall: 0.8848 - Specificity: 0.9990 - F1: 0.8801 - Loss: 0.1345\n",
      "\n",
      "Batch 144/387 ━━━━━━━━━━━━━━━━━━━━ 12:26:17\n",
      "Accuracy: 0.9977 - Precision: 0.8897 - Recall: 0.8837 - Specificity: 0.9990 - F1: 0.8799 - Loss: 0.1349\n",
      "\n",
      "Batch 145/387 ━━━━━━━━━━━━━━━━━━━━ 12:27:38\n",
      "Accuracy: 0.9977 - Precision: 0.8903 - Recall: 0.8837 - Specificity: 0.9990 - F1: 0.8802 - Loss: 0.1346\n",
      "\n",
      "Batch 146/387 ━━━━━━━━━━━━━━━━━━━━ 12:29:14\n",
      "Accuracy: 0.9977 - Precision: 0.8908 - Recall: 0.8838 - Specificity: 0.9990 - F1: 0.8805 - Loss: 0.1343\n",
      "\n",
      "Batch 147/387 ━━━━━━━━━━━━━━━━━━━━ 12:30:33\n",
      "Accuracy: 0.9977 - Precision: 0.8913 - Recall: 0.8828 - Specificity: 0.9990 - F1: 0.8802 - Loss: 0.1348\n",
      "\n",
      "Batch 148/387 ━━━━━━━━━━━━━━━━━━━━ 12:32:06\n",
      "Accuracy: 0.9977 - Precision: 0.8897 - Recall: 0.8833 - Specificity: 0.9990 - F1: 0.8795 - Loss: 0.1355\n",
      "\n",
      "Batch 149/387 ━━━━━━━━━━━━━━━━━━━━ 12:33:28\n",
      "Accuracy: 0.9977 - Precision: 0.8898 - Recall: 0.8834 - Specificity: 0.9990 - F1: 0.8796 - Loss: 0.1353\n",
      "\n",
      "Batch 150/387 ━━━━━━━━━━━━━━━━━━━━ 12:35:06\n",
      "Accuracy: 0.9977 - Precision: 0.8894 - Recall: 0.8842 - Specificity: 0.9990 - F1: 0.8798 - Loss: 0.1352\n",
      "\n",
      "Batch 151/387 ━━━━━━━━━━━━━━━━━━━━ 12:36:41\n",
      "Accuracy: 0.9977 - Precision: 0.8879 - Recall: 0.8842 - Specificity: 0.9990 - F1: 0.8790 - Loss: 0.1359\n",
      "\n",
      "Batch 152/387 ━━━━━━━━━━━━━━━━━━━━ 12:38:18\n",
      "Accuracy: 0.9977 - Precision: 0.8884 - Recall: 0.8844 - Specificity: 0.9990 - F1: 0.8794 - Loss: 0.1355\n",
      "\n",
      "Batch 153/387 ━━━━━━━━━━━━━━━━━━━━ 12:55:52\n",
      "Accuracy: 0.9977 - Precision: 0.8882 - Recall: 0.8846 - Specificity: 0.9990 - F1: 0.8795 - Loss: 0.1354\n",
      "\n",
      "Batch 154/387 ━━━━━━━━━━━━━━━━━━━━ 12:57:34\n",
      "Accuracy: 0.9977 - Precision: 0.8886 - Recall: 0.8849 - Specificity: 0.9990 - F1: 0.8799 - Loss: 0.1350\n",
      "\n",
      "Batch 155/387 ━━━━━━━━━━━━━━━━━━━━ 12:59:13\n",
      "Accuracy: 0.9977 - Precision: 0.8887 - Recall: 0.8854 - Specificity: 0.9990 - F1: 0.8802 - Loss: 0.1346\n",
      "\n",
      "Batch 156/387 ━━━━━━━━━━━━━━━━━━━━ 13:00:57\n",
      "Accuracy: 0.9977 - Precision: 0.8877 - Recall: 0.8855 - Specificity: 0.9990 - F1: 0.8797 - Loss: 0.1351\n",
      "\n",
      "Batch 157/387 ━━━━━━━━━━━━━━━━━━━━ 13:02:22\n",
      "Accuracy: 0.9977 - Precision: 0.8882 - Recall: 0.8856 - Specificity: 0.9990 - F1: 0.8801 - Loss: 0.1348\n",
      "\n",
      "Batch 158/387 ━━━━━━━━━━━━━━━━━━━━ 13:03:58\n",
      "Accuracy: 0.9977 - Precision: 0.8887 - Recall: 0.8859 - Specificity: 0.9990 - F1: 0.8805 - Loss: 0.1344\n",
      "\n",
      "Batch 159/387 ━━━━━━━━━━━━━━━━━━━━ 13:05:22\n",
      "Accuracy: 0.9977 - Precision: 0.8892 - Recall: 0.8853 - Specificity: 0.9990 - F1: 0.8805 - Loss: 0.1344\n",
      "\n",
      "Batch 160/387 ━━━━━━━━━━━━━━━━━━━━ 13:07:01\n",
      "Accuracy: 0.9977 - Precision: 0.8892 - Recall: 0.8855 - Specificity: 0.9990 - F1: 0.8806 - Loss: 0.1342\n",
      "\n",
      "Batch 161/387 ━━━━━━━━━━━━━━━━━━━━ 13:08:49\n",
      "Accuracy: 0.9977 - Precision: 0.8897 - Recall: 0.8855 - Specificity: 0.9990 - F1: 0.8808 - Loss: 0.1340\n",
      "\n",
      "Batch 162/387 ━━━━━━━━━━━━━━━━━━━━ 13:10:26\n",
      "Accuracy: 0.9977 - Precision: 0.8902 - Recall: 0.8851 - Specificity: 0.9990 - F1: 0.8809 - Loss: 0.1340\n",
      "\n",
      "Batch 163/387 ━━━━━━━━━━━━━━━━━━━━ 13:12:04\n",
      "Accuracy: 0.9977 - Precision: 0.8893 - Recall: 0.8856 - Specificity: 0.9990 - F1: 0.8806 - Loss: 0.1343\n",
      "\n",
      "Batch 164/387 ━━━━━━━━━━━━━━━━━━━━ 13:13:39\n",
      "Accuracy: 0.9977 - Precision: 0.8897 - Recall: 0.8852 - Specificity: 0.9990 - F1: 0.8807 - Loss: 0.1343\n",
      "\n",
      "Batch 165/387 ━━━━━━━━━━━━━━━━━━━━ 13:15:19\n",
      "Accuracy: 0.9977 - Precision: 0.8903 - Recall: 0.8856 - Specificity: 0.9990 - F1: 0.8812 - Loss: 0.1337\n",
      "\n",
      "Batch 166/387 ━━━━━━━━━━━━━━━━━━━━ 13:17:35\n",
      "Accuracy: 0.9977 - Precision: 0.8897 - Recall: 0.8860 - Specificity: 0.9990 - F1: 0.8811 - Loss: 0.1338\n",
      "\n",
      "Batch 167/387 ━━━━━━━━━━━━━━━━━━━━ 13:20:12\n",
      "Accuracy: 0.9977 - Precision: 0.8900 - Recall: 0.8864 - Specificity: 0.9990 - F1: 0.8815 - Loss: 0.1334\n",
      "\n",
      "Batch 168/387 ━━━━━━━━━━━━━━━━━━━━ 13:22:29\n",
      "Accuracy: 0.9977 - Precision: 0.8894 - Recall: 0.8871 - Specificity: 0.9990 - F1: 0.8815 - Loss: 0.1334\n",
      "\n",
      "Batch 169/387 ━━━━━━━━━━━━━━━━━━━━ 13:24:25\n",
      "Accuracy: 0.9977 - Precision: 0.8895 - Recall: 0.8875 - Specificity: 0.9990 - F1: 0.8818 - Loss: 0.1331\n",
      "\n",
      "Batch 170/387 ━━━━━━━━━━━━━━━━━━━━ 13:26:51\n",
      "Accuracy: 0.9977 - Precision: 0.8899 - Recall: 0.8874 - Specificity: 0.9990 - F1: 0.8820 - Loss: 0.1328\n",
      "\n",
      "Batch 171/387 ━━━━━━━━━━━━━━━━━━━━ 13:29:09\n",
      "Accuracy: 0.9977 - Precision: 0.8898 - Recall: 0.8875 - Specificity: 0.9990 - F1: 0.8820 - Loss: 0.1328\n",
      "\n",
      "Batch 172/387 ━━━━━━━━━━━━━━━━━━━━ 13:31:11\n",
      "Accuracy: 0.9977 - Precision: 0.8896 - Recall: 0.8864 - Specificity: 0.9990 - F1: 0.8813 - Loss: 0.1334\n",
      "\n",
      "Batch 173/387 ━━━━━━━━━━━━━━━━━━━━ 13:32:51\n",
      "Accuracy: 0.9977 - Precision: 0.8900 - Recall: 0.8863 - Specificity: 0.9990 - F1: 0.8815 - Loss: 0.1333\n",
      "\n",
      "Batch 174/387 ━━━━━━━━━━━━━━━━━━━━ 13:34:30\n",
      "Accuracy: 0.9977 - Precision: 0.8904 - Recall: 0.8862 - Specificity: 0.9990 - F1: 0.8817 - Loss: 0.1331\n",
      "\n",
      "Batch 175/387 ━━━━━━━━━━━━━━━━━━━━ 13:36:03\n",
      "Accuracy: 0.9977 - Precision: 0.8906 - Recall: 0.8865 - Specificity: 0.9990 - F1: 0.8820 - Loss: 0.1327\n",
      "\n",
      "Batch 176/387 ━━━━━━━━━━━━━━━━━━━━ 13:37:30\n",
      "Accuracy: 0.9977 - Precision: 0.8911 - Recall: 0.8857 - Specificity: 0.9990 - F1: 0.8818 - Loss: 0.1330\n",
      "\n",
      "Batch 177/387 ━━━━━━━━━━━━━━━━━━━━ 13:39:01\n",
      "Accuracy: 0.9977 - Precision: 0.8897 - Recall: 0.8861 - Specificity: 0.9990 - F1: 0.8811 - Loss: 0.1338\n",
      "\n",
      "Batch 178/387 ━━━━━━━━━━━━━━━━━━━━ 13:40:34\n",
      "Accuracy: 0.9977 - Precision: 0.8894 - Recall: 0.8866 - Specificity: 0.9990 - F1: 0.8812 - Loss: 0.1336\n",
      "\n",
      "Batch 179/387 ━━━━━━━━━━━━━━━━━━━━ 13:42:00\n",
      "Accuracy: 0.9977 - Precision: 0.8887 - Recall: 0.8850 - Specificity: 0.9990 - F1: 0.8801 - Loss: 0.1349\n",
      "\n",
      "Batch 180/387 ━━━━━━━━━━━━━━━━━━━━ 13:43:25\n",
      "Accuracy: 0.9977 - Precision: 0.8889 - Recall: 0.8848 - Specificity: 0.9990 - F1: 0.8801 - Loss: 0.1349\n",
      "\n",
      "Batch 181/387 ━━━━━━━━━━━━━━━━━━━━ 13:44:59\n",
      "Accuracy: 0.9977 - Precision: 0.8892 - Recall: 0.8847 - Specificity: 0.9990 - F1: 0.8802 - Loss: 0.1347\n",
      "\n",
      "Batch 182/387 ━━━━━━━━━━━━━━━━━━━━ 13:46:35\n",
      "Accuracy: 0.9977 - Precision: 0.8896 - Recall: 0.8850 - Specificity: 0.9990 - F1: 0.8806 - Loss: 0.1343\n",
      "\n",
      "Batch 183/387 ━━━━━━━━━━━━━━━━━━━━ 13:48:18\n",
      "Accuracy: 0.9977 - Precision: 0.8899 - Recall: 0.8854 - Specificity: 0.9990 - F1: 0.8810 - Loss: 0.1339\n",
      "\n",
      "Batch 184/387 ━━━━━━━━━━━━━━━━━━━━ 13:49:56\n",
      "Accuracy: 0.9977 - Precision: 0.8900 - Recall: 0.8859 - Specificity: 0.9990 - F1: 0.8813 - Loss: 0.1335\n",
      "\n",
      "Batch 185/387 ━━━━━━━━━━━━━━━━━━━━ 13:51:33\n",
      "Accuracy: 0.9977 - Precision: 0.8892 - Recall: 0.8863 - Specificity: 0.9990 - F1: 0.8811 - Loss: 0.1337\n",
      "\n",
      "Batch 186/387 ━━━━━━━━━━━━━━━━━━━━ 13:53:04\n",
      "Accuracy: 0.9977 - Precision: 0.8886 - Recall: 0.8868 - Specificity: 0.9990 - F1: 0.8810 - Loss: 0.1338\n",
      "\n",
      "Batch 187/387 ━━━━━━━━━━━━━━━━━━━━ 13:54:36\n",
      "Accuracy: 0.9977 - Precision: 0.8887 - Recall: 0.8873 - Specificity: 0.9990 - F1: 0.8813 - Loss: 0.1334\n",
      "\n",
      "Batch 188/387 ━━━━━━━━━━━━━━━━━━━━ 13:56:07\n",
      "Accuracy: 0.9977 - Precision: 0.8886 - Recall: 0.8859 - Specificity: 0.9990 - F1: 0.8805 - Loss: 0.1343\n",
      "\n",
      "Batch 189/387 ━━━━━━━━━━━━━━━━━━━━ 13:57:37\n",
      "Accuracy: 0.9977 - Precision: 0.8891 - Recall: 0.8849 - Specificity: 0.9990 - F1: 0.8802 - Loss: 0.1346\n",
      "\n",
      "Batch 190/387 ━━━━━━━━━━━━━━━━━━━━ 13:59:05\n",
      "Accuracy: 0.9977 - Precision: 0.8896 - Recall: 0.8842 - Specificity: 0.9990 - F1: 0.8800 - Loss: 0.1348\n",
      "\n",
      "Batch 191/387 ━━━━━━━━━━━━━━━━━━━━ 14:00:32\n",
      "Accuracy: 0.9977 - Precision: 0.8899 - Recall: 0.8834 - Specificity: 0.9990 - F1: 0.8797 - Loss: 0.1351\n",
      "\n",
      "Batch 192/387 ━━━━━━━━━━━━━━━━━━━━ 14:01:50\n",
      "Accuracy: 0.9977 - Precision: 0.8902 - Recall: 0.8835 - Specificity: 0.9990 - F1: 0.8800 - Loss: 0.1348\n",
      "\n",
      "Batch 193/387 ━━━━━━━━━━━━━━━━━━━━ 14:03:10\n",
      "Accuracy: 0.9977 - Precision: 0.8906 - Recall: 0.8831 - Specificity: 0.9990 - F1: 0.8800 - Loss: 0.1348\n",
      "\n",
      "Batch 194/387 ━━━━━━━━━━━━━━━━━━━━ 14:04:38\n",
      "Accuracy: 0.9977 - Precision: 0.8910 - Recall: 0.8833 - Specificity: 0.9990 - F1: 0.8803 - Loss: 0.1345\n",
      "\n",
      "Batch 195/387 ━━━━━━━━━━━━━━━━━━━━ 14:05:56\n",
      "Accuracy: 0.9977 - Precision: 0.8905 - Recall: 0.8827 - Specificity: 0.9990 - F1: 0.8798 - Loss: 0.1350\n",
      "\n",
      "Batch 196/387 ━━━━━━━━━━━━━━━━━━━━ 14:07:32\n",
      "Accuracy: 0.9977 - Precision: 0.8906 - Recall: 0.8831 - Specificity: 0.9990 - F1: 0.8801 - Loss: 0.1348\n",
      "\n",
      "Batch 197/387 ━━━━━━━━━━━━━━━━━━━━ 14:09:04\n",
      "Accuracy: 0.9977 - Precision: 0.8902 - Recall: 0.8834 - Specificity: 0.9990 - F1: 0.8801 - Loss: 0.1348\n",
      "\n",
      "Batch 198/387 ━━━━━━━━━━━━━━━━━━━━ 14:10:32\n",
      "Accuracy: 0.9977 - Precision: 0.8901 - Recall: 0.8838 - Specificity: 0.9990 - F1: 0.8802 - Loss: 0.1346\n",
      "\n",
      "Batch 199/387 ━━━━━━━━━━━━━━━━━━━━ 14:12:05\n",
      "Accuracy: 0.9977 - Precision: 0.8904 - Recall: 0.8841 - Specificity: 0.9990 - F1: 0.8806 - Loss: 0.1343\n",
      "\n",
      "Batch 200/387 ━━━━━━━━━━━━━━━━━━━━ 14:13:38\n",
      "Accuracy: 0.9977 - Precision: 0.8906 - Recall: 0.8842 - Specificity: 0.9990 - F1: 0.8807 - Loss: 0.1342\n",
      "\n",
      "Batch 201/387 ━━━━━━━━━━━━━━━━━━━━ 14:15:06\n",
      "Accuracy: 0.9977 - Precision: 0.8907 - Recall: 0.8836 - Specificity: 0.9990 - F1: 0.8805 - Loss: 0.1345\n",
      "\n",
      "Batch 202/387 ━━━━━━━━━━━━━━━━━━━━ 14:16:39\n",
      "Accuracy: 0.9977 - Precision: 0.8909 - Recall: 0.8840 - Specificity: 0.9990 - F1: 0.8808 - Loss: 0.1341\n",
      "\n",
      "Batch 203/387 ━━━━━━━━━━━━━━━━━━━━ 14:18:07\n",
      "Accuracy: 0.9977 - Precision: 0.8909 - Recall: 0.8839 - Specificity: 0.9990 - F1: 0.8808 - Loss: 0.1341\n",
      "\n",
      "Batch 204/387 ━━━━━━━━━━━━━━━━━━━━ 14:19:43\n",
      "Accuracy: 0.9977 - Precision: 0.8911 - Recall: 0.8843 - Specificity: 0.9990 - F1: 0.8811 - Loss: 0.1339\n",
      "\n",
      "Batch 205/387 ━━━━━━━━━━━━━━━━━━━━ 14:21:04\n",
      "Accuracy: 0.9977 - Precision: 0.8913 - Recall: 0.8844 - Specificity: 0.9990 - F1: 0.8813 - Loss: 0.1337\n",
      "\n",
      "Batch 206/387 ━━━━━━━━━━━━━━━━━━━━ 14:22:22\n",
      "Accuracy: 0.9977 - Precision: 0.8915 - Recall: 0.8844 - Specificity: 0.9990 - F1: 0.8814 - Loss: 0.1335\n",
      "\n",
      "Batch 207/387 ━━━━━━━━━━━━━━━━━━━━ 14:23:46\n",
      "Accuracy: 0.9977 - Precision: 0.8919 - Recall: 0.8846 - Specificity: 0.9990 - F1: 0.8817 - Loss: 0.1332\n",
      "\n",
      "Batch 208/387 ━━━━━━━━━━━━━━━━━━━━ 14:25:16\n",
      "Accuracy: 0.9977 - Precision: 0.8921 - Recall: 0.8850 - Specificity: 0.9990 - F1: 0.8821 - Loss: 0.1328\n",
      "\n",
      "Batch 209/387 ━━━━━━━━━━━━━━━━━━━━ 14:26:51\n",
      "Accuracy: 0.9977 - Precision: 0.8916 - Recall: 0.8855 - Specificity: 0.9990 - F1: 0.8821 - Loss: 0.1328\n",
      "\n",
      "Batch 210/387 ━━━━━━━━━━━━━━━━━━━━ 14:28:17\n",
      "Accuracy: 0.9977 - Precision: 0.8906 - Recall: 0.8859 - Specificity: 0.9990 - F1: 0.8817 - Loss: 0.1332\n",
      "\n",
      "Batch 211/387 ━━━━━━━━━━━━━━━━━━━━ 14:29:50\n",
      "Accuracy: 0.9977 - Precision: 0.8878 - Recall: 0.8852 - Specificity: 0.9990 - F1: 0.8795 - Loss: 0.1355\n",
      "\n",
      "Batch 212/387 ━━━━━━━━━━━━━━━━━━━━ 14:31:09\n",
      "Accuracy: 0.9976 - Precision: 0.8857 - Recall: 0.8850 - Specificity: 0.9989 - F1: 0.8781 - Loss: 0.1370\n",
      "\n",
      "Batch 213/387 ━━━━━━━━━━━━━━━━━━━━ 14:32:40\n",
      "Accuracy: 0.9976 - Precision: 0.8856 - Recall: 0.8854 - Specificity: 0.9989 - F1: 0.8783 - Loss: 0.1368\n",
      "\n",
      "Batch 214/387 ━━━━━━━━━━━━━━━━━━━━ 14:34:11\n",
      "Accuracy: 0.9976 - Precision: 0.8861 - Recall: 0.8851 - Specificity: 0.9989 - F1: 0.8784 - Loss: 0.1368\n",
      "\n",
      "Batch 215/387 ━━━━━━━━━━━━━━━━━━━━ 14:35:54\n",
      "Accuracy: 0.9976 - Precision: 0.8862 - Recall: 0.8852 - Specificity: 0.9989 - F1: 0.8786 - Loss: 0.1366\n",
      "\n",
      "Batch 216/387 ━━━━━━━━━━━━━━━━━━━━ 14:37:44\n",
      "Accuracy: 0.9976 - Precision: 0.8865 - Recall: 0.8848 - Specificity: 0.9989 - F1: 0.8785 - Loss: 0.1367\n",
      "\n",
      "Batch 217/387 ━━━━━━━━━━━━━━━━━━━━ 14:39:36\n",
      "Accuracy: 0.9976 - Precision: 0.8870 - Recall: 0.8831 - Specificity: 0.9989 - F1: 0.8775 - Loss: 0.1378\n",
      "\n",
      "Batch 218/387 ━━━━━━━━━━━━━━━━━━━━ 14:41:23\n",
      "Accuracy: 0.9976 - Precision: 0.8875 - Recall: 0.8831 - Specificity: 0.9990 - F1: 0.8778 - Loss: 0.1375\n",
      "\n",
      "Batch 219/387 ━━━━━━━━━━━━━━━━━━━━ 14:43:12\n",
      "Accuracy: 0.9976 - Precision: 0.8879 - Recall: 0.8808 - Specificity: 0.9990 - F1: 0.8763 - Loss: 0.1392\n",
      "\n",
      "Batch 220/387 ━━━━━━━━━━━━━━━━━━━━ 14:44:46\n",
      "Accuracy: 0.9976 - Precision: 0.8883 - Recall: 0.8806 - Specificity: 0.9990 - F1: 0.8765 - Loss: 0.1390\n",
      "\n",
      "Batch 221/387 ━━━━━━━━━━━━━━━━━━━━ 14:46:36\n",
      "Accuracy: 0.9976 - Precision: 0.8886 - Recall: 0.8805 - Specificity: 0.9990 - F1: 0.8766 - Loss: 0.1388\n",
      "\n",
      "Batch 222/387 ━━━━━━━━━━━━━━━━━━━━ 14:48:25\n",
      "Accuracy: 0.9976 - Precision: 0.8890 - Recall: 0.8800 - Specificity: 0.9990 - F1: 0.8765 - Loss: 0.1390\n",
      "\n",
      "Batch 223/387 ━━━━━━━━━━━━━━━━━━━━ 14:50:07\n",
      "Accuracy: 0.9976 - Precision: 0.8893 - Recall: 0.8803 - Specificity: 0.9990 - F1: 0.8768 - Loss: 0.1386\n",
      "\n",
      "Batch 224/387 ━━━━━━━━━━━━━━━━━━━━ 14:51:46\n",
      "Accuracy: 0.9976 - Precision: 0.8892 - Recall: 0.8806 - Specificity: 0.9990 - F1: 0.8769 - Loss: 0.1385\n",
      "\n",
      "Batch 225/387 ━━━━━━━━━━━━━━━━━━━━ 14:53:18\n",
      "Accuracy: 0.9976 - Precision: 0.8895 - Recall: 0.8809 - Specificity: 0.9990 - F1: 0.8773 - Loss: 0.1381\n",
      "\n",
      "Batch 226/387 ━━━━━━━━━━━━━━━━━━━━ 14:54:58\n",
      "Accuracy: 0.9976 - Precision: 0.8892 - Recall: 0.8814 - Specificity: 0.9990 - F1: 0.8773 - Loss: 0.1380\n",
      "\n",
      "Batch 227/387 ━━━━━━━━━━━━━━━━━━━━ 14:56:32\n",
      "Accuracy: 0.9976 - Precision: 0.8883 - Recall: 0.8814 - Specificity: 0.9990 - F1: 0.8769 - Loss: 0.1385\n",
      "\n",
      "Batch 228/387 ━━━━━━━━━━━━━━━━━━━━ 14:58:13\n",
      "Accuracy: 0.9976 - Precision: 0.8880 - Recall: 0.8817 - Specificity: 0.9989 - F1: 0.8769 - Loss: 0.1385\n",
      "\n",
      "Batch 229/387 ━━━━━━━━━━━━━━━━━━━━ 14:59:43\n",
      "Accuracy: 0.9976 - Precision: 0.8879 - Recall: 0.8817 - Specificity: 0.9989 - F1: 0.8769 - Loss: 0.1385\n",
      "\n",
      "Batch 230/387 ━━━━━━━━━━━━━━━━━━━━ 15:01:09\n",
      "Accuracy: 0.9976 - Precision: 0.8874 - Recall: 0.8817 - Specificity: 0.9989 - F1: 0.8766 - Loss: 0.1388\n",
      "\n",
      "Batch 231/387 ━━━━━━━━━━━━━━━━━━━━ 15:02:34\n",
      "Accuracy: 0.9976 - Precision: 0.8871 - Recall: 0.8820 - Specificity: 0.9989 - F1: 0.8767 - Loss: 0.1387\n",
      "\n",
      "Batch 232/387 ━━━━━━━━━━━━━━━━━━━━ 15:03:58\n",
      "Accuracy: 0.9976 - Precision: 0.8874 - Recall: 0.8823 - Specificity: 0.9989 - F1: 0.8770 - Loss: 0.1384\n",
      "\n",
      "Batch 233/387 ━━━━━━━━━━━━━━━━━━━━ 15:05:20\n",
      "Accuracy: 0.9976 - Precision: 0.8861 - Recall: 0.8827 - Specificity: 0.9989 - F1: 0.8764 - Loss: 0.1390\n",
      "\n",
      "Batch 234/387 ━━━━━━━━━━━━━━━━━━━━ 15:06:53\n",
      "Accuracy: 0.9976 - Precision: 0.8863 - Recall: 0.8824 - Specificity: 0.9989 - F1: 0.8764 - Loss: 0.1390\n",
      "\n",
      "Batch 235/387 ━━━━━━━━━━━━━━━━━━━━ 15:08:24\n",
      "Accuracy: 0.9976 - Precision: 0.8861 - Recall: 0.8825 - Specificity: 0.9989 - F1: 0.8764 - Loss: 0.1390\n",
      "\n",
      "Batch 236/387 ━━━━━━━━━━━━━━━━━━━━ 15:09:46\n",
      "Accuracy: 0.9976 - Precision: 0.8863 - Recall: 0.8828 - Specificity: 0.9990 - F1: 0.8766 - Loss: 0.1387\n",
      "\n",
      "Batch 237/387 ━━━━━━━━━━━━━━━━━━━━ 15:11:09\n",
      "Accuracy: 0.9976 - Precision: 0.8867 - Recall: 0.8825 - Specificity: 0.9990 - F1: 0.8767 - Loss: 0.1387\n",
      "\n",
      "Batch 238/387 ━━━━━━━━━━━━━━━━━━━━ 15:12:40\n",
      "Accuracy: 0.9976 - Precision: 0.8871 - Recall: 0.8825 - Specificity: 0.9990 - F1: 0.8769 - Loss: 0.1385\n",
      "\n",
      "Batch 239/387 ━━━━━━━━━━━━━━━━━━━━ 15:14:00\n",
      "Accuracy: 0.9976 - Precision: 0.8874 - Recall: 0.8821 - Specificity: 0.9990 - F1: 0.8769 - Loss: 0.1385\n",
      "\n",
      "Batch 240/387 ━━━━━━━━━━━━━━━━━━━━ 15:15:26\n",
      "Accuracy: 0.9976 - Precision: 0.8878 - Recall: 0.8816 - Specificity: 0.9990 - F1: 0.8768 - Loss: 0.1386\n",
      "\n",
      "Batch 241/387 ━━━━━━━━━━━━━━━━━━━━ 15:17:01\n",
      "Accuracy: 0.9976 - Precision: 0.8881 - Recall: 0.8819 - Specificity: 0.9990 - F1: 0.8771 - Loss: 0.1383\n",
      "\n",
      "Batch 242/387 ━━━━━━━━━━━━━━━━━━━━ 15:18:27\n",
      "Accuracy: 0.9976 - Precision: 0.8883 - Recall: 0.8822 - Specificity: 0.9990 - F1: 0.8774 - Loss: 0.1380\n",
      "\n",
      "Batch 243/387 ━━━━━━━━━━━━━━━━━━━━ 15:19:55\n",
      "Accuracy: 0.9976 - Precision: 0.8886 - Recall: 0.8823 - Specificity: 0.9990 - F1: 0.8777 - Loss: 0.1377\n",
      "\n",
      "Batch 244/387 ━━━━━━━━━━━━━━━━━━━━ 15:21:31\n",
      "Accuracy: 0.9976 - Precision: 0.8887 - Recall: 0.8827 - Specificity: 0.9990 - F1: 0.8779 - Loss: 0.1375\n",
      "\n",
      "Batch 245/387 ━━━━━━━━━━━━━━━━━━━━ 15:23:02\n",
      "Accuracy: 0.9976 - Precision: 0.8885 - Recall: 0.8825 - Specificity: 0.9990 - F1: 0.8777 - Loss: 0.1376\n",
      "\n",
      "Batch 246/387 ━━━━━━━━━━━━━━━━━━━━ 15:24:42\n",
      "Accuracy: 0.9976 - Precision: 0.8880 - Recall: 0.8829 - Specificity: 0.9990 - F1: 0.8777 - Loss: 0.1376\n",
      "\n",
      "Batch 247/387 ━━━━━━━━━━━━━━━━━━━━ 15:26:08\n",
      "Accuracy: 0.9976 - Precision: 0.8870 - Recall: 0.8826 - Specificity: 0.9990 - F1: 0.8770 - Loss: 0.1383\n",
      "\n",
      "Batch 248/387 ━━━━━━━━━━━━━━━━━━━━ 15:27:36\n",
      "Accuracy: 0.9976 - Precision: 0.8871 - Recall: 0.8824 - Specificity: 0.9990 - F1: 0.8770 - Loss: 0.1383\n",
      "\n",
      "Batch 249/387 ━━━━━━━━━━━━━━━━━━━━ 15:29:03\n",
      "Accuracy: 0.9976 - Precision: 0.8876 - Recall: 0.8818 - Specificity: 0.9990 - F1: 0.8769 - Loss: 0.1386\n",
      "\n",
      "Batch 250/387 ━━━━━━━━━━━━━━━━━━━━ 15:30:20\n",
      "Accuracy: 0.9976 - Precision: 0.8878 - Recall: 0.8821 - Specificity: 0.9990 - F1: 0.8772 - Loss: 0.1382\n",
      "\n",
      "Batch 251/387 ━━━━━━━━━━━━━━━━━━━━ 15:31:51\n",
      "Accuracy: 0.9976 - Precision: 0.8879 - Recall: 0.8822 - Specificity: 0.9990 - F1: 0.8773 - Loss: 0.1381\n",
      "\n",
      "Batch 252/387 ━━━━━━━━━━━━━━━━━━━━ 15:33:16\n",
      "Accuracy: 0.9976 - Precision: 0.8878 - Recall: 0.8826 - Specificity: 0.9990 - F1: 0.8775 - Loss: 0.1379\n",
      "\n",
      "Batch 253/387 ━━━━━━━━━━━━━━━━━━━━ 15:34:53\n",
      "Accuracy: 0.9976 - Precision: 0.8880 - Recall: 0.8825 - Specificity: 0.9990 - F1: 0.8776 - Loss: 0.1378\n",
      "\n",
      "Batch 254/387 ━━━━━━━━━━━━━━━━━━━━ 15:36:27\n",
      "Accuracy: 0.9976 - Precision: 0.8881 - Recall: 0.8820 - Specificity: 0.9990 - F1: 0.8773 - Loss: 0.1380\n",
      "\n",
      "Batch 255/387 ━━━━━━━━━━━━━━━━━━━━ 15:37:56\n",
      "Accuracy: 0.9976 - Precision: 0.8882 - Recall: 0.8820 - Specificity: 0.9990 - F1: 0.8774 - Loss: 0.1379\n",
      "\n",
      "Batch 256/387 ━━━━━━━━━━━━━━━━━━━━ 15:39:19\n",
      "Accuracy: 0.9976 - Precision: 0.8877 - Recall: 0.8814 - Specificity: 0.9990 - F1: 0.8769 - Loss: 0.1384\n",
      "\n",
      "Batch 257/387 ━━━━━━━━━━━━━━━━━━━━ 15:40:41\n",
      "Accuracy: 0.9976 - Precision: 0.8877 - Recall: 0.8801 - Specificity: 0.9990 - F1: 0.8761 - Loss: 0.1393\n",
      "\n",
      "Batch 258/387 ━━━━━━━━━━━━━━━━━━━━ 15:42:11\n",
      "Accuracy: 0.9976 - Precision: 0.8880 - Recall: 0.8803 - Specificity: 0.9990 - F1: 0.8764 - Loss: 0.1390\n",
      "\n",
      "Batch 259/387 ━━━━━━━━━━━━━━━━━━━━ 15:43:49\n",
      "Accuracy: 0.9976 - Precision: 0.8882 - Recall: 0.8804 - Specificity: 0.9990 - F1: 0.8766 - Loss: 0.1388\n",
      "\n",
      "Batch 260/387 ━━━━━━━━━━━━━━━━━━━━ 15:45:28\n",
      "Accuracy: 0.9976 - Precision: 0.8880 - Recall: 0.8803 - Specificity: 0.9990 - F1: 0.8765 - Loss: 0.1389\n",
      "\n",
      "Batch 261/387 ━━━━━━━━━━━━━━━━━━━━ 15:46:58\n",
      "Accuracy: 0.9976 - Precision: 0.8877 - Recall: 0.8792 - Specificity: 0.9990 - F1: 0.8757 - Loss: 0.1397\n",
      "\n",
      "Batch 262/387 ━━━━━━━━━━━━━━━━━━━━ 15:48:27\n",
      "Accuracy: 0.9976 - Precision: 0.8877 - Recall: 0.8796 - Specificity: 0.9990 - F1: 0.8759 - Loss: 0.1394\n",
      "\n",
      "Batch 263/387 ━━━━━━━━━━━━━━━━━━━━ 15:49:52\n",
      "Accuracy: 0.9976 - Precision: 0.8878 - Recall: 0.8796 - Specificity: 0.9990 - F1: 0.8760 - Loss: 0.1393\n",
      "\n",
      "Batch 264/387 ━━━━━━━━━━━━━━━━━━━━ 15:51:25\n",
      "Accuracy: 0.9976 - Precision: 0.8882 - Recall: 0.8799 - Specificity: 0.9990 - F1: 0.8764 - Loss: 0.1390\n",
      "\n",
      "Batch 265/387 ━━━━━━━━━━━━━━━━━━━━ 15:53:01\n",
      "Accuracy: 0.9976 - Precision: 0.8882 - Recall: 0.8799 - Specificity: 0.9990 - F1: 0.8764 - Loss: 0.1388\n",
      "\n",
      "Batch 266/387 ━━━━━━━━━━━━━━━━━━━━ 15:54:28\n",
      "Accuracy: 0.9976 - Precision: 0.8884 - Recall: 0.8803 - Specificity: 0.9990 - F1: 0.8767 - Loss: 0.1385\n",
      "\n",
      "Batch 267/387 ━━━━━━━━━━━━━━━━━━━━ 15:56:09\n",
      "Accuracy: 0.9976 - Precision: 0.8883 - Recall: 0.8807 - Specificity: 0.9990 - F1: 0.8769 - Loss: 0.1383\n",
      "\n",
      "Batch 268/387 ━━━━━━━━━━━━━━━━━━━━ 15:57:40\n",
      "Accuracy: 0.9976 - Precision: 0.8877 - Recall: 0.8811 - Specificity: 0.9990 - F1: 0.8768 - Loss: 0.1385\n",
      "\n",
      "Batch 269/387 ━━━━━━━━━━━━━━━━━━━━ 15:59:16\n",
      "Accuracy: 0.9976 - Precision: 0.8874 - Recall: 0.8815 - Specificity: 0.9990 - F1: 0.8768 - Loss: 0.1384\n",
      "\n",
      "Batch 270/387 ━━━━━━━━━━━━━━━━━━━━ 16:00:39\n",
      "Accuracy: 0.9976 - Precision: 0.8875 - Recall: 0.8818 - Specificity: 0.9990 - F1: 0.8770 - Loss: 0.1382\n",
      "\n",
      "Batch 271/387 ━━━━━━━━━━━━━━━━━━━━ 16:02:20\n",
      "Accuracy: 0.9976 - Precision: 0.8876 - Recall: 0.8821 - Specificity: 0.9990 - F1: 0.8773 - Loss: 0.1379\n",
      "\n",
      "Batch 272/387 ━━━━━━━━━━━━━━━━━━━━ 16:03:58\n",
      "Accuracy: 0.9977 - Precision: 0.8877 - Recall: 0.8824 - Specificity: 0.9990 - F1: 0.8775 - Loss: 0.1376\n",
      "\n",
      "Batch 273/387 ━━━━━━━━━━━━━━━━━━━━ 16:05:26\n",
      "Accuracy: 0.9977 - Precision: 0.8879 - Recall: 0.8825 - Specificity: 0.9990 - F1: 0.8777 - Loss: 0.1375\n",
      "\n",
      "Batch 274/387 ━━━━━━━━━━━━━━━━━━━━ 16:07:00\n",
      "Accuracy: 0.9976 - Precision: 0.8883 - Recall: 0.8818 - Specificity: 0.9990 - F1: 0.8775 - Loss: 0.1377\n",
      "\n",
      "Batch 275/387 ━━━━━━━━━━━━━━━━━━━━ 16:08:23\n",
      "Accuracy: 0.9976 - Precision: 0.8886 - Recall: 0.8821 - Specificity: 0.9990 - F1: 0.8777 - Loss: 0.1374\n",
      "\n",
      "Batch 276/387 ━━━━━━━━━━━━━━━━━━━━ 16:09:47\n",
      "Accuracy: 0.9976 - Precision: 0.8887 - Recall: 0.8823 - Specificity: 0.9990 - F1: 0.8780 - Loss: 0.1372\n",
      "\n",
      "Batch 277/387 ━━━━━━━━━━━━━━━━━━━━ 16:11:20\n",
      "Accuracy: 0.9977 - Precision: 0.8889 - Recall: 0.8824 - Specificity: 0.9990 - F1: 0.8782 - Loss: 0.1370\n",
      "\n",
      "Batch 278/387 ━━━━━━━━━━━━━━━━━━━━ 16:12:56\n",
      "Accuracy: 0.9977 - Precision: 0.8893 - Recall: 0.8826 - Specificity: 0.9990 - F1: 0.8784 - Loss: 0.1367\n",
      "\n",
      "Batch 279/387 ━━━━━━━━━━━━━━━━━━━━ 16:14:26\n",
      "Accuracy: 0.9977 - Precision: 0.8889 - Recall: 0.8829 - Specificity: 0.9990 - F1: 0.8784 - Loss: 0.1367\n",
      "\n",
      "Batch 280/387 ━━━━━━━━━━━━━━━━━━━━ 16:16:02\n",
      "Accuracy: 0.9976 - Precision: 0.8877 - Recall: 0.8833 - Specificity: 0.9990 - F1: 0.8778 - Loss: 0.1374\n",
      "\n",
      "Batch 281/387 ━━━━━━━━━━━━━━━━━━━━ 16:17:33\n",
      "Accuracy: 0.9977 - Precision: 0.8875 - Recall: 0.8835 - Specificity: 0.9990 - F1: 0.8778 - Loss: 0.1373\n",
      "\n",
      "Batch 282/387 ━━━━━━━━━━━━━━━━━━━━ 16:19:09\n",
      "Accuracy: 0.9977 - Precision: 0.8877 - Recall: 0.8834 - Specificity: 0.9990 - F1: 0.8779 - Loss: 0.1372\n",
      "\n",
      "Batch 283/387 ━━━━━━━━━━━━━━━━━━━━ 16:20:39\n",
      "Accuracy: 0.9977 - Precision: 0.8879 - Recall: 0.8836 - Specificity: 0.9990 - F1: 0.8781 - Loss: 0.1370\n",
      "\n",
      "Batch 284/387 ━━━━━━━━━━━━━━━━━━━━ 16:22:24\n",
      "Accuracy: 0.9977 - Precision: 0.8876 - Recall: 0.8835 - Specificity: 0.9990 - F1: 0.8779 - Loss: 0.1372\n",
      "\n",
      "Batch 285/387 ━━━━━━━━━━━━━━━━━━━━ 16:23:49\n",
      "Accuracy: 0.9977 - Precision: 0.8874 - Recall: 0.8838 - Specificity: 0.9990 - F1: 0.8780 - Loss: 0.1371\n",
      "\n",
      "Batch 286/387 ━━━━━━━━━━━━━━━━━━━━ 16:25:19\n",
      "Accuracy: 0.9977 - Precision: 0.8866 - Recall: 0.8838 - Specificity: 0.9990 - F1: 0.8776 - Loss: 0.1375\n",
      "\n",
      "Batch 287/387 ━━━━━━━━━━━━━━━━━━━━ 16:26:48\n",
      "Accuracy: 0.9977 - Precision: 0.8857 - Recall: 0.8836 - Specificity: 0.9990 - F1: 0.8770 - Loss: 0.1381\n",
      "\n",
      "Batch 288/387 ━━━━━━━━━━━━━━━━━━━━ 16:28:24\n",
      "Accuracy: 0.9976 - Precision: 0.8861 - Recall: 0.8820 - Specificity: 0.9990 - F1: 0.8759 - Loss: 0.1394\n",
      "\n",
      "Batch 289/387 ━━━━━━━━━━━━━━━━━━━━ 16:30:01\n",
      "Accuracy: 0.9976 - Precision: 0.8865 - Recall: 0.8818 - Specificity: 0.9990 - F1: 0.8760 - Loss: 0.1393\n",
      "\n",
      "Batch 290/387 ━━━━━━━━━━━━━━━━━━━━ 16:31:25\n",
      "Accuracy: 0.9976 - Precision: 0.8869 - Recall: 0.8804 - Specificity: 0.9990 - F1: 0.8752 - Loss: 0.1404\n",
      "\n",
      "Batch 291/387 ━━━━━━━━━━━━━━━━━━━━ 16:32:44\n",
      "Accuracy: 0.9976 - Precision: 0.8873 - Recall: 0.8783 - Specificity: 0.9990 - F1: 0.8736 - Loss: 0.1422\n",
      "\n",
      "Batch 292/387 ━━━━━━━━━━━━━━━━━━━━ 16:34:09\n",
      "Accuracy: 0.9976 - Precision: 0.8874 - Recall: 0.8780 - Specificity: 0.9990 - F1: 0.8736 - Loss: 0.1422\n",
      "\n",
      "Batch 293/387 ━━━━━━━━━━━━━━━━━━━━ 16:35:39\n",
      "Accuracy: 0.9976 - Precision: 0.8875 - Recall: 0.8774 - Specificity: 0.9990 - F1: 0.8734 - Loss: 0.1425\n",
      "\n",
      "Batch 294/387 ━━━━━━━━━━━━━━━━━━━━ 16:37:19\n",
      "Accuracy: 0.9976 - Precision: 0.8879 - Recall: 0.8770 - Specificity: 0.9990 - F1: 0.8733 - Loss: 0.1426\n",
      "\n",
      "Batch 295/387 ━━━━━━━━━━━━━━━━━━━━ 16:38:52\n",
      "Accuracy: 0.9976 - Precision: 0.8882 - Recall: 0.8764 - Specificity: 0.9990 - F1: 0.8731 - Loss: 0.1428\n",
      "\n",
      "Batch 296/387 ━━━━━━━━━━━━━━━━━━━━ 16:40:26\n",
      "Accuracy: 0.9976 - Precision: 0.8883 - Recall: 0.8767 - Specificity: 0.9990 - F1: 0.8734 - Loss: 0.1425\n",
      "\n",
      "Batch 297/387 ━━━━━━━━━━━━━━━━━━━━ 16:42:02\n",
      "Accuracy: 0.9976 - Precision: 0.8880 - Recall: 0.8769 - Specificity: 0.9990 - F1: 0.8733 - Loss: 0.1425\n",
      "\n",
      "Batch 298/387 ━━━━━━━━━━━━━━━━━━━━ 16:43:31\n",
      "Accuracy: 0.9976 - Precision: 0.8880 - Recall: 0.8773 - Specificity: 0.9990 - F1: 0.8735 - Loss: 0.1424\n",
      "\n",
      "Batch 299/387 ━━━━━━━━━━━━━━━━━━━━ 16:44:59\n",
      "Accuracy: 0.9976 - Precision: 0.8880 - Recall: 0.8776 - Specificity: 0.9990 - F1: 0.8737 - Loss: 0.1421\n",
      "\n",
      "Batch 300/387 ━━━━━━━━━━━━━━━━━━━━ 16:46:27\n",
      "Accuracy: 0.9975 - Precision: 0.8869 - Recall: 0.8777 - Specificity: 0.9990 - F1: 0.8732 - Loss: 0.1428\n",
      "\n",
      "Batch 301/387 ━━━━━━━━━━━━━━━━━━━━ 16:48:03\n",
      "Accuracy: 0.9975 - Precision: 0.8869 - Recall: 0.8780 - Specificity: 0.9990 - F1: 0.8733 - Loss: 0.1427\n",
      "\n",
      "Batch 302/387 ━━━━━━━━━━━━━━━━━━━━ 16:49:36\n",
      "Accuracy: 0.9976 - Precision: 0.8861 - Recall: 0.8784 - Specificity: 0.9990 - F1: 0.8730 - Loss: 0.1430\n",
      "\n",
      "Batch 303/387 ━━━━━━━━━━━━━━━━━━━━ 16:50:52\n",
      "Accuracy: 0.9975 - Precision: 0.8847 - Recall: 0.8787 - Specificity: 0.9990 - F1: 0.8721 - Loss: 0.1440\n",
      "\n",
      "Batch 304/387 ━━━━━━━━━━━━━━━━━━━━ 16:52:32\n",
      "Accuracy: 0.9976 - Precision: 0.8848 - Recall: 0.8790 - Specificity: 0.9990 - F1: 0.8723 - Loss: 0.1437\n",
      "\n",
      "Batch 305/387 ━━━━━━━━━━━━━━━━━━━━ 16:54:11\n",
      "Accuracy: 0.9976 - Precision: 0.8851 - Recall: 0.8791 - Specificity: 0.9990 - F1: 0.8726 - Loss: 0.1435\n",
      "\n",
      "Batch 306/387 ━━━━━━━━━━━━━━━━━━━━ 16:55:47\n",
      "Accuracy: 0.9976 - Precision: 0.8846 - Recall: 0.8786 - Specificity: 0.9990 - F1: 0.8721 - Loss: 0.1440\n",
      "\n",
      "Batch 307/387 ━━━━━━━━━━━━━━━━━━━━ 16:57:33\n",
      "Accuracy: 0.9975 - Precision: 0.8848 - Recall: 0.8786 - Specificity: 0.9990 - F1: 0.8722 - Loss: 0.1439\n",
      "\n",
      "Batch 308/387 ━━━━━━━━━━━━━━━━━━━━ 16:59:03\n",
      "Accuracy: 0.9976 - Precision: 0.8851 - Recall: 0.8787 - Specificity: 0.9990 - F1: 0.8725 - Loss: 0.1436\n",
      "\n",
      "Batch 309/387 ━━━━━━━━━━━━━━━━━━━━ 17:00:28\n",
      "Accuracy: 0.9976 - Precision: 0.8848 - Recall: 0.8790 - Specificity: 0.9990 - F1: 0.8725 - Loss: 0.1436\n",
      "\n",
      "Batch 310/387 ━━━━━━━━━━━━━━━━━━━━ 17:02:09\n",
      "Accuracy: 0.9976 - Precision: 0.8852 - Recall: 0.8789 - Specificity: 0.9990 - F1: 0.8726 - Loss: 0.1435\n",
      "\n",
      "Batch 311/387 ━━━━━━━━━━━━━━━━━━━━ 17:03:43\n",
      "Accuracy: 0.9976 - Precision: 0.8854 - Recall: 0.8784 - Specificity: 0.9990 - F1: 0.8725 - Loss: 0.1436\n",
      "\n",
      "Batch 312/387 ━━━━━━━━━━━━━━━━━━━━ 17:05:12\n",
      "Accuracy: 0.9976 - Precision: 0.8857 - Recall: 0.8781 - Specificity: 0.9990 - F1: 0.8725 - Loss: 0.1436\n",
      "\n",
      "Batch 313/387 ━━━━━━━━━━━━━━━━━━━━ 17:06:48\n",
      "Accuracy: 0.9976 - Precision: 0.8857 - Recall: 0.8780 - Specificity: 0.9990 - F1: 0.8725 - Loss: 0.1436\n",
      "\n",
      "Batch 314/387 ━━━━━━━━━━━━━━━━━━━━ 17:08:34\n",
      "Accuracy: 0.9976 - Precision: 0.8854 - Recall: 0.8783 - Specificity: 0.9990 - F1: 0.8725 - Loss: 0.1436\n",
      "\n",
      "Batch 315/387 ━━━━━━━━━━━━━━━━━━━━ 17:10:00\n",
      "Accuracy: 0.9976 - Precision: 0.8857 - Recall: 0.8784 - Specificity: 0.9990 - F1: 0.8727 - Loss: 0.1433\n",
      "\n",
      "Batch 316/387 ━━━━━━━━━━━━━━━━━━━━ 17:11:36\n",
      "Accuracy: 0.9976 - Precision: 0.8860 - Recall: 0.8784 - Specificity: 0.9990 - F1: 0.8729 - Loss: 0.1431\n",
      "\n",
      "Batch 317/387 ━━━━━━━━━━━━━━━━━━━━ 17:13:02\n",
      "Accuracy: 0.9976 - Precision: 0.8864 - Recall: 0.8779 - Specificity: 0.9990 - F1: 0.8728 - Loss: 0.1433\n",
      "\n",
      "Batch 318/387 ━━━━━━━━━━━━━━━━━━━━ 17:14:29\n",
      "Accuracy: 0.9976 - Precision: 0.8866 - Recall: 0.8777 - Specificity: 0.9990 - F1: 0.8728 - Loss: 0.1432\n",
      "\n",
      "Batch 319/387 ━━━━━━━━━━━━━━━━━━━━ 17:15:46\n",
      "Accuracy: 0.9975 - Precision: 0.8870 - Recall: 0.8770 - Specificity: 0.9990 - F1: 0.8725 - Loss: 0.1437\n",
      "\n",
      "Batch 320/387 ━━━━━━━━━━━━━━━━━━━━ 17:17:18\n",
      "Accuracy: 0.9975 - Precision: 0.8872 - Recall: 0.8771 - Specificity: 0.9990 - F1: 0.8727 - Loss: 0.1435\n",
      "\n",
      "Batch 321/387 ━━━━━━━━━━━━━━━━━━━━ 17:18:41\n",
      "Accuracy: 0.9975 - Precision: 0.8875 - Recall: 0.8772 - Specificity: 0.9990 - F1: 0.8729 - Loss: 0.1433\n",
      "\n",
      "Batch 322/387 ━━━━━━━━━━━━━━━━━━━━ 17:20:14\n",
      "Accuracy: 0.9975 - Precision: 0.8876 - Recall: 0.8774 - Specificity: 0.9990 - F1: 0.8731 - Loss: 0.1430\n",
      "\n",
      "Batch 323/387 ━━━━━━━━━━━━━━━━━━━━ 17:21:31\n",
      "Accuracy: 0.9975 - Precision: 0.8877 - Recall: 0.8776 - Specificity: 0.9990 - F1: 0.8733 - Loss: 0.1428\n",
      "\n",
      "Batch 324/387 ━━━━━━━━━━━━━━━━━━━━ 17:23:00\n",
      "Accuracy: 0.9975 - Precision: 0.8879 - Recall: 0.8778 - Specificity: 0.9990 - F1: 0.8735 - Loss: 0.1426\n",
      "\n",
      "Batch 325/387 ━━━━━━━━━━━━━━━━━━━━ 17:24:29\n",
      "Accuracy: 0.9975 - Precision: 0.8878 - Recall: 0.8779 - Specificity: 0.9990 - F1: 0.8735 - Loss: 0.1425\n",
      "\n",
      "Batch 326/387 ━━━━━━━━━━━━━━━━━━━━ 17:25:41\n",
      "Accuracy: 0.9975 - Precision: 0.8877 - Recall: 0.8778 - Specificity: 0.9990 - F1: 0.8734 - Loss: 0.1426\n",
      "\n",
      "Batch 327/387 ━━━━━━━━━━━━━━━━━━━━ 17:26:55\n",
      "Accuracy: 0.9975 - Precision: 0.8879 - Recall: 0.8779 - Specificity: 0.9990 - F1: 0.8736 - Loss: 0.1425\n",
      "\n",
      "Batch 328/387 ━━━━━━━━━━━━━━━━━━━━ 17:28:17\n",
      "Accuracy: 0.9976 - Precision: 0.8881 - Recall: 0.8779 - Specificity: 0.9990 - F1: 0.8737 - Loss: 0.1423\n",
      "\n",
      "Batch 329/387 ━━━━━━━━━━━━━━━━━━━━ 17:29:33\n",
      "Accuracy: 0.9975 - Precision: 0.8877 - Recall: 0.8780 - Specificity: 0.9990 - F1: 0.8736 - Loss: 0.1425\n",
      "\n",
      "Batch 330/387 ━━━━━━━━━━━━━━━━━━━━ 17:31:06\n",
      "Accuracy: 0.9975 - Precision: 0.8879 - Recall: 0.8782 - Specificity: 0.9990 - F1: 0.8739 - Loss: 0.1422\n",
      "\n",
      "Batch 331/387 ━━━━━━━━━━━━━━━━━━━━ 17:32:33\n",
      "Accuracy: 0.9975 - Precision: 0.8879 - Recall: 0.8785 - Specificity: 0.9990 - F1: 0.8740 - Loss: 0.1421\n",
      "\n",
      "Batch 332/387 ━━━━━━━━━━━━━━━━━━━━ 17:33:55\n",
      "Accuracy: 0.9975 - Precision: 0.8880 - Recall: 0.8786 - Specificity: 0.9990 - F1: 0.8741 - Loss: 0.1419\n",
      "\n",
      "Batch 333/387 ━━━━━━━━━━━━━━━━━━━━ 17:35:16\n",
      "Accuracy: 0.9976 - Precision: 0.8880 - Recall: 0.8789 - Specificity: 0.9990 - F1: 0.8743 - Loss: 0.1417\n",
      "\n",
      "Batch 334/387 ━━━━━━━━━━━━━━━━━━━━ 17:36:38\n",
      "Accuracy: 0.9975 - Precision: 0.8874 - Recall: 0.8793 - Specificity: 0.9990 - F1: 0.8742 - Loss: 0.1419\n",
      "\n",
      "Batch 335/387 ━━━━━━━━━━━━━━━━━━━━ 17:37:59\n",
      "Accuracy: 0.9976 - Precision: 0.8873 - Recall: 0.8791 - Specificity: 0.9990 - F1: 0.8740 - Loss: 0.1420\n",
      "\n",
      "Batch 336/387 ━━━━━━━━━━━━━━━━━━━━ 17:39:22\n",
      "Accuracy: 0.9976 - Precision: 0.8873 - Recall: 0.8792 - Specificity: 0.9990 - F1: 0.8741 - Loss: 0.1419\n",
      "\n",
      "Batch 337/387 ━━━━━━━━━━━━━━━━━━━━ 17:40:46\n",
      "Accuracy: 0.9976 - Precision: 0.8866 - Recall: 0.8796 - Specificity: 0.9990 - F1: 0.8739 - Loss: 0.1421\n",
      "\n",
      "Batch 338/387 ━━━━━━━━━━━━━━━━━━━━ 17:42:08\n",
      "Accuracy: 0.9975 - Precision: 0.8868 - Recall: 0.8787 - Specificity: 0.9990 - F1: 0.8735 - Loss: 0.1427\n",
      "\n",
      "Batch 339/387 ━━━━━━━━━━━━━━━━━━━━ 17:43:37\n",
      "Accuracy: 0.9975 - Precision: 0.8871 - Recall: 0.8782 - Specificity: 0.9990 - F1: 0.8733 - Loss: 0.1428\n",
      "\n",
      "Batch 340/387 ━━━━━━━━━━━━━━━━━━━━ 17:44:54\n",
      "Accuracy: 0.9975 - Precision: 0.8872 - Recall: 0.8782 - Specificity: 0.9990 - F1: 0.8734 - Loss: 0.1428\n",
      "\n",
      "Batch 341/387 ━━━━━━━━━━━━━━━━━━━━ 17:46:17\n",
      "Accuracy: 0.9975 - Precision: 0.8875 - Recall: 0.8783 - Specificity: 0.9990 - F1: 0.8736 - Loss: 0.1426\n",
      "\n",
      "Batch 342/387 ━━━━━━━━━━━━━━━━━━━━ 17:47:40\n",
      "Accuracy: 0.9975 - Precision: 0.8862 - Recall: 0.8786 - Specificity: 0.9989 - F1: 0.8729 - Loss: 0.1434\n",
      "\n",
      "Batch 343/387 ━━━━━━━━━━━━━━━━━━━━ 17:48:59\n",
      "Accuracy: 0.9975 - Precision: 0.8862 - Recall: 0.8787 - Specificity: 0.9989 - F1: 0.8729 - Loss: 0.1433\n",
      "\n",
      "Batch 344/387 ━━━━━━━━━━━━━━━━━━━━ 17:50:26\n",
      "Accuracy: 0.9975 - Precision: 0.8863 - Recall: 0.8789 - Specificity: 0.9989 - F1: 0.8731 - Loss: 0.1432\n",
      "\n",
      "Batch 345/387 ━━━━━━━━━━━━━━━━━━━━ 17:51:47\n",
      "Accuracy: 0.9975 - Precision: 0.8864 - Recall: 0.8789 - Specificity: 0.9989 - F1: 0.8732 - Loss: 0.1430\n",
      "\n",
      "Batch 346/387 ━━━━━━━━━━━━━━━━━━━━ 17:53:20\n",
      "Accuracy: 0.9975 - Precision: 0.8867 - Recall: 0.8788 - Specificity: 0.9990 - F1: 0.8733 - Loss: 0.1429\n",
      "\n",
      "Batch 347/387 ━━━━━━━━━━━━━━━━━━━━ 17:54:47\n",
      "Accuracy: 0.9975 - Precision: 0.8869 - Recall: 0.8789 - Specificity: 0.9990 - F1: 0.8734 - Loss: 0.1427\n",
      "\n",
      "Batch 348/387 ━━━━━━━━━━━━━━━━━━━━ 17:56:14\n",
      "Accuracy: 0.9975 - Precision: 0.8870 - Recall: 0.8791 - Specificity: 0.9990 - F1: 0.8736 - Loss: 0.1425\n",
      "\n",
      "Batch 349/387 ━━━━━━━━━━━━━━━━━━━━ 17:57:30\n",
      "Accuracy: 0.9975 - Precision: 0.8855 - Recall: 0.8793 - Specificity: 0.9989 - F1: 0.8726 - Loss: 0.1436\n",
      "\n",
      "Batch 350/387 ━━━━━━━━━━━━━━━━━━━━ 17:59:00\n",
      "Accuracy: 0.9975 - Precision: 0.8857 - Recall: 0.8795 - Specificity: 0.9989 - F1: 0.8728 - Loss: 0.1433\n",
      "\n",
      "Batch 351/387 ━━━━━━━━━━━━━━━━━━━━ 18:00:34\n",
      "Accuracy: 0.9975 - Precision: 0.8860 - Recall: 0.8792 - Specificity: 0.9989 - F1: 0.8728 - Loss: 0.1433\n",
      "\n",
      "Batch 352/387 ━━━━━━━━━━━━━━━━━━━━ 18:02:01\n",
      "Accuracy: 0.9975 - Precision: 0.8863 - Recall: 0.8793 - Specificity: 0.9989 - F1: 0.8731 - Loss: 0.1431\n",
      "\n",
      "Batch 353/387 ━━━━━━━━━━━━━━━━━━━━ 18:03:39\n",
      "Accuracy: 0.9975 - Precision: 0.8865 - Recall: 0.8792 - Specificity: 0.9989 - F1: 0.8731 - Loss: 0.1431\n",
      "\n",
      "Batch 354/387 ━━━━━━━━━━━━━━━━━━━━ 18:05:10\n",
      "Accuracy: 0.9975 - Precision: 0.8866 - Recall: 0.8793 - Specificity: 0.9989 - F1: 0.8733 - Loss: 0.1429\n",
      "\n",
      "Batch 355/387 ━━━━━━━━━━━━━━━━━━━━ 18:06:40\n",
      "Accuracy: 0.9975 - Precision: 0.8868 - Recall: 0.8795 - Specificity: 0.9990 - F1: 0.8735 - Loss: 0.1426\n",
      "\n",
      "Batch 356/387 ━━━━━━━━━━━━━━━━━━━━ 18:08:17\n",
      "Accuracy: 0.9975 - Precision: 0.8858 - Recall: 0.8794 - Specificity: 0.9989 - F1: 0.8728 - Loss: 0.1433\n",
      "\n",
      "Batch 357/387 ━━━━━━━━━━━━━━━━━━━━ 18:09:33\n",
      "Accuracy: 0.9975 - Precision: 0.8846 - Recall: 0.8796 - Specificity: 0.9989 - F1: 0.8722 - Loss: 0.1440\n",
      "\n",
      "Batch 358/387 ━━━━━━━━━━━━━━━━━━━━ 18:10:54\n",
      "Accuracy: 0.9975 - Precision: 0.8844 - Recall: 0.8799 - Specificity: 0.9989 - F1: 0.8722 - Loss: 0.1440\n",
      "\n",
      "Batch 359/387 ━━━━━━━━━━━━━━━━━━━━ 18:12:26\n",
      "Accuracy: 0.9975 - Precision: 0.8845 - Recall: 0.8791 - Specificity: 0.9989 - F1: 0.8718 - Loss: 0.1444\n",
      "\n",
      "Batch 360/387 ━━━━━━━━━━━━━━━━━━━━ 18:13:54\n",
      "Accuracy: 0.9975 - Precision: 0.8842 - Recall: 0.8787 - Specificity: 0.9989 - F1: 0.8714 - Loss: 0.1448\n",
      "\n",
      "Batch 361/387 ━━━━━━━━━━━━━━━━━━━━ 18:15:24\n",
      "Accuracy: 0.9975 - Precision: 0.8844 - Recall: 0.8782 - Specificity: 0.9989 - F1: 0.8712 - Loss: 0.1450\n",
      "\n",
      "Batch 362/387 ━━━━━━━━━━━━━━━━━━━━ 18:16:47\n",
      "Accuracy: 0.9975 - Precision: 0.8842 - Recall: 0.8785 - Specificity: 0.9989 - F1: 0.8713 - Loss: 0.1449\n",
      "\n",
      "Batch 363/387 ━━━━━━━━━━━━━━━━━━━━ 18:18:16\n",
      "Accuracy: 0.9975 - Precision: 0.8843 - Recall: 0.8787 - Specificity: 0.9989 - F1: 0.8715 - Loss: 0.1447\n",
      "\n",
      "Batch 364/387 ━━━━━━━━━━━━━━━━━━━━ 18:19:34\n",
      "Accuracy: 0.9975 - Precision: 0.8842 - Recall: 0.8789 - Specificity: 0.9989 - F1: 0.8716 - Loss: 0.1446\n",
      "\n",
      "Batch 365/387 ━━━━━━━━━━━━━━━━━━━━ 18:20:59\n",
      "Accuracy: 0.9975 - Precision: 0.8844 - Recall: 0.8790 - Specificity: 0.9989 - F1: 0.8717 - Loss: 0.1444\n",
      "\n",
      "Batch 366/387 ━━━━━━━━━━━━━━━━━━━━ 18:22:26\n",
      "Accuracy: 0.9975 - Precision: 0.8845 - Recall: 0.8792 - Specificity: 0.9989 - F1: 0.8719 - Loss: 0.1442\n",
      "\n",
      "Batch 367/387 ━━━━━━━━━━━━━━━━━━━━ 18:23:53\n",
      "Accuracy: 0.9975 - Precision: 0.8846 - Recall: 0.8792 - Specificity: 0.9989 - F1: 0.8720 - Loss: 0.1441\n",
      "\n",
      "Batch 368/387 ━━━━━━━━━━━━━━━━━━━━ 18:25:12\n",
      "Accuracy: 0.9975 - Precision: 0.8845 - Recall: 0.8793 - Specificity: 0.9989 - F1: 0.8720 - Loss: 0.1441\n",
      "\n",
      "Batch 369/387 ━━━━━━━━━━━━━━━━━━━━ 18:26:38\n",
      "Accuracy: 0.9975 - Precision: 0.8846 - Recall: 0.8791 - Specificity: 0.9989 - F1: 0.8720 - Loss: 0.1441\n",
      "\n",
      "Batch 370/387 ━━━━━━━━━━━━━━━━━━━━ 18:28:16\n",
      "Accuracy: 0.9975 - Precision: 0.8847 - Recall: 0.8793 - Specificity: 0.9989 - F1: 0.8722 - Loss: 0.1439\n",
      "\n",
      "Batch 371/387 ━━━━━━━━━━━━━━━━━━━━ 18:29:43\n",
      "Accuracy: 0.9975 - Precision: 0.8850 - Recall: 0.8790 - Specificity: 0.9990 - F1: 0.8722 - Loss: 0.1439\n",
      "\n",
      "Batch 372/387 ━━━━━━━━━━━━━━━━━━━━ 18:31:08\n",
      "Accuracy: 0.9975 - Precision: 0.8853 - Recall: 0.8789 - Specificity: 0.9990 - F1: 0.8723 - Loss: 0.1438\n",
      "\n",
      "Batch 373/387 ━━━━━━━━━━━━━━━━━━━━ 18:32:34\n",
      "Accuracy: 0.9975 - Precision: 0.8855 - Recall: 0.8790 - Specificity: 0.9990 - F1: 0.8725 - Loss: 0.1436\n",
      "\n",
      "Batch 374/387 ━━━━━━━━━━━━━━━━━━━━ 18:33:57\n",
      "Accuracy: 0.9975 - Precision: 0.8857 - Recall: 0.8789 - Specificity: 0.9990 - F1: 0.8725 - Loss: 0.1436\n",
      "\n",
      "Batch 375/387 ━━━━━━━━━━━━━━━━━━━━ 18:35:16\n",
      "Accuracy: 0.9975 - Precision: 0.8856 - Recall: 0.8791 - Specificity: 0.9990 - F1: 0.8726 - Loss: 0.1435\n",
      "\n",
      "Batch 376/387 ━━━━━━━━━━━━━━━━━━━━ 18:36:41\n",
      "Accuracy: 0.9975 - Precision: 0.8857 - Recall: 0.8793 - Specificity: 0.9990 - F1: 0.8728 - Loss: 0.1432\n",
      "\n",
      "Batch 377/387 ━━━━━━━━━━━━━━━━━━━━ 18:38:11\n",
      "Accuracy: 0.9975 - Precision: 0.8858 - Recall: 0.8796 - Specificity: 0.9990 - F1: 0.8730 - Loss: 0.1430\n",
      "\n",
      "Batch 378/387 ━━━━━━━━━━━━━━━━━━━━ 18:39:34\n",
      "Accuracy: 0.9975 - Precision: 0.8861 - Recall: 0.8795 - Specificity: 0.9990 - F1: 0.8731 - Loss: 0.1429\n",
      "\n",
      "Batch 379/387 ━━━━━━━━━━━━━━━━━━━━ 18:40:55\n",
      "Accuracy: 0.9975 - Precision: 0.8859 - Recall: 0.8798 - Specificity: 0.9990 - F1: 0.8731 - Loss: 0.1429\n",
      "\n",
      "Batch 380/387 ━━━━━━━━━━━━━━━━━━━━ 18:42:26\n",
      "Accuracy: 0.9975 - Precision: 0.8849 - Recall: 0.8801 - Specificity: 0.9990 - F1: 0.8726 - Loss: 0.1434\n",
      "\n",
      "Batch 381/387 ━━━━━━━━━━━━━━━━━━━━ 18:43:53\n",
      "Accuracy: 0.9976 - Precision: 0.8848 - Recall: 0.8803 - Specificity: 0.9990 - F1: 0.8727 - Loss: 0.1433\n",
      "\n",
      "Batch 382/387 ━━━━━━━━━━━━━━━━━━━━ 18:45:17\n",
      "Accuracy: 0.9975 - Precision: 0.8850 - Recall: 0.8796 - Specificity: 0.9990 - F1: 0.8723 - Loss: 0.1437\n",
      "\n",
      "Batch 383/387 ━━━━━━━━━━━━━━━━━━━━ 18:46:40\n",
      "Accuracy: 0.9975 - Precision: 0.8852 - Recall: 0.8797 - Specificity: 0.9990 - F1: 0.8725 - Loss: 0.1435\n",
      "\n",
      "Batch 384/387 ━━━━━━━━━━━━━━━━━━━━ 18:48:04\n",
      "Accuracy: 0.9975 - Precision: 0.8846 - Recall: 0.8797 - Specificity: 0.9990 - F1: 0.8722 - Loss: 0.1438\n",
      "\n",
      "Batch 385/387 ━━━━━━━━━━━━━━━━━━━━ 18:49:38\n",
      "Accuracy: 0.9975 - Precision: 0.8848 - Recall: 0.8796 - Specificity: 0.9990 - F1: 0.8723 - Loss: 0.1437\n",
      "\n",
      "Batch 386/387 ━━━━━━━━━━━━━━━━━━━━ 18:51:19\n",
      "Accuracy: 0.9975 - Precision: 0.8843 - Recall: 0.8797 - Specificity: 0.9990 - F1: 0.8721 - Loss: 0.1439\n",
      "\n",
      "Batch 387/387 ━━━━━━━━━━━━━━━━━━━━ 18:52:41\n",
      "Accuracy: 0.9975 - Precision: 0.8845 - Recall: 0.8797 - Specificity: 0.9990 - F1: 0.8722 - Loss: 0.1439\n",
      "\n",
      "End of Epoch 7\n",
      "\n",
      "Epoch 8/50\n",
      "Batch 1/387 ━━━━━━━━━━━━━━━━━━━━ 19:14:25\n",
      "Accuracy: 0.9985 - Precision: 0.9324 - Recall: 0.9145 - Specificity: 0.9994 - F1: 0.9233 - Loss: 0.0859\n",
      "\n",
      "Batch 2/387 ━━━━━━━━━━━━━━━━━━━━ 19:15:51\n",
      "Accuracy: 0.9990 - Precision: 0.8195 - Recall: 0.9147 - Specificity: 0.9995 - F1: 0.8603 - Loss: 0.1479\n",
      "\n",
      "Batch 3/387 ━━━━━━━━━━━━━━━━━━━━ 19:17:10\n",
      "Accuracy: 0.9991 - Precision: 0.8729 - Recall: 0.8265 - Specificity: 0.9997 - F1: 0.8341 - Loss: 0.1745\n",
      "\n",
      "Batch 4/387 ━━━━━━━━━━━━━━━━━━━━ 19:18:24\n",
      "Accuracy: 0.9982 - Precision: 0.8949 - Recall: 0.7868 - Specificity: 0.9997 - F1: 0.8226 - Loss: 0.1918\n",
      "\n",
      "Batch 5/387 ━━━━━━━━━━━━━━━━━━━━ 19:19:40\n",
      "Accuracy: 0.9984 - Precision: 0.9066 - Recall: 0.7983 - Specificity: 0.9997 - F1: 0.8371 - Loss: 0.1771\n",
      "\n",
      "Batch 6/387 ━━━━━━━━━━━━━━━━━━━━ 19:21:10\n",
      "Accuracy: 0.9986 - Precision: 0.9181 - Recall: 0.8165 - Specificity: 0.9997 - F1: 0.8544 - Loss: 0.1590\n",
      "\n",
      "Batch 7/387 ━━━━━━━━━━━━━━━━━━━━ 19:22:29\n",
      "Accuracy: 0.9983 - Precision: 0.9104 - Recall: 0.8340 - Specificity: 0.9994 - F1: 0.8609 - Loss: 0.1528\n",
      "\n",
      "Batch 8/387 ━━━━━━━━━━━━━━━━━━━━ 19:23:52\n",
      "Accuracy: 0.9983 - Precision: 0.9183 - Recall: 0.8324 - Specificity: 0.9995 - F1: 0.8647 - Loss: 0.1490\n",
      "\n",
      "Batch 9/387 ━━━━━━━━━━━━━━━━━━━━ 19:25:09\n",
      "Accuracy: 0.9984 - Precision: 0.9229 - Recall: 0.8438 - Specificity: 0.9995 - F1: 0.8739 - Loss: 0.1391\n",
      "\n",
      "Batch 10/387 ━━━━━━━━━━━━━━━━━━━━ 19:26:18\n",
      "Accuracy: 0.9984 - Precision: 0.9291 - Recall: 0.8519 - Specificity: 0.9995 - F1: 0.8818 - Loss: 0.1310\n",
      "\n",
      "Batch 11/387 ━━━━━━━━━━━━━━━━━━━━ 19:27:44\n",
      "Accuracy: 0.9984 - Precision: 0.9281 - Recall: 0.8624 - Specificity: 0.9995 - F1: 0.8873 - Loss: 0.1252\n",
      "\n",
      "Batch 12/387 ━━━━━━━━━━━━━━━━━━━━ 19:29:06\n",
      "Accuracy: 0.9984 - Precision: 0.9300 - Recall: 0.8693 - Specificity: 0.9995 - F1: 0.8923 - Loss: 0.1198\n",
      "\n",
      "Batch 13/387 ━━━━━━━━━━━━━━━━━━━━ 19:30:31\n",
      "Accuracy: 0.9984 - Precision: 0.9261 - Recall: 0.8780 - Specificity: 0.9994 - F1: 0.8951 - Loss: 0.1167\n",
      "\n",
      "Batch 14/387 ━━━━━━━━━━━━━━━━━━━━ 19:31:55\n",
      "Accuracy: 0.9984 - Precision: 0.9257 - Recall: 0.8798 - Specificity: 0.9994 - F1: 0.8963 - Loss: 0.1158\n",
      "\n",
      "Batch 15/387 ━━━━━━━━━━━━━━━━━━━━ 19:33:19\n",
      "Accuracy: 0.9983 - Precision: 0.9225 - Recall: 0.8799 - Specificity: 0.9993 - F1: 0.8952 - Loss: 0.1171\n",
      "\n",
      "Batch 16/387 ━━━━━━━━━━━━━━━━━━━━ 19:34:46\n",
      "Accuracy: 0.9983 - Precision: 0.9254 - Recall: 0.8839 - Specificity: 0.9993 - F1: 0.8990 - Loss: 0.1129\n",
      "\n",
      "Batch 17/387 ━━━━━━━━━━━━━━━━━━━━ 19:36:02\n",
      "Accuracy: 0.9983 - Precision: 0.9267 - Recall: 0.8882 - Specificity: 0.9993 - F1: 0.9021 - Loss: 0.1096\n",
      "\n",
      "Batch 18/387 ━━━━━━━━━━━━━━━━━━━━ 19:37:16\n",
      "Accuracy: 0.9984 - Precision: 0.9267 - Recall: 0.8915 - Specificity: 0.9993 - F1: 0.9041 - Loss: 0.1074\n",
      "\n",
      "Batch 19/387 ━━━━━━━━━━━━━━━━━━━━ 19:38:45\n",
      "Accuracy: 0.9982 - Precision: 0.9293 - Recall: 0.8923 - Specificity: 0.9993 - F1: 0.9060 - Loss: 0.1062\n",
      "\n",
      "Batch 20/387 ━━━━━━━━━━━━━━━━━━━━ 19:40:14\n",
      "Accuracy: 0.9983 - Precision: 0.9274 - Recall: 0.8950 - Specificity: 0.9993 - F1: 0.9066 - Loss: 0.1054\n",
      "\n",
      "Batch 21/387 ━━━━━━━━━━━━━━━━━━━━ 19:41:35\n",
      "Accuracy: 0.9982 - Precision: 0.9272 - Recall: 0.8952 - Specificity: 0.9993 - F1: 0.9068 - Loss: 0.1055\n",
      "\n",
      "Batch 22/387 ━━━━━━━━━━━━━━━━━━━━ 19:43:06\n",
      "Accuracy: 0.9982 - Precision: 0.9288 - Recall: 0.8991 - Specificity: 0.9993 - F1: 0.9097 - Loss: 0.1023\n",
      "\n",
      "Batch 23/387 ━━━━━━━━━━━━━━━━━━━━ 19:44:24\n",
      "Accuracy: 0.9982 - Precision: 0.9218 - Recall: 0.9013 - Specificity: 0.9992 - F1: 0.9071 - Loss: 0.1050\n",
      "\n",
      "Batch 24/387 ━━━━━━━━━━━━━━━━━━━━ 19:45:52\n",
      "Accuracy: 0.9982 - Precision: 0.9212 - Recall: 0.9038 - Specificity: 0.9992 - F1: 0.9082 - Loss: 0.1039\n",
      "\n",
      "Batch 25/387 ━━━━━━━━━━━━━━━━━━━━ 19:47:25\n",
      "Accuracy: 0.9982 - Precision: 0.9218 - Recall: 0.9039 - Specificity: 0.9992 - F1: 0.9087 - Loss: 0.1034\n",
      "\n",
      "Batch 26/387 ━━━━━━━━━━━━━━━━━━━━ 19:48:55\n",
      "Accuracy: 0.9982 - Precision: 0.9228 - Recall: 0.9050 - Specificity: 0.9992 - F1: 0.9099 - Loss: 0.1021\n",
      "\n",
      "Batch 27/387 ━━━━━━━━━━━━━━━━━━━━ 19:50:15\n",
      "Accuracy: 0.9982 - Precision: 0.9097 - Recall: 0.9040 - Specificity: 0.9992 - F1: 0.9018 - Loss: 0.1105\n",
      "\n",
      "Batch 28/387 ━━━━━━━━━━━━━━━━━━━━ 19:51:30\n",
      "Accuracy: 0.9982 - Precision: 0.9086 - Recall: 0.9004 - Specificity: 0.9992 - F1: 0.8995 - Loss: 0.1126\n",
      "\n",
      "Batch 29/387 ━━━━━━━━━━━━━━━━━━━━ 19:53:03\n",
      "Accuracy: 0.9982 - Precision: 0.9104 - Recall: 0.8964 - Specificity: 0.9992 - F1: 0.8983 - Loss: 0.1138\n",
      "\n",
      "Batch 30/387 ━━━━━━━━━━━━━━━━━━━━ 19:54:32\n",
      "Accuracy: 0.9982 - Precision: 0.9120 - Recall: 0.8966 - Specificity: 0.9992 - F1: 0.8994 - Loss: 0.1127\n",
      "\n",
      "Batch 31/387 ━━━━━━━━━━━━━━━━━━━━ 19:56:04\n",
      "Accuracy: 0.9983 - Precision: 0.9114 - Recall: 0.8984 - Specificity: 0.9992 - F1: 0.9001 - Loss: 0.1118\n",
      "\n",
      "Batch 32/387 ━━━━━━━━━━━━━━━━━━━━ 19:57:44\n",
      "Accuracy: 0.9982 - Precision: 0.9079 - Recall: 0.9005 - Specificity: 0.9992 - F1: 0.8993 - Loss: 0.1128\n",
      "\n",
      "Batch 33/387 ━━━━━━━━━━━━━━━━━━━━ 19:59:14\n",
      "Accuracy: 0.9982 - Precision: 0.9050 - Recall: 0.9026 - Specificity: 0.9991 - F1: 0.8988 - Loss: 0.1131\n",
      "\n",
      "Batch 34/387 ━━━━━━━━━━━━━━━━━━━━ 20:00:33\n",
      "Accuracy: 0.9982 - Precision: 0.9073 - Recall: 0.8992 - Specificity: 0.9992 - F1: 0.8981 - Loss: 0.1138\n",
      "\n",
      "Batch 35/387 ━━━━━━━━━━━━━━━━━━━━ 20:02:05\n",
      "Accuracy: 0.9983 - Precision: 0.9092 - Recall: 0.8989 - Specificity: 0.9992 - F1: 0.8990 - Loss: 0.1128\n",
      "\n",
      "Batch 36/387 ━━━━━━━━━━━━━━━━━━━━ 20:03:32\n",
      "Accuracy: 0.9982 - Precision: 0.9109 - Recall: 0.8980 - Specificity: 0.9992 - F1: 0.8995 - Loss: 0.1124\n",
      "\n",
      "Batch 37/387 ━━━━━━━━━━━━━━━━━━━━ 20:05:04\n",
      "Accuracy: 0.9982 - Precision: 0.9126 - Recall: 0.8981 - Specificity: 0.9992 - F1: 0.9005 - Loss: 0.1115\n",
      "\n",
      "Batch 38/387 ━━━━━━━━━━━━━━━━━━━━ 20:06:33\n",
      "Accuracy: 0.9982 - Precision: 0.9147 - Recall: 0.8975 - Specificity: 0.9992 - F1: 0.9012 - Loss: 0.1106\n",
      "\n",
      "Batch 39/387 ━━━━━━━━━━━━━━━━━━━━ 20:08:05\n",
      "Accuracy: 0.9982 - Precision: 0.9158 - Recall: 0.8969 - Specificity: 0.9992 - F1: 0.9015 - Loss: 0.1104\n",
      "\n",
      "Batch 40/387 ━━━━━━━━━━━━━━━━━━━━ 20:09:21\n",
      "Accuracy: 0.9982 - Precision: 0.9164 - Recall: 0.8982 - Specificity: 0.9992 - F1: 0.9026 - Loss: 0.1093\n",
      "\n",
      "Batch 41/387 ━━━━━━━━━━━━━━━━━━━━ 20:10:48\n",
      "Accuracy: 0.9982 - Precision: 0.9171 - Recall: 0.8991 - Specificity: 0.9992 - F1: 0.9035 - Loss: 0.1083\n",
      "\n",
      "Batch 42/387 ━━━━━━━━━━━━━━━━━━━━ 20:12:11\n",
      "Accuracy: 0.9982 - Precision: 0.9189 - Recall: 0.8984 - Specificity: 0.9992 - F1: 0.9041 - Loss: 0.1078\n",
      "\n",
      "Batch 43/387 ━━━━━━━━━━━━━━━━━━━━ 20:13:31\n",
      "Accuracy: 0.9981 - Precision: 0.9203 - Recall: 0.8931 - Specificity: 0.9992 - F1: 0.9016 - Loss: 0.1106\n",
      "\n",
      "Batch 44/387 ━━━━━━━━━━━━━━━━━━━━ 20:14:59\n",
      "Accuracy: 0.9981 - Precision: 0.9199 - Recall: 0.8941 - Specificity: 0.9992 - F1: 0.9020 - Loss: 0.1101\n",
      "\n",
      "Batch 45/387 ━━━━━━━━━━━━━━━━━━━━ 20:16:15\n",
      "Accuracy: 0.9981 - Precision: 0.9201 - Recall: 0.8946 - Specificity: 0.9992 - F1: 0.9025 - Loss: 0.1097\n",
      "\n",
      "Batch 46/387 ━━━━━━━━━━━━━━━━━━━━ 20:17:45\n",
      "Accuracy: 0.9981 - Precision: 0.9196 - Recall: 0.8964 - Specificity: 0.9992 - F1: 0.9032 - Loss: 0.1090\n",
      "\n",
      "Batch 47/387 ━━━━━━━━━━━━━━━━━━━━ 20:19:06\n",
      "Accuracy: 0.9981 - Precision: 0.9193 - Recall: 0.8979 - Specificity: 0.9992 - F1: 0.9039 - Loss: 0.1083\n",
      "\n",
      "Batch 48/387 ━━━━━━━━━━━━━━━━━━━━ 20:20:21\n",
      "Accuracy: 0.9981 - Precision: 0.9177 - Recall: 0.8992 - Specificity: 0.9992 - F1: 0.9037 - Loss: 0.1085\n",
      "\n",
      "Batch 49/387 ━━━━━━━━━━━━━━━━━━━━ 20:21:38\n",
      "Accuracy: 0.9981 - Precision: 0.9160 - Recall: 0.9010 - Specificity: 0.9991 - F1: 0.9038 - Loss: 0.1085\n",
      "\n",
      "Batch 50/387 ━━━━━━━━━━━━━━━━━━━━ 20:23:02\n",
      "Accuracy: 0.9981 - Precision: 0.9162 - Recall: 0.9003 - Specificity: 0.9991 - F1: 0.9036 - Loss: 0.1087\n",
      "\n",
      "Batch 51/387 ━━━━━━━━━━━━━━━━━━━━ 20:24:26\n",
      "Accuracy: 0.9980 - Precision: 0.9169 - Recall: 0.9003 - Specificity: 0.9991 - F1: 0.9040 - Loss: 0.1084\n",
      "\n",
      "Batch 52/387 ━━━━━━━━━━━━━━━━━━━━ 20:25:46\n",
      "Accuracy: 0.9980 - Precision: 0.9125 - Recall: 0.9002 - Specificity: 0.9991 - F1: 0.9016 - Loss: 0.1110\n",
      "\n",
      "Batch 53/387 ━━━━━━━━━━━━━━━━━━━━ 20:27:19\n",
      "Accuracy: 0.9980 - Precision: 0.9120 - Recall: 0.9009 - Specificity: 0.9991 - F1: 0.9018 - Loss: 0.1107\n",
      "\n",
      "Batch 54/387 ━━━━━━━━━━━━━━━━━━━━ 20:28:36\n",
      "Accuracy: 0.9980 - Precision: 0.9127 - Recall: 0.9020 - Specificity: 0.9991 - F1: 0.9027 - Loss: 0.1097\n",
      "\n",
      "Batch 55/387 ━━━━━━━━━━━━━━━━━━━━ 20:29:55\n",
      "Accuracy: 0.9980 - Precision: 0.9133 - Recall: 0.9029 - Specificity: 0.9991 - F1: 0.9036 - Loss: 0.1087\n",
      "\n",
      "Batch 56/387 ━━━━━━━━━━━━━━━━━━━━ 20:31:21\n",
      "Accuracy: 0.9981 - Precision: 0.9129 - Recall: 0.9030 - Specificity: 0.9991 - F1: 0.9035 - Loss: 0.1088\n",
      "\n",
      "Batch 57/387 ━━━━━━━━━━━━━━━━━━━━ 20:32:43\n",
      "Accuracy: 0.9980 - Precision: 0.9118 - Recall: 0.8992 - Specificity: 0.9991 - F1: 0.9010 - Loss: 0.1114\n",
      "\n",
      "Batch 58/387 ━━━━━━━━━━━━━━━━━━━━ 20:34:12\n",
      "Accuracy: 0.9981 - Precision: 0.9090 - Recall: 0.9007 - Specificity: 0.9991 - F1: 0.9001 - Loss: 0.1122\n",
      "\n",
      "Batch 59/387 ━━━━━━━━━━━━━━━━━━━━ 20:35:31\n",
      "Accuracy: 0.9980 - Precision: 0.9099 - Recall: 0.9002 - Specificity: 0.9991 - F1: 0.9004 - Loss: 0.1120\n",
      "\n",
      "Batch 60/387 ━━━━━━━━━━━━━━━━━━━━ 20:36:52\n",
      "Accuracy: 0.9980 - Precision: 0.9113 - Recall: 0.9003 - Specificity: 0.9991 - F1: 0.9012 - Loss: 0.1112\n",
      "\n",
      "Batch 61/387 ━━━━━━━━━━━━━━━━━━━━ 20:38:15\n",
      "Accuracy: 0.9981 - Precision: 0.9125 - Recall: 0.9007 - Specificity: 0.9991 - F1: 0.9020 - Loss: 0.1103\n",
      "\n",
      "Batch 62/387 ━━━━━━━━━━━━━━━━━━━━ 20:39:34\n",
      "Accuracy: 0.9981 - Precision: 0.9114 - Recall: 0.9021 - Specificity: 0.9991 - F1: 0.9022 - Loss: 0.1101\n",
      "\n",
      "Batch 63/387 ━━━━━━━━━━━━━━━━━━━━ 20:40:52\n",
      "Accuracy: 0.9980 - Precision: 0.9124 - Recall: 0.8993 - Specificity: 0.9991 - F1: 0.9011 - Loss: 0.1115\n",
      "\n",
      "Batch 64/387 ━━━━━━━━━━━━━━━━━━━━ 20:42:06\n",
      "Accuracy: 0.9979 - Precision: 0.9136 - Recall: 0.8974 - Specificity: 0.9992 - F1: 0.9006 - Loss: 0.1123\n",
      "\n",
      "Batch 65/387 ━━━━━━━━━━━━━━━━━━━━ 20:43:22\n",
      "Accuracy: 0.9979 - Precision: 0.9148 - Recall: 0.8959 - Specificity: 0.9992 - F1: 0.9004 - Loss: 0.1128\n",
      "\n",
      "Batch 66/387 ━━━━━━━━━━━━━━━━━━━━ 20:44:47\n",
      "Accuracy: 0.9979 - Precision: 0.9142 - Recall: 0.8964 - Specificity: 0.9992 - F1: 0.9004 - Loss: 0.1127\n",
      "\n",
      "Batch 67/387 ━━━━━━━━━━━━━━━━━━━━ 20:46:06\n",
      "Accuracy: 0.9979 - Precision: 0.9149 - Recall: 0.8968 - Specificity: 0.9992 - F1: 0.9010 - Loss: 0.1120\n",
      "\n",
      "Batch 68/387 ━━━━━━━━━━━━━━━━━━━━ 20:47:31\n",
      "Accuracy: 0.9979 - Precision: 0.9127 - Recall: 0.8978 - Specificity: 0.9992 - F1: 0.9003 - Loss: 0.1128\n",
      "\n",
      "Batch 69/387 ━━━━━━━━━━━━━━━━━━━━ 20:48:50\n",
      "Accuracy: 0.9979 - Precision: 0.9133 - Recall: 0.8985 - Specificity: 0.9992 - F1: 0.9010 - Loss: 0.1120\n",
      "\n",
      "Batch 70/387 ━━━━━━━━━━━━━━━━━━━━ 20:50:37\n",
      "Accuracy: 0.9978 - Precision: 0.9127 - Recall: 0.8958 - Specificity: 0.9991 - F1: 0.8993 - Loss: 0.1141\n",
      "\n",
      "Batch 71/387 ━━━━━━━━━━━━━━━━━━━━ 20:52:18\n",
      "Accuracy: 0.9979 - Precision: 0.9121 - Recall: 0.8968 - Specificity: 0.9992 - F1: 0.8996 - Loss: 0.1138\n",
      "\n",
      "Batch 72/387 ━━━━━━━━━━━━━━━━━━━━ 20:53:58\n",
      "Accuracy: 0.9979 - Precision: 0.9119 - Recall: 0.8977 - Specificity: 0.9992 - F1: 0.9000 - Loss: 0.1133\n",
      "\n",
      "Batch 73/387 ━━━━━━━━━━━━━━━━━━━━ 20:55:22\n",
      "Accuracy: 0.9979 - Precision: 0.9129 - Recall: 0.8981 - Specificity: 0.9992 - F1: 0.9007 - Loss: 0.1125\n",
      "\n",
      "Batch 74/387 ━━━━━━━━━━━━━━━━━━━━ 20:57:05\n",
      "Accuracy: 0.9979 - Precision: 0.9103 - Recall: 0.8990 - Specificity: 0.9991 - F1: 0.8997 - Loss: 0.1135\n",
      "\n",
      "Batch 75/387 ━━━━━━━━━━━━━━━━━━━━ 20:58:31\n",
      "Accuracy: 0.9979 - Precision: 0.9108 - Recall: 0.8998 - Specificity: 0.9991 - F1: 0.9004 - Loss: 0.1128\n",
      "\n",
      "Batch 76/387 ━━━━━━━━━━━━━━━━━━━━ 21:00:11\n",
      "Accuracy: 0.9979 - Precision: 0.9111 - Recall: 0.9007 - Specificity: 0.9991 - F1: 0.9010 - Loss: 0.1121\n",
      "\n",
      "Batch 77/387 ━━━━━━━━━━━━━━━━━━━━ 21:01:36\n",
      "Accuracy: 0.9979 - Precision: 0.9095 - Recall: 0.9000 - Specificity: 0.9991 - F1: 0.9000 - Loss: 0.1132\n",
      "\n",
      "Batch 78/387 ━━━━━━━━━━━━━━━━━━━━ 21:03:03\n",
      "Accuracy: 0.9979 - Precision: 0.9087 - Recall: 0.9007 - Specificity: 0.9991 - F1: 0.8999 - Loss: 0.1132\n",
      "\n",
      "Batch 79/387 ━━━━━━━━━━━━━━━━━━━━ 21:04:42\n",
      "Accuracy: 0.9979 - Precision: 0.9091 - Recall: 0.9003 - Specificity: 0.9991 - F1: 0.9000 - Loss: 0.1131\n",
      "\n",
      "Batch 80/387 ━━━━━━━━━━━━━━━━━━━━ 21:06:20\n",
      "Accuracy: 0.9979 - Precision: 0.9091 - Recall: 0.9011 - Specificity: 0.9991 - F1: 0.9005 - Loss: 0.1126\n",
      "\n",
      "Batch 81/387 ━━━━━━━━━━━━━━━━━━━━ 21:07:46\n",
      "Accuracy: 0.9979 - Precision: 0.9062 - Recall: 0.9017 - Specificity: 0.9991 - F1: 0.8990 - Loss: 0.1140\n",
      "\n",
      "Batch 82/387 ━━━━━━━━━━━━━━━━━━━━ 21:09:11\n",
      "Accuracy: 0.9979 - Precision: 0.9073 - Recall: 0.9005 - Specificity: 0.9991 - F1: 0.8989 - Loss: 0.1142\n",
      "\n",
      "Batch 83/387 ━━━━━━━━━━━━━━━━━━━━ 21:10:41\n",
      "Accuracy: 0.9979 - Precision: 0.9069 - Recall: 0.8999 - Specificity: 0.9991 - F1: 0.8985 - Loss: 0.1148\n",
      "\n",
      "Batch 84/387 ━━━━━━━━━━━━━━━━━━━━ 21:11:57\n",
      "Accuracy: 0.9979 - Precision: 0.9078 - Recall: 0.8995 - Specificity: 0.9991 - F1: 0.8988 - Loss: 0.1146\n",
      "\n",
      "Batch 85/387 ━━━━━━━━━━━━━━━━━━━━ 21:13:33\n",
      "Accuracy: 0.9978 - Precision: 0.9081 - Recall: 0.8992 - Specificity: 0.9991 - F1: 0.8988 - Loss: 0.1146\n",
      "\n",
      "Batch 86/387 ━━━━━━━━━━━━━━━━━━━━ 21:15:08\n",
      "Accuracy: 0.9978 - Precision: 0.9087 - Recall: 0.8990 - Specificity: 0.9991 - F1: 0.8991 - Loss: 0.1144\n",
      "\n",
      "Batch 87/387 ━━━━━━━━━━━━━━━━━━━━ 21:16:33\n",
      "Accuracy: 0.9978 - Precision: 0.9088 - Recall: 0.8991 - Specificity: 0.9991 - F1: 0.8991 - Loss: 0.1143\n",
      "\n",
      "Batch 88/387 ━━━━━━━━━━━━━━━━━━━━ 21:18:11\n",
      "Accuracy: 0.9978 - Precision: 0.9095 - Recall: 0.8992 - Specificity: 0.9991 - F1: 0.8996 - Loss: 0.1138\n",
      "\n",
      "Batch 89/387 ━━━━━━━━━━━━━━━━━━━━ 21:19:36\n",
      "Accuracy: 0.9978 - Precision: 0.9101 - Recall: 0.8991 - Specificity: 0.9991 - F1: 0.8999 - Loss: 0.1135\n",
      "\n",
      "Batch 90/387 ━━━━━━━━━━━━━━━━━━━━ 21:21:03\n",
      "Accuracy: 0.9978 - Precision: 0.9106 - Recall: 0.8989 - Specificity: 0.9991 - F1: 0.9001 - Loss: 0.1134\n",
      "\n",
      "Batch 91/387 ━━━━━━━━━━━━━━━━━━━━ 21:22:36\n",
      "Accuracy: 0.9978 - Precision: 0.9108 - Recall: 0.8997 - Specificity: 0.9991 - F1: 0.9007 - Loss: 0.1127\n",
      "\n",
      "Batch 92/387 ━━━━━━━━━━━━━━━━━━━━ 21:24:03\n",
      "Accuracy: 0.9979 - Precision: 0.9085 - Recall: 0.8989 - Specificity: 0.9991 - F1: 0.8991 - Loss: 0.1143\n",
      "\n",
      "Batch 93/387 ━━━━━━━━━━━━━━━━━━━━ 21:25:23\n",
      "Accuracy: 0.9979 - Precision: 0.9062 - Recall: 0.8999 - Specificity: 0.9991 - F1: 0.8982 - Loss: 0.1152\n",
      "\n",
      "Batch 94/387 ━━━━━━━━━━━━━━━━━━━━ 21:26:53\n",
      "Accuracy: 0.9979 - Precision: 0.9065 - Recall: 0.9006 - Specificity: 0.9991 - F1: 0.8987 - Loss: 0.1146\n",
      "\n",
      "Batch 95/387 ━━━━━━━━━━━━━━━━━━━━ 21:28:25\n",
      "Accuracy: 0.9979 - Precision: 0.9065 - Recall: 0.9012 - Specificity: 0.9991 - F1: 0.8991 - Loss: 0.1142\n",
      "\n",
      "Batch 96/387 ━━━━━━━━━━━━━━━━━━━━ 21:29:58\n",
      "Accuracy: 0.9979 - Precision: 0.9065 - Recall: 0.9008 - Specificity: 0.9991 - F1: 0.8990 - Loss: 0.1143\n",
      "\n",
      "Batch 97/387 ━━━━━━━━━━━━━━━━━━━━ 21:31:25\n",
      "Accuracy: 0.9979 - Precision: 0.9053 - Recall: 0.9000 - Specificity: 0.9991 - F1: 0.8980 - Loss: 0.1153\n",
      "\n",
      "Batch 98/387 ━━━━━━━━━━━━━━━━━━━━ 21:33:03\n",
      "Accuracy: 0.9979 - Precision: 0.9060 - Recall: 0.8990 - Specificity: 0.9991 - F1: 0.8978 - Loss: 0.1156\n",
      "\n",
      "Batch 99/387 ━━━━━━━━━━━━━━━━━━━━ 21:34:25\n",
      "Accuracy: 0.9979 - Precision: 0.9058 - Recall: 0.8996 - Specificity: 0.9991 - F1: 0.8980 - Loss: 0.1153\n",
      "\n",
      "Batch 100/387 ━━━━━━━━━━━━━━━━━━━━ 21:36:01\n",
      "Accuracy: 0.9979 - Precision: 0.9064 - Recall: 0.9002 - Specificity: 0.9991 - F1: 0.8987 - Loss: 0.1146\n",
      "\n",
      "Batch 101/387 ━━━━━━━━━━━━━━━━━━━━ 21:37:37\n",
      "Accuracy: 0.9979 - Precision: 0.9073 - Recall: 0.8989 - Specificity: 0.9991 - F1: 0.8984 - Loss: 0.1149\n",
      "\n",
      "Batch 102/387 ━━━━━━━━━━━━━━━━━━━━ 21:38:56\n",
      "Accuracy: 0.9979 - Precision: 0.9076 - Recall: 0.8997 - Specificity: 0.9991 - F1: 0.8990 - Loss: 0.1143\n",
      "\n",
      "Batch 103/387 ━━━━━━━━━━━━━━━━━━━━ 21:40:16\n",
      "Accuracy: 0.9979 - Precision: 0.9082 - Recall: 0.8993 - Specificity: 0.9991 - F1: 0.8991 - Loss: 0.1142\n",
      "\n",
      "Batch 104/387 ━━━━━━━━━━━━━━━━━━━━ 21:41:49\n",
      "Accuracy: 0.9979 - Precision: 0.9083 - Recall: 0.8991 - Specificity: 0.9991 - F1: 0.8991 - Loss: 0.1142\n",
      "\n",
      "Batch 105/387 ━━━━━━━━━━━━━━━━━━━━ 21:43:15\n",
      "Accuracy: 0.9979 - Precision: 0.9072 - Recall: 0.8989 - Specificity: 0.9991 - F1: 0.8985 - Loss: 0.1148\n",
      "\n",
      "Batch 106/387 ━━━━━━━━━━━━━━━━━━━━ 21:44:37\n",
      "Accuracy: 0.9979 - Precision: 0.9075 - Recall: 0.8977 - Specificity: 0.9991 - F1: 0.8980 - Loss: 0.1154\n",
      "\n",
      "Batch 107/387 ━━━━━━━━━━━━━━━━━━━━ 21:45:53\n",
      "Accuracy: 0.9979 - Precision: 0.9082 - Recall: 0.8979 - Specificity: 0.9992 - F1: 0.8985 - Loss: 0.1148\n",
      "\n",
      "Batch 108/387 ━━━━━━━━━━━━━━━━━━━━ 21:47:17\n",
      "Accuracy: 0.9979 - Precision: 0.9088 - Recall: 0.8984 - Specificity: 0.9992 - F1: 0.8991 - Loss: 0.1142\n",
      "\n",
      "Batch 109/387 ━━━━━━━━━━━━━━━━━━━━ 21:48:46\n",
      "Accuracy: 0.9979 - Precision: 0.9082 - Recall: 0.8985 - Specificity: 0.9991 - F1: 0.8988 - Loss: 0.1145\n",
      "\n",
      "Batch 110/387 ━━━━━━━━━━━━━━━━━━━━ 21:50:09\n",
      "Accuracy: 0.9978 - Precision: 0.9066 - Recall: 0.8992 - Specificity: 0.9991 - F1: 0.8983 - Loss: 0.1152\n",
      "\n",
      "Batch 111/387 ━━━━━━━━━━━━━━━━━━━━ 21:51:34\n",
      "Accuracy: 0.9978 - Precision: 0.9071 - Recall: 0.8987 - Specificity: 0.9991 - F1: 0.8983 - Loss: 0.1153\n",
      "\n",
      "Batch 112/387 ━━━━━━━━━━━━━━━━━━━━ 21:53:01\n",
      "Accuracy: 0.9978 - Precision: 0.9065 - Recall: 0.8993 - Specificity: 0.9991 - F1: 0.8983 - Loss: 0.1153\n",
      "\n",
      "Batch 113/387 ━━━━━━━━━━━━━━━━━━━━ 21:54:38\n",
      "Accuracy: 0.9978 - Precision: 0.9068 - Recall: 0.8991 - Specificity: 0.9991 - F1: 0.8983 - Loss: 0.1151\n",
      "\n",
      "Batch 114/387 ━━━━━━━━━━━━━━━━━━━━ 21:56:00\n",
      "Accuracy: 0.9978 - Precision: 0.9061 - Recall: 0.8996 - Specificity: 0.9991 - F1: 0.8983 - Loss: 0.1152\n",
      "\n",
      "Batch 115/387 ━━━━━━━━━━━━━━━━━━━━ 21:57:35\n",
      "Accuracy: 0.9978 - Precision: 0.9057 - Recall: 0.8992 - Specificity: 0.9991 - F1: 0.8979 - Loss: 0.1156\n",
      "\n",
      "Batch 116/387 ━━━━━━━━━━━━━━━━━━━━ 21:59:07\n",
      "Accuracy: 0.9978 - Precision: 0.9062 - Recall: 0.8987 - Specificity: 0.9991 - F1: 0.8979 - Loss: 0.1156\n",
      "\n",
      "Batch 117/387 ━━━━━━━━━━━━━━━━━━━━ 22:00:36\n",
      "Accuracy: 0.9979 - Precision: 0.9056 - Recall: 0.8978 - Specificity: 0.9991 - F1: 0.8972 - Loss: 0.1163\n",
      "\n",
      "Batch 118/387 ━━━━━━━━━━━━━━━━━━━━ 22:01:58\n",
      "Accuracy: 0.9979 - Precision: 0.9056 - Recall: 0.8984 - Specificity: 0.9991 - F1: 0.8976 - Loss: 0.1159\n",
      "\n",
      "Batch 119/387 ━━━━━━━━━━━━━━━━━━━━ 22:03:36\n",
      "Accuracy: 0.9979 - Precision: 0.9056 - Recall: 0.8987 - Specificity: 0.9991 - F1: 0.8977 - Loss: 0.1157\n",
      "\n",
      "Batch 120/387 ━━━━━━━━━━━━━━━━━━━━ 22:05:01\n",
      "Accuracy: 0.9979 - Precision: 0.9054 - Recall: 0.8986 - Specificity: 0.9991 - F1: 0.8976 - Loss: 0.1158\n",
      "\n",
      "Batch 121/387 ━━━━━━━━━━━━━━━━━━━━ 22:06:27\n",
      "Accuracy: 0.9979 - Precision: 0.9050 - Recall: 0.8991 - Specificity: 0.9991 - F1: 0.8977 - Loss: 0.1158\n",
      "\n",
      "Batch 122/387 ━━━━━━━━━━━━━━━━━━━━ 22:07:47\n",
      "Accuracy: 0.9979 - Precision: 0.9049 - Recall: 0.8993 - Specificity: 0.9991 - F1: 0.8977 - Loss: 0.1157\n",
      "\n",
      "Batch 123/387 ━━━━━━━━━━━━━━━━━━━━ 22:09:15\n",
      "Accuracy: 0.9979 - Precision: 0.9053 - Recall: 0.8995 - Specificity: 0.9991 - F1: 0.8981 - Loss: 0.1154\n",
      "\n",
      "Batch 124/387 ━━━━━━━━━━━━━━━━━━━━ 22:10:46\n",
      "Accuracy: 0.9979 - Precision: 0.9059 - Recall: 0.8993 - Specificity: 0.9991 - F1: 0.8983 - Loss: 0.1151\n",
      "\n",
      "Batch 125/387 ━━━━━━━━━━━━━━━━━━━━ 22:12:12\n",
      "Accuracy: 0.9979 - Precision: 0.9058 - Recall: 0.8995 - Specificity: 0.9991 - F1: 0.8984 - Loss: 0.1150\n",
      "\n",
      "Batch 126/387 ━━━━━━━━━━━━━━━━━━━━ 22:13:34\n",
      "Accuracy: 0.9979 - Precision: 0.9063 - Recall: 0.8963 - Specificity: 0.9991 - F1: 0.8965 - Loss: 0.1170\n",
      "\n",
      "Batch 127/387 ━━━━━━━━━━━━━━━━━━━━ 22:15:11\n",
      "Accuracy: 0.9978 - Precision: 0.9059 - Recall: 0.8947 - Specificity: 0.9991 - F1: 0.8954 - Loss: 0.1182\n",
      "\n",
      "Batch 128/387 ━━━━━━━━━━━━━━━━━━━━ 22:16:43\n",
      "Accuracy: 0.9978 - Precision: 0.9064 - Recall: 0.8951 - Specificity: 0.9991 - F1: 0.8959 - Loss: 0.1176\n",
      "\n",
      "Batch 129/387 ━━━━━━━━━━━━━━━━━━━━ 22:18:13\n",
      "Accuracy: 0.9979 - Precision: 0.9064 - Recall: 0.8958 - Specificity: 0.9991 - F1: 0.8963 - Loss: 0.1172\n",
      "\n",
      "Batch 130/387 ━━━━━━━━━━━━━━━━━━━━ 22:19:53\n",
      "Accuracy: 0.9979 - Precision: 0.9064 - Recall: 0.8965 - Specificity: 0.9991 - F1: 0.8967 - Loss: 0.1168\n",
      "\n",
      "Batch 131/387 ━━━━━━━━━━━━━━━━━━━━ 22:21:29\n",
      "Accuracy: 0.9979 - Precision: 0.9066 - Recall: 0.8957 - Specificity: 0.9991 - F1: 0.8964 - Loss: 0.1170\n",
      "\n",
      "Batch 132/387 ━━━━━━━━━━━━━━━━━━━━ 22:23:00\n",
      "Accuracy: 0.9979 - Precision: 0.9060 - Recall: 0.8957 - Specificity: 0.9991 - F1: 0.8961 - Loss: 0.1174\n",
      "\n",
      "Batch 133/387 ━━━━━━━━━━━━━━━━━━━━ 22:24:35\n",
      "Accuracy: 0.9979 - Precision: 0.9067 - Recall: 0.8955 - Specificity: 0.9991 - F1: 0.8964 - Loss: 0.1171\n",
      "\n",
      "Batch 134/387 ━━━━━━━━━━━━━━━━━━━━ 22:26:05\n",
      "Accuracy: 0.9979 - Precision: 0.9070 - Recall: 0.8960 - Specificity: 0.9991 - F1: 0.8968 - Loss: 0.1166\n",
      "\n",
      "Batch 135/387 ━━━━━━━━━━━━━━━━━━━━ 22:27:26\n",
      "Accuracy: 0.9979 - Precision: 0.9061 - Recall: 0.8964 - Specificity: 0.9991 - F1: 0.8965 - Loss: 0.1169\n",
      "\n",
      "Batch 136/387 ━━━━━━━━━━━━━━━━━━━━ 22:28:51\n",
      "Accuracy: 0.9979 - Precision: 0.9064 - Recall: 0.8967 - Specificity: 0.9991 - F1: 0.8969 - Loss: 0.1166\n",
      "\n",
      "Batch 137/387 ━━━━━━━━━━━━━━━━━━━━ 22:30:11\n",
      "Accuracy: 0.9979 - Precision: 0.9066 - Recall: 0.8969 - Specificity: 0.9991 - F1: 0.8971 - Loss: 0.1163\n",
      "\n",
      "Batch 138/387 ━━━━━━━━━━━━━━━━━━━━ 22:31:38\n",
      "Accuracy: 0.9979 - Precision: 0.9062 - Recall: 0.8974 - Specificity: 0.9991 - F1: 0.8972 - Loss: 0.1162\n",
      "\n",
      "Batch 139/387 ━━━━━━━━━━━━━━━━━━━━ 22:33:02\n",
      "Accuracy: 0.9979 - Precision: 0.9051 - Recall: 0.8982 - Specificity: 0.9991 - F1: 0.8969 - Loss: 0.1165\n",
      "\n",
      "Batch 140/387 ━━━━━━━━━━━━━━━━━━━━ 22:34:43\n",
      "Accuracy: 0.9979 - Precision: 0.9017 - Recall: 0.8983 - Specificity: 0.9991 - F1: 0.8947 - Loss: 0.1188\n",
      "\n",
      "Batch 141/387 ━━━━━━━━━━━━━━━━━━━━ 22:36:14\n",
      "Accuracy: 0.9979 - Precision: 0.9010 - Recall: 0.8988 - Specificity: 0.9991 - F1: 0.8946 - Loss: 0.1189\n",
      "\n",
      "Batch 142/387 ━━━━━━━━━━━━━━━━━━━━ 22:37:30\n",
      "Accuracy: 0.9978 - Precision: 0.9016 - Recall: 0.8976 - Specificity: 0.9991 - F1: 0.8942 - Loss: 0.1194\n",
      "\n",
      "Batch 143/387 ━━━━━━━━━━━━━━━━━━━━ 22:39:03\n",
      "Accuracy: 0.9978 - Precision: 0.9022 - Recall: 0.8978 - Specificity: 0.9991 - F1: 0.8945 - Loss: 0.1190\n",
      "\n",
      "Batch 144/387 ━━━━━━━━━━━━━━━━━━━━ 22:40:42\n",
      "Accuracy: 0.9979 - Precision: 0.9024 - Recall: 0.8978 - Specificity: 0.9991 - F1: 0.8947 - Loss: 0.1188\n",
      "\n",
      "Batch 145/387 ━━━━━━━━━━━━━━━━━━━━ 22:42:27\n",
      "Accuracy: 0.9979 - Precision: 0.9028 - Recall: 0.8979 - Specificity: 0.9991 - F1: 0.8950 - Loss: 0.1185\n",
      "\n",
      "Batch 146/387 ━━━━━━━━━━━━━━━━━━━━ 22:43:50\n",
      "Accuracy: 0.9979 - Precision: 0.9031 - Recall: 0.8983 - Specificity: 0.9991 - F1: 0.8954 - Loss: 0.1181\n",
      "\n",
      "Batch 147/387 ━━━━━━━━━━━━━━━━━━━━ 22:45:23\n",
      "Accuracy: 0.9979 - Precision: 0.9022 - Recall: 0.8965 - Specificity: 0.9991 - F1: 0.8940 - Loss: 0.1195\n",
      "\n",
      "Batch 148/387 ━━━━━━━━━━━━━━━━━━━━ 22:47:03\n",
      "Accuracy: 0.9979 - Precision: 0.9027 - Recall: 0.8961 - Specificity: 0.9991 - F1: 0.8941 - Loss: 0.1194\n",
      "\n",
      "Batch 149/387 ━━━━━━━━━━━━━━━━━━━━ 22:48:37\n",
      "Accuracy: 0.9979 - Precision: 0.9030 - Recall: 0.8950 - Specificity: 0.9991 - F1: 0.8936 - Loss: 0.1199\n",
      "\n",
      "Batch 150/387 ━━━━━━━━━━━━━━━━━━━━ 22:50:10\n",
      "Accuracy: 0.9979 - Precision: 0.9028 - Recall: 0.8953 - Specificity: 0.9991 - F1: 0.8937 - Loss: 0.1198\n",
      "\n",
      "Batch 151/387 ━━━━━━━━━━━━━━━━━━━━ 22:51:34\n",
      "Accuracy: 0.9979 - Precision: 0.9031 - Recall: 0.8957 - Specificity: 0.9991 - F1: 0.8941 - Loss: 0.1194\n",
      "\n",
      "Batch 152/387 ━━━━━━━━━━━━━━━━━━━━ 22:53:13\n",
      "Accuracy: 0.9978 - Precision: 0.9028 - Recall: 0.8951 - Specificity: 0.9991 - F1: 0.8937 - Loss: 0.1199\n",
      "\n",
      "Batch 153/387 ━━━━━━━━━━━━━━━━━━━━ 22:54:52\n",
      "Accuracy: 0.9978 - Precision: 0.9031 - Recall: 0.8949 - Specificity: 0.9991 - F1: 0.8937 - Loss: 0.1199\n",
      "\n",
      "Batch 154/387 ━━━━━━━━━━━━━━━━━━━━ 22:56:19\n",
      "Accuracy: 0.9979 - Precision: 0.9033 - Recall: 0.8953 - Specificity: 0.9991 - F1: 0.8941 - Loss: 0.1195\n",
      "\n",
      "Batch 155/387 ━━━━━━━━━━━━━━━━━━━━ 22:57:49\n",
      "Accuracy: 0.9979 - Precision: 0.9034 - Recall: 0.8945 - Specificity: 0.9991 - F1: 0.8937 - Loss: 0.1198\n",
      "\n",
      "Batch 156/387 ━━━━━━━━━━━━━━━━━━━━ 22:59:21\n",
      "Accuracy: 0.9979 - Precision: 0.9039 - Recall: 0.8932 - Specificity: 0.9991 - F1: 0.8932 - Loss: 0.1205\n",
      "\n",
      "Batch 157/387 ━━━━━━━━━━━━━━━━━━━━ 23:00:45\n",
      "Accuracy: 0.9979 - Precision: 0.9039 - Recall: 0.8935 - Specificity: 0.9991 - F1: 0.8934 - Loss: 0.1202\n",
      "\n",
      "Batch 158/387 ━━━━━━━━━━━━━━━━━━━━ 23:02:16\n",
      "Accuracy: 0.9979 - Precision: 0.9034 - Recall: 0.8941 - Specificity: 0.9991 - F1: 0.8934 - Loss: 0.1201\n",
      "\n",
      "Batch 159/387 ━━━━━━━━━━━━━━━━━━━━ 23:03:43\n",
      "Accuracy: 0.9979 - Precision: 0.9033 - Recall: 0.8938 - Specificity: 0.9991 - F1: 0.8932 - Loss: 0.1203\n",
      "\n",
      "Batch 160/387 ━━━━━━━━━━━━━━━━━━━━ 23:05:14\n",
      "Accuracy: 0.9979 - Precision: 0.9031 - Recall: 0.8943 - Specificity: 0.9991 - F1: 0.8934 - Loss: 0.1201\n",
      "\n",
      "Batch 161/387 ━━━━━━━━━━━━━━━━━━━━ 23:06:51\n",
      "Accuracy: 0.9979 - Precision: 0.9032 - Recall: 0.8948 - Specificity: 0.9991 - F1: 0.8937 - Loss: 0.1197\n",
      "\n",
      "Batch 162/387 ━━━━━━━━━━━━━━━━━━━━ 23:08:06\n",
      "Accuracy: 0.9979 - Precision: 0.9022 - Recall: 0.8949 - Specificity: 0.9991 - F1: 0.8933 - Loss: 0.1202\n",
      "\n",
      "Batch 163/387 ━━━━━━━━━━━━━━━━━━━━ 23:09:32\n",
      "Accuracy: 0.9979 - Precision: 0.9027 - Recall: 0.8939 - Specificity: 0.9991 - F1: 0.8930 - Loss: 0.1206\n",
      "\n",
      "Batch 164/387 ━━━━━━━━━━━━━━━━━━━━ 23:11:01\n",
      "Accuracy: 0.9979 - Precision: 0.9020 - Recall: 0.8942 - Specificity: 0.9991 - F1: 0.8927 - Loss: 0.1208\n",
      "\n",
      "Batch 165/387 ━━━━━━━━━━━━━━━━━━━━ 23:12:19\n",
      "Accuracy: 0.9979 - Precision: 0.9020 - Recall: 0.8944 - Specificity: 0.9991 - F1: 0.8929 - Loss: 0.1207\n",
      "\n",
      "Batch 166/387 ━━━━━━━━━━━━━━━━━━━━ 23:13:38\n",
      "Accuracy: 0.9979 - Precision: 0.9015 - Recall: 0.8946 - Specificity: 0.9991 - F1: 0.8927 - Loss: 0.1209\n",
      "\n",
      "Batch 167/387 ━━━━━━━━━━━━━━━━━━━━ 23:15:05\n",
      "Accuracy: 0.9979 - Precision: 0.9017 - Recall: 0.8941 - Specificity: 0.9991 - F1: 0.8926 - Loss: 0.1210\n",
      "\n",
      "Batch 168/387 ━━━━━━━━━━━━━━━━━━━━ 23:16:43\n",
      "Accuracy: 0.9979 - Precision: 0.9019 - Recall: 0.8943 - Specificity: 0.9991 - F1: 0.8929 - Loss: 0.1207\n",
      "\n",
      "Batch 169/387 ━━━━━━━━━━━━━━━━━━━━ 23:18:13\n",
      "Accuracy: 0.9979 - Precision: 0.9024 - Recall: 0.8938 - Specificity: 0.9991 - F1: 0.8928 - Loss: 0.1208\n",
      "\n",
      "Batch 170/387 ━━━━━━━━━━━━━━━━━━━━ 23:19:48\n",
      "Accuracy: 0.9978 - Precision: 0.9029 - Recall: 0.8929 - Specificity: 0.9991 - F1: 0.8925 - Loss: 0.1212\n",
      "\n",
      "Batch 171/387 ━━━━━━━━━━━━━━━━━━━━ 23:21:19\n",
      "Accuracy: 0.9978 - Precision: 0.9027 - Recall: 0.8931 - Specificity: 0.9991 - F1: 0.8926 - Loss: 0.1212\n",
      "\n",
      "Batch 172/387 ━━━━━━━━━━━━━━━━━━━━ 23:22:43\n",
      "Accuracy: 0.9978 - Precision: 0.9031 - Recall: 0.8933 - Specificity: 0.9991 - F1: 0.8929 - Loss: 0.1208\n",
      "\n",
      "Batch 173/387 ━━━━━━━━━━━━━━━━━━━━ 23:24:09\n",
      "Accuracy: 0.9978 - Precision: 0.9031 - Recall: 0.8937 - Specificity: 0.9991 - F1: 0.8931 - Loss: 0.1206\n",
      "\n",
      "Batch 174/387 ━━━━━━━━━━━━━━━━━━━━ 23:25:43\n",
      "Accuracy: 0.9978 - Precision: 0.9033 - Recall: 0.8933 - Specificity: 0.9991 - F1: 0.8930 - Loss: 0.1206\n",
      "\n",
      "Batch 175/387 ━━━━━━━━━━━━━━━━━━━━ 23:27:12\n",
      "Accuracy: 0.9978 - Precision: 0.9034 - Recall: 0.8936 - Specificity: 0.9991 - F1: 0.8933 - Loss: 0.1204\n",
      "\n",
      "Batch 176/387 ━━━━━━━━━━━━━━━━━━━━ 23:28:50\n",
      "Accuracy: 0.9978 - Precision: 0.9020 - Recall: 0.8937 - Specificity: 0.9991 - F1: 0.8925 - Loss: 0.1212\n",
      "\n",
      "Batch 177/387 ━━━━━━━━━━━━━━━━━━━━ 23:30:08\n",
      "Accuracy: 0.9978 - Precision: 0.9004 - Recall: 0.8942 - Specificity: 0.9991 - F1: 0.8918 - Loss: 0.1219\n",
      "\n",
      "Batch 178/387 ━━━━━━━━━━━━━━━━━━━━ 23:31:43\n",
      "Accuracy: 0.9978 - Precision: 0.9009 - Recall: 0.8941 - Specificity: 0.9991 - F1: 0.8920 - Loss: 0.1217\n",
      "\n",
      "Batch 179/387 ━━━━━━━━━━━━━━━━━━━━ 23:33:25\n",
      "Accuracy: 0.9978 - Precision: 0.9008 - Recall: 0.8944 - Specificity: 0.9991 - F1: 0.8921 - Loss: 0.1216\n",
      "\n",
      "Batch 180/387 ━━━━━━━━━━━━━━━━━━━━ 23:34:50\n",
      "Accuracy: 0.9978 - Precision: 0.8991 - Recall: 0.8921 - Specificity: 0.9991 - F1: 0.8901 - Loss: 0.1236\n",
      "\n",
      "Batch 181/387 ━━━━━━━━━━━━━━━━━━━━ 23:36:21\n",
      "Accuracy: 0.9978 - Precision: 0.8995 - Recall: 0.8918 - Specificity: 0.9991 - F1: 0.8902 - Loss: 0.1236\n",
      "\n",
      "Batch 182/387 ━━━━━━━━━━━━━━━━━━━━ 23:37:43\n",
      "Accuracy: 0.9978 - Precision: 0.8998 - Recall: 0.8917 - Specificity: 0.9991 - F1: 0.8903 - Loss: 0.1234\n",
      "\n",
      "Batch 183/387 ━━━━━━━━━━━━━━━━━━━━ 23:39:23\n",
      "Accuracy: 0.9978 - Precision: 0.8999 - Recall: 0.8915 - Specificity: 0.9991 - F1: 0.8903 - Loss: 0.1235\n",
      "\n",
      "Batch 184/387 ━━━━━━━━━━━━━━━━━━━━ 23:40:50\n",
      "Accuracy: 0.9978 - Precision: 0.8995 - Recall: 0.8914 - Specificity: 0.9991 - F1: 0.8901 - Loss: 0.1237\n",
      "\n",
      "Batch 185/387 ━━━━━━━━━━━━━━━━━━━━ 23:42:39\n",
      "Accuracy: 0.9978 - Precision: 0.8998 - Recall: 0.8916 - Specificity: 0.9991 - F1: 0.8903 - Loss: 0.1234\n",
      "\n",
      "Batch 186/387 ━━━━━━━━━━━━━━━━━━━━ 23:44:11\n",
      "Accuracy: 0.9978 - Precision: 0.9001 - Recall: 0.8916 - Specificity: 0.9991 - F1: 0.8905 - Loss: 0.1232\n",
      "\n",
      "Batch 187/387 ━━━━━━━━━━━━━━━━━━━━ 23:45:29\n",
      "Accuracy: 0.9978 - Precision: 0.8997 - Recall: 0.8921 - Specificity: 0.9991 - F1: 0.8905 - Loss: 0.1231\n",
      "\n",
      "Batch 188/387 ━━━━━━━━━━━━━━━━━━━━ 23:47:05\n",
      "Accuracy: 0.9979 - Precision: 0.9000 - Recall: 0.8924 - Specificity: 0.9991 - F1: 0.8908 - Loss: 0.1228\n",
      "\n",
      "Batch 189/387 ━━━━━━━━━━━━━━━━━━━━ 23:48:29\n",
      "Accuracy: 0.9979 - Precision: 0.8995 - Recall: 0.8927 - Specificity: 0.9991 - F1: 0.8907 - Loss: 0.1229\n",
      "\n",
      "Batch 190/387 ━━━━━━━━━━━━━━━━━━━━ 23:49:58\n",
      "Accuracy: 0.9979 - Precision: 0.8994 - Recall: 0.8908 - Specificity: 0.9991 - F1: 0.8895 - Loss: 0.1242\n",
      "\n",
      "Batch 191/387 ━━━━━━━━━━━━━━━━━━━━ 23:51:31\n",
      "Accuracy: 0.9979 - Precision: 0.8995 - Recall: 0.8911 - Specificity: 0.9991 - F1: 0.8897 - Loss: 0.1239\n",
      "\n",
      "Batch 192/387 ━━━━━━━━━━━━━━━━━━━━ 23:53:01\n",
      "Accuracy: 0.9979 - Precision: 0.8992 - Recall: 0.8915 - Specificity: 0.9991 - F1: 0.8898 - Loss: 0.1238\n",
      "\n",
      "Batch 193/387 ━━━━━━━━━━━━━━━━━━━━ 23:54:22\n",
      "Accuracy: 0.9979 - Precision: 0.8996 - Recall: 0.8917 - Specificity: 0.9991 - F1: 0.8901 - Loss: 0.1235\n",
      "\n",
      "Batch 194/387 ━━━━━━━━━━━━━━━━━━━━ 23:55:56\n",
      "Accuracy: 0.9979 - Precision: 0.8987 - Recall: 0.8919 - Specificity: 0.9991 - F1: 0.8898 - Loss: 0.1238\n",
      "\n",
      "Batch 195/387 ━━━━━━━━━━━━━━━━━━━━ 23:57:17\n",
      "Accuracy: 0.9979 - Precision: 0.8990 - Recall: 0.8921 - Specificity: 0.9991 - F1: 0.8900 - Loss: 0.1236\n",
      "\n",
      "Batch 196/387 ━━━━━━━━━━━━━━━━━━━━ 23:58:45\n",
      "Accuracy: 0.9979 - Precision: 0.8994 - Recall: 0.8921 - Specificity: 0.9991 - F1: 0.8902 - Loss: 0.1233\n",
      "\n",
      "Batch 197/387 ━━━━━━━━━━━━━━━━━━━━ 00:00:18\n",
      "Accuracy: 0.9979 - Precision: 0.8991 - Recall: 0.8921 - Specificity: 0.9991 - F1: 0.8901 - Loss: 0.1234\n",
      "\n",
      "Batch 198/387 ━━━━━━━━━━━━━━━━━━━━ 00:01:59\n",
      "Accuracy: 0.9979 - Precision: 0.8994 - Recall: 0.8924 - Specificity: 0.9991 - F1: 0.8904 - Loss: 0.1231\n",
      "\n",
      "Batch 199/387 ━━━━━━━━━━━━━━━━━━━━ 00:03:36\n",
      "Accuracy: 0.9979 - Precision: 0.8996 - Recall: 0.8926 - Specificity: 0.9991 - F1: 0.8907 - Loss: 0.1228\n",
      "\n",
      "Batch 200/387 ━━━━━━━━━━━━━━━━━━━━ 00:05:07\n",
      "Accuracy: 0.9979 - Precision: 0.9000 - Recall: 0.8919 - Specificity: 0.9991 - F1: 0.8905 - Loss: 0.1232\n",
      "\n",
      "Batch 201/387 ━━━━━━━━━━━━━━━━━━━━ 00:06:28\n",
      "Accuracy: 0.9979 - Precision: 0.8991 - Recall: 0.8911 - Specificity: 0.9991 - F1: 0.8897 - Loss: 0.1241\n",
      "\n",
      "Batch 202/387 ━━━━━━━━━━━━━━━━━━━━ 00:07:55\n",
      "Accuracy: 0.9978 - Precision: 0.8995 - Recall: 0.8906 - Specificity: 0.9991 - F1: 0.8896 - Loss: 0.1242\n",
      "\n",
      "Batch 203/387 ━━━━━━━━━━━━━━━━━━━━ 00:09:20\n",
      "Accuracy: 0.9978 - Precision: 0.8997 - Recall: 0.8886 - Specificity: 0.9991 - F1: 0.8883 - Loss: 0.1256\n",
      "\n",
      "Batch 204/387 ━━━━━━━━━━━━━━━━━━━━ 00:10:45\n",
      "Accuracy: 0.9978 - Precision: 0.9001 - Recall: 0.8886 - Specificity: 0.9991 - F1: 0.8885 - Loss: 0.1253\n",
      "\n",
      "Batch 205/387 ━━━━━━━━━━━━━━━━━━━━ 00:12:21\n",
      "Accuracy: 0.9978 - Precision: 0.9003 - Recall: 0.8883 - Specificity: 0.9991 - F1: 0.8885 - Loss: 0.1254\n",
      "\n",
      "Batch 206/387 ━━━━━━━━━━━━━━━━━━━━ 00:13:49\n",
      "Accuracy: 0.9978 - Precision: 0.9003 - Recall: 0.8879 - Specificity: 0.9991 - F1: 0.8883 - Loss: 0.1256\n",
      "\n",
      "Batch 207/387 ━━━━━━━━━━━━━━━━━━━━ 00:15:06\n",
      "Accuracy: 0.9978 - Precision: 0.8994 - Recall: 0.8883 - Specificity: 0.9991 - F1: 0.8880 - Loss: 0.1260\n",
      "\n",
      "Batch 208/387 ━━━━━━━━━━━━━━━━━━━━ 00:16:27\n",
      "Accuracy: 0.9978 - Precision: 0.8991 - Recall: 0.8888 - Specificity: 0.9991 - F1: 0.8881 - Loss: 0.1258\n",
      "\n",
      "Batch 209/387 ━━━━━━━━━━━━━━━━━━━━ 00:17:43\n",
      "Accuracy: 0.9978 - Precision: 0.8990 - Recall: 0.8891 - Specificity: 0.9991 - F1: 0.8882 - Loss: 0.1257\n",
      "\n",
      "Batch 210/387 ━━━━━━━━━━━━━━━━━━━━ 00:18:59\n",
      "Accuracy: 0.9978 - Precision: 0.8992 - Recall: 0.8894 - Specificity: 0.9991 - F1: 0.8885 - Loss: 0.1255\n",
      "\n",
      "Batch 211/387 ━━━━━━━━━━━━━━━━━━━━ 00:20:29\n",
      "Accuracy: 0.9978 - Precision: 0.8993 - Recall: 0.8895 - Specificity: 0.9991 - F1: 0.8886 - Loss: 0.1253\n",
      "\n",
      "Batch 212/387 ━━━━━━━━━━━━━━━━━━━━ 00:21:51\n",
      "Accuracy: 0.9978 - Precision: 0.8988 - Recall: 0.8899 - Specificity: 0.9991 - F1: 0.8886 - Loss: 0.1254\n",
      "\n",
      "Batch 213/387 ━━━━━━━━━━━━━━━━━━━━ 00:23:19\n",
      "Accuracy: 0.9978 - Precision: 0.8980 - Recall: 0.8904 - Specificity: 0.9991 - F1: 0.8884 - Loss: 0.1256\n",
      "\n",
      "Batch 214/387 ━━━━━━━━━━━━━━━━━━━━ 00:24:53\n",
      "Accuracy: 0.9978 - Precision: 0.8981 - Recall: 0.8904 - Specificity: 0.9991 - F1: 0.8884 - Loss: 0.1255\n",
      "\n",
      "Batch 215/387 ━━━━━━━━━━━━━━━━━━━━ 00:26:32\n",
      "Accuracy: 0.9978 - Precision: 0.8972 - Recall: 0.8908 - Specificity: 0.9991 - F1: 0.8881 - Loss: 0.1258\n",
      "\n",
      "Batch 216/387 ━━━━━━━━━━━━━━━━━━━━ 00:27:54\n",
      "Accuracy: 0.9978 - Precision: 0.8974 - Recall: 0.8911 - Specificity: 0.9991 - F1: 0.8883 - Loss: 0.1256\n",
      "\n",
      "Batch 217/387 ━━━━━━━━━━━━━━━━━━━━ 00:29:23\n",
      "Accuracy: 0.9978 - Precision: 0.8964 - Recall: 0.8915 - Specificity: 0.9991 - F1: 0.8880 - Loss: 0.1259\n",
      "\n",
      "Batch 218/387 ━━━━━━━━━━━━━━━━━━━━ 00:30:43\n",
      "Accuracy: 0.9978 - Precision: 0.8967 - Recall: 0.8913 - Specificity: 0.9991 - F1: 0.8880 - Loss: 0.1260\n",
      "\n",
      "Batch 219/387 ━━━━━━━━━━━━━━━━━━━━ 00:32:12\n",
      "Accuracy: 0.9978 - Precision: 0.8966 - Recall: 0.8916 - Specificity: 0.9991 - F1: 0.8882 - Loss: 0.1258\n",
      "\n",
      "Batch 220/387 ━━━━━━━━━━━━━━━━━━━━ 00:33:37\n",
      "Accuracy: 0.9978 - Precision: 0.8969 - Recall: 0.8912 - Specificity: 0.9991 - F1: 0.8881 - Loss: 0.1259\n",
      "\n",
      "Batch 221/387 ━━━━━━━━━━━━━━━━━━━━ 00:35:08\n",
      "Accuracy: 0.9978 - Precision: 0.8973 - Recall: 0.8913 - Specificity: 0.9991 - F1: 0.8884 - Loss: 0.1256\n",
      "\n",
      "Batch 222/387 ━━━━━━━━━━━━━━━━━━━━ 00:36:37\n",
      "Accuracy: 0.9978 - Precision: 0.8975 - Recall: 0.8910 - Specificity: 0.9991 - F1: 0.8883 - Loss: 0.1257\n",
      "\n",
      "Batch 223/387 ━━━━━━━━━━━━━━━━━━━━ 00:38:12\n",
      "Accuracy: 0.9978 - Precision: 0.8974 - Recall: 0.8911 - Specificity: 0.9991 - F1: 0.8884 - Loss: 0.1257\n",
      "\n",
      "Batch 224/387 ━━━━━━━━━━━━━━━━━━━━ 00:39:36\n",
      "Accuracy: 0.9978 - Precision: 0.8971 - Recall: 0.8913 - Specificity: 0.9991 - F1: 0.8883 - Loss: 0.1257\n",
      "\n",
      "Batch 225/387 ━━━━━━━━━━━━━━━━━━━━ 00:41:00\n",
      "Accuracy: 0.9978 - Precision: 0.8975 - Recall: 0.8910 - Specificity: 0.9991 - F1: 0.8884 - Loss: 0.1256\n",
      "\n",
      "Batch 226/387 ━━━━━━━━━━━━━━━━━━━━ 00:42:18\n",
      "Accuracy: 0.9978 - Precision: 0.8979 - Recall: 0.8902 - Specificity: 0.9991 - F1: 0.8881 - Loss: 0.1260\n",
      "\n",
      "Batch 227/387 ━━━━━━━━━━━━━━━━━━━━ 00:43:44\n",
      "Accuracy: 0.9978 - Precision: 0.8982 - Recall: 0.8901 - Specificity: 0.9991 - F1: 0.8882 - Loss: 0.1258\n",
      "\n",
      "Batch 228/387 ━━━━━━━━━━━━━━━━━━━━ 00:45:09\n",
      "Accuracy: 0.9978 - Precision: 0.8984 - Recall: 0.8897 - Specificity: 0.9991 - F1: 0.8881 - Loss: 0.1259\n",
      "\n",
      "Batch 229/387 ━━━━━━━━━━━━━━━━━━━━ 00:46:41\n",
      "Accuracy: 0.9978 - Precision: 0.8984 - Recall: 0.8894 - Specificity: 0.9991 - F1: 0.8880 - Loss: 0.1260\n",
      "\n",
      "Batch 230/387 ━━━━━━━━━━━━━━━━━━━━ 00:48:28\n",
      "Accuracy: 0.9978 - Precision: 0.8984 - Recall: 0.8897 - Specificity: 0.9991 - F1: 0.8882 - Loss: 0.1259\n",
      "\n",
      "Batch 231/387 ━━━━━━━━━━━━━━━━━━━━ 00:50:00\n",
      "Accuracy: 0.9978 - Precision: 0.8987 - Recall: 0.8899 - Specificity: 0.9991 - F1: 0.8884 - Loss: 0.1256\n",
      "\n",
      "Batch 232/387 ━━━━━━━━━━━━━━━━━━━━ 00:51:32\n",
      "Accuracy: 0.9978 - Precision: 0.8986 - Recall: 0.8897 - Specificity: 0.9991 - F1: 0.8883 - Loss: 0.1257\n",
      "\n",
      "Batch 233/387 ━━━━━━━━━━━━━━━━━━━━ 00:53:12\n",
      "Accuracy: 0.9978 - Precision: 0.8985 - Recall: 0.8896 - Specificity: 0.9991 - F1: 0.8882 - Loss: 0.1259\n",
      "\n",
      "Batch 234/387 ━━━━━━━━━━━━━━━━━━━━ 00:54:43\n",
      "Accuracy: 0.9978 - Precision: 0.8974 - Recall: 0.8896 - Specificity: 0.9990 - F1: 0.8876 - Loss: 0.1265\n",
      "\n",
      "Batch 235/387 ━━━━━━━━━━━━━━━━━━━━ 00:56:11\n",
      "Accuracy: 0.9978 - Precision: 0.8971 - Recall: 0.8899 - Specificity: 0.9990 - F1: 0.8876 - Loss: 0.1266\n",
      "\n",
      "Batch 236/387 ━━━━━━━━━━━━━━━━━━━━ 00:57:37\n",
      "Accuracy: 0.9978 - Precision: 0.8971 - Recall: 0.8899 - Specificity: 0.9990 - F1: 0.8877 - Loss: 0.1265\n",
      "\n",
      "Batch 237/387 ━━━━━━━━━━━━━━━━━━━━ 00:59:06\n",
      "Accuracy: 0.9978 - Precision: 0.8973 - Recall: 0.8894 - Specificity: 0.9990 - F1: 0.8875 - Loss: 0.1268\n",
      "\n",
      "Batch 238/387 ━━━━━━━━━━━━━━━━━━━━ 01:00:43\n",
      "Accuracy: 0.9978 - Precision: 0.8966 - Recall: 0.8895 - Specificity: 0.9990 - F1: 0.8872 - Loss: 0.1271\n",
      "\n",
      "Batch 239/387 ━━━━━━━━━━━━━━━━━━━━ 01:02:01\n",
      "Accuracy: 0.9978 - Precision: 0.8955 - Recall: 0.8891 - Specificity: 0.9990 - F1: 0.8864 - Loss: 0.1279\n",
      "\n",
      "Batch 240/387 ━━━━━━━━━━━━━━━━━━━━ 01:03:29\n",
      "Accuracy: 0.9978 - Precision: 0.8954 - Recall: 0.8895 - Specificity: 0.9990 - F1: 0.8865 - Loss: 0.1277\n",
      "\n",
      "Batch 241/387 ━━━━━━━━━━━━━━━━━━━━ 01:05:14\n",
      "Accuracy: 0.9978 - Precision: 0.8953 - Recall: 0.8897 - Specificity: 0.9990 - F1: 0.8866 - Loss: 0.1276\n",
      "\n",
      "Batch 242/387 ━━━━━━━━━━━━━━━━━━━━ 01:06:53\n",
      "Accuracy: 0.9978 - Precision: 0.8954 - Recall: 0.8899 - Specificity: 0.9990 - F1: 0.8868 - Loss: 0.1274\n",
      "\n",
      "Batch 243/387 ━━━━━━━━━━━━━━━━━━━━ 01:08:35\n",
      "Accuracy: 0.9978 - Precision: 0.8946 - Recall: 0.8903 - Specificity: 0.9990 - F1: 0.8865 - Loss: 0.1277\n",
      "\n",
      "Batch 244/387 ━━━━━━━━━━━━━━━━━━━━ 01:10:00\n",
      "Accuracy: 0.9978 - Precision: 0.8950 - Recall: 0.8898 - Specificity: 0.9990 - F1: 0.8864 - Loss: 0.1279\n",
      "\n",
      "Batch 245/387 ━━━━━━━━━━━━━━━━━━━━ 01:11:38\n",
      "Accuracy: 0.9977 - Precision: 0.8954 - Recall: 0.8896 - Specificity: 0.9990 - F1: 0.8865 - Loss: 0.1278\n",
      "\n",
      "Batch 246/387 ━━━━━━━━━━━━━━━━━━━━ 01:13:05\n",
      "Accuracy: 0.9977 - Precision: 0.8942 - Recall: 0.8900 - Specificity: 0.9990 - F1: 0.8860 - Loss: 0.1284\n",
      "\n",
      "Batch 247/387 ━━━━━━━━━━━━━━━━━━━━ 01:14:24\n",
      "Accuracy: 0.9977 - Precision: 0.8946 - Recall: 0.8901 - Specificity: 0.9990 - F1: 0.8862 - Loss: 0.1281\n",
      "\n",
      "Batch 248/387 ━━━━━━━━━━━━━━━━━━━━ 01:15:49\n",
      "Accuracy: 0.9977 - Precision: 0.8942 - Recall: 0.8900 - Specificity: 0.9990 - F1: 0.8860 - Loss: 0.1284\n",
      "\n",
      "Batch 249/387 ━━━━━━━━━━━━━━━━━━━━ 01:17:05\n",
      "Accuracy: 0.9977 - Precision: 0.8934 - Recall: 0.8897 - Specificity: 0.9990 - F1: 0.8854 - Loss: 0.1289\n",
      "\n",
      "Batch 250/387 ━━━━━━━━━━━━━━━━━━━━ 01:18:37\n",
      "Accuracy: 0.9977 - Precision: 0.8937 - Recall: 0.8878 - Specificity: 0.9990 - F1: 0.8842 - Loss: 0.1303\n",
      "\n",
      "Batch 251/387 ━━━━━━━━━━━━━━━━━━━━ 01:20:23\n",
      "Accuracy: 0.9977 - Precision: 0.8941 - Recall: 0.8875 - Specificity: 0.9990 - F1: 0.8843 - Loss: 0.1302\n",
      "\n",
      "Batch 252/387 ━━━━━━━━━━━━━━━━━━━━ 01:21:54\n",
      "Accuracy: 0.9977 - Precision: 0.8944 - Recall: 0.8876 - Specificity: 0.9990 - F1: 0.8845 - Loss: 0.1299\n",
      "\n",
      "Batch 253/387 ━━━━━━━━━━━━━━━━━━━━ 01:23:12\n",
      "Accuracy: 0.9977 - Precision: 0.8949 - Recall: 0.8875 - Specificity: 0.9990 - F1: 0.8846 - Loss: 0.1298\n",
      "\n",
      "Batch 254/387 ━━━━━━━━━━━━━━━━━━━━ 01:24:51\n",
      "Accuracy: 0.9977 - Precision: 0.8941 - Recall: 0.8869 - Specificity: 0.9990 - F1: 0.8840 - Loss: 0.1304\n",
      "\n",
      "Batch 255/387 ━━━━━━━━━━━━━━━━━━━━ 01:26:25\n",
      "Accuracy: 0.9977 - Precision: 0.8944 - Recall: 0.8871 - Specificity: 0.9990 - F1: 0.8843 - Loss: 0.1301\n",
      "\n",
      "Batch 256/387 ━━━━━━━━━━━━━━━━━━━━ 01:28:00\n",
      "Accuracy: 0.9977 - Precision: 0.8947 - Recall: 0.8868 - Specificity: 0.9990 - F1: 0.8843 - Loss: 0.1301\n",
      "\n",
      "Batch 257/387 ━━━━━━━━━━━━━━━━━━━━ 01:29:37\n",
      "Accuracy: 0.9977 - Precision: 0.8950 - Recall: 0.8865 - Specificity: 0.9990 - F1: 0.8843 - Loss: 0.1301\n",
      "\n",
      "Batch 258/387 ━━━━━━━━━━━━━━━━━━━━ 01:31:02\n",
      "Accuracy: 0.9977 - Precision: 0.8954 - Recall: 0.8859 - Specificity: 0.9990 - F1: 0.8841 - Loss: 0.1303\n",
      "\n",
      "Batch 259/387 ━━━━━━━━━━━━━━━━━━━━ 01:32:34\n",
      "Accuracy: 0.9977 - Precision: 0.8947 - Recall: 0.8862 - Specificity: 0.9990 - F1: 0.8839 - Loss: 0.1305\n",
      "\n",
      "Batch 260/387 ━━━━━━━━━━━━━━━━━━━━ 01:33:58\n",
      "Accuracy: 0.9977 - Precision: 0.8943 - Recall: 0.8865 - Specificity: 0.9990 - F1: 0.8838 - Loss: 0.1306\n",
      "\n",
      "Batch 261/387 ━━━━━━━━━━━━━━━━━━━━ 01:35:43\n",
      "Accuracy: 0.9977 - Precision: 0.8929 - Recall: 0.8865 - Specificity: 0.9990 - F1: 0.8829 - Loss: 0.1315\n",
      "\n",
      "Batch 262/387 ━━━━━━━━━━━━━━━━━━━━ 01:37:22\n",
      "Accuracy: 0.9977 - Precision: 0.8931 - Recall: 0.8867 - Specificity: 0.9990 - F1: 0.8832 - Loss: 0.1312\n",
      "\n",
      "Batch 263/387 ━━━━━━━━━━━━━━━━━━━━ 01:38:55\n",
      "Accuracy: 0.9977 - Precision: 0.8922 - Recall: 0.8871 - Specificity: 0.9990 - F1: 0.8829 - Loss: 0.1316\n",
      "\n",
      "Batch 264/387 ━━━━━━━━━━━━━━━━━━━━ 01:40:34\n",
      "Accuracy: 0.9977 - Precision: 0.8923 - Recall: 0.8867 - Specificity: 0.9990 - F1: 0.8827 - Loss: 0.1317\n",
      "\n",
      "Batch 265/387 ━━━━━━━━━━━━━━━━━━━━ 01:42:03\n",
      "Accuracy: 0.9977 - Precision: 0.8925 - Recall: 0.8865 - Specificity: 0.9990 - F1: 0.8827 - Loss: 0.1318\n",
      "\n",
      "Batch 266/387 ━━━━━━━━━━━━━━━━━━━━ 01:43:39\n",
      "Accuracy: 0.9977 - Precision: 0.8927 - Recall: 0.8868 - Specificity: 0.9990 - F1: 0.8830 - Loss: 0.1315\n",
      "\n",
      "Batch 267/387 ━━━━━━━━━━━━━━━━━━━━ 01:45:06\n",
      "Accuracy: 0.9977 - Precision: 0.8927 - Recall: 0.8867 - Specificity: 0.9990 - F1: 0.8830 - Loss: 0.1315\n",
      "\n",
      "Batch 268/387 ━━━━━━━━━━━━━━━━━━━━ 01:46:30\n",
      "Accuracy: 0.9977 - Precision: 0.8926 - Recall: 0.8870 - Specificity: 0.9990 - F1: 0.8831 - Loss: 0.1314\n",
      "\n",
      "Batch 269/387 ━━━━━━━━━━━━━━━━━━━━ 01:48:17\n",
      "Accuracy: 0.9977 - Precision: 0.8927 - Recall: 0.8871 - Specificity: 0.9990 - F1: 0.8832 - Loss: 0.1313\n",
      "\n",
      "Batch 270/387 ━━━━━━━━━━━━━━━━━━━━ 01:49:42\n",
      "Accuracy: 0.9977 - Precision: 0.8927 - Recall: 0.8873 - Specificity: 0.9990 - F1: 0.8833 - Loss: 0.1312\n",
      "\n",
      "Batch 271/387 ━━━━━━━━━━━━━━━━━━━━ 01:51:13\n",
      "Accuracy: 0.9977 - Precision: 0.8928 - Recall: 0.8874 - Specificity: 0.9990 - F1: 0.8835 - Loss: 0.1310\n",
      "\n",
      "Batch 272/387 ━━━━━━━━━━━━━━━━━━━━ 01:52:54\n",
      "Accuracy: 0.9977 - Precision: 0.8930 - Recall: 0.8867 - Specificity: 0.9990 - F1: 0.8831 - Loss: 0.1313\n",
      "\n",
      "Batch 273/387 ━━━━━━━━━━━━━━━━━━━━ 01:54:15\n",
      "Accuracy: 0.9977 - Precision: 0.8930 - Recall: 0.8867 - Specificity: 0.9990 - F1: 0.8832 - Loss: 0.1313\n",
      "\n",
      "Batch 274/387 ━━━━━━━━━━━━━━━━━━━━ 01:55:45\n",
      "Accuracy: 0.9977 - Precision: 0.8931 - Recall: 0.8871 - Specificity: 0.9990 - F1: 0.8834 - Loss: 0.1310\n",
      "\n",
      "Batch 275/387 ━━━━━━━━━━━━━━━━━━━━ 01:57:14\n",
      "Accuracy: 0.9977 - Precision: 0.8931 - Recall: 0.8868 - Specificity: 0.9990 - F1: 0.8833 - Loss: 0.1312\n",
      "\n",
      "Batch 276/387 ━━━━━━━━━━━━━━━━━━━━ 01:58:40\n",
      "Accuracy: 0.9977 - Precision: 0.8933 - Recall: 0.8870 - Specificity: 0.9990 - F1: 0.8836 - Loss: 0.1309\n",
      "\n",
      "Batch 277/387 ━━━━━━━━━━━━━━━━━━━━ 02:00:26\n",
      "Accuracy: 0.9977 - Precision: 0.8936 - Recall: 0.8872 - Specificity: 0.9990 - F1: 0.8838 - Loss: 0.1307\n",
      "\n",
      "Batch 278/387 ━━━━━━━━━━━━━━━━━━━━ 02:01:52\n",
      "Accuracy: 0.9977 - Precision: 0.8939 - Recall: 0.8872 - Specificity: 0.9990 - F1: 0.8840 - Loss: 0.1305\n",
      "\n",
      "Batch 279/387 ━━━━━━━━━━━━━━━━━━━━ 02:03:32\n",
      "Accuracy: 0.9977 - Precision: 0.8941 - Recall: 0.8873 - Specificity: 0.9990 - F1: 0.8841 - Loss: 0.1303\n",
      "\n",
      "Batch 280/387 ━━━━━━━━━━━━━━━━━━━━ 02:04:53\n",
      "Accuracy: 0.9977 - Precision: 0.8942 - Recall: 0.8873 - Specificity: 0.9990 - F1: 0.8842 - Loss: 0.1302\n",
      "\n",
      "Batch 281/387 ━━━━━━━━━━━━━━━━━━━━ 02:06:13\n",
      "Accuracy: 0.9977 - Precision: 0.8938 - Recall: 0.8875 - Specificity: 0.9990 - F1: 0.8841 - Loss: 0.1303\n",
      "\n",
      "Batch 282/387 ━━━━━━━━━━━━━━━━━━━━ 02:07:41\n",
      "Accuracy: 0.9977 - Precision: 0.8938 - Recall: 0.8873 - Specificity: 0.9990 - F1: 0.8840 - Loss: 0.1305\n",
      "\n",
      "Batch 283/387 ━━━━━━━━━━━━━━━━━━━━ 02:09:15\n",
      "Accuracy: 0.9977 - Precision: 0.8940 - Recall: 0.8876 - Specificity: 0.9990 - F1: 0.8843 - Loss: 0.1302\n",
      "\n",
      "Batch 284/387 ━━━━━━━━━━━━━━━━━━━━ 02:10:41\n",
      "Accuracy: 0.9977 - Precision: 0.8932 - Recall: 0.8878 - Specificity: 0.9990 - F1: 0.8839 - Loss: 0.1305\n",
      "\n",
      "Batch 285/387 ━━━━━━━━━━━━━━━━━━━━ 02:11:56\n",
      "Accuracy: 0.9977 - Precision: 0.8917 - Recall: 0.8877 - Specificity: 0.9990 - F1: 0.8829 - Loss: 0.1316\n",
      "\n",
      "Batch 286/387 ━━━━━━━━━━━━━━━━━━━━ 02:13:28\n",
      "Accuracy: 0.9977 - Precision: 0.8916 - Recall: 0.8878 - Specificity: 0.9990 - F1: 0.8830 - Loss: 0.1315\n",
      "\n",
      "Batch 287/387 ━━━━━━━━━━━━━━━━━━━━ 02:15:05\n",
      "Accuracy: 0.9977 - Precision: 0.8919 - Recall: 0.8881 - Specificity: 0.9990 - F1: 0.8833 - Loss: 0.1312\n",
      "\n",
      "Batch 288/387 ━━━━━━━━━━━━━━━━━━━━ 02:16:41\n",
      "Accuracy: 0.9977 - Precision: 0.8921 - Recall: 0.8880 - Specificity: 0.9990 - F1: 0.8833 - Loss: 0.1312\n",
      "\n",
      "Batch 289/387 ━━━━━━━━━━━━━━━━━━━━ 02:18:14\n",
      "Accuracy: 0.9977 - Precision: 0.8921 - Recall: 0.8880 - Specificity: 0.9990 - F1: 0.8834 - Loss: 0.1311\n",
      "\n",
      "Batch 290/387 ━━━━━━━━━━━━━━━━━━━━ 02:19:48\n",
      "Accuracy: 0.9977 - Precision: 0.8919 - Recall: 0.8884 - Specificity: 0.9990 - F1: 0.8835 - Loss: 0.1310\n",
      "\n",
      "Batch 291/387 ━━━━━━━━━━━━━━━━━━━━ 02:21:16\n",
      "Accuracy: 0.9977 - Precision: 0.8914 - Recall: 0.8880 - Specificity: 0.9990 - F1: 0.8831 - Loss: 0.1315\n",
      "\n",
      "Batch 292/387 ━━━━━━━━━━━━━━━━━━━━ 02:22:49\n",
      "Accuracy: 0.9977 - Precision: 0.8917 - Recall: 0.8877 - Specificity: 0.9990 - F1: 0.8831 - Loss: 0.1315\n",
      "\n",
      "Batch 293/387 ━━━━━━━━━━━━━━━━━━━━ 02:24:16\n",
      "Accuracy: 0.9977 - Precision: 0.8919 - Recall: 0.8869 - Specificity: 0.9990 - F1: 0.8827 - Loss: 0.1319\n",
      "\n",
      "Batch 294/387 ━━━━━━━━━━━━━━━━━━━━ 02:25:42\n",
      "Accuracy: 0.9977 - Precision: 0.8923 - Recall: 0.8869 - Specificity: 0.9990 - F1: 0.8829 - Loss: 0.1317\n",
      "\n",
      "Batch 295/387 ━━━━━━━━━━━━━━━━━━━━ 02:27:15\n",
      "Accuracy: 0.9977 - Precision: 0.8924 - Recall: 0.8870 - Specificity: 0.9990 - F1: 0.8830 - Loss: 0.1316\n",
      "\n",
      "Batch 296/387 ━━━━━━━━━━━━━━━━━━━━ 02:28:41\n",
      "Accuracy: 0.9977 - Precision: 0.8925 - Recall: 0.8865 - Specificity: 0.9990 - F1: 0.8828 - Loss: 0.1318\n",
      "\n",
      "Batch 297/387 ━━━━━━━━━━━━━━━━━━━━ 02:30:18\n",
      "Accuracy: 0.9977 - Precision: 0.8926 - Recall: 0.8867 - Specificity: 0.9990 - F1: 0.8830 - Loss: 0.1316\n",
      "\n",
      "Batch 298/387 ━━━━━━━━━━━━━━━━━━━━ 02:31:45\n",
      "Accuracy: 0.9977 - Precision: 0.8928 - Recall: 0.8867 - Specificity: 0.9990 - F1: 0.8831 - Loss: 0.1315\n",
      "\n",
      "Batch 299/387 ━━━━━━━━━━━━━━━━━━━━ 02:33:04\n",
      "Accuracy: 0.9977 - Precision: 0.8930 - Recall: 0.8867 - Specificity: 0.9990 - F1: 0.8832 - Loss: 0.1314\n",
      "\n",
      "Batch 300/387 ━━━━━━━━━━━━━━━━━━━━ 02:34:28\n",
      "Accuracy: 0.9977 - Precision: 0.8930 - Recall: 0.8864 - Specificity: 0.9990 - F1: 0.8830 - Loss: 0.1315\n",
      "\n",
      "Batch 301/387 ━━━━━━━━━━━━━━━━━━━━ 02:35:52\n",
      "Accuracy: 0.9977 - Precision: 0.8932 - Recall: 0.8866 - Specificity: 0.9990 - F1: 0.8833 - Loss: 0.1313\n",
      "\n",
      "Batch 302/387 ━━━━━━━━━━━━━━━━━━━━ 02:37:19\n",
      "Accuracy: 0.9977 - Precision: 0.8929 - Recall: 0.8869 - Specificity: 0.9990 - F1: 0.8833 - Loss: 0.1313\n",
      "\n",
      "Batch 303/387 ━━━━━━━━━━━━━━━━━━━━ 02:38:42\n",
      "Accuracy: 0.9977 - Precision: 0.8924 - Recall: 0.8872 - Specificity: 0.9990 - F1: 0.8832 - Loss: 0.1314\n",
      "\n",
      "Batch 304/387 ━━━━━━━━━━━━━━━━━━━━ 02:40:06\n",
      "Accuracy: 0.9977 - Precision: 0.8927 - Recall: 0.8870 - Specificity: 0.9990 - F1: 0.8832 - Loss: 0.1313\n",
      "\n",
      "Batch 305/387 ━━━━━━━━━━━━━━━━━━━━ 02:41:31\n",
      "Accuracy: 0.9977 - Precision: 0.8929 - Recall: 0.8873 - Specificity: 0.9990 - F1: 0.8835 - Loss: 0.1310\n",
      "\n",
      "Batch 306/387 ━━━━━━━━━━━━━━━━━━━━ 02:43:01\n",
      "Accuracy: 0.9977 - Precision: 0.8924 - Recall: 0.8876 - Specificity: 0.9990 - F1: 0.8834 - Loss: 0.1311\n",
      "\n",
      "Batch 307/387 ━━━━━━━━━━━━━━━━━━━━ 02:44:26\n",
      "Accuracy: 0.9977 - Precision: 0.8906 - Recall: 0.8879 - Specificity: 0.9990 - F1: 0.8821 - Loss: 0.1325\n",
      "\n",
      "Batch 308/387 ━━━━━━━━━━━━━━━━━━━━ 02:46:00\n",
      "Accuracy: 0.9977 - Precision: 0.8902 - Recall: 0.8879 - Specificity: 0.9990 - F1: 0.8819 - Loss: 0.1326\n",
      "\n",
      "Batch 309/387 ━━━━━━━━━━━━━━━━━━━━ 02:47:27\n",
      "Accuracy: 0.9977 - Precision: 0.8905 - Recall: 0.8878 - Specificity: 0.9990 - F1: 0.8820 - Loss: 0.1326\n",
      "\n",
      "Batch 310/387 ━━━━━━━━━━━━━━━━━━━━ 02:49:00\n",
      "Accuracy: 0.9977 - Precision: 0.8905 - Recall: 0.8877 - Specificity: 0.9990 - F1: 0.8820 - Loss: 0.1326\n",
      "\n",
      "Batch 311/387 ━━━━━━━━━━━━━━━━━━━━ 02:50:25\n",
      "Accuracy: 0.9977 - Precision: 0.8905 - Recall: 0.8880 - Specificity: 0.9990 - F1: 0.8822 - Loss: 0.1324\n",
      "\n",
      "Batch 312/387 ━━━━━━━━━━━━━━━━━━━━ 02:51:41\n",
      "Accuracy: 0.9977 - Precision: 0.8905 - Recall: 0.8877 - Specificity: 0.9990 - F1: 0.8820 - Loss: 0.1325\n",
      "\n",
      "Batch 313/387 ━━━━━━━━━━━━━━━━━━━━ 02:52:58\n",
      "Accuracy: 0.9977 - Precision: 0.8903 - Recall: 0.8869 - Specificity: 0.9990 - F1: 0.8815 - Loss: 0.1331\n",
      "\n",
      "Batch 314/387 ━━━━━━━━━━━━━━━━━━━━ 02:54:29\n",
      "Accuracy: 0.9977 - Precision: 0.8906 - Recall: 0.8858 - Specificity: 0.9990 - F1: 0.8809 - Loss: 0.1337\n",
      "\n",
      "Batch 315/387 ━━━━━━━━━━━━━━━━━━━━ 02:55:52\n",
      "Accuracy: 0.9977 - Precision: 0.8909 - Recall: 0.8855 - Specificity: 0.9990 - F1: 0.8809 - Loss: 0.1338\n",
      "\n",
      "Batch 316/387 ━━━━━━━━━━━━━━━━━━━━ 02:57:17\n",
      "Accuracy: 0.9977 - Precision: 0.8910 - Recall: 0.8857 - Specificity: 0.9990 - F1: 0.8811 - Loss: 0.1336\n",
      "\n",
      "Batch 317/387 ━━━━━━━━━━━━━━━━━━━━ 02:58:52\n",
      "Accuracy: 0.9977 - Precision: 0.8911 - Recall: 0.8854 - Specificity: 0.9990 - F1: 0.8810 - Loss: 0.1336\n",
      "\n",
      "Batch 318/387 ━━━━━━━━━━━━━━━━━━━━ 03:00:27\n",
      "Accuracy: 0.9977 - Precision: 0.8909 - Recall: 0.8857 - Specificity: 0.9990 - F1: 0.8811 - Loss: 0.1336\n",
      "\n",
      "Batch 319/387 ━━━━━━━━━━━━━━━━━━━━ 03:01:58\n",
      "Accuracy: 0.9977 - Precision: 0.8912 - Recall: 0.8854 - Specificity: 0.9990 - F1: 0.8811 - Loss: 0.1336\n",
      "\n",
      "Batch 320/387 ━━━━━━━━━━━━━━━━━━━━ 03:03:33\n",
      "Accuracy: 0.9977 - Precision: 0.8914 - Recall: 0.8857 - Specificity: 0.9990 - F1: 0.8813 - Loss: 0.1333\n",
      "\n",
      "Batch 321/387 ━━━━━━━━━━━━━━━━━━━━ 03:05:06\n",
      "Accuracy: 0.9977 - Precision: 0.8916 - Recall: 0.8856 - Specificity: 0.9990 - F1: 0.8814 - Loss: 0.1333\n",
      "\n",
      "Batch 322/387 ━━━━━━━━━━━━━━━━━━━━ 03:06:33\n",
      "Accuracy: 0.9977 - Precision: 0.8919 - Recall: 0.8855 - Specificity: 0.9990 - F1: 0.8815 - Loss: 0.1331\n",
      "\n",
      "Batch 323/387 ━━━━━━━━━━━━━━━━━━━━ 03:08:03\n",
      "Accuracy: 0.9977 - Precision: 0.8908 - Recall: 0.8856 - Specificity: 0.9990 - F1: 0.8809 - Loss: 0.1338\n",
      "\n",
      "Batch 324/387 ━━━━━━━━━━━━━━━━━━━━ 03:09:30\n",
      "Accuracy: 0.9977 - Precision: 0.8907 - Recall: 0.8857 - Specificity: 0.9990 - F1: 0.8809 - Loss: 0.1338\n",
      "\n",
      "Batch 325/387 ━━━━━━━━━━━━━━━━━━━━ 03:10:51\n",
      "Accuracy: 0.9977 - Precision: 0.8907 - Recall: 0.8857 - Specificity: 0.9990 - F1: 0.8809 - Loss: 0.1338\n",
      "\n",
      "Batch 326/387 ━━━━━━━━━━━━━━━━━━━━ 03:12:27\n",
      "Accuracy: 0.9977 - Precision: 0.8908 - Recall: 0.8858 - Specificity: 0.9990 - F1: 0.8810 - Loss: 0.1337\n",
      "\n",
      "Batch 327/387 ━━━━━━━━━━━━━━━━━━━━ 03:13:59\n",
      "Accuracy: 0.9977 - Precision: 0.8900 - Recall: 0.8861 - Specificity: 0.9990 - F1: 0.8807 - Loss: 0.1340\n",
      "\n",
      "Batch 328/387 ━━━━━━━━━━━━━━━━━━━━ 03:15:21\n",
      "Accuracy: 0.9977 - Precision: 0.8903 - Recall: 0.8862 - Specificity: 0.9990 - F1: 0.8809 - Loss: 0.1338\n",
      "\n",
      "Batch 329/387 ━━━━━━━━━━━━━━━━━━━━ 03:16:56\n",
      "Accuracy: 0.9977 - Precision: 0.8901 - Recall: 0.8864 - Specificity: 0.9990 - F1: 0.8809 - Loss: 0.1338\n",
      "\n",
      "Batch 330/387 ━━━━━━━━━━━━━━━━━━━━ 03:18:23\n",
      "Accuracy: 0.9977 - Precision: 0.8903 - Recall: 0.8865 - Specificity: 0.9990 - F1: 0.8811 - Loss: 0.1336\n",
      "\n",
      "Batch 331/387 ━━━━━━━━━━━━━━━━━━━━ 03:19:46\n",
      "Accuracy: 0.9977 - Precision: 0.8906 - Recall: 0.8865 - Specificity: 0.9990 - F1: 0.8813 - Loss: 0.1334\n",
      "\n",
      "Batch 332/387 ━━━━━━━━━━━━━━━━━━━━ 03:21:11\n",
      "Accuracy: 0.9977 - Precision: 0.8909 - Recall: 0.8866 - Specificity: 0.9990 - F1: 0.8815 - Loss: 0.1332\n",
      "\n",
      "Batch 333/387 ━━━━━━━━━━━━━━━━━━━━ 03:22:35\n",
      "Accuracy: 0.9977 - Precision: 0.8909 - Recall: 0.8867 - Specificity: 0.9990 - F1: 0.8816 - Loss: 0.1331\n",
      "\n",
      "Batch 334/387 ━━━━━━━━━━━━━━━━━━━━ 03:23:53\n",
      "Accuracy: 0.9977 - Precision: 0.8912 - Recall: 0.8869 - Specificity: 0.9990 - F1: 0.8818 - Loss: 0.1328\n",
      "\n",
      "Batch 335/387 ━━━━━━━━━━━━━━━━━━━━ 03:25:21\n",
      "Accuracy: 0.9977 - Precision: 0.8914 - Recall: 0.8869 - Specificity: 0.9990 - F1: 0.8819 - Loss: 0.1327\n",
      "\n",
      "Batch 336/387 ━━━━━━━━━━━━━━━━━━━━ 03:26:49\n",
      "Accuracy: 0.9977 - Precision: 0.8914 - Recall: 0.8870 - Specificity: 0.9990 - F1: 0.8820 - Loss: 0.1326\n",
      "\n",
      "Batch 337/387 ━━━━━━━━━━━━━━━━━━━━ 03:28:25\n",
      "Accuracy: 0.9977 - Precision: 0.8916 - Recall: 0.8872 - Specificity: 0.9990 - F1: 0.8822 - Loss: 0.1324\n",
      "\n",
      "Batch 338/387 ━━━━━━━━━━━━━━━━━━━━ 03:29:41\n",
      "Accuracy: 0.9977 - Precision: 0.8911 - Recall: 0.8872 - Specificity: 0.9990 - F1: 0.8819 - Loss: 0.1326\n",
      "\n",
      "Batch 339/387 ━━━━━━━━━━━━━━━━━━━━ 03:31:10\n",
      "Accuracy: 0.9977 - Precision: 0.8912 - Recall: 0.8872 - Specificity: 0.9990 - F1: 0.8820 - Loss: 0.1325\n",
      "\n",
      "Batch 340/387 ━━━━━━━━━━━━━━━━━━━━ 03:32:31\n",
      "Accuracy: 0.9977 - Precision: 0.8914 - Recall: 0.8866 - Specificity: 0.9990 - F1: 0.8818 - Loss: 0.1328\n",
      "\n",
      "Batch 341/387 ━━━━━━━━━━━━━━━━━━━━ 03:33:52\n",
      "Accuracy: 0.9977 - Precision: 0.8916 - Recall: 0.8864 - Specificity: 0.9990 - F1: 0.8818 - Loss: 0.1328\n",
      "\n",
      "Batch 342/387 ━━━━━━━━━━━━━━━━━━━━ 03:35:14\n",
      "Accuracy: 0.9977 - Precision: 0.8917 - Recall: 0.8865 - Specificity: 0.9990 - F1: 0.8819 - Loss: 0.1327\n",
      "\n",
      "Batch 343/387 ━━━━━━━━━━━━━━━━━━━━ 03:36:45\n",
      "Accuracy: 0.9977 - Precision: 0.8917 - Recall: 0.8865 - Specificity: 0.9990 - F1: 0.8819 - Loss: 0.1326\n",
      "\n",
      "Batch 344/387 ━━━━━━━━━━━━━━━━━━━━ 03:38:17\n",
      "Accuracy: 0.9977 - Precision: 0.8917 - Recall: 0.8868 - Specificity: 0.9990 - F1: 0.8821 - Loss: 0.1325\n",
      "\n",
      "Batch 345/387 ━━━━━━━━━━━━━━━━━━━━ 03:39:41\n",
      "Accuracy: 0.9977 - Precision: 0.8918 - Recall: 0.8871 - Specificity: 0.9990 - F1: 0.8823 - Loss: 0.1322\n",
      "\n",
      "Batch 346/387 ━━━━━━━━━━━━━━━━━━━━ 03:41:12\n",
      "Accuracy: 0.9977 - Precision: 0.8920 - Recall: 0.8873 - Specificity: 0.9990 - F1: 0.8825 - Loss: 0.1320\n",
      "\n",
      "Batch 347/387 ━━━━━━━━━━━━━━━━━━━━ 03:42:31\n",
      "Accuracy: 0.9977 - Precision: 0.8920 - Recall: 0.8875 - Specificity: 0.9990 - F1: 0.8826 - Loss: 0.1319\n",
      "\n",
      "Batch 348/387 ━━━━━━━━━━━━━━━━━━━━ 03:43:59\n",
      "Accuracy: 0.9977 - Precision: 0.8917 - Recall: 0.8878 - Specificity: 0.9990 - F1: 0.8826 - Loss: 0.1319\n",
      "\n",
      "Batch 349/387 ━━━━━━━━━━━━━━━━━━━━ 03:45:22\n",
      "Accuracy: 0.9977 - Precision: 0.8919 - Recall: 0.8881 - Specificity: 0.9990 - F1: 0.8829 - Loss: 0.1316\n",
      "\n",
      "Batch 350/387 ━━━━━━━━━━━━━━━━━━━━ 03:46:50\n",
      "Accuracy: 0.9977 - Precision: 0.8913 - Recall: 0.8883 - Specificity: 0.9990 - F1: 0.8827 - Loss: 0.1319\n",
      "\n",
      "Batch 351/387 ━━━━━━━━━━━━━━━━━━━━ 03:48:34\n",
      "Accuracy: 0.9977 - Precision: 0.8904 - Recall: 0.8885 - Specificity: 0.9990 - F1: 0.8822 - Loss: 0.1324\n",
      "\n",
      "Batch 352/387 ━━━━━━━━━━━━━━━━━━━━ 03:50:06\n",
      "Accuracy: 0.9977 - Precision: 0.8906 - Recall: 0.8884 - Specificity: 0.9990 - F1: 0.8822 - Loss: 0.1323\n",
      "\n",
      "Batch 353/387 ━━━━━━━━━━━━━━━━━━━━ 03:51:31\n",
      "Accuracy: 0.9977 - Precision: 0.8907 - Recall: 0.8886 - Specificity: 0.9990 - F1: 0.8824 - Loss: 0.1321\n",
      "\n",
      "Batch 354/387 ━━━━━━━━━━━━━━━━━━━━ 03:52:53\n",
      "Accuracy: 0.9977 - Precision: 0.8909 - Recall: 0.8887 - Specificity: 0.9990 - F1: 0.8826 - Loss: 0.1319\n",
      "\n",
      "Batch 355/387 ━━━━━━━━━━━━━━━━━━━━ 03:54:12\n",
      "Accuracy: 0.9977 - Precision: 0.8911 - Recall: 0.8888 - Specificity: 0.9990 - F1: 0.8827 - Loss: 0.1318\n",
      "\n",
      "Batch 356/387 ━━━━━━━━━━━━━━━━━━━━ 03:55:37\n",
      "Accuracy: 0.9977 - Precision: 0.8913 - Recall: 0.8886 - Specificity: 0.9990 - F1: 0.8827 - Loss: 0.1318\n",
      "\n",
      "Batch 357/387 ━━━━━━━━━━━━━━━━━━━━ 03:57:18\n",
      "Accuracy: 0.9977 - Precision: 0.8914 - Recall: 0.8885 - Specificity: 0.9990 - F1: 0.8828 - Loss: 0.1317\n",
      "\n",
      "Batch 358/387 ━━━━━━━━━━━━━━━━━━━━ 03:58:43\n",
      "Accuracy: 0.9977 - Precision: 0.8916 - Recall: 0.8887 - Specificity: 0.9990 - F1: 0.8830 - Loss: 0.1315\n",
      "\n",
      "Batch 359/387 ━━━━━━━━━━━━━━━━━━━━ 04:00:10\n",
      "Accuracy: 0.9977 - Precision: 0.8919 - Recall: 0.8888 - Specificity: 0.9990 - F1: 0.8832 - Loss: 0.1313\n",
      "\n",
      "Batch 360/387 ━━━━━━━━━━━━━━━━━━━━ 04:01:33\n",
      "Accuracy: 0.9977 - Precision: 0.8921 - Recall: 0.8888 - Specificity: 0.9990 - F1: 0.8834 - Loss: 0.1311\n",
      "\n",
      "Batch 361/387 ━━━━━━━━━━━━━━━━━━━━ 04:03:01\n",
      "Accuracy: 0.9977 - Precision: 0.8917 - Recall: 0.8884 - Specificity: 0.9990 - F1: 0.8830 - Loss: 0.1315\n",
      "\n",
      "Batch 362/387 ━━━━━━━━━━━━━━━━━━━━ 04:04:21\n",
      "Accuracy: 0.9977 - Precision: 0.8917 - Recall: 0.8886 - Specificity: 0.9990 - F1: 0.8831 - Loss: 0.1314\n",
      "\n",
      "Batch 363/387 ━━━━━━━━━━━━━━━━━━━━ 04:05:43\n",
      "Accuracy: 0.9977 - Precision: 0.8916 - Recall: 0.8887 - Specificity: 0.9990 - F1: 0.8831 - Loss: 0.1314\n",
      "\n",
      "Batch 364/387 ━━━━━━━━━━━━━━━━━━━━ 04:07:03\n",
      "Accuracy: 0.9977 - Precision: 0.8912 - Recall: 0.8888 - Specificity: 0.9990 - F1: 0.8829 - Loss: 0.1316\n",
      "\n",
      "Batch 365/387 ━━━━━━━━━━━━━━━━━━━━ 04:08:21\n",
      "Accuracy: 0.9977 - Precision: 0.8904 - Recall: 0.8886 - Specificity: 0.9990 - F1: 0.8824 - Loss: 0.1321\n",
      "\n",
      "Batch 366/387 ━━━━━━━━━━━━━━━━━━━━ 04:09:48\n",
      "Accuracy: 0.9977 - Precision: 0.8906 - Recall: 0.8888 - Specificity: 0.9990 - F1: 0.8826 - Loss: 0.1319\n",
      "\n",
      "Batch 367/387 ━━━━━━━━━━━━━━━━━━━━ 04:11:13\n",
      "Accuracy: 0.9977 - Precision: 0.8908 - Recall: 0.8889 - Specificity: 0.9990 - F1: 0.8828 - Loss: 0.1317\n",
      "\n",
      "Batch 368/387 ━━━━━━━━━━━━━━━━━━━━ 04:12:45\n",
      "Accuracy: 0.9977 - Precision: 0.8909 - Recall: 0.8890 - Specificity: 0.9990 - F1: 0.8829 - Loss: 0.1316\n",
      "\n",
      "Batch 369/387 ━━━━━━━━━━━━━━━━━━━━ 04:14:07\n",
      "Accuracy: 0.9977 - Precision: 0.8912 - Recall: 0.8884 - Specificity: 0.9990 - F1: 0.8827 - Loss: 0.1319\n",
      "\n",
      "Batch 370/387 ━━━━━━━━━━━━━━━━━━━━ 04:15:37\n",
      "Accuracy: 0.9977 - Precision: 0.8915 - Recall: 0.8881 - Specificity: 0.9990 - F1: 0.8826 - Loss: 0.1320\n",
      "\n",
      "Batch 371/387 ━━━━━━━━━━━━━━━━━━━━ 04:17:15\n",
      "Accuracy: 0.9977 - Precision: 0.8915 - Recall: 0.8881 - Specificity: 0.9990 - F1: 0.8826 - Loss: 0.1320\n",
      "\n",
      "Batch 372/387 ━━━━━━━━━━━━━━━━━━━━ 04:18:45\n",
      "Accuracy: 0.9977 - Precision: 0.8916 - Recall: 0.8882 - Specificity: 0.9990 - F1: 0.8828 - Loss: 0.1318\n",
      "\n",
      "Batch 373/387 ━━━━━━━━━━━━━━━━━━━━ 04:20:19\n",
      "Accuracy: 0.9977 - Precision: 0.8913 - Recall: 0.8877 - Specificity: 0.9990 - F1: 0.8824 - Loss: 0.1322\n",
      "\n",
      "Batch 374/387 ━━━━━━━━━━━━━━━━━━━━ 04:21:36\n",
      "Accuracy: 0.9977 - Precision: 0.8914 - Recall: 0.8874 - Specificity: 0.9990 - F1: 0.8823 - Loss: 0.1323\n",
      "\n",
      "Batch 375/387 ━━━━━━━━━━━━━━━━━━━━ 04:22:57\n",
      "Accuracy: 0.9977 - Precision: 0.8914 - Recall: 0.8873 - Specificity: 0.9990 - F1: 0.8823 - Loss: 0.1323\n",
      "\n",
      "Batch 376/387 ━━━━━━━━━━━━━━━━━━━━ 04:24:16\n",
      "Accuracy: 0.9977 - Precision: 0.8916 - Recall: 0.8875 - Specificity: 0.9990 - F1: 0.8825 - Loss: 0.1321\n",
      "\n",
      "Batch 377/387 ━━━━━━━━━━━━━━━━━━━━ 04:25:45\n",
      "Accuracy: 0.9977 - Precision: 0.8909 - Recall: 0.8874 - Specificity: 0.9990 - F1: 0.8821 - Loss: 0.1326\n",
      "\n",
      "Batch 378/387 ━━━━━━━━━━━━━━━━━━━━ 04:27:09\n",
      "Accuracy: 0.9977 - Precision: 0.8909 - Recall: 0.8874 - Specificity: 0.9990 - F1: 0.8821 - Loss: 0.1325\n",
      "\n",
      "Batch 379/387 ━━━━━━━━━━━━━━━━━━━━ 04:28:35\n",
      "Accuracy: 0.9977 - Precision: 0.8907 - Recall: 0.8877 - Specificity: 0.9990 - F1: 0.8821 - Loss: 0.1325\n",
      "\n",
      "Batch 380/387 ━━━━━━━━━━━━━━━━━━━━ 04:29:54\n",
      "Accuracy: 0.9977 - Precision: 0.8909 - Recall: 0.8869 - Specificity: 0.9990 - F1: 0.8817 - Loss: 0.1329\n",
      "\n",
      "Batch 381/387 ━━━━━━━━━━━━━━━━━━━━ 04:31:23\n",
      "Accuracy: 0.9977 - Precision: 0.8910 - Recall: 0.8868 - Specificity: 0.9990 - F1: 0.8818 - Loss: 0.1329\n",
      "\n",
      "Batch 382/387 ━━━━━━━━━━━━━━━━━━━━ 04:32:49\n",
      "Accuracy: 0.9977 - Precision: 0.8910 - Recall: 0.8868 - Specificity: 0.9990 - F1: 0.8817 - Loss: 0.1329\n",
      "\n",
      "Batch 383/387 ━━━━━━━━━━━━━━━━━━━━ 04:34:09\n",
      "Accuracy: 0.9977 - Precision: 0.8910 - Recall: 0.8865 - Specificity: 0.9990 - F1: 0.8816 - Loss: 0.1330\n",
      "\n",
      "Batch 384/387 ━━━━━━━━━━━━━━━━━━━━ 04:35:37\n",
      "Accuracy: 0.9977 - Precision: 0.8911 - Recall: 0.8857 - Specificity: 0.9990 - F1: 0.8812 - Loss: 0.1335\n",
      "\n",
      "Batch 385/387 ━━━━━━━━━━━━━━━━━━━━ 04:37:06\n",
      "Accuracy: 0.9977 - Precision: 0.8912 - Recall: 0.8859 - Specificity: 0.9990 - F1: 0.8814 - Loss: 0.1333\n",
      "\n",
      "Batch 386/387 ━━━━━━━━━━━━━━━━━━━━ 04:38:40\n",
      "Accuracy: 0.9977 - Precision: 0.8913 - Recall: 0.8861 - Specificity: 0.9990 - F1: 0.8815 - Loss: 0.1331\n",
      "\n",
      "Batch 387/387 ━━━━━━━━━━━━━━━━━━━━ 04:40:08\n",
      "Accuracy: 0.9977 - Precision: 0.8908 - Recall: 0.8864 - Specificity: 0.9990 - F1: 0.8814 - Loss: 0.1333\n",
      "\n",
      "End of Epoch 8\n",
      "\n",
      "Epoch 9/50\n",
      "Batch 1/387 ━━━━━━━━━━━━━━━━━━━━ 09:10:52\n",
      "Accuracy: 0.9978 - Precision: 0.7576 - Recall: 0.9951 - Specificity: 0.9978 - F1: 0.8603 - Loss: 0.1559\n",
      "\n",
      "Batch 2/387 ━━━━━━━━━━━━━━━━━━━━ 09:12:27\n",
      "Accuracy: 0.9982 - Precision: 0.8242 - Recall: 0.9949 - Specificity: 0.9983 - F1: 0.9001 - Loss: 0.1113\n",
      "\n",
      "Batch 3/387 ━━━━━━━━━━━━━━━━━━━━ 09:14:04\n",
      "Accuracy: 0.9981 - Precision: 0.8459 - Recall: 0.9928 - Specificity: 0.9981 - F1: 0.9122 - Loss: 0.0994\n",
      "\n",
      "Batch 4/387 ━━━━━━━━━━━━━━━━━━━━ 09:15:35\n",
      "Accuracy: 0.9982 - Precision: 0.8609 - Recall: 0.9909 - Specificity: 0.9983 - F1: 0.9201 - Loss: 0.0904\n",
      "\n",
      "Batch 5/387 ━━━━━━━━━━━━━━━━━━━━ 09:17:07\n",
      "Accuracy: 0.9981 - Precision: 0.8614 - Recall: 0.9913 - Specificity: 0.9982 - F1: 0.9208 - Loss: 0.0900\n",
      "\n",
      "Batch 6/387 ━━━━━━━━━━━━━━━━━━━━ 09:18:26\n",
      "Accuracy: 0.9976 - Precision: 0.8338 - Recall: 0.9881 - Specificity: 0.9977 - F1: 0.9025 - Loss: 0.1113\n",
      "\n",
      "Batch 7/387 ━━━━━━━━━━━━━━━━━━━━ 09:20:04\n",
      "Accuracy: 0.9977 - Precision: 0.8481 - Recall: 0.9735 - Specificity: 0.9979 - F1: 0.9035 - Loss: 0.1105\n",
      "\n",
      "Batch 8/387 ━━━━━━━━━━━━━━━━━━━━ 09:21:28\n",
      "Accuracy: 0.9977 - Precision: 0.8452 - Recall: 0.9623 - Specificity: 0.9981 - F1: 0.8972 - Loss: 0.1168\n",
      "\n",
      "Batch 9/387 ━━━━━━━━━━━━━━━━━━━━ 09:23:02\n",
      "Accuracy: 0.9977 - Precision: 0.8579 - Recall: 0.9582 - Specificity: 0.9982 - F1: 0.9022 - Loss: 0.1117\n",
      "\n",
      "Batch 10/387 ━━━━━━━━━━━━━━━━━━━━ 09:24:27\n",
      "Accuracy: 0.9978 - Precision: 0.8656 - Recall: 0.9499 - Specificity: 0.9983 - F1: 0.9024 - Loss: 0.1112\n",
      "\n",
      "Batch 11/387 ━━━━━━━━━━━━━━━━━━━━ 09:25:58\n",
      "Accuracy: 0.9978 - Precision: 0.8476 - Recall: 0.9469 - Specificity: 0.9983 - F1: 0.8906 - Loss: 0.1235\n",
      "\n",
      "Batch 12/387 ━━━━━━━━━━━━━━━━━━━━ 09:27:29\n",
      "Accuracy: 0.9978 - Precision: 0.8594 - Recall: 0.9297 - Specificity: 0.9984 - F1: 0.8870 - Loss: 0.1272\n",
      "\n",
      "Batch 13/387 ━━━━━━━━━━━━━━━━━━━━ 09:29:04\n",
      "Accuracy: 0.9976 - Precision: 0.8700 - Recall: 0.9155 - Specificity: 0.9986 - F1: 0.8843 - Loss: 0.1312\n",
      "\n",
      "Batch 14/387 ━━━━━━━━━━━━━━━━━━━━ 09:30:29\n",
      "Accuracy: 0.9974 - Precision: 0.8774 - Recall: 0.9099 - Specificity: 0.9986 - F1: 0.8855 - Loss: 0.1312\n",
      "\n",
      "Batch 15/387 ━━━━━━━━━━━━━━━━━━━━ 09:32:06\n",
      "Accuracy: 0.9974 - Precision: 0.8856 - Recall: 0.8929 - Specificity: 0.9987 - F1: 0.8792 - Loss: 0.1380\n",
      "\n",
      "Batch 16/387 ━━━━━━━━━━━━━━━━━━━━ 09:33:39\n",
      "Accuracy: 0.9973 - Precision: 0.8915 - Recall: 0.8867 - Specificity: 0.9988 - F1: 0.8791 - Loss: 0.1384\n",
      "\n",
      "Batch 17/387 ━━━━━━━━━━━━━━━━━━━━ 09:35:13\n",
      "Accuracy: 0.9973 - Precision: 0.8968 - Recall: 0.8872 - Specificity: 0.9988 - F1: 0.8825 - Loss: 0.1346\n",
      "\n",
      "Batch 18/387 ━━━━━━━━━━━━━━━━━━━━ 09:36:44\n",
      "Accuracy: 0.9972 - Precision: 0.8981 - Recall: 0.8838 - Specificity: 0.9988 - F1: 0.8818 - Loss: 0.1356\n",
      "\n",
      "Batch 19/387 ━━━━━━━━━━━━━━━━━━━━ 09:38:10\n",
      "Accuracy: 0.9972 - Precision: 0.8996 - Recall: 0.8840 - Specificity: 0.9988 - F1: 0.8831 - Loss: 0.1341\n",
      "\n",
      "Batch 20/387 ━━━━━━━━━━━━━━━━━━━━ 09:39:34\n",
      "Accuracy: 0.9973 - Precision: 0.8973 - Recall: 0.8798 - Specificity: 0.9989 - F1: 0.8802 - Loss: 0.1367\n",
      "\n",
      "Batch 21/387 ━━━━━━━━━━━━━━━━━━━━ 09:41:02\n",
      "Accuracy: 0.9973 - Precision: 0.9003 - Recall: 0.8825 - Specificity: 0.9989 - F1: 0.8835 - Loss: 0.1332\n",
      "\n",
      "Batch 22/387 ━━━━━━━━━━━━━━━━━━━━ 09:42:23\n",
      "Accuracy: 0.9974 - Precision: 0.8984 - Recall: 0.8858 - Specificity: 0.9989 - F1: 0.8844 - Loss: 0.1319\n",
      "\n",
      "Batch 23/387 ━━━━━━━━━━━━━━━━━━━━ 09:43:55\n",
      "Accuracy: 0.9974 - Precision: 0.8872 - Recall: 0.8900 - Specificity: 0.9989 - F1: 0.8797 - Loss: 0.1366\n",
      "\n",
      "Batch 24/387 ━━━━━━━━━━━━━━━━━━━━ 09:45:27\n",
      "Accuracy: 0.9975 - Precision: 0.8776 - Recall: 0.8932 - Specificity: 0.9989 - F1: 0.8756 - Loss: 0.1406\n",
      "\n",
      "Batch 25/387 ━━━━━━━━━━━━━━━━━━━━ 09:46:53\n",
      "Accuracy: 0.9975 - Precision: 0.8714 - Recall: 0.8971 - Specificity: 0.9988 - F1: 0.8740 - Loss: 0.1421\n",
      "\n",
      "Batch 26/387 ━━━━━━━━━━━━━━━━━━━━ 09:48:30\n",
      "Accuracy: 0.9976 - Precision: 0.8721 - Recall: 0.8993 - Specificity: 0.9989 - F1: 0.8758 - Loss: 0.1401\n",
      "\n",
      "Batch 27/387 ━━━━━━━━━━━━━━━━━━━━ 09:49:58\n",
      "Accuracy: 0.9975 - Precision: 0.8730 - Recall: 0.8971 - Specificity: 0.9988 - F1: 0.8755 - Loss: 0.1408\n",
      "\n",
      "Batch 28/387 ━━━━━━━━━━━━━━━━━━━━ 09:51:34\n",
      "Accuracy: 0.9975 - Precision: 0.8763 - Recall: 0.8975 - Specificity: 0.9989 - F1: 0.8777 - Loss: 0.1383\n",
      "\n",
      "Batch 29/387 ━━━━━━━━━━━━━━━━━━━━ 09:52:54\n",
      "Accuracy: 0.9975 - Precision: 0.8802 - Recall: 0.8972 - Specificity: 0.9989 - F1: 0.8797 - Loss: 0.1365\n",
      "\n",
      "Batch 30/387 ━━━━━━━━━━━━━━━━━━━━ 09:54:17\n",
      "Accuracy: 0.9975 - Precision: 0.8836 - Recall: 0.8973 - Specificity: 0.9989 - F1: 0.8817 - Loss: 0.1343\n",
      "\n",
      "Batch 31/387 ━━━━━━━━━━━━━━━━━━━━ 09:55:40\n",
      "Accuracy: 0.9975 - Precision: 0.8868 - Recall: 0.8985 - Specificity: 0.9989 - F1: 0.8842 - Loss: 0.1316\n",
      "\n",
      "Batch 32/387 ━━━━━━━━━━━━━━━━━━━━ 09:57:14\n",
      "Accuracy: 0.9976 - Precision: 0.8893 - Recall: 0.8946 - Specificity: 0.9990 - F1: 0.8834 - Loss: 0.1322\n",
      "\n",
      "Batch 33/387 ━━━━━━━━━━━━━━━━━━━━ 09:58:49\n",
      "Accuracy: 0.9974 - Precision: 0.8917 - Recall: 0.8886 - Specificity: 0.9990 - F1: 0.8811 - Loss: 0.1353\n",
      "\n",
      "Batch 34/387 ━━━━━━━━━━━━━━━━━━━━ 10:00:22\n",
      "Accuracy: 0.9975 - Precision: 0.8945 - Recall: 0.8901 - Specificity: 0.9990 - F1: 0.8835 - Loss: 0.1326\n",
      "\n",
      "Batch 35/387 ━━━━━━━━━━━━━━━━━━━━ 10:01:45\n",
      "Accuracy: 0.9974 - Precision: 0.8952 - Recall: 0.8903 - Specificity: 0.9990 - F1: 0.8843 - Loss: 0.1320\n",
      "\n",
      "Batch 36/387 ━━━━━━━━━━━━━━━━━━━━ 10:03:41\n",
      "Accuracy: 0.9975 - Precision: 0.8977 - Recall: 0.8914 - Specificity: 0.9990 - F1: 0.8863 - Loss: 0.1297\n",
      "\n",
      "Batch 37/387 ━━━━━━━━━━━━━━━━━━━━ 10:05:32\n",
      "Accuracy: 0.9975 - Precision: 0.8984 - Recall: 0.8872 - Specificity: 0.9990 - F1: 0.8844 - Loss: 0.1317\n",
      "\n",
      "Batch 38/387 ━━━━━━━━━━━━━━━━━━━━ 10:07:00\n",
      "Accuracy: 0.9975 - Precision: 0.8969 - Recall: 0.8894 - Specificity: 0.9990 - F1: 0.8849 - Loss: 0.1310\n",
      "\n",
      "Batch 39/387 ━━━━━━━━━━━━━━━━━━━━ 10:08:35\n",
      "Accuracy: 0.9975 - Precision: 0.8981 - Recall: 0.8895 - Specificity: 0.9990 - F1: 0.8858 - Loss: 0.1301\n",
      "\n",
      "Batch 40/387 ━━━━━━━━━━━━━━━━━━━━ 10:10:19\n",
      "Accuracy: 0.9976 - Precision: 0.8994 - Recall: 0.8917 - Specificity: 0.9991 - F1: 0.8877 - Loss: 0.1279\n",
      "\n",
      "Batch 41/387 ━━━━━━━━━━━━━━━━━━━━ 10:11:42\n",
      "Accuracy: 0.9976 - Precision: 0.8990 - Recall: 0.8924 - Specificity: 0.9990 - F1: 0.8880 - Loss: 0.1276\n",
      "\n",
      "Batch 42/387 ━━━━━━━━━━━━━━━━━━━━ 10:13:22\n",
      "Accuracy: 0.9976 - Precision: 0.8982 - Recall: 0.8938 - Specificity: 0.9990 - F1: 0.8884 - Loss: 0.1271\n",
      "\n",
      "Batch 43/387 ━━━━━━━━━━━━━━━━━━━━ 10:14:52\n",
      "Accuracy: 0.9975 - Precision: 0.8962 - Recall: 0.8952 - Specificity: 0.9990 - F1: 0.8882 - Loss: 0.1273\n",
      "\n",
      "Batch 44/387 ━━━━━━━━━━━━━━━━━━━━ 10:16:22\n",
      "Accuracy: 0.9976 - Precision: 0.8972 - Recall: 0.8970 - Specificity: 0.9990 - F1: 0.8898 - Loss: 0.1256\n",
      "\n",
      "Batch 45/387 ━━━━━━━━━━━━━━━━━━━━ 10:17:45\n",
      "Accuracy: 0.9976 - Precision: 0.8976 - Recall: 0.8982 - Specificity: 0.9990 - F1: 0.8907 - Loss: 0.1246\n",
      "\n",
      "Batch 46/387 ━━━━━━━━━━━━━━━━━━━━ 10:19:16\n",
      "Accuracy: 0.9975 - Precision: 0.8962 - Recall: 0.8998 - Specificity: 0.9989 - F1: 0.8908 - Loss: 0.1245\n",
      "\n",
      "Batch 47/387 ━━━━━━━━━━━━━━━━━━━━ 10:20:49\n",
      "Accuracy: 0.9976 - Precision: 0.8975 - Recall: 0.9013 - Specificity: 0.9989 - F1: 0.8924 - Loss: 0.1228\n",
      "\n",
      "Batch 48/387 ━━━━━━━━━━━━━━━━━━━━ 10:22:16\n",
      "Accuracy: 0.9976 - Precision: 0.8960 - Recall: 0.9027 - Specificity: 0.9989 - F1: 0.8924 - Loss: 0.1227\n",
      "\n",
      "Batch 49/387 ━━━━━━━━━━━━━━━━━━━━ 10:23:40\n",
      "Accuracy: 0.9976 - Precision: 0.8950 - Recall: 0.9040 - Specificity: 0.9989 - F1: 0.8926 - Loss: 0.1226\n",
      "\n",
      "Batch 50/387 ━━━━━━━━━━━━━━━━━━━━ 10:25:08\n",
      "Accuracy: 0.9976 - Precision: 0.8960 - Recall: 0.9044 - Specificity: 0.9989 - F1: 0.8934 - Loss: 0.1216\n",
      "\n",
      "Batch 51/387 ━━━━━━━━━━━━━━━━━━━━ 10:26:35\n",
      "Accuracy: 0.9976 - Precision: 0.8973 - Recall: 0.9049 - Specificity: 0.9989 - F1: 0.8945 - Loss: 0.1205\n",
      "\n",
      "Batch 52/387 ━━━━━━━━━━━━━━━━━━━━ 10:28:06\n",
      "Accuracy: 0.9976 - Precision: 0.8961 - Recall: 0.9060 - Specificity: 0.9989 - F1: 0.8944 - Loss: 0.1204\n",
      "\n",
      "Batch 53/387 ━━━━━━━━━━━━━━━━━━━━ 10:29:40\n",
      "Accuracy: 0.9977 - Precision: 0.8949 - Recall: 0.9058 - Specificity: 0.9989 - F1: 0.8938 - Loss: 0.1209\n",
      "\n",
      "Batch 54/387 ━━━━━━━━━━━━━━━━━━━━ 10:31:18\n",
      "Accuracy: 0.9977 - Precision: 0.8963 - Recall: 0.9058 - Specificity: 0.9989 - F1: 0.8947 - Loss: 0.1200\n",
      "\n",
      "Batch 55/387 ━━━━━━━━━━━━━━━━━━━━ 10:32:46\n",
      "Accuracy: 0.9977 - Precision: 0.8974 - Recall: 0.9066 - Specificity: 0.9989 - F1: 0.8957 - Loss: 0.1188\n",
      "\n",
      "Batch 56/387 ━━━━━━━━━━━━━━━━━━━━ 10:34:34\n",
      "Accuracy: 0.9977 - Precision: 0.8947 - Recall: 0.9071 - Specificity: 0.9989 - F1: 0.8945 - Loss: 0.1199\n",
      "\n",
      "Batch 57/387 ━━━━━━━━━━━━━━━━━━━━ 10:36:04\n",
      "Accuracy: 0.9977 - Precision: 0.8962 - Recall: 0.9056 - Specificity: 0.9990 - F1: 0.8945 - Loss: 0.1200\n",
      "\n",
      "Batch 58/387 ━━━━━━━━━━━━━━━━━━━━ 10:37:34\n",
      "Accuracy: 0.9977 - Precision: 0.8980 - Recall: 0.9038 - Specificity: 0.9990 - F1: 0.8945 - Loss: 0.1199\n",
      "\n",
      "Batch 59/387 ━━━━━━━━━━━━━━━━━━━━ 10:39:04\n",
      "Accuracy: 0.9977 - Precision: 0.8996 - Recall: 0.9030 - Specificity: 0.9990 - F1: 0.8949 - Loss: 0.1195\n",
      "\n",
      "Batch 60/387 ━━━━━━━━━━━━━━━━━━━━ 10:40:35\n",
      "Accuracy: 0.9977 - Precision: 0.8969 - Recall: 0.8995 - Specificity: 0.9990 - F1: 0.8919 - Loss: 0.1225\n",
      "\n",
      "Batch 61/387 ━━━━━━━━━━━━━━━━━━━━ 10:42:13\n",
      "Accuracy: 0.9978 - Precision: 0.8978 - Recall: 0.8998 - Specificity: 0.9990 - F1: 0.8926 - Loss: 0.1216\n",
      "\n",
      "Batch 62/387 ━━━━━━━━━━━━━━━━━━━━ 10:43:46\n",
      "Accuracy: 0.9977 - Precision: 0.8993 - Recall: 0.8962 - Specificity: 0.9990 - F1: 0.8911 - Loss: 0.1232\n",
      "\n",
      "Batch 63/387 ━━━━━━━━━━━━━━━━━━━━ 10:45:15\n",
      "Accuracy: 0.9977 - Precision: 0.9006 - Recall: 0.8962 - Specificity: 0.9990 - F1: 0.8919 - Loss: 0.1224\n",
      "\n",
      "Batch 64/387 ━━━━━━━━━━━━━━━━━━━━ 10:46:55\n",
      "Accuracy: 0.9978 - Precision: 0.9008 - Recall: 0.8946 - Specificity: 0.9990 - F1: 0.8912 - Loss: 0.1230\n",
      "\n",
      "Batch 65/387 ━━━━━━━━━━━━━━━━━━━━ 10:48:28\n",
      "Accuracy: 0.9978 - Precision: 0.9018 - Recall: 0.8950 - Specificity: 0.9991 - F1: 0.8920 - Loss: 0.1221\n",
      "\n",
      "Batch 66/387 ━━━━━━━━━━━━━━━━━━━━ 10:50:05\n",
      "Accuracy: 0.9978 - Precision: 0.9022 - Recall: 0.8948 - Specificity: 0.9991 - F1: 0.8922 - Loss: 0.1219\n",
      "\n",
      "Batch 67/387 ━━━━━━━━━━━━━━━━━━━━ 10:51:34\n",
      "Accuracy: 0.9978 - Precision: 0.9026 - Recall: 0.8953 - Specificity: 0.9991 - F1: 0.8927 - Loss: 0.1213\n",
      "\n",
      "Batch 68/387 ━━━━━━━━━━━━━━━━━━━━ 10:53:11\n",
      "Accuracy: 0.9978 - Precision: 0.9035 - Recall: 0.8959 - Specificity: 0.9991 - F1: 0.8935 - Loss: 0.1204\n",
      "\n",
      "Batch 69/387 ━━━━━━━━━━━━━━━━━━━━ 10:54:41\n",
      "Accuracy: 0.9977 - Precision: 0.8978 - Recall: 0.8973 - Specificity: 0.9990 - F1: 0.8904 - Loss: 0.1239\n",
      "\n",
      "Batch 70/387 ━━━━━━━━━━━━━━━━━━━━ 10:56:27\n",
      "Accuracy: 0.9978 - Precision: 0.8933 - Recall: 0.8979 - Specificity: 0.9990 - F1: 0.8879 - Loss: 0.1266\n",
      "\n",
      "Batch 71/387 ━━━━━━━━━━━━━━━━━━━━ 10:57:53\n",
      "Accuracy: 0.9977 - Precision: 0.8914 - Recall: 0.8963 - Specificity: 0.9990 - F1: 0.8863 - Loss: 0.1283\n",
      "\n",
      "Batch 72/387 ━━━━━━━━━━━━━━━━━━━━ 10:59:24\n",
      "Accuracy: 0.9977 - Precision: 0.8912 - Recall: 0.8971 - Specificity: 0.9989 - F1: 0.8867 - Loss: 0.1279\n",
      "\n",
      "Batch 73/387 ━━━━━━━━━━━━━━━━━━━━ 11:00:47\n",
      "Accuracy: 0.9977 - Precision: 0.8921 - Recall: 0.8971 - Specificity: 0.9990 - F1: 0.8872 - Loss: 0.1274\n",
      "\n",
      "Batch 74/387 ━━━━━━━━━━━━━━━━━━━━ 11:02:15\n",
      "Accuracy: 0.9977 - Precision: 0.8933 - Recall: 0.8967 - Specificity: 0.9990 - F1: 0.8877 - Loss: 0.1268\n",
      "\n",
      "Batch 75/387 ━━━━━━━━━━━━━━━━━━━━ 11:03:54\n",
      "Accuracy: 0.9978 - Precision: 0.8930 - Recall: 0.8973 - Specificity: 0.9990 - F1: 0.8879 - Loss: 0.1265\n",
      "\n",
      "Batch 76/387 ━━━━━━━━━━━━━━━━━━━━ 11:05:34\n",
      "Accuracy: 0.9977 - Precision: 0.8891 - Recall: 0.8963 - Specificity: 0.9990 - F1: 0.8853 - Loss: 0.1292\n",
      "\n",
      "Batch 77/387 ━━━━━━━━━━━━━━━━━━━━ 11:07:02\n",
      "Accuracy: 0.9978 - Precision: 0.8884 - Recall: 0.8968 - Specificity: 0.9990 - F1: 0.8853 - Loss: 0.1291\n",
      "\n",
      "Batch 78/387 ━━━━━━━━━━━━━━━━━━━━ 11:08:31\n",
      "Accuracy: 0.9978 - Precision: 0.8865 - Recall: 0.8975 - Specificity: 0.9990 - F1: 0.8846 - Loss: 0.1297\n",
      "\n",
      "Batch 79/387 ━━━━━━━━━━━━━━━━━━━━ 11:09:58\n",
      "Accuracy: 0.9978 - Precision: 0.8874 - Recall: 0.8975 - Specificity: 0.9990 - F1: 0.8852 - Loss: 0.1291\n",
      "\n",
      "Batch 80/387 ━━━━━━━━━━━━━━━━━━━━ 11:11:33\n",
      "Accuracy: 0.9977 - Precision: 0.8885 - Recall: 0.8939 - Specificity: 0.9990 - F1: 0.8834 - Loss: 0.1313\n",
      "\n",
      "Batch 81/387 ━━━━━━━━━━━━━━━━━━━━ 11:13:00\n",
      "Accuracy: 0.9977 - Precision: 0.8897 - Recall: 0.8934 - Specificity: 0.9990 - F1: 0.8838 - Loss: 0.1308\n",
      "\n",
      "Batch 82/387 ━━━━━━━━━━━━━━━━━━━━ 11:14:40\n",
      "Accuracy: 0.9978 - Precision: 0.8892 - Recall: 0.8940 - Specificity: 0.9990 - F1: 0.8840 - Loss: 0.1305\n",
      "\n",
      "Batch 83/387 ━━━━━━━━━━━━━━━━━━━━ 11:16:18\n",
      "Accuracy: 0.9977 - Precision: 0.8899 - Recall: 0.8895 - Specificity: 0.9990 - F1: 0.8814 - Loss: 0.1336\n",
      "\n",
      "Batch 84/387 ━━━━━━━━━━━━━━━━━━━━ 11:17:51\n",
      "Accuracy: 0.9977 - Precision: 0.8906 - Recall: 0.8848 - Specificity: 0.9990 - F1: 0.8787 - Loss: 0.1366\n",
      "\n",
      "Batch 85/387 ━━━━━━━━━━━━━━━━━━━━ 11:19:15\n",
      "Accuracy: 0.9976 - Precision: 0.8903 - Recall: 0.8817 - Specificity: 0.9990 - F1: 0.8769 - Loss: 0.1386\n",
      "\n",
      "Batch 86/387 ━━━━━━━━━━━━━━━━━━━━ 11:20:51\n",
      "Accuracy: 0.9976 - Precision: 0.8914 - Recall: 0.8790 - Specificity: 0.9990 - F1: 0.8758 - Loss: 0.1398\n",
      "\n",
      "Batch 87/387 ━━━━━━━━━━━━━━━━━━━━ 11:22:23\n",
      "Accuracy: 0.9976 - Precision: 0.8912 - Recall: 0.8789 - Specificity: 0.9990 - F1: 0.8757 - Loss: 0.1398\n",
      "\n",
      "Batch 88/387 ━━━━━━━━━━━━━━━━━━━━ 11:23:54\n",
      "Accuracy: 0.9976 - Precision: 0.8906 - Recall: 0.8784 - Specificity: 0.9990 - F1: 0.8752 - Loss: 0.1403\n",
      "\n",
      "Batch 89/387 ━━━━━━━━━━━━━━━━━━━━ 11:25:33\n",
      "Accuracy: 0.9976 - Precision: 0.8913 - Recall: 0.8789 - Specificity: 0.9990 - F1: 0.8760 - Loss: 0.1395\n",
      "\n",
      "Batch 90/387 ━━━━━━━━━━━━━━━━━━━━ 11:27:03\n",
      "Accuracy: 0.9976 - Precision: 0.8922 - Recall: 0.8791 - Specificity: 0.9990 - F1: 0.8766 - Loss: 0.1389\n",
      "\n",
      "Batch 91/387 ━━━━━━━━━━━━━━━━━━━━ 11:28:44\n",
      "Accuracy: 0.9976 - Precision: 0.8933 - Recall: 0.8792 - Specificity: 0.9990 - F1: 0.8773 - Loss: 0.1382\n",
      "\n",
      "Batch 92/387 ━━━━━━━━━━━━━━━━━━━━ 11:30:11\n",
      "Accuracy: 0.9976 - Precision: 0.8933 - Recall: 0.8799 - Specificity: 0.9990 - F1: 0.8777 - Loss: 0.1377\n",
      "\n",
      "Batch 93/387 ━━━━━━━━━━━━━━━━━━━━ 11:31:47\n",
      "Accuracy: 0.9976 - Precision: 0.8925 - Recall: 0.8812 - Specificity: 0.9990 - F1: 0.8780 - Loss: 0.1374\n",
      "\n",
      "Batch 94/387 ━━━━━━━━━━━━━━━━━━━━ 11:33:13\n",
      "Accuracy: 0.9976 - Precision: 0.8927 - Recall: 0.8815 - Specificity: 0.9990 - F1: 0.8784 - Loss: 0.1370\n",
      "\n",
      "Batch 95/387 ━━━━━━━━━━━━━━━━━━━━ 11:34:37\n",
      "Accuracy: 0.9976 - Precision: 0.8927 - Recall: 0.8828 - Specificity: 0.9990 - F1: 0.8790 - Loss: 0.1363\n",
      "\n",
      "Batch 96/387 ━━━━━━━━━━━━━━━━━━━━ 11:36:13\n",
      "Accuracy: 0.9976 - Precision: 0.8915 - Recall: 0.8835 - Specificity: 0.9990 - F1: 0.8788 - Loss: 0.1365\n",
      "\n",
      "Batch 97/387 ━━━━━━━━━━━━━━━━━━━━ 11:37:47\n",
      "Accuracy: 0.9977 - Precision: 0.8913 - Recall: 0.8840 - Specificity: 0.9990 - F1: 0.8790 - Loss: 0.1362\n",
      "\n",
      "Batch 98/387 ━━━━━━━━━━━━━━━━━━━━ 11:39:15\n",
      "Accuracy: 0.9976 - Precision: 0.8921 - Recall: 0.8843 - Specificity: 0.9990 - F1: 0.8796 - Loss: 0.1356\n",
      "\n",
      "Batch 99/387 ━━━━━━━━━━━━━━━━━━━━ 11:40:45\n",
      "Accuracy: 0.9976 - Precision: 0.8926 - Recall: 0.8851 - Specificity: 0.9990 - F1: 0.8804 - Loss: 0.1348\n",
      "\n",
      "Batch 100/387 ━━━━━━━━━━━━━━━━━━━━ 11:42:21\n",
      "Accuracy: 0.9977 - Precision: 0.8917 - Recall: 0.8861 - Specificity: 0.9990 - F1: 0.8804 - Loss: 0.1347\n",
      "\n",
      "Batch 101/387 ━━━━━━━━━━━━━━━━━━━━ 11:43:54\n",
      "Accuracy: 0.9976 - Precision: 0.8918 - Recall: 0.8867 - Specificity: 0.9990 - F1: 0.8808 - Loss: 0.1343\n",
      "\n",
      "Batch 102/387 ━━━━━━━━━━━━━━━━━━━━ 11:45:29\n",
      "Accuracy: 0.9976 - Precision: 0.8923 - Recall: 0.8873 - Specificity: 0.9990 - F1: 0.8815 - Loss: 0.1336\n",
      "\n",
      "Batch 103/387 ━━━━━━━━━━━━━━━━━━━━ 11:47:01\n",
      "Accuracy: 0.9976 - Precision: 0.8921 - Recall: 0.8878 - Specificity: 0.9990 - F1: 0.8817 - Loss: 0.1334\n",
      "\n",
      "Batch 104/387 ━━━━━━━━━━━━━━━━━━━━ 11:48:25\n",
      "Accuracy: 0.9977 - Precision: 0.8929 - Recall: 0.8874 - Specificity: 0.9990 - F1: 0.8819 - Loss: 0.1331\n",
      "\n",
      "Batch 105/387 ━━━━━━━━━━━━━━━━━━━━ 11:49:59\n",
      "Accuracy: 0.9976 - Precision: 0.8886 - Recall: 0.8875 - Specificity: 0.9990 - F1: 0.8792 - Loss: 0.1359\n",
      "\n",
      "Batch 106/387 ━━━━━━━━━━━━━━━━━━━━ 11:51:30\n",
      "Accuracy: 0.9977 - Precision: 0.8891 - Recall: 0.8875 - Specificity: 0.9990 - F1: 0.8795 - Loss: 0.1355\n",
      "\n",
      "Batch 107/387 ━━━━━━━━━━━━━━━━━━━━ 11:52:52\n",
      "Accuracy: 0.9977 - Precision: 0.8891 - Recall: 0.8880 - Specificity: 0.9990 - F1: 0.8798 - Loss: 0.1352\n",
      "\n",
      "Batch 108/387 ━━━━━━━━━━━━━━━━━━━━ 11:54:22\n",
      "Accuracy: 0.9977 - Precision: 0.8885 - Recall: 0.8886 - Specificity: 0.9990 - F1: 0.8799 - Loss: 0.1351\n",
      "\n",
      "Batch 109/387 ━━━━━━━━━━━━━━━━━━━━ 11:55:58\n",
      "Accuracy: 0.9977 - Precision: 0.8895 - Recall: 0.8888 - Specificity: 0.9990 - F1: 0.8805 - Loss: 0.1344\n",
      "\n",
      "Batch 110/387 ━━━━━━━━━━━━━━━━━━━━ 11:57:27\n",
      "Accuracy: 0.9976 - Precision: 0.8898 - Recall: 0.8889 - Specificity: 0.9990 - F1: 0.8808 - Loss: 0.1341\n",
      "\n",
      "Batch 111/387 ━━━━━━━━━━━━━━━━━━━━ 11:59:08\n",
      "Accuracy: 0.9976 - Precision: 0.8905 - Recall: 0.8892 - Specificity: 0.9990 - F1: 0.8813 - Loss: 0.1336\n",
      "\n",
      "Batch 112/387 ━━━━━━━━━━━━━━━━━━━━ 12:00:38\n",
      "Accuracy: 0.9977 - Precision: 0.8912 - Recall: 0.8888 - Specificity: 0.9990 - F1: 0.8815 - Loss: 0.1334\n",
      "\n",
      "Batch 113/387 ━━━━━━━━━━━━━━━━━━━━ 12:02:15\n",
      "Accuracy: 0.9977 - Precision: 0.8917 - Recall: 0.8885 - Specificity: 0.9990 - F1: 0.8817 - Loss: 0.1332\n",
      "\n",
      "Batch 114/387 ━━━━━━━━━━━━━━━━━━━━ 12:03:47\n",
      "Accuracy: 0.9977 - Precision: 0.8918 - Recall: 0.8871 - Specificity: 0.9990 - F1: 0.8810 - Loss: 0.1338\n",
      "\n",
      "Batch 115/387 ━━━━━━━━━━━━━━━━━━━━ 12:05:20\n",
      "Accuracy: 0.9977 - Precision: 0.8918 - Recall: 0.8854 - Specificity: 0.9990 - F1: 0.8802 - Loss: 0.1346\n",
      "\n",
      "Batch 116/387 ━━━━━━━━━━━━━━━━━━━━ 12:06:51\n",
      "Accuracy: 0.9977 - Precision: 0.8898 - Recall: 0.8853 - Specificity: 0.9990 - F1: 0.8791 - Loss: 0.1359\n",
      "\n",
      "Batch 117/387 ━━━━━━━━━━━━━━━━━━━━ 12:08:10\n",
      "Accuracy: 0.9977 - Precision: 0.8901 - Recall: 0.8857 - Specificity: 0.9990 - F1: 0.8795 - Loss: 0.1354\n",
      "\n",
      "Batch 118/387 ━━━━━━━━━━━━━━━━━━━━ 12:09:28\n",
      "Accuracy: 0.9977 - Precision: 0.8901 - Recall: 0.8863 - Specificity: 0.9990 - F1: 0.8799 - Loss: 0.1350\n",
      "\n",
      "Batch 119/387 ━━━━━━━━━━━━━━━━━━━━ 12:11:07\n",
      "Accuracy: 0.9977 - Precision: 0.8908 - Recall: 0.8865 - Specificity: 0.9990 - F1: 0.8804 - Loss: 0.1345\n",
      "\n",
      "Batch 120/387 ━━━━━━━━━━━━━━━━━━━━ 12:12:36\n",
      "Accuracy: 0.9977 - Precision: 0.8903 - Recall: 0.8853 - Specificity: 0.9990 - F1: 0.8796 - Loss: 0.1352\n",
      "\n",
      "Batch 121/387 ━━━━━━━━━━━━━━━━━━━━ 12:14:10\n",
      "Accuracy: 0.9977 - Precision: 0.8908 - Recall: 0.8857 - Specificity: 0.9990 - F1: 0.8801 - Loss: 0.1347\n",
      "\n",
      "Batch 122/387 ━━━━━━━━━━━━━━━━━━━━ 12:15:31\n",
      "Accuracy: 0.9977 - Precision: 0.8916 - Recall: 0.8861 - Specificity: 0.9990 - F1: 0.8807 - Loss: 0.1340\n",
      "\n",
      "Batch 123/387 ━━━━━━━━━━━━━━━━━━━━ 12:17:05\n",
      "Accuracy: 0.9977 - Precision: 0.8917 - Recall: 0.8868 - Specificity: 0.9990 - F1: 0.8812 - Loss: 0.1335\n",
      "\n",
      "Batch 124/387 ━━━━━━━━━━━━━━━━━━━━ 12:18:46\n",
      "Accuracy: 0.9977 - Precision: 0.8923 - Recall: 0.8873 - Specificity: 0.9990 - F1: 0.8818 - Loss: 0.1328\n",
      "\n",
      "Batch 125/387 ━━━━━━━━━━━━━━━━━━━━ 12:20:22\n",
      "Accuracy: 0.9977 - Precision: 0.8926 - Recall: 0.8879 - Specificity: 0.9990 - F1: 0.8823 - Loss: 0.1322\n",
      "\n",
      "Batch 126/387 ━━━━━━━━━━━━━━━━━━━━ 12:21:59\n",
      "Accuracy: 0.9978 - Precision: 0.8933 - Recall: 0.8885 - Specificity: 0.9990 - F1: 0.8830 - Loss: 0.1314\n",
      "\n",
      "Batch 127/387 ━━━━━━━━━━━━━━━━━━━━ 12:23:19\n",
      "Accuracy: 0.9978 - Precision: 0.8935 - Recall: 0.8888 - Specificity: 0.9990 - F1: 0.8834 - Loss: 0.1311\n",
      "\n",
      "Batch 128/387 ━━━━━━━━━━━━━━━━━━━━ 12:25:00\n",
      "Accuracy: 0.9978 - Precision: 0.8942 - Recall: 0.8892 - Specificity: 0.9990 - F1: 0.8839 - Loss: 0.1305\n",
      "\n",
      "Batch 129/387 ━━━━━━━━━━━━━━━━━━━━ 12:26:31\n",
      "Accuracy: 0.9978 - Precision: 0.8946 - Recall: 0.8896 - Specificity: 0.9990 - F1: 0.8844 - Loss: 0.1300\n",
      "\n",
      "Batch 130/387 ━━━━━━━━━━━━━━━━━━━━ 12:28:03\n",
      "Accuracy: 0.9977 - Precision: 0.8942 - Recall: 0.8900 - Specificity: 0.9990 - F1: 0.8845 - Loss: 0.1300\n",
      "\n",
      "Batch 131/387 ━━━━━━━━━━━━━━━━━━━━ 12:29:41\n",
      "Accuracy: 0.9977 - Precision: 0.8943 - Recall: 0.8906 - Specificity: 0.9990 - F1: 0.8849 - Loss: 0.1296\n",
      "\n",
      "Batch 132/387 ━━━━━━━━━━━━━━━━━━━━ 12:31:19\n",
      "Accuracy: 0.9978 - Precision: 0.8950 - Recall: 0.8910 - Specificity: 0.9990 - F1: 0.8854 - Loss: 0.1289\n",
      "\n",
      "Batch 133/387 ━━━━━━━━━━━━━━━━━━━━ 12:32:56\n",
      "Accuracy: 0.9978 - Precision: 0.8947 - Recall: 0.8910 - Specificity: 0.9990 - F1: 0.8854 - Loss: 0.1290\n",
      "\n",
      "Batch 134/387 ━━━━━━━━━━━━━━━━━━━━ 12:34:31\n",
      "Accuracy: 0.9977 - Precision: 0.8953 - Recall: 0.8898 - Specificity: 0.9990 - F1: 0.8850 - Loss: 0.1296\n",
      "\n",
      "Batch 135/387 ━━━━━━━━━━━━━━━━━━━━ 12:36:05\n",
      "Accuracy: 0.9977 - Precision: 0.8953 - Recall: 0.8887 - Specificity: 0.9990 - F1: 0.8844 - Loss: 0.1303\n",
      "\n",
      "Batch 136/387 ━━━━━━━━━━━━━━━━━━━━ 12:37:40\n",
      "Accuracy: 0.9977 - Precision: 0.8954 - Recall: 0.8894 - Specificity: 0.9990 - F1: 0.8848 - Loss: 0.1298\n",
      "\n",
      "Batch 137/387 ━━━━━━━━━━━━━━━━━━━━ 12:39:14\n",
      "Accuracy: 0.9977 - Precision: 0.8955 - Recall: 0.8899 - Specificity: 0.9990 - F1: 0.8852 - Loss: 0.1294\n",
      "\n",
      "Batch 138/387 ━━━━━━━━━━━━━━━━━━━━ 12:40:45\n",
      "Accuracy: 0.9977 - Precision: 0.8951 - Recall: 0.8907 - Specificity: 0.9990 - F1: 0.8854 - Loss: 0.1292\n",
      "\n",
      "Batch 139/387 ━━━━━━━━━━━━━━━━━━━━ 12:42:22\n",
      "Accuracy: 0.9977 - Precision: 0.8954 - Recall: 0.8912 - Specificity: 0.9990 - F1: 0.8859 - Loss: 0.1287\n",
      "\n",
      "Batch 140/387 ━━━━━━━━━━━━━━━━━━━━ 12:43:56\n",
      "Accuracy: 0.9977 - Precision: 0.8958 - Recall: 0.8909 - Specificity: 0.9990 - F1: 0.8859 - Loss: 0.1287\n",
      "\n",
      "Batch 141/387 ━━━━━━━━━━━━━━━━━━━━ 12:45:21\n",
      "Accuracy: 0.9977 - Precision: 0.8964 - Recall: 0.8914 - Specificity: 0.9990 - F1: 0.8866 - Loss: 0.1280\n",
      "\n",
      "Batch 142/387 ━━━━━━━━━━━━━━━━━━━━ 12:46:49\n",
      "Accuracy: 0.9977 - Precision: 0.8968 - Recall: 0.8910 - Specificity: 0.9990 - F1: 0.8866 - Loss: 0.1279\n",
      "\n",
      "Batch 143/387 ━━━━━━━━━━━━━━━━━━━━ 12:48:34\n",
      "Accuracy: 0.9977 - Precision: 0.8969 - Recall: 0.8912 - Specificity: 0.9990 - F1: 0.8868 - Loss: 0.1277\n",
      "\n",
      "Batch 144/387 ━━━━━━━━━━━━━━━━━━━━ 12:50:17\n",
      "Accuracy: 0.9977 - Precision: 0.8961 - Recall: 0.8911 - Specificity: 0.9990 - F1: 0.8863 - Loss: 0.1282\n",
      "\n",
      "Batch 145/387 ━━━━━━━━━━━━━━━━━━━━ 12:51:49\n",
      "Accuracy: 0.9977 - Precision: 0.8964 - Recall: 0.8914 - Specificity: 0.9990 - F1: 0.8867 - Loss: 0.1278\n",
      "\n",
      "Batch 146/387 ━━━━━━━━━━━━━━━━━━━━ 12:53:10\n",
      "Accuracy: 0.9977 - Precision: 0.8964 - Recall: 0.8918 - Specificity: 0.9990 - F1: 0.8870 - Loss: 0.1275\n",
      "\n",
      "Batch 147/387 ━━━━━━━━━━━━━━━━━━━━ 12:54:41\n",
      "Accuracy: 0.9977 - Precision: 0.8963 - Recall: 0.8923 - Specificity: 0.9990 - F1: 0.8872 - Loss: 0.1272\n",
      "\n",
      "Batch 148/387 ━━━━━━━━━━━━━━━━━━━━ 12:56:21\n",
      "Accuracy: 0.9978 - Precision: 0.8966 - Recall: 0.8906 - Specificity: 0.9990 - F1: 0.8863 - Loss: 0.1280\n",
      "\n",
      "Batch 149/387 ━━━━━━━━━━━━━━━━━━━━ 12:57:58\n",
      "Accuracy: 0.9978 - Precision: 0.8972 - Recall: 0.8908 - Specificity: 0.9990 - F1: 0.8868 - Loss: 0.1275\n",
      "\n",
      "Batch 150/387 ━━━━━━━━━━━━━━━━━━━━ 12:59:37\n",
      "Accuracy: 0.9978 - Precision: 0.8965 - Recall: 0.8905 - Specificity: 0.9990 - F1: 0.8863 - Loss: 0.1280\n",
      "\n",
      "Batch 151/387 ━━━━━━━━━━━━━━━━━━━━ 13:01:21\n",
      "Accuracy: 0.9978 - Precision: 0.8967 - Recall: 0.8910 - Specificity: 0.9990 - F1: 0.8867 - Loss: 0.1276\n",
      "\n",
      "Batch 152/387 ━━━━━━━━━━━━━━━━━━━━ 13:02:55\n",
      "Accuracy: 0.9978 - Precision: 0.8968 - Recall: 0.8916 - Specificity: 0.9990 - F1: 0.8871 - Loss: 0.1271\n",
      "\n",
      "Batch 153/387 ━━━━━━━━━━━━━━━━━━━━ 13:04:24\n",
      "Accuracy: 0.9978 - Precision: 0.8972 - Recall: 0.8911 - Specificity: 0.9990 - F1: 0.8871 - Loss: 0.1271\n",
      "\n",
      "Batch 154/387 ━━━━━━━━━━━━━━━━━━━━ 13:06:04\n",
      "Accuracy: 0.9978 - Precision: 0.8969 - Recall: 0.8915 - Specificity: 0.9990 - F1: 0.8871 - Loss: 0.1270\n",
      "\n",
      "Batch 155/387 ━━━━━━━━━━━━━━━━━━━━ 13:07:32\n",
      "Accuracy: 0.9978 - Precision: 0.8973 - Recall: 0.8917 - Specificity: 0.9990 - F1: 0.8875 - Loss: 0.1266\n",
      "\n",
      "Batch 156/387 ━━━━━━━━━━━━━━━━━━━━ 13:09:04\n",
      "Accuracy: 0.9978 - Precision: 0.8979 - Recall: 0.8920 - Specificity: 0.9990 - F1: 0.8879 - Loss: 0.1262\n",
      "\n",
      "Batch 157/387 ━━━━━━━━━━━━━━━━━━━━ 13:10:39\n",
      "Accuracy: 0.9978 - Precision: 0.8982 - Recall: 0.8923 - Specificity: 0.9990 - F1: 0.8883 - Loss: 0.1257\n",
      "\n",
      "Batch 158/387 ━━━━━━━━━━━━━━━━━━━━ 13:12:10\n",
      "Accuracy: 0.9978 - Precision: 0.8986 - Recall: 0.8926 - Specificity: 0.9990 - F1: 0.8887 - Loss: 0.1253\n",
      "\n",
      "Batch 159/387 ━━━━━━━━━━━━━━━━━━━━ 13:13:43\n",
      "Accuracy: 0.9978 - Precision: 0.8991 - Recall: 0.8928 - Specificity: 0.9990 - F1: 0.8891 - Loss: 0.1249\n",
      "\n",
      "Batch 160/387 ━━━━━━━━━━━━━━━━━━━━ 13:15:13\n",
      "Accuracy: 0.9978 - Precision: 0.8991 - Recall: 0.8921 - Specificity: 0.9990 - F1: 0.8888 - Loss: 0.1252\n",
      "\n",
      "Batch 161/387 ━━━━━━━━━━━━━━━━━━━━ 13:16:51\n",
      "Accuracy: 0.9978 - Precision: 0.8990 - Recall: 0.8925 - Specificity: 0.9990 - F1: 0.8890 - Loss: 0.1250\n",
      "\n",
      "Batch 162/387 ━━━━━━━━━━━━━━━━━━━━ 13:18:34\n",
      "Accuracy: 0.9978 - Precision: 0.8992 - Recall: 0.8929 - Specificity: 0.9990 - F1: 0.8893 - Loss: 0.1246\n",
      "\n",
      "Batch 163/387 ━━━━━━━━━━━━━━━━━━━━ 13:20:08\n",
      "Accuracy: 0.9978 - Precision: 0.8995 - Recall: 0.8933 - Specificity: 0.9990 - F1: 0.8897 - Loss: 0.1242\n",
      "\n",
      "Batch 164/387 ━━━━━━━━━━━━━━━━━━━━ 13:21:43\n",
      "Accuracy: 0.9978 - Precision: 0.8991 - Recall: 0.8931 - Specificity: 0.9990 - F1: 0.8894 - Loss: 0.1245\n",
      "\n",
      "Batch 165/387 ━━━━━━━━━━━━━━━━━━━━ 13:23:12\n",
      "Accuracy: 0.9978 - Precision: 0.8984 - Recall: 0.8937 - Specificity: 0.9990 - F1: 0.8893 - Loss: 0.1245\n",
      "\n",
      "Batch 166/387 ━━━━━━━━━━━━━━━━━━━━ 13:24:45\n",
      "Accuracy: 0.9978 - Precision: 0.8987 - Recall: 0.8941 - Specificity: 0.9990 - F1: 0.8897 - Loss: 0.1241\n",
      "\n",
      "Batch 167/387 ━━━━━━━━━━━━━━━━━━━━ 13:26:21\n",
      "Accuracy: 0.9978 - Precision: 0.8990 - Recall: 0.8937 - Specificity: 0.9990 - F1: 0.8897 - Loss: 0.1242\n",
      "\n",
      "Batch 168/387 ━━━━━━━━━━━━━━━━━━━━ 13:27:57\n",
      "Accuracy: 0.9978 - Precision: 0.8975 - Recall: 0.8940 - Specificity: 0.9990 - F1: 0.8889 - Loss: 0.1250\n",
      "\n",
      "Batch 169/387 ━━━━━━━━━━━━━━━━━━━━ 13:29:25\n",
      "Accuracy: 0.9978 - Precision: 0.8977 - Recall: 0.8939 - Specificity: 0.9990 - F1: 0.8890 - Loss: 0.1249\n",
      "\n",
      "Batch 170/387 ━━━━━━━━━━━━━━━━━━━━ 13:31:01\n",
      "Accuracy: 0.9978 - Precision: 0.8983 - Recall: 0.8927 - Specificity: 0.9990 - F1: 0.8886 - Loss: 0.1255\n",
      "\n",
      "Batch 171/387 ━━━━━━━━━━━━━━━━━━━━ 13:32:37\n",
      "Accuracy: 0.9978 - Precision: 0.8984 - Recall: 0.8930 - Specificity: 0.9990 - F1: 0.8888 - Loss: 0.1252\n",
      "\n",
      "Batch 172/387 ━━━━━━━━━━━━━━━━━━━━ 13:34:03\n",
      "Accuracy: 0.9978 - Precision: 0.8988 - Recall: 0.8932 - Specificity: 0.9990 - F1: 0.8892 - Loss: 0.1248\n",
      "\n",
      "Batch 173/387 ━━━━━━━━━━━━━━━━━━━━ 13:35:33\n",
      "Accuracy: 0.9978 - Precision: 0.8990 - Recall: 0.8934 - Specificity: 0.9990 - F1: 0.8894 - Loss: 0.1245\n",
      "\n",
      "Batch 174/387 ━━━━━━━━━━━━━━━━━━━━ 13:37:08\n",
      "Accuracy: 0.9978 - Precision: 0.8994 - Recall: 0.8936 - Specificity: 0.9990 - F1: 0.8897 - Loss: 0.1242\n",
      "\n",
      "Batch 175/387 ━━━━━━━━━━━━━━━━━━━━ 13:38:49\n",
      "Accuracy: 0.9978 - Precision: 0.8989 - Recall: 0.8940 - Specificity: 0.9990 - F1: 0.8897 - Loss: 0.1242\n",
      "\n",
      "Batch 176/387 ━━━━━━━━━━━━━━━━━━━━ 13:40:15\n",
      "Accuracy: 0.9978 - Precision: 0.8989 - Recall: 0.8945 - Specificity: 0.9990 - F1: 0.8900 - Loss: 0.1238\n",
      "\n",
      "Batch 177/387 ━━━━━━━━━━━━━━━━━━━━ 13:41:41\n",
      "Accuracy: 0.9978 - Precision: 0.8993 - Recall: 0.8948 - Specificity: 0.9990 - F1: 0.8903 - Loss: 0.1235\n",
      "\n",
      "Batch 178/387 ━━━━━━━━━━━━━━━━━━━━ 13:43:12\n",
      "Accuracy: 0.9978 - Precision: 0.8989 - Recall: 0.8929 - Specificity: 0.9990 - F1: 0.8891 - Loss: 0.1248\n",
      "\n",
      "Batch 179/387 ━━━━━━━━━━━━━━━━━━━━ 13:44:31\n",
      "Accuracy: 0.9978 - Precision: 0.8994 - Recall: 0.8925 - Specificity: 0.9990 - F1: 0.8892 - Loss: 0.1247\n",
      "\n",
      "Batch 180/387 ━━━━━━━━━━━━━━━━━━━━ 13:46:09\n",
      "Accuracy: 0.9978 - Precision: 0.8997 - Recall: 0.8923 - Specificity: 0.9990 - F1: 0.8892 - Loss: 0.1247\n",
      "\n",
      "Batch 181/387 ━━━━━━━━━━━━━━━━━━━━ 13:47:46\n",
      "Accuracy: 0.9978 - Precision: 0.9001 - Recall: 0.8923 - Specificity: 0.9990 - F1: 0.8895 - Loss: 0.1245\n",
      "\n",
      "Batch 182/387 ━━━━━━━━━━━━━━━━━━━━ 13:49:14\n",
      "Accuracy: 0.9978 - Precision: 0.8995 - Recall: 0.8925 - Specificity: 0.9990 - F1: 0.8893 - Loss: 0.1247\n",
      "\n",
      "Batch 183/387 ━━━━━━━━━━━━━━━━━━━━ 13:50:53\n",
      "Accuracy: 0.9978 - Precision: 0.8999 - Recall: 0.8926 - Specificity: 0.9990 - F1: 0.8896 - Loss: 0.1244\n",
      "\n",
      "Batch 184/387 ━━━━━━━━━━━━━━━━━━━━ 13:52:20\n",
      "Accuracy: 0.9978 - Precision: 0.8998 - Recall: 0.8921 - Specificity: 0.9990 - F1: 0.8893 - Loss: 0.1247\n",
      "\n",
      "Batch 185/387 ━━━━━━━━━━━━━━━━━━━━ 13:53:51\n",
      "Accuracy: 0.9978 - Precision: 0.8986 - Recall: 0.8911 - Specificity: 0.9990 - F1: 0.8882 - Loss: 0.1258\n",
      "\n",
      "Batch 186/387 ━━━━━━━━━━━━━━━━━━━━ 13:55:29\n",
      "Accuracy: 0.9978 - Precision: 0.8989 - Recall: 0.8911 - Specificity: 0.9990 - F1: 0.8884 - Loss: 0.1257\n",
      "\n",
      "Batch 187/387 ━━━━━━━━━━━━━━━━━━━━ 13:57:02\n",
      "Accuracy: 0.9978 - Precision: 0.8993 - Recall: 0.8914 - Specificity: 0.9990 - F1: 0.8887 - Loss: 0.1253\n",
      "\n",
      "Batch 188/387 ━━━━━━━━━━━━━━━━━━━━ 13:58:27\n",
      "Accuracy: 0.9978 - Precision: 0.8995 - Recall: 0.8919 - Specificity: 0.9990 - F1: 0.8891 - Loss: 0.1249\n",
      "\n",
      "Batch 189/387 ━━━━━━━━━━━━━━━━━━━━ 14:00:02\n",
      "Accuracy: 0.9978 - Precision: 0.8986 - Recall: 0.8923 - Specificity: 0.9990 - F1: 0.8889 - Loss: 0.1252\n",
      "\n",
      "Batch 190/387 ━━━━━━━━━━━━━━━━━━━━ 14:01:31\n",
      "Accuracy: 0.9978 - Precision: 0.8981 - Recall: 0.8922 - Specificity: 0.9990 - F1: 0.8886 - Loss: 0.1255\n",
      "\n",
      "Batch 191/387 ━━━━━━━━━━━━━━━━━━━━ 14:02:54\n",
      "Accuracy: 0.9978 - Precision: 0.8977 - Recall: 0.8924 - Specificity: 0.9990 - F1: 0.8885 - Loss: 0.1256\n",
      "\n",
      "Batch 192/387 ━━━━━━━━━━━━━━━━━━━━ 14:04:32\n",
      "Accuracy: 0.9978 - Precision: 0.8973 - Recall: 0.8928 - Specificity: 0.9990 - F1: 0.8885 - Loss: 0.1256\n",
      "\n",
      "Batch 193/387 ━━━━━━━━━━━━━━━━━━━━ 14:06:12\n",
      "Accuracy: 0.9978 - Precision: 0.8964 - Recall: 0.8928 - Specificity: 0.9990 - F1: 0.8880 - Loss: 0.1261\n",
      "\n",
      "Batch 194/387 ━━━━━━━━━━━━━━━━━━━━ 14:07:41\n",
      "Accuracy: 0.9978 - Precision: 0.8961 - Recall: 0.8933 - Specificity: 0.9990 - F1: 0.8881 - Loss: 0.1260\n",
      "\n",
      "Batch 195/387 ━━━━━━━━━━━━━━━━━━━━ 14:09:11\n",
      "Accuracy: 0.9977 - Precision: 0.8955 - Recall: 0.8935 - Specificity: 0.9990 - F1: 0.8880 - Loss: 0.1263\n",
      "\n",
      "Batch 196/387 ━━━━━━━━━━━━━━━━━━━━ 14:10:46\n",
      "Accuracy: 0.9978 - Precision: 0.8958 - Recall: 0.8934 - Specificity: 0.9990 - F1: 0.8881 - Loss: 0.1261\n",
      "\n",
      "Batch 197/387 ━━━━━━━━━━━━━━━━━━━━ 14:12:11\n",
      "Accuracy: 0.9977 - Precision: 0.8963 - Recall: 0.8927 - Specificity: 0.9990 - F1: 0.8879 - Loss: 0.1263\n",
      "\n",
      "Batch 198/387 ━━━━━━━━━━━━━━━━━━━━ 14:13:39\n",
      "Accuracy: 0.9978 - Precision: 0.8954 - Recall: 0.8928 - Specificity: 0.9990 - F1: 0.8874 - Loss: 0.1268\n",
      "\n",
      "Batch 199/387 ━━━━━━━━━━━━━━━━━━━━ 14:15:17\n",
      "Accuracy: 0.9978 - Precision: 0.8957 - Recall: 0.8919 - Specificity: 0.9990 - F1: 0.8871 - Loss: 0.1270\n",
      "\n",
      "Batch 200/387 ━━━━━━━━━━━━━━━━━━━━ 14:16:44\n",
      "Accuracy: 0.9978 - Precision: 0.8960 - Recall: 0.8917 - Specificity: 0.9990 - F1: 0.8872 - Loss: 0.1270\n",
      "\n",
      "Batch 201/387 ━━━━━━━━━━━━━━━━━━━━ 14:18:10\n",
      "Accuracy: 0.9978 - Precision: 0.8964 - Recall: 0.8918 - Specificity: 0.9990 - F1: 0.8875 - Loss: 0.1267\n",
      "\n",
      "Batch 202/387 ━━━━━━━━━━━━━━━━━━━━ 14:19:58\n",
      "Accuracy: 0.9978 - Precision: 0.8968 - Recall: 0.8909 - Specificity: 0.9990 - F1: 0.8871 - Loss: 0.1270\n",
      "\n",
      "Batch 203/387 ━━━━━━━━━━━━━━━━━━━━ 14:21:46\n",
      "Accuracy: 0.9978 - Precision: 0.8973 - Recall: 0.8904 - Specificity: 0.9990 - F1: 0.8871 - Loss: 0.1271\n",
      "\n",
      "Batch 204/387 ━━━━━━━━━━━━━━━━━━━━ 14:23:22\n",
      "Accuracy: 0.9977 - Precision: 0.8977 - Recall: 0.8902 - Specificity: 0.9990 - F1: 0.8872 - Loss: 0.1270\n",
      "\n",
      "Batch 205/387 ━━━━━━━━━━━━━━━━━━━━ 14:24:47\n",
      "Accuracy: 0.9978 - Precision: 0.8979 - Recall: 0.8904 - Specificity: 0.9990 - F1: 0.8874 - Loss: 0.1268\n",
      "\n",
      "Batch 206/387 ━━━━━━━━━━━━━━━━━━━━ 14:26:37\n",
      "Accuracy: 0.9978 - Precision: 0.8972 - Recall: 0.8908 - Specificity: 0.9990 - F1: 0.8873 - Loss: 0.1270\n",
      "\n",
      "Batch 207/387 ━━━━━━━━━━━━━━━━━━━━ 14:28:19\n",
      "Accuracy: 0.9978 - Precision: 0.8975 - Recall: 0.8910 - Specificity: 0.9990 - F1: 0.8875 - Loss: 0.1267\n",
      "\n",
      "Batch 208/387 ━━━━━━━━━━━━━━━━━━━━ 14:29:54\n",
      "Accuracy: 0.9978 - Precision: 0.8977 - Recall: 0.8911 - Specificity: 0.9990 - F1: 0.8877 - Loss: 0.1265\n",
      "\n",
      "Batch 209/387 ━━━━━━━━━━━━━━━━━━━━ 14:31:30\n",
      "Accuracy: 0.9978 - Precision: 0.8974 - Recall: 0.8912 - Specificity: 0.9990 - F1: 0.8876 - Loss: 0.1266\n",
      "\n",
      "Batch 210/387 ━━━━━━━━━━━━━━━━━━━━ 14:33:16\n",
      "Accuracy: 0.9978 - Precision: 0.8976 - Recall: 0.8910 - Specificity: 0.9990 - F1: 0.8876 - Loss: 0.1266\n",
      "\n",
      "Batch 211/387 ━━━━━━━━━━━━━━━━━━━━ 14:34:35\n",
      "Accuracy: 0.9977 - Precision: 0.8971 - Recall: 0.8909 - Specificity: 0.9990 - F1: 0.8874 - Loss: 0.1269\n",
      "\n",
      "Batch 212/387 ━━━━━━━━━━━━━━━━━━━━ 14:36:10\n",
      "Accuracy: 0.9978 - Precision: 0.8971 - Recall: 0.8913 - Specificity: 0.9990 - F1: 0.8876 - Loss: 0.1266\n",
      "\n",
      "Batch 213/387 ━━━━━━━━━━━━━━━━━━━━ 14:37:35\n",
      "Accuracy: 0.9978 - Precision: 0.8970 - Recall: 0.8915 - Specificity: 0.9990 - F1: 0.8877 - Loss: 0.1265\n",
      "\n",
      "Batch 214/387 ━━━━━━━━━━━━━━━━━━━━ 14:39:05\n",
      "Accuracy: 0.9978 - Precision: 0.8965 - Recall: 0.8917 - Specificity: 0.9990 - F1: 0.8876 - Loss: 0.1267\n",
      "\n",
      "Batch 215/387 ━━━━━━━━━━━━━━━━━━━━ 14:40:34\n",
      "Accuracy: 0.9977 - Precision: 0.8961 - Recall: 0.8911 - Specificity: 0.9990 - F1: 0.8871 - Loss: 0.1272\n",
      "\n",
      "Batch 216/387 ━━━━━━━━━━━━━━━━━━━━ 14:42:08\n",
      "Accuracy: 0.9977 - Precision: 0.8958 - Recall: 0.8914 - Specificity: 0.9990 - F1: 0.8871 - Loss: 0.1272\n",
      "\n",
      "Batch 217/387 ━━━━━━━━━━━━━━━━━━━━ 14:43:38\n",
      "Accuracy: 0.9978 - Precision: 0.8954 - Recall: 0.8912 - Specificity: 0.9990 - F1: 0.8868 - Loss: 0.1274\n",
      "\n",
      "Batch 218/387 ━━━━━━━━━━━━━━━━━━━━ 14:45:12\n",
      "Accuracy: 0.9978 - Precision: 0.8958 - Recall: 0.8913 - Specificity: 0.9990 - F1: 0.8871 - Loss: 0.1271\n",
      "\n",
      "Batch 219/387 ━━━━━━━━━━━━━━━━━━━━ 14:46:41\n",
      "Accuracy: 0.9978 - Precision: 0.8956 - Recall: 0.8916 - Specificity: 0.9990 - F1: 0.8871 - Loss: 0.1271\n",
      "\n",
      "Batch 220/387 ━━━━━━━━━━━━━━━━━━━━ 14:48:04\n",
      "Accuracy: 0.9978 - Precision: 0.8961 - Recall: 0.8913 - Specificity: 0.9990 - F1: 0.8872 - Loss: 0.1270\n",
      "\n",
      "Batch 221/387 ━━━━━━━━━━━━━━━━━━━━ 14:49:36\n",
      "Accuracy: 0.9978 - Precision: 0.8965 - Recall: 0.8907 - Specificity: 0.9990 - F1: 0.8871 - Loss: 0.1271\n",
      "\n",
      "Batch 222/387 ━━━━━━━━━━━━━━━━━━━━ 14:51:04\n",
      "Accuracy: 0.9978 - Precision: 0.8964 - Recall: 0.8907 - Specificity: 0.9990 - F1: 0.8871 - Loss: 0.1271\n",
      "\n",
      "Batch 223/387 ━━━━━━━━━━━━━━━━━━━━ 14:52:27\n",
      "Accuracy: 0.9978 - Precision: 0.8954 - Recall: 0.8903 - Specificity: 0.9990 - F1: 0.8864 - Loss: 0.1278\n",
      "\n",
      "Batch 224/387 ━━━━━━━━━━━━━━━━━━━━ 14:54:06\n",
      "Accuracy: 0.9978 - Precision: 0.8957 - Recall: 0.8905 - Specificity: 0.9990 - F1: 0.8866 - Loss: 0.1276\n",
      "\n",
      "Batch 225/387 ━━━━━━━━━━━━━━━━━━━━ 14:55:30\n",
      "Accuracy: 0.9978 - Precision: 0.8956 - Recall: 0.8899 - Specificity: 0.9990 - F1: 0.8863 - Loss: 0.1279\n",
      "\n",
      "Batch 226/387 ━━━━━━━━━━━━━━━━━━━━ 14:56:56\n",
      "Accuracy: 0.9978 - Precision: 0.8959 - Recall: 0.8891 - Specificity: 0.9990 - F1: 0.8860 - Loss: 0.1281\n",
      "\n",
      "Batch 227/387 ━━━━━━━━━━━━━━━━━━━━ 14:58:34\n",
      "Accuracy: 0.9978 - Precision: 0.8960 - Recall: 0.8888 - Specificity: 0.9990 - F1: 0.8859 - Loss: 0.1283\n",
      "\n",
      "Batch 228/387 ━━━━━━━━━━━━━━━━━━━━ 15:00:11\n",
      "Accuracy: 0.9978 - Precision: 0.8958 - Recall: 0.8891 - Specificity: 0.9990 - F1: 0.8860 - Loss: 0.1281\n",
      "\n",
      "Batch 229/387 ━━━━━━━━━━━━━━━━━━━━ 15:01:28\n",
      "Accuracy: 0.9978 - Precision: 0.8960 - Recall: 0.8881 - Specificity: 0.9990 - F1: 0.8855 - Loss: 0.1286\n",
      "\n",
      "Batch 230/387 ━━━━━━━━━━━━━━━━━━━━ 15:03:00\n",
      "Accuracy: 0.9978 - Precision: 0.8962 - Recall: 0.8885 - Specificity: 0.9990 - F1: 0.8858 - Loss: 0.1283\n",
      "\n",
      "Batch 231/387 ━━━━━━━━━━━━━━━━━━━━ 15:04:42\n",
      "Accuracy: 0.9978 - Precision: 0.8961 - Recall: 0.8887 - Specificity: 0.9990 - F1: 0.8859 - Loss: 0.1282\n",
      "\n",
      "Batch 232/387 ━━━━━━━━━━━━━━━━━━━━ 15:06:14\n",
      "Accuracy: 0.9978 - Precision: 0.8939 - Recall: 0.8882 - Specificity: 0.9990 - F1: 0.8843 - Loss: 0.1299\n",
      "\n",
      "Batch 233/387 ━━━━━━━━━━━━━━━━━━━━ 15:07:39\n",
      "Accuracy: 0.9978 - Precision: 0.8941 - Recall: 0.8885 - Specificity: 0.9990 - F1: 0.8846 - Loss: 0.1296\n",
      "\n",
      "Batch 234/387 ━━━━━━━━━━━━━━━━━━━━ 15:09:12\n",
      "Accuracy: 0.9978 - Precision: 0.8935 - Recall: 0.8889 - Specificity: 0.9990 - F1: 0.8844 - Loss: 0.1297\n",
      "\n",
      "Batch 235/387 ━━━━━━━━━━━━━━━━━━━━ 15:10:43\n",
      "Accuracy: 0.9978 - Precision: 0.8928 - Recall: 0.8874 - Specificity: 0.9990 - F1: 0.8833 - Loss: 0.1308\n",
      "\n",
      "Batch 236/387 ━━━━━━━━━━━━━━━━━━━━ 15:12:08\n",
      "Accuracy: 0.9978 - Precision: 0.8926 - Recall: 0.8877 - Specificity: 0.9990 - F1: 0.8834 - Loss: 0.1308\n",
      "\n",
      "Batch 237/387 ━━━━━━━━━━━━━━━━━━━━ 15:13:49\n",
      "Accuracy: 0.9978 - Precision: 0.8928 - Recall: 0.8876 - Specificity: 0.9990 - F1: 0.8835 - Loss: 0.1307\n",
      "\n",
      "Batch 238/387 ━━━━━━━━━━━━━━━━━━━━ 15:15:24\n",
      "Accuracy: 0.9978 - Precision: 0.8932 - Recall: 0.8870 - Specificity: 0.9990 - F1: 0.8833 - Loss: 0.1309\n",
      "\n",
      "Batch 239/387 ━━━━━━━━━━━━━━━━━━━━ 15:16:57\n",
      "Accuracy: 0.9977 - Precision: 0.8935 - Recall: 0.8865 - Specificity: 0.9990 - F1: 0.8832 - Loss: 0.1311\n",
      "\n",
      "Batch 240/387 ━━━━━━━━━━━━━━━━━━━━ 15:18:39\n",
      "Accuracy: 0.9978 - Precision: 0.8938 - Recall: 0.8868 - Specificity: 0.9990 - F1: 0.8835 - Loss: 0.1308\n",
      "\n",
      "Batch 241/387 ━━━━━━━━━━━━━━━━━━━━ 15:20:15\n",
      "Accuracy: 0.9978 - Precision: 0.8931 - Recall: 0.8872 - Specificity: 0.9990 - F1: 0.8833 - Loss: 0.1309\n",
      "\n",
      "Batch 242/387 ━━━━━━━━━━━━━━━━━━━━ 15:21:44\n",
      "Accuracy: 0.9978 - Precision: 0.8933 - Recall: 0.8872 - Specificity: 0.9990 - F1: 0.8835 - Loss: 0.1308\n",
      "\n",
      "Batch 243/387 ━━━━━━━━━━━━━━━━━━━━ 15:23:17\n",
      "Accuracy: 0.9978 - Precision: 0.8934 - Recall: 0.8874 - Specificity: 0.9990 - F1: 0.8836 - Loss: 0.1306\n",
      "\n",
      "Batch 244/387 ━━━━━━━━━━━━━━━━━━━━ 15:24:37\n",
      "Accuracy: 0.9978 - Precision: 0.8935 - Recall: 0.8876 - Specificity: 0.9990 - F1: 0.8838 - Loss: 0.1304\n",
      "\n",
      "Batch 245/387 ━━━━━━━━━━━━━━━━━━━━ 15:26:05\n",
      "Accuracy: 0.9978 - Precision: 0.8937 - Recall: 0.8873 - Specificity: 0.9990 - F1: 0.8838 - Loss: 0.1304\n",
      "\n",
      "Batch 246/387 ━━━━━━━━━━━━━━━━━━━━ 15:27:41\n",
      "Accuracy: 0.9978 - Precision: 0.8940 - Recall: 0.8873 - Specificity: 0.9990 - F1: 0.8839 - Loss: 0.1303\n",
      "\n",
      "Batch 247/387 ━━━━━━━━━━━━━━━━━━━━ 15:29:08\n",
      "Accuracy: 0.9978 - Precision: 0.8941 - Recall: 0.8871 - Specificity: 0.9990 - F1: 0.8839 - Loss: 0.1303\n",
      "\n",
      "Batch 248/387 ━━━━━━━━━━━━━━━━━━━━ 15:30:45\n",
      "Accuracy: 0.9978 - Precision: 0.8933 - Recall: 0.8872 - Specificity: 0.9990 - F1: 0.8835 - Loss: 0.1307\n",
      "\n",
      "Batch 249/387 ━━━━━━━━━━━━━━━━━━━━ 15:32:17\n",
      "Accuracy: 0.9978 - Precision: 0.8936 - Recall: 0.8869 - Specificity: 0.9990 - F1: 0.8835 - Loss: 0.1307\n",
      "\n",
      "Batch 250/387 ━━━━━━━━━━━━━━━━━━━━ 15:33:41\n",
      "Accuracy: 0.9978 - Precision: 0.8927 - Recall: 0.8872 - Specificity: 0.9990 - F1: 0.8831 - Loss: 0.1311\n",
      "\n",
      "Batch 251/387 ━━━━━━━━━━━━━━━━━━━━ 15:35:15\n",
      "Accuracy: 0.9978 - Precision: 0.8926 - Recall: 0.8875 - Specificity: 0.9990 - F1: 0.8832 - Loss: 0.1310\n",
      "\n",
      "Batch 252/387 ━━━━━━━━━━━━━━━━━━━━ 15:36:44\n",
      "Accuracy: 0.9978 - Precision: 0.8924 - Recall: 0.8877 - Specificity: 0.9990 - F1: 0.8832 - Loss: 0.1309\n",
      "\n",
      "Batch 253/387 ━━━━━━━━━━━━━━━━━━━━ 15:38:10\n",
      "Accuracy: 0.9978 - Precision: 0.8921 - Recall: 0.8879 - Specificity: 0.9990 - F1: 0.8832 - Loss: 0.1309\n",
      "\n",
      "Batch 254/387 ━━━━━━━━━━━━━━━━━━━━ 15:39:35\n",
      "Accuracy: 0.9978 - Precision: 0.8922 - Recall: 0.8875 - Specificity: 0.9990 - F1: 0.8831 - Loss: 0.1311\n",
      "\n",
      "Batch 255/387 ━━━━━━━━━━━━━━━━━━━━ 15:40:56\n",
      "Accuracy: 0.9978 - Precision: 0.8920 - Recall: 0.8875 - Specificity: 0.9990 - F1: 0.8830 - Loss: 0.1311\n",
      "\n",
      "Batch 256/387 ━━━━━━━━━━━━━━━━━━━━ 15:42:16\n",
      "Accuracy: 0.9978 - Precision: 0.8917 - Recall: 0.8874 - Specificity: 0.9990 - F1: 0.8828 - Loss: 0.1313\n",
      "\n",
      "Batch 257/387 ━━━━━━━━━━━━━━━━━━━━ 15:43:51\n",
      "Accuracy: 0.9978 - Precision: 0.8920 - Recall: 0.8871 - Specificity: 0.9990 - F1: 0.8828 - Loss: 0.1313\n",
      "\n",
      "Batch 258/387 ━━━━━━━━━━━━━━━━━━━━ 15:45:11\n",
      "Accuracy: 0.9978 - Precision: 0.8916 - Recall: 0.8875 - Specificity: 0.9990 - F1: 0.8828 - Loss: 0.1313\n",
      "\n",
      "Batch 259/387 ━━━━━━━━━━━━━━━━━━━━ 15:46:38\n",
      "Accuracy: 0.9978 - Precision: 0.8917 - Recall: 0.8876 - Specificity: 0.9990 - F1: 0.8830 - Loss: 0.1312\n",
      "\n",
      "Batch 260/387 ━━━━━━━━━━━━━━━━━━━━ 15:48:01\n",
      "Accuracy: 0.9978 - Precision: 0.8916 - Recall: 0.8868 - Specificity: 0.9990 - F1: 0.8825 - Loss: 0.1316\n",
      "\n",
      "Batch 261/387 ━━━━━━━━━━━━━━━━━━━━ 15:49:21\n",
      "Accuracy: 0.9978 - Precision: 0.8920 - Recall: 0.8862 - Specificity: 0.9990 - F1: 0.8823 - Loss: 0.1319\n",
      "\n",
      "Batch 262/387 ━━━━━━━━━━━━━━━━━━━━ 15:50:47\n",
      "Accuracy: 0.9978 - Precision: 0.8923 - Recall: 0.8865 - Specificity: 0.9990 - F1: 0.8827 - Loss: 0.1315\n",
      "\n",
      "Batch 263/387 ━━━━━━━━━━━━━━━━━━━━ 15:52:19\n",
      "Accuracy: 0.9978 - Precision: 0.8922 - Recall: 0.8868 - Specificity: 0.9990 - F1: 0.8828 - Loss: 0.1314\n",
      "\n",
      "Batch 264/387 ━━━━━━━━━━━━━━━━━━━━ 15:53:35\n",
      "Accuracy: 0.9978 - Precision: 0.8924 - Recall: 0.8869 - Specificity: 0.9990 - F1: 0.8830 - Loss: 0.1312\n",
      "\n",
      "Batch 265/387 ━━━━━━━━━━━━━━━━━━━━ 15:55:19\n",
      "Accuracy: 0.9978 - Precision: 0.8926 - Recall: 0.8873 - Specificity: 0.9990 - F1: 0.8833 - Loss: 0.1308\n",
      "\n",
      "Batch 266/387 ━━━━━━━━━━━━━━━━━━━━ 15:56:47\n",
      "Accuracy: 0.9978 - Precision: 0.8929 - Recall: 0.8872 - Specificity: 0.9990 - F1: 0.8834 - Loss: 0.1307\n",
      "\n",
      "Batch 267/387 ━━━━━━━━━━━━━━━━━━━━ 15:58:28\n",
      "Accuracy: 0.9978 - Precision: 0.8931 - Recall: 0.8872 - Specificity: 0.9990 - F1: 0.8835 - Loss: 0.1306\n",
      "\n",
      "Batch 268/387 ━━━━━━━━━━━━━━━━━━━━ 15:59:46\n",
      "Accuracy: 0.9978 - Precision: 0.8934 - Recall: 0.8874 - Specificity: 0.9990 - F1: 0.8838 - Loss: 0.1303\n",
      "\n",
      "Batch 269/387 ━━━━━━━━━━━━━━━━━━━━ 16:01:17\n",
      "Accuracy: 0.9978 - Precision: 0.8929 - Recall: 0.8873 - Specificity: 0.9990 - F1: 0.8835 - Loss: 0.1306\n",
      "\n",
      "Batch 270/387 ━━━━━━━━━━━━━━━━━━━━ 16:02:48\n",
      "Accuracy: 0.9978 - Precision: 0.8931 - Recall: 0.8873 - Specificity: 0.9990 - F1: 0.8837 - Loss: 0.1304\n",
      "\n",
      "Batch 271/387 ━━━━━━━━━━━━━━━━━━━━ 16:04:13\n",
      "Accuracy: 0.9978 - Precision: 0.8922 - Recall: 0.8877 - Specificity: 0.9990 - F1: 0.8833 - Loss: 0.1308\n",
      "\n",
      "Batch 272/387 ━━━━━━━━━━━━━━━━━━━━ 16:05:47\n",
      "Accuracy: 0.9978 - Precision: 0.8921 - Recall: 0.8880 - Specificity: 0.9990 - F1: 0.8834 - Loss: 0.1307\n",
      "\n",
      "Batch 273/387 ━━━━━━━━━━━━━━━━━━━━ 16:07:24\n",
      "Accuracy: 0.9978 - Precision: 0.8920 - Recall: 0.8882 - Specificity: 0.9990 - F1: 0.8835 - Loss: 0.1306\n",
      "\n",
      "Batch 274/387 ━━━━━━━━━━━━━━━━━━━━ 16:08:51\n",
      "Accuracy: 0.9978 - Precision: 0.8921 - Recall: 0.8878 - Specificity: 0.9990 - F1: 0.8833 - Loss: 0.1307\n",
      "\n",
      "Batch 275/387 ━━━━━━━━━━━━━━━━━━━━ 16:10:21\n",
      "Accuracy: 0.9978 - Precision: 0.8923 - Recall: 0.8881 - Specificity: 0.9990 - F1: 0.8836 - Loss: 0.1305\n",
      "\n",
      "Batch 276/387 ━━━━━━━━━━━━━━━━━━━━ 16:11:43\n",
      "Accuracy: 0.9978 - Precision: 0.8925 - Recall: 0.8881 - Specificity: 0.9990 - F1: 0.8837 - Loss: 0.1303\n",
      "\n",
      "Batch 277/387 ━━━━━━━━━━━━━━━━━━━━ 16:13:12\n",
      "Accuracy: 0.9978 - Precision: 0.8920 - Recall: 0.8877 - Specificity: 0.9990 - F1: 0.8833 - Loss: 0.1309\n",
      "\n",
      "Batch 278/387 ━━━━━━━━━━━━━━━━━━━━ 16:14:38\n",
      "Accuracy: 0.9978 - Precision: 0.8921 - Recall: 0.8875 - Specificity: 0.9990 - F1: 0.8832 - Loss: 0.1309\n",
      "\n",
      "Batch 279/387 ━━━━━━━━━━━━━━━━━━━━ 16:16:07\n",
      "Accuracy: 0.9978 - Precision: 0.8921 - Recall: 0.8878 - Specificity: 0.9990 - F1: 0.8834 - Loss: 0.1307\n",
      "\n",
      "Batch 280/387 ━━━━━━━━━━━━━━━━━━━━ 16:17:48\n",
      "Accuracy: 0.9978 - Precision: 0.8924 - Recall: 0.8879 - Specificity: 0.9990 - F1: 0.8836 - Loss: 0.1305\n",
      "\n",
      "Batch 281/387 ━━━━━━━━━━━━━━━━━━━━ 16:19:24\n",
      "Accuracy: 0.9978 - Precision: 0.8920 - Recall: 0.8881 - Specificity: 0.9990 - F1: 0.8835 - Loss: 0.1305\n",
      "\n",
      "Batch 282/387 ━━━━━━━━━━━━━━━━━━━━ 16:20:56\n",
      "Accuracy: 0.9978 - Precision: 0.8923 - Recall: 0.8881 - Specificity: 0.9990 - F1: 0.8837 - Loss: 0.1304\n",
      "\n",
      "Batch 283/387 ━━━━━━━━━━━━━━━━━━━━ 16:22:24\n",
      "Accuracy: 0.9978 - Precision: 0.8926 - Recall: 0.8877 - Specificity: 0.9990 - F1: 0.8836 - Loss: 0.1304\n",
      "\n",
      "Batch 284/387 ━━━━━━━━━━━━━━━━━━━━ 16:24:00\n",
      "Accuracy: 0.9978 - Precision: 0.8929 - Recall: 0.8873 - Specificity: 0.9990 - F1: 0.8836 - Loss: 0.1305\n",
      "\n",
      "Batch 285/387 ━━━━━━━━━━━━━━━━━━━━ 16:25:39\n",
      "Accuracy: 0.9978 - Precision: 0.8922 - Recall: 0.8871 - Specificity: 0.9990 - F1: 0.8831 - Loss: 0.1309\n",
      "\n",
      "Batch 286/387 ━━━━━━━━━━━━━━━━━━━━ 16:27:13\n",
      "Accuracy: 0.9978 - Precision: 0.8915 - Recall: 0.8871 - Specificity: 0.9990 - F1: 0.8827 - Loss: 0.1313\n",
      "\n",
      "Batch 287/387 ━━━━━━━━━━━━━━━━━━━━ 16:28:49\n",
      "Accuracy: 0.9978 - Precision: 0.8918 - Recall: 0.8865 - Specificity: 0.9990 - F1: 0.8825 - Loss: 0.1315\n",
      "\n",
      "Batch 288/387 ━━━━━━━━━━━━━━━━━━━━ 16:30:14\n",
      "Accuracy: 0.9978 - Precision: 0.8921 - Recall: 0.8862 - Specificity: 0.9990 - F1: 0.8825 - Loss: 0.1316\n",
      "\n",
      "Batch 289/387 ━━━━━━━━━━━━━━━━━━━━ 16:31:59\n",
      "Accuracy: 0.9978 - Precision: 0.8921 - Recall: 0.8860 - Specificity: 0.9990 - F1: 0.8824 - Loss: 0.1317\n",
      "\n",
      "Batch 290/387 ━━━━━━━━━━━━━━━━━━━━ 16:33:33\n",
      "Accuracy: 0.9978 - Precision: 0.8922 - Recall: 0.8858 - Specificity: 0.9990 - F1: 0.8824 - Loss: 0.1317\n",
      "\n",
      "Batch 291/387 ━━━━━━━━━━━━━━━━━━━━ 16:35:03\n",
      "Accuracy: 0.9978 - Precision: 0.8925 - Recall: 0.8857 - Specificity: 0.9990 - F1: 0.8825 - Loss: 0.1316\n",
      "\n",
      "Batch 292/387 ━━━━━━━━━━━━━━━━━━━━ 16:36:27\n",
      "Accuracy: 0.9978 - Precision: 0.8923 - Recall: 0.8859 - Specificity: 0.9990 - F1: 0.8825 - Loss: 0.1316\n",
      "\n",
      "Batch 293/387 ━━━━━━━━━━━━━━━━━━━━ 16:38:19\n",
      "Accuracy: 0.9978 - Precision: 0.8922 - Recall: 0.8860 - Specificity: 0.9990 - F1: 0.8826 - Loss: 0.1316\n",
      "\n",
      "Batch 294/387 ━━━━━━━━━━━━━━━━━━━━ 16:39:54\n",
      "Accuracy: 0.9978 - Precision: 0.8924 - Recall: 0.8862 - Specificity: 0.9990 - F1: 0.8828 - Loss: 0.1314\n",
      "\n",
      "Batch 295/387 ━━━━━━━━━━━━━━━━━━━━ 16:41:18\n",
      "Accuracy: 0.9978 - Precision: 0.8927 - Recall: 0.8864 - Specificity: 0.9990 - F1: 0.8830 - Loss: 0.1311\n",
      "\n",
      "Batch 296/387 ━━━━━━━━━━━━━━━━━━━━ 16:43:05\n",
      "Accuracy: 0.9978 - Precision: 0.8926 - Recall: 0.8865 - Specificity: 0.9990 - F1: 0.8831 - Loss: 0.1310\n",
      "\n",
      "Batch 297/387 ━━━━━━━━━━━━━━━━━━━━ 16:44:46\n",
      "Accuracy: 0.9978 - Precision: 0.8920 - Recall: 0.8869 - Specificity: 0.9990 - F1: 0.8829 - Loss: 0.1312\n",
      "\n",
      "Batch 298/387 ━━━━━━━━━━━━━━━━━━━━ 16:46:06\n",
      "Accuracy: 0.9978 - Precision: 0.8913 - Recall: 0.8869 - Specificity: 0.9990 - F1: 0.8825 - Loss: 0.1316\n",
      "\n",
      "Batch 299/387 ━━━━━━━━━━━━━━━━━━━━ 16:47:45\n",
      "Accuracy: 0.9978 - Precision: 0.8908 - Recall: 0.8870 - Specificity: 0.9990 - F1: 0.8823 - Loss: 0.1317\n",
      "\n",
      "Batch 300/387 ━━━━━━━━━━━━━━━━━━━━ 16:49:17\n",
      "Accuracy: 0.9978 - Precision: 0.8911 - Recall: 0.8870 - Specificity: 0.9990 - F1: 0.8825 - Loss: 0.1316\n",
      "\n",
      "Batch 301/387 ━━━━━━━━━━━━━━━━━━━━ 16:51:11\n",
      "Accuracy: 0.9978 - Precision: 0.8912 - Recall: 0.8872 - Specificity: 0.9990 - F1: 0.8827 - Loss: 0.1314\n",
      "\n",
      "Batch 302/387 ━━━━━━━━━━━━━━━━━━━━ 16:52:46\n",
      "Accuracy: 0.9978 - Precision: 0.8907 - Recall: 0.8876 - Specificity: 0.9990 - F1: 0.8826 - Loss: 0.1315\n",
      "\n",
      "Batch 303/387 ━━━━━━━━━━━━━━━━━━━━ 16:54:21\n",
      "Accuracy: 0.9978 - Precision: 0.8910 - Recall: 0.8876 - Specificity: 0.9990 - F1: 0.8828 - Loss: 0.1313\n",
      "\n",
      "Batch 304/387 ━━━━━━━━━━━━━━━━━━━━ 16:55:57\n",
      "Accuracy: 0.9978 - Precision: 0.8913 - Recall: 0.8877 - Specificity: 0.9990 - F1: 0.8829 - Loss: 0.1311\n",
      "\n",
      "Batch 305/387 ━━━━━━━━━━━━━━━━━━━━ 16:57:22\n",
      "Accuracy: 0.9978 - Precision: 0.8916 - Recall: 0.8873 - Specificity: 0.9990 - F1: 0.8829 - Loss: 0.1312\n",
      "\n",
      "Batch 306/387 ━━━━━━━━━━━━━━━━━━━━ 16:58:52\n",
      "Accuracy: 0.9978 - Precision: 0.8919 - Recall: 0.8873 - Specificity: 0.9990 - F1: 0.8831 - Loss: 0.1310\n",
      "\n",
      "Batch 307/387 ━━━━━━━━━━━━━━━━━━━━ 17:00:22\n",
      "Accuracy: 0.9978 - Precision: 0.8918 - Recall: 0.8873 - Specificity: 0.9990 - F1: 0.8830 - Loss: 0.1310\n",
      "\n",
      "Batch 308/387 ━━━━━━━━━━━━━━━━━━━━ 17:01:53\n",
      "Accuracy: 0.9978 - Precision: 0.8922 - Recall: 0.8873 - Specificity: 0.9990 - F1: 0.8832 - Loss: 0.1308\n",
      "\n",
      "Batch 309/387 ━━━━━━━━━━━━━━━━━━━━ 17:03:16\n",
      "Accuracy: 0.9978 - Precision: 0.8923 - Recall: 0.8870 - Specificity: 0.9990 - F1: 0.8831 - Loss: 0.1309\n",
      "\n",
      "Batch 310/387 ━━━━━━━━━━━━━━━━━━━━ 17:04:53\n",
      "Accuracy: 0.9978 - Precision: 0.8924 - Recall: 0.8872 - Specificity: 0.9990 - F1: 0.8833 - Loss: 0.1307\n",
      "\n",
      "Batch 311/387 ━━━━━━━━━━━━━━━━━━━━ 17:06:27\n",
      "Accuracy: 0.9978 - Precision: 0.8925 - Recall: 0.8866 - Specificity: 0.9990 - F1: 0.8830 - Loss: 0.1309\n",
      "\n",
      "Batch 312/387 ━━━━━━━━━━━━━━━━━━━━ 17:08:05\n",
      "Accuracy: 0.9978 - Precision: 0.8925 - Recall: 0.8868 - Specificity: 0.9990 - F1: 0.8831 - Loss: 0.1308\n",
      "\n",
      "Batch 313/387 ━━━━━━━━━━━━━━━━━━━━ 17:09:21\n",
      "Accuracy: 0.9978 - Precision: 0.8921 - Recall: 0.8863 - Specificity: 0.9990 - F1: 0.8827 - Loss: 0.1312\n",
      "\n",
      "Batch 314/387 ━━━━━━━━━━━━━━━━━━━━ 17:10:56\n",
      "Accuracy: 0.9978 - Precision: 0.8920 - Recall: 0.8864 - Specificity: 0.9990 - F1: 0.8827 - Loss: 0.1312\n",
      "\n",
      "Batch 315/387 ━━━━━━━━━━━━━━━━━━━━ 17:12:34\n",
      "Accuracy: 0.9978 - Precision: 0.8921 - Recall: 0.8864 - Specificity: 0.9990 - F1: 0.8828 - Loss: 0.1311\n",
      "\n",
      "Batch 316/387 ━━━━━━━━━━━━━━━━━━━━ 17:14:02\n",
      "Accuracy: 0.9978 - Precision: 0.8922 - Recall: 0.8865 - Specificity: 0.9990 - F1: 0.8829 - Loss: 0.1311\n",
      "\n",
      "Batch 317/387 ━━━━━━━━━━━━━━━━━━━━ 17:15:25\n",
      "Accuracy: 0.9978 - Precision: 0.8923 - Recall: 0.8867 - Specificity: 0.9990 - F1: 0.8831 - Loss: 0.1308\n",
      "\n",
      "Batch 318/387 ━━━━━━━━━━━━━━━━━━━━ 17:17:01\n",
      "Accuracy: 0.9978 - Precision: 0.8925 - Recall: 0.8869 - Specificity: 0.9990 - F1: 0.8833 - Loss: 0.1306\n",
      "\n",
      "Batch 319/387 ━━━━━━━━━━━━━━━━━━━━ 17:18:29\n",
      "Accuracy: 0.9978 - Precision: 0.8925 - Recall: 0.8873 - Specificity: 0.9990 - F1: 0.8835 - Loss: 0.1304\n",
      "\n",
      "Batch 320/387 ━━━━━━━━━━━━━━━━━━━━ 17:19:58\n",
      "Accuracy: 0.9978 - Precision: 0.8920 - Recall: 0.8875 - Specificity: 0.9990 - F1: 0.8833 - Loss: 0.1305\n",
      "\n",
      "Batch 321/387 ━━━━━━━━━━━━━━━━━━━━ 17:21:18\n",
      "Accuracy: 0.9978 - Precision: 0.8915 - Recall: 0.8877 - Specificity: 0.9990 - F1: 0.8832 - Loss: 0.1307\n",
      "\n",
      "Batch 322/387 ━━━━━━━━━━━━━━━━━━━━ 17:22:44\n",
      "Accuracy: 0.9978 - Precision: 0.8910 - Recall: 0.8878 - Specificity: 0.9990 - F1: 0.8830 - Loss: 0.1309\n",
      "\n",
      "Batch 323/387 ━━━━━━━━━━━━━━━━━━━━ 17:24:14\n",
      "Accuracy: 0.9978 - Precision: 0.8911 - Recall: 0.8880 - Specificity: 0.9990 - F1: 0.8831 - Loss: 0.1307\n",
      "\n",
      "Batch 324/387 ━━━━━━━━━━━━━━━━━━━━ 17:26:02\n",
      "Accuracy: 0.9978 - Precision: 0.8911 - Recall: 0.8878 - Specificity: 0.9990 - F1: 0.8830 - Loss: 0.1308\n",
      "\n",
      "Batch 325/387 ━━━━━━━━━━━━━━━━━━━━ 17:27:40\n",
      "Accuracy: 0.9978 - Precision: 0.8909 - Recall: 0.8881 - Specificity: 0.9990 - F1: 0.8831 - Loss: 0.1308\n",
      "\n",
      "Batch 326/387 ━━━━━━━━━━━━━━━━━━━━ 17:29:01\n",
      "Accuracy: 0.9978 - Precision: 0.8907 - Recall: 0.8875 - Specificity: 0.9990 - F1: 0.8827 - Loss: 0.1312\n",
      "\n",
      "Batch 327/387 ━━━━━━━━━━━━━━━━━━━━ 17:30:35\n",
      "Accuracy: 0.9978 - Precision: 0.8904 - Recall: 0.8871 - Specificity: 0.9990 - F1: 0.8824 - Loss: 0.1316\n",
      "\n",
      "Batch 328/387 ━━━━━━━━━━━━━━━━━━━━ 17:32:03\n",
      "Accuracy: 0.9978 - Precision: 0.8908 - Recall: 0.8866 - Specificity: 0.9990 - F1: 0.8823 - Loss: 0.1318\n",
      "\n",
      "Batch 329/387 ━━━━━━━━━━━━━━━━━━━━ 17:33:38\n",
      "Accuracy: 0.9978 - Precision: 0.8909 - Recall: 0.8866 - Specificity: 0.9990 - F1: 0.8824 - Loss: 0.1316\n",
      "\n",
      "Batch 330/387 ━━━━━━━━━━━━━━━━━━━━ 17:35:04\n",
      "Accuracy: 0.9978 - Precision: 0.8911 - Recall: 0.8866 - Specificity: 0.9990 - F1: 0.8825 - Loss: 0.1315\n",
      "\n",
      "Batch 331/387 ━━━━━━━━━━━━━━━━━━━━ 17:36:35\n",
      "Accuracy: 0.9978 - Precision: 0.8911 - Recall: 0.8867 - Specificity: 0.9990 - F1: 0.8825 - Loss: 0.1314\n",
      "\n",
      "Batch 332/387 ━━━━━━━━━━━━━━━━━━━━ 17:38:13\n",
      "Accuracy: 0.9978 - Precision: 0.8910 - Recall: 0.8870 - Specificity: 0.9990 - F1: 0.8826 - Loss: 0.1313\n",
      "\n",
      "Batch 333/387 ━━━━━━━━━━━━━━━━━━━━ 17:39:43\n",
      "Accuracy: 0.9978 - Precision: 0.8913 - Recall: 0.8871 - Specificity: 0.9990 - F1: 0.8828 - Loss: 0.1311\n",
      "\n",
      "Batch 334/387 ━━━━━━━━━━━━━━━━━━━━ 17:41:16\n",
      "Accuracy: 0.9978 - Precision: 0.8915 - Recall: 0.8872 - Specificity: 0.9990 - F1: 0.8830 - Loss: 0.1309\n",
      "\n",
      "Batch 335/387 ━━━━━━━━━━━━━━━━━━━━ 17:42:52\n",
      "Accuracy: 0.9978 - Precision: 0.8915 - Recall: 0.8874 - Specificity: 0.9990 - F1: 0.8831 - Loss: 0.1308\n",
      "\n",
      "Batch 336/387 ━━━━━━━━━━━━━━━━━━━━ 17:44:30\n",
      "Accuracy: 0.9978 - Precision: 0.8917 - Recall: 0.8876 - Specificity: 0.9990 - F1: 0.8833 - Loss: 0.1305\n",
      "\n",
      "Batch 337/387 ━━━━━━━━━━━━━━━━━━━━ 17:45:49\n",
      "Accuracy: 0.9978 - Precision: 0.8918 - Recall: 0.8878 - Specificity: 0.9990 - F1: 0.8835 - Loss: 0.1304\n",
      "\n",
      "Batch 338/387 ━━━━━━━━━━━━━━━━━━━━ 17:47:25\n",
      "Accuracy: 0.9978 - Precision: 0.8921 - Recall: 0.8869 - Specificity: 0.9990 - F1: 0.8831 - Loss: 0.1308\n",
      "\n",
      "Batch 339/387 ━━━━━━━━━━━━━━━━━━━━ 17:49:06\n",
      "Accuracy: 0.9978 - Precision: 0.8922 - Recall: 0.8869 - Specificity: 0.9990 - F1: 0.8831 - Loss: 0.1308\n",
      "\n",
      "Batch 340/387 ━━━━━━━━━━━━━━━━━━━━ 17:50:25\n",
      "Accuracy: 0.9978 - Precision: 0.8917 - Recall: 0.8871 - Specificity: 0.9990 - F1: 0.8830 - Loss: 0.1309\n",
      "\n",
      "Batch 341/387 ━━━━━━━━━━━━━━━━━━━━ 17:51:50\n",
      "Accuracy: 0.9978 - Precision: 0.8919 - Recall: 0.8871 - Specificity: 0.9990 - F1: 0.8831 - Loss: 0.1308\n",
      "\n",
      "Batch 342/387 ━━━━━━━━━━━━━━━━━━━━ 17:53:20\n",
      "Accuracy: 0.9978 - Precision: 0.8915 - Recall: 0.8872 - Specificity: 0.9990 - F1: 0.8829 - Loss: 0.1309\n",
      "\n",
      "Batch 343/387 ━━━━━━━━━━━━━━━━━━━━ 17:54:52\n",
      "Accuracy: 0.9978 - Precision: 0.8912 - Recall: 0.8874 - Specificity: 0.9990 - F1: 0.8829 - Loss: 0.1310\n",
      "\n",
      "Batch 344/387 ━━━━━━━━━━━━━━━━━━━━ 17:56:16\n",
      "Accuracy: 0.9978 - Precision: 0.8914 - Recall: 0.8871 - Specificity: 0.9990 - F1: 0.8828 - Loss: 0.1311\n",
      "\n",
      "Batch 345/387 ━━━━━━━━━━━━━━━━━━━━ 17:57:34\n",
      "Accuracy: 0.9978 - Precision: 0.8917 - Recall: 0.8870 - Specificity: 0.9990 - F1: 0.8829 - Loss: 0.1310\n",
      "\n",
      "Batch 346/387 ━━━━━━━━━━━━━━━━━━━━ 17:59:06\n",
      "Accuracy: 0.9978 - Precision: 0.8920 - Recall: 0.8871 - Specificity: 0.9990 - F1: 0.8831 - Loss: 0.1308\n",
      "\n",
      "Batch 347/387 ━━━━━━━━━━━━━━━━━━━━ 18:00:32\n",
      "Accuracy: 0.9978 - Precision: 0.8921 - Recall: 0.8872 - Specificity: 0.9990 - F1: 0.8832 - Loss: 0.1307\n",
      "\n",
      "Batch 348/387 ━━━━━━━━━━━━━━━━━━━━ 18:02:09\n",
      "Accuracy: 0.9978 - Precision: 0.8924 - Recall: 0.8864 - Specificity: 0.9990 - F1: 0.8829 - Loss: 0.1310\n",
      "\n",
      "Batch 349/387 ━━━━━━━━━━━━━━━━━━━━ 18:03:49\n",
      "Accuracy: 0.9978 - Precision: 0.8924 - Recall: 0.8866 - Specificity: 0.9990 - F1: 0.8831 - Loss: 0.1309\n",
      "\n",
      "Batch 350/387 ━━━━━━━━━━━━━━━━━━━━ 18:05:25\n",
      "Accuracy: 0.9978 - Precision: 0.8926 - Recall: 0.8866 - Specificity: 0.9990 - F1: 0.8832 - Loss: 0.1308\n",
      "\n",
      "Batch 351/387 ━━━━━━━━━━━━━━━━━━━━ 18:06:47\n",
      "Accuracy: 0.9978 - Precision: 0.8926 - Recall: 0.8866 - Specificity: 0.9990 - F1: 0.8832 - Loss: 0.1308\n",
      "\n",
      "Batch 352/387 ━━━━━━━━━━━━━━━━━━━━ 18:08:18\n",
      "Accuracy: 0.9978 - Precision: 0.8925 - Recall: 0.8868 - Specificity: 0.9990 - F1: 0.8833 - Loss: 0.1307\n",
      "\n",
      "Batch 353/387 ━━━━━━━━━━━━━━━━━━━━ 18:09:44\n",
      "Accuracy: 0.9978 - Precision: 0.8927 - Recall: 0.8868 - Specificity: 0.9990 - F1: 0.8834 - Loss: 0.1306\n",
      "\n",
      "Batch 354/387 ━━━━━━━━━━━━━━━━━━━━ 18:11:04\n",
      "Accuracy: 0.9978 - Precision: 0.8927 - Recall: 0.8871 - Specificity: 0.9990 - F1: 0.8835 - Loss: 0.1304\n",
      "\n",
      "Batch 355/387 ━━━━━━━━━━━━━━━━━━━━ 18:12:28\n",
      "Accuracy: 0.9978 - Precision: 0.8924 - Recall: 0.8873 - Specificity: 0.9990 - F1: 0.8834 - Loss: 0.1306\n",
      "\n",
      "Batch 356/387 ━━━━━━━━━━━━━━━━━━━━ 18:13:55\n",
      "Accuracy: 0.9978 - Precision: 0.8922 - Recall: 0.8875 - Specificity: 0.9990 - F1: 0.8834 - Loss: 0.1305\n",
      "\n",
      "Batch 357/387 ━━━━━━━━━━━━━━━━━━━━ 18:15:28\n",
      "Accuracy: 0.9978 - Precision: 0.8919 - Recall: 0.8866 - Specificity: 0.9990 - F1: 0.8828 - Loss: 0.1312\n",
      "\n",
      "Batch 358/387 ━━━━━━━━━━━━━━━━━━━━ 18:17:01\n",
      "Accuracy: 0.9978 - Precision: 0.8920 - Recall: 0.8866 - Specificity: 0.9990 - F1: 0.8829 - Loss: 0.1311\n",
      "\n",
      "Batch 359/387 ━━━━━━━━━━━━━━━━━━━━ 18:18:44\n",
      "Accuracy: 0.9978 - Precision: 0.8920 - Recall: 0.8867 - Specificity: 0.9990 - F1: 0.8829 - Loss: 0.1311\n",
      "\n",
      "Batch 360/387 ━━━━━━━━━━━━━━━━━━━━ 18:20:11\n",
      "Accuracy: 0.9978 - Precision: 0.8913 - Recall: 0.8865 - Specificity: 0.9990 - F1: 0.8825 - Loss: 0.1316\n",
      "\n",
      "Batch 361/387 ━━━━━━━━━━━━━━━━━━━━ 18:21:31\n",
      "Accuracy: 0.9978 - Precision: 0.8914 - Recall: 0.8861 - Specificity: 0.9990 - F1: 0.8823 - Loss: 0.1318\n",
      "\n",
      "Batch 362/387 ━━━━━━━━━━━━━━━━━━━━ 18:23:11\n",
      "Accuracy: 0.9978 - Precision: 0.8915 - Recall: 0.8859 - Specificity: 0.9990 - F1: 0.8823 - Loss: 0.1318\n",
      "\n",
      "Batch 363/387 ━━━━━━━━━━━━━━━━━━━━ 18:24:51\n",
      "Accuracy: 0.9978 - Precision: 0.8915 - Recall: 0.8861 - Specificity: 0.9990 - F1: 0.8824 - Loss: 0.1317\n",
      "\n",
      "Batch 364/387 ━━━━━━━━━━━━━━━━━━━━ 18:26:23\n",
      "Accuracy: 0.9978 - Precision: 0.8917 - Recall: 0.8863 - Specificity: 0.9990 - F1: 0.8826 - Loss: 0.1315\n",
      "\n",
      "Batch 365/387 ━━━━━━━━━━━━━━━━━━━━ 18:27:59\n",
      "Accuracy: 0.9978 - Precision: 0.8919 - Recall: 0.8863 - Specificity: 0.9990 - F1: 0.8827 - Loss: 0.1314\n",
      "\n",
      "Batch 366/387 ━━━━━━━━━━━━━━━━━━━━ 18:29:32\n",
      "Accuracy: 0.9978 - Precision: 0.8915 - Recall: 0.8863 - Specificity: 0.9990 - F1: 0.8825 - Loss: 0.1316\n",
      "\n",
      "Batch 367/387 ━━━━━━━━━━━━━━━━━━━━ 18:31:06\n",
      "Accuracy: 0.9978 - Precision: 0.8917 - Recall: 0.8864 - Specificity: 0.9990 - F1: 0.8827 - Loss: 0.1314\n",
      "\n",
      "Batch 368/387 ━━━━━━━━━━━━━━━━━━━━ 18:32:47\n",
      "Accuracy: 0.9978 - Precision: 0.8919 - Recall: 0.8859 - Specificity: 0.9990 - F1: 0.8825 - Loss: 0.1317\n",
      "\n",
      "Batch 369/387 ━━━━━━━━━━━━━━━━━━━━ 18:34:11\n",
      "Accuracy: 0.9978 - Precision: 0.8920 - Recall: 0.8854 - Specificity: 0.9990 - F1: 0.8823 - Loss: 0.1319\n",
      "\n",
      "Batch 370/387 ━━━━━━━━━━━━━━━━━━━━ 18:35:26\n",
      "Accuracy: 0.9978 - Precision: 0.8923 - Recall: 0.8850 - Specificity: 0.9990 - F1: 0.8821 - Loss: 0.1321\n",
      "\n",
      "Batch 371/387 ━━━━━━━━━━━━━━━━━━━━ 18:36:47\n",
      "Accuracy: 0.9978 - Precision: 0.8918 - Recall: 0.8847 - Specificity: 0.9990 - F1: 0.8818 - Loss: 0.1325\n",
      "\n",
      "Batch 372/387 ━━━━━━━━━━━━━━━━━━━━ 18:38:06\n",
      "Accuracy: 0.9978 - Precision: 0.8920 - Recall: 0.8849 - Specificity: 0.9990 - F1: 0.8820 - Loss: 0.1323\n",
      "\n",
      "Batch 373/387 ━━━━━━━━━━━━━━━━━━━━ 18:39:34\n",
      "Accuracy: 0.9978 - Precision: 0.8915 - Recall: 0.8849 - Specificity: 0.9990 - F1: 0.8817 - Loss: 0.1326\n",
      "\n",
      "Batch 374/387 ━━━━━━━━━━━━━━━━━━━━ 18:40:57\n",
      "Accuracy: 0.9978 - Precision: 0.8917 - Recall: 0.8850 - Specificity: 0.9990 - F1: 0.8819 - Loss: 0.1324\n",
      "\n",
      "Batch 375/387 ━━━━━━━━━━━━━━━━━━━━ 18:42:20\n",
      "Accuracy: 0.9978 - Precision: 0.8919 - Recall: 0.8850 - Specificity: 0.9990 - F1: 0.8820 - Loss: 0.1322\n",
      "\n",
      "Batch 376/387 ━━━━━━━━━━━━━━━━━━━━ 18:44:02\n",
      "Accuracy: 0.9978 - Precision: 0.8921 - Recall: 0.8852 - Specificity: 0.9990 - F1: 0.8822 - Loss: 0.1320\n",
      "\n",
      "Batch 377/387 ━━━━━━━━━━━━━━━━━━━━ 18:45:40\n",
      "Accuracy: 0.9978 - Precision: 0.8920 - Recall: 0.8852 - Specificity: 0.9990 - F1: 0.8822 - Loss: 0.1321\n",
      "\n",
      "Batch 378/387 ━━━━━━━━━━━━━━━━━━━━ 18:47:03\n",
      "Accuracy: 0.9978 - Precision: 0.8916 - Recall: 0.8854 - Specificity: 0.9990 - F1: 0.8821 - Loss: 0.1322\n",
      "\n",
      "Batch 379/387 ━━━━━━━━━━━━━━━━━━━━ 18:48:30\n",
      "Accuracy: 0.9978 - Precision: 0.8917 - Recall: 0.8855 - Specificity: 0.9990 - F1: 0.8822 - Loss: 0.1321\n",
      "\n",
      "Batch 380/387 ━━━━━━━━━━━━━━━━━━━━ 18:49:54\n",
      "Accuracy: 0.9977 - Precision: 0.8918 - Recall: 0.8852 - Specificity: 0.9990 - F1: 0.8820 - Loss: 0.1323\n",
      "\n",
      "Batch 381/387 ━━━━━━━━━━━━━━━━━━━━ 18:51:25\n",
      "Accuracy: 0.9977 - Precision: 0.8920 - Recall: 0.8832 - Specificity: 0.9990 - F1: 0.8804 - Loss: 0.1341\n",
      "\n",
      "Batch 382/387 ━━━━━━━━━━━━━━━━━━━━ 18:52:40\n",
      "Accuracy: 0.9977 - Precision: 0.8920 - Recall: 0.8835 - Specificity: 0.9990 - F1: 0.8805 - Loss: 0.1340\n",
      "\n",
      "Batch 383/387 ━━━━━━━━━━━━━━━━━━━━ 18:54:03\n",
      "Accuracy: 0.9977 - Precision: 0.8921 - Recall: 0.8833 - Specificity: 0.9990 - F1: 0.8805 - Loss: 0.1340\n",
      "\n",
      "Batch 384/387 ━━━━━━━━━━━━━━━━━━━━ 18:55:37\n",
      "Accuracy: 0.9977 - Precision: 0.8922 - Recall: 0.8836 - Specificity: 0.9990 - F1: 0.8807 - Loss: 0.1338\n",
      "\n",
      "Batch 385/387 ━━━━━━━━━━━━━━━━━━━━ 18:57:01\n",
      "Accuracy: 0.9977 - Precision: 0.8921 - Recall: 0.8838 - Specificity: 0.9990 - F1: 0.8808 - Loss: 0.1337\n",
      "\n",
      "Batch 386/387 ━━━━━━━━━━━━━━━━━━━━ 18:58:32\n",
      "Accuracy: 0.9977 - Precision: 0.8920 - Recall: 0.8841 - Specificity: 0.9990 - F1: 0.8808 - Loss: 0.1336\n",
      "\n",
      "Batch 387/387 ━━━━━━━━━━━━━━━━━━━━ 18:59:49\n",
      "Accuracy: 0.9977 - Precision: 0.8920 - Recall: 0.8843 - Specificity: 0.9990 - F1: 0.8810 - Loss: 0.1335\n",
      "\n",
      "End of Epoch 9\n",
      "\n",
      "Epoch 10/50\n",
      "Batch 1/387 ━━━━━━━━━━━━━━━━━━━━ 19:21:45\n",
      "Accuracy: 0.9950 - Precision: 0.7487 - Recall: 0.9739 - Specificity: 0.9953 - F1: 0.8465 - Loss: 0.1756\n",
      "\n",
      "Batch 2/387 ━━━━━━━━━━━━━━━━━━━━ 19:23:22\n",
      "Accuracy: 0.9934 - Precision: 0.7166 - Recall: 0.9312 - Specificity: 0.9944 - F1: 0.8099 - Loss: 0.2200\n",
      "\n",
      "Batch 3/387 ━━━━━━━━━━━━━━━━━━━━ 19:24:45\n",
      "Accuracy: 0.9944 - Precision: 0.7739 - Recall: 0.9352 - Specificity: 0.9954 - F1: 0.8450 - Loss: 0.1799\n",
      "\n",
      "Batch 4/387 ━━━━━━━━━━━━━━━━━━━━ 19:26:31\n",
      "Accuracy: 0.9955 - Precision: 0.8205 - Recall: 0.9472 - Specificity: 0.9964 - F1: 0.8766 - Loss: 0.1441\n",
      "\n",
      "Batch 5/387 ━━━━━━━━━━━━━━━━━━━━ 19:28:06\n",
      "Accuracy: 0.9953 - Precision: 0.7976 - Recall: 0.9491 - Specificity: 0.9961 - F1: 0.8638 - Loss: 0.1574\n",
      "\n",
      "Batch 6/387 ━━━━━━━━━━━━━━━━━━━━ 19:29:52\n",
      "Accuracy: 0.9955 - Precision: 0.7344 - Recall: 0.9487 - Specificity: 0.9962 - F1: 0.8165 - Loss: 0.2038\n",
      "\n",
      "Batch 7/387 ━━━━━━━━━━━━━━━━━━━━ 19:31:21\n",
      "Accuracy: 0.9953 - Precision: 0.6613 - Recall: 0.9374 - Specificity: 0.9959 - F1: 0.7505 - Loss: 0.2714\n",
      "\n",
      "Batch 8/387 ━━━━━━━━━━━━━━━━━━━━ 19:32:48\n",
      "Accuracy: 0.9956 - Precision: 0.6338 - Recall: 0.9302 - Specificity: 0.9962 - F1: 0.7302 - Loss: 0.2906\n",
      "\n",
      "Batch 9/387 ━━━━━━━━━━━━━━━━━━━━ 19:34:19\n",
      "Accuracy: 0.9960 - Precision: 0.6736 - Recall: 0.9251 - Specificity: 0.9966 - F1: 0.7529 - Loss: 0.2666\n",
      "\n",
      "Batch 10/387 ━━━━━━━━━━━━━━━━━━━━ 19:35:45\n",
      "Accuracy: 0.9957 - Precision: 0.7053 - Recall: 0.8987 - Specificity: 0.9969 - F1: 0.7570 - Loss: 0.2641\n",
      "\n",
      "Batch 11/387 ━━━━━━━━━━━━━━━━━━━━ 19:37:16\n",
      "Accuracy: 0.9956 - Precision: 0.7317 - Recall: 0.8761 - Specificity: 0.9972 - F1: 0.7596 - Loss: 0.2639\n",
      "\n",
      "Batch 12/387 ━━━━━━━━━━━━━━━━━━━━ 19:38:47\n",
      "Accuracy: 0.9957 - Precision: 0.7304 - Recall: 0.8826 - Specificity: 0.9972 - F1: 0.7645 - Loss: 0.2582\n",
      "\n",
      "Batch 13/387 ━━━━━━━━━━━━━━━━━━━━ 19:40:08\n",
      "Accuracy: 0.9959 - Precision: 0.7487 - Recall: 0.8766 - Specificity: 0.9974 - F1: 0.7733 - Loss: 0.2484\n",
      "\n",
      "Batch 14/387 ━━━━━━━━━━━━━━━━━━━━ 19:41:32\n",
      "Accuracy: 0.9961 - Precision: 0.7665 - Recall: 0.8764 - Specificity: 0.9976 - F1: 0.7847 - Loss: 0.2363\n",
      "\n",
      "Batch 15/387 ━━━━━━━━━━━━━━━━━━━━ 19:43:13\n",
      "Accuracy: 0.9961 - Precision: 0.7816 - Recall: 0.8668 - Specificity: 0.9977 - F1: 0.7885 - Loss: 0.2320\n",
      "\n",
      "Batch 16/387 ━━━━━━━━━━━━━━━━━━━━ 19:44:45\n",
      "Accuracy: 0.9963 - Precision: 0.7952 - Recall: 0.8410 - Specificity: 0.9979 - F1: 0.7782 - Loss: 0.2413\n",
      "\n",
      "Batch 17/387 ━━━━━━━━━━━━━━━━━━━━ 19:46:09\n",
      "Accuracy: 0.9964 - Precision: 0.7983 - Recall: 0.8334 - Specificity: 0.9980 - F1: 0.7780 - Loss: 0.2409\n",
      "\n",
      "Batch 18/387 ━━━━━━━━━━━━━━━━━━━━ 19:47:36\n",
      "Accuracy: 0.9965 - Precision: 0.8092 - Recall: 0.8345 - Specificity: 0.9981 - F1: 0.7858 - Loss: 0.2325\n",
      "\n",
      "Batch 19/387 ━━━━━━━━━━━━━━━━━━━━ 19:49:08\n",
      "Accuracy: 0.9965 - Precision: 0.8187 - Recall: 0.8286 - Specificity: 0.9982 - F1: 0.7884 - Loss: 0.2300\n",
      "\n",
      "Batch 20/387 ━━━━━━━━━━━━━━━━━━━━ 19:50:41\n",
      "Accuracy: 0.9966 - Precision: 0.8120 - Recall: 0.8313 - Specificity: 0.9982 - F1: 0.7875 - Loss: 0.2310\n",
      "\n",
      "Batch 21/387 ━━━━━━━━━━━━━━━━━━━━ 19:52:12\n",
      "Accuracy: 0.9966 - Precision: 0.8184 - Recall: 0.8288 - Specificity: 0.9983 - F1: 0.7907 - Loss: 0.2280\n",
      "\n",
      "Batch 22/387 ━━━━━━━━━━━━━━━━━━━━ 19:53:52\n",
      "Accuracy: 0.9966 - Precision: 0.8252 - Recall: 0.8328 - Specificity: 0.9983 - F1: 0.7976 - Loss: 0.2207\n",
      "\n",
      "Batch 23/387 ━━━━━━━━━━━━━━━━━━━━ 19:55:32\n",
      "Accuracy: 0.9967 - Precision: 0.8238 - Recall: 0.8398 - Specificity: 0.9983 - F1: 0.8012 - Loss: 0.2169\n",
      "\n",
      "Batch 24/387 ━━━━━━━━━━━━━━━━━━━━ 19:57:06\n",
      "Accuracy: 0.9967 - Precision: 0.8228 - Recall: 0.8323 - Specificity: 0.9983 - F1: 0.7980 - Loss: 0.2203\n",
      "\n",
      "Batch 25/387 ━━━━━━━━━━━━━━━━━━━━ 19:58:30\n",
      "Accuracy: 0.9968 - Precision: 0.8267 - Recall: 0.8355 - Specificity: 0.9984 - F1: 0.8028 - Loss: 0.2153\n",
      "\n",
      "Batch 26/387 ━━━━━━━━━━━━━━━━━━━━ 20:00:07\n",
      "Accuracy: 0.9968 - Precision: 0.8275 - Recall: 0.8383 - Specificity: 0.9984 - F1: 0.8056 - Loss: 0.2124\n",
      "\n",
      "Batch 27/387 ━━━━━━━━━━━━━━━━━━━━ 20:01:44\n",
      "Accuracy: 0.9969 - Precision: 0.8225 - Recall: 0.8437 - Specificity: 0.9984 - F1: 0.8059 - Loss: 0.2126\n",
      "\n",
      "Batch 28/387 ━━━━━━━━━━━━━━━━━━━━ 20:03:07\n",
      "Accuracy: 0.9970 - Precision: 0.8253 - Recall: 0.8480 - Specificity: 0.9984 - F1: 0.8103 - Loss: 0.2080\n",
      "\n",
      "Batch 29/387 ━━━━━━━━━━━━━━━━━━━━ 20:04:38\n",
      "Accuracy: 0.9970 - Precision: 0.8312 - Recall: 0.8489 - Specificity: 0.9985 - F1: 0.8145 - Loss: 0.2036\n",
      "\n",
      "Batch 30/387 ━━━━━━━━━━━━━━━━━━━━ 20:06:12\n",
      "Accuracy: 0.9970 - Precision: 0.8353 - Recall: 0.8494 - Specificity: 0.9985 - F1: 0.8176 - Loss: 0.2006\n",
      "\n",
      "Batch 31/387 ━━━━━━━━━━━━━━━━━━━━ 20:07:37\n",
      "Accuracy: 0.9970 - Precision: 0.8395 - Recall: 0.8524 - Specificity: 0.9985 - F1: 0.8220 - Loss: 0.1960\n",
      "\n",
      "Batch 32/387 ━━━━━━━━━━━━━━━━━━━━ 20:09:13\n",
      "Accuracy: 0.9970 - Precision: 0.8435 - Recall: 0.8510 - Specificity: 0.9986 - F1: 0.8238 - Loss: 0.1944\n",
      "\n",
      "Batch 33/387 ━━━━━━━━━━━━━━━━━━━━ 20:10:36\n",
      "Accuracy: 0.9969 - Precision: 0.8467 - Recall: 0.8518 - Specificity: 0.9986 - F1: 0.8265 - Loss: 0.1919\n",
      "\n",
      "Batch 34/387 ━━━━━━━━━━━━━━━━━━━━ 20:12:16\n",
      "Accuracy: 0.9970 - Precision: 0.8443 - Recall: 0.8519 - Specificity: 0.9986 - F1: 0.8259 - Loss: 0.1923\n",
      "\n",
      "Batch 35/387 ━━━━━━━━━━━━━━━━━━━━ 20:13:48\n",
      "Accuracy: 0.9970 - Precision: 0.8454 - Recall: 0.8539 - Specificity: 0.9986 - F1: 0.8281 - Loss: 0.1900\n",
      "\n",
      "Batch 36/387 ━━━━━━━━━━━━━━━━━━━━ 20:15:19\n",
      "Accuracy: 0.9970 - Precision: 0.8482 - Recall: 0.8539 - Specificity: 0.9986 - F1: 0.8301 - Loss: 0.1881\n",
      "\n",
      "Batch 37/387 ━━━━━━━━━━━━━━━━━━━━ 20:16:46\n",
      "Accuracy: 0.9970 - Precision: 0.8512 - Recall: 0.8547 - Specificity: 0.9986 - F1: 0.8325 - Loss: 0.1856\n",
      "\n",
      "Batch 38/387 ━━━━━━━━━━━━━━━━━━━━ 20:18:17\n",
      "Accuracy: 0.9970 - Precision: 0.8541 - Recall: 0.8519 - Specificity: 0.9987 - F1: 0.8327 - Loss: 0.1855\n",
      "\n",
      "Batch 39/387 ━━━━━━━━━━━━━━━━━━━━ 20:19:54\n",
      "Accuracy: 0.9970 - Precision: 0.8568 - Recall: 0.8531 - Specificity: 0.9987 - F1: 0.8351 - Loss: 0.1830\n",
      "\n",
      "Batch 40/387 ━━━━━━━━━━━━━━━━━━━━ 20:21:16\n",
      "Accuracy: 0.9971 - Precision: 0.8593 - Recall: 0.8559 - Specificity: 0.9987 - F1: 0.8383 - Loss: 0.1796\n",
      "\n",
      "Batch 41/387 ━━━━━━━━━━━━━━━━━━━━ 20:22:35\n",
      "Accuracy: 0.9971 - Precision: 0.8607 - Recall: 0.8518 - Specificity: 0.9987 - F1: 0.8370 - Loss: 0.1811\n",
      "\n",
      "Batch 42/387 ━━━━━━━━━━━━━━━━━━━━ 20:24:12\n",
      "Accuracy: 0.9971 - Precision: 0.8633 - Recall: 0.8494 - Specificity: 0.9987 - F1: 0.8373 - Loss: 0.1810\n",
      "\n",
      "Batch 43/387 ━━━━━━━━━━━━━━━━━━━━ 20:25:50\n",
      "Accuracy: 0.9971 - Precision: 0.8659 - Recall: 0.8504 - Specificity: 0.9988 - F1: 0.8395 - Loss: 0.1788\n",
      "\n",
      "Batch 44/387 ━━━━━━━━━━━━━━━━━━━━ 20:27:19\n",
      "Accuracy: 0.9971 - Precision: 0.8664 - Recall: 0.8504 - Specificity: 0.9988 - F1: 0.8401 - Loss: 0.1780\n",
      "\n",
      "Batch 45/387 ━━━━━━━━━━━━━━━━━━━━ 20:28:42\n",
      "Accuracy: 0.9971 - Precision: 0.8668 - Recall: 0.8531 - Specificity: 0.9988 - F1: 0.8420 - Loss: 0.1760\n",
      "\n",
      "Batch 46/387 ━━━━━━━━━━━━━━━━━━━━ 20:30:14\n",
      "Accuracy: 0.9971 - Precision: 0.8680 - Recall: 0.8552 - Specificity: 0.9987 - F1: 0.8441 - Loss: 0.1738\n",
      "\n",
      "Batch 47/387 ━━━━━━━━━━━━━━━━━━━━ 20:31:46\n",
      "Accuracy: 0.9969 - Precision: 0.8543 - Recall: 0.8581 - Specificity: 0.9985 - F1: 0.8339 - Loss: 0.1854\n",
      "\n",
      "Batch 48/387 ━━━━━━━━━━━━━━━━━━━━ 20:33:11\n",
      "Accuracy: 0.9969 - Precision: 0.8475 - Recall: 0.8608 - Specificity: 0.9985 - F1: 0.8309 - Loss: 0.1886\n",
      "\n",
      "Batch 49/387 ━━━━━━━━━━━━━━━━━━━━ 20:34:43\n",
      "Accuracy: 0.9970 - Precision: 0.8501 - Recall: 0.8631 - Specificity: 0.9985 - F1: 0.8337 - Loss: 0.1854\n",
      "\n",
      "Batch 50/387 ━━━━━━━━━━━━━━━━━━━━ 20:36:07\n",
      "Accuracy: 0.9970 - Precision: 0.8519 - Recall: 0.8639 - Specificity: 0.9985 - F1: 0.8355 - Loss: 0.1836\n",
      "\n",
      "Batch 51/387 ━━━━━━━━━━━━━━━━━━━━ 20:37:42\n",
      "Accuracy: 0.9970 - Precision: 0.8538 - Recall: 0.8652 - Specificity: 0.9985 - F1: 0.8375 - Loss: 0.1813\n",
      "\n",
      "Batch 52/387 ━━━━━━━━━━━━━━━━━━━━ 20:39:00\n",
      "Accuracy: 0.9971 - Precision: 0.8559 - Recall: 0.8662 - Specificity: 0.9986 - F1: 0.8395 - Loss: 0.1792\n",
      "\n",
      "Batch 53/387 ━━━━━━━━━━━━━━━━━━━━ 20:40:40\n",
      "Accuracy: 0.9971 - Precision: 0.8563 - Recall: 0.8674 - Specificity: 0.9986 - F1: 0.8407 - Loss: 0.1778\n",
      "\n",
      "Batch 54/387 ━━━━━━━━━━━━━━━━━━━━ 20:42:09\n",
      "Accuracy: 0.9971 - Precision: 0.8567 - Recall: 0.8665 - Specificity: 0.9986 - F1: 0.8408 - Loss: 0.1776\n",
      "\n",
      "Batch 55/387 ━━━━━━━━━━━━━━━━━━━━ 20:43:41\n",
      "Accuracy: 0.9972 - Precision: 0.8570 - Recall: 0.8656 - Specificity: 0.9986 - F1: 0.8409 - Loss: 0.1774\n",
      "\n",
      "Batch 56/387 ━━━━━━━━━━━━━━━━━━━━ 20:45:19\n",
      "Accuracy: 0.9972 - Precision: 0.8575 - Recall: 0.8655 - Specificity: 0.9986 - F1: 0.8414 - Loss: 0.1768\n",
      "\n",
      "Batch 57/387 ━━━━━━━━━━━━━━━━━━━━ 20:46:57\n",
      "Accuracy: 0.9972 - Precision: 0.8586 - Recall: 0.8656 - Specificity: 0.9986 - F1: 0.8424 - Loss: 0.1756\n",
      "\n",
      "Batch 58/387 ━━━━━━━━━━━━━━━━━━━━ 20:48:35\n",
      "Accuracy: 0.9972 - Precision: 0.8566 - Recall: 0.8668 - Specificity: 0.9986 - F1: 0.8421 - Loss: 0.1758\n",
      "\n",
      "Batch 59/387 ━━━━━━━━━━━━━━━━━━━━ 20:49:47\n",
      "Accuracy: 0.9973 - Precision: 0.8576 - Recall: 0.8647 - Specificity: 0.9987 - F1: 0.8418 - Loss: 0.1761\n",
      "\n",
      "Batch 60/387 ━━━━━━━━━━━━━━━━━━━━ 20:51:24\n",
      "Accuracy: 0.9972 - Precision: 0.8535 - Recall: 0.8651 - Specificity: 0.9986 - F1: 0.8398 - Loss: 0.1782\n",
      "\n",
      "Batch 61/387 ━━━━━━━━━━━━━━━━━━━━ 20:52:56\n",
      "Accuracy: 0.9972 - Precision: 0.8554 - Recall: 0.8646 - Specificity: 0.9986 - F1: 0.8408 - Loss: 0.1772\n",
      "\n",
      "Batch 62/387 ━━━━━━━━━━━━━━━━━━━━ 20:54:26\n",
      "Accuracy: 0.9973 - Precision: 0.8575 - Recall: 0.8656 - Specificity: 0.9987 - F1: 0.8426 - Loss: 0.1753\n",
      "\n",
      "Batch 63/387 ━━━━━━━━━━━━━━━━━━━━ 20:56:03\n",
      "Accuracy: 0.9973 - Precision: 0.8590 - Recall: 0.8669 - Specificity: 0.9987 - F1: 0.8443 - Loss: 0.1734\n",
      "\n",
      "Batch 64/387 ━━━━━━━━━━━━━━━━━━━━ 20:57:45\n",
      "Accuracy: 0.9973 - Precision: 0.8608 - Recall: 0.8675 - Specificity: 0.9987 - F1: 0.8458 - Loss: 0.1718\n",
      "\n",
      "Batch 65/387 ━━━━━━━━━━━━━━━━━━━━ 20:59:12\n",
      "Accuracy: 0.9973 - Precision: 0.8622 - Recall: 0.8686 - Specificity: 0.9987 - F1: 0.8473 - Loss: 0.1701\n",
      "\n",
      "Batch 66/387 ━━━━━━━━━━━━━━━━━━━━ 21:00:44\n",
      "Accuracy: 0.9973 - Precision: 0.8642 - Recall: 0.8663 - Specificity: 0.9987 - F1: 0.8471 - Loss: 0.1704\n",
      "\n",
      "Batch 67/387 ━━━━━━━━━━━━━━━━━━━━ 21:02:19\n",
      "Accuracy: 0.9973 - Precision: 0.8652 - Recall: 0.8661 - Specificity: 0.9987 - F1: 0.8477 - Loss: 0.1697\n",
      "\n",
      "Batch 68/387 ━━━━━━━━━━━━━━━━━━━━ 21:03:51\n",
      "Accuracy: 0.9972 - Precision: 0.8655 - Recall: 0.8627 - Specificity: 0.9987 - F1: 0.8461 - Loss: 0.1720\n",
      "\n",
      "Batch 69/387 ━━━━━━━━━━━━━━━━━━━━ 21:05:13\n",
      "Accuracy: 0.9973 - Precision: 0.8636 - Recall: 0.8633 - Specificity: 0.9987 - F1: 0.8457 - Loss: 0.1725\n",
      "\n",
      "Batch 70/387 ━━━━━━━━━━━━━━━━━━━━ 21:06:39\n",
      "Accuracy: 0.9973 - Precision: 0.8645 - Recall: 0.8641 - Specificity: 0.9987 - F1: 0.8467 - Loss: 0.1713\n",
      "\n",
      "Batch 71/387 ━━━━━━━━━━━━━━━━━━━━ 21:08:17\n",
      "Accuracy: 0.9972 - Precision: 0.8662 - Recall: 0.8627 - Specificity: 0.9987 - F1: 0.8469 - Loss: 0.1712\n",
      "\n",
      "Batch 72/387 ━━━━━━━━━━━━━━━━━━━━ 21:09:47\n",
      "Accuracy: 0.9973 - Precision: 0.8623 - Recall: 0.8644 - Specificity: 0.9987 - F1: 0.8454 - Loss: 0.1727\n",
      "\n",
      "Batch 73/387 ━━━━━━━━━━━━━━━━━━━━ 21:11:12\n",
      "Accuracy: 0.9973 - Precision: 0.8620 - Recall: 0.8661 - Specificity: 0.9987 - F1: 0.8462 - Loss: 0.1718\n",
      "\n",
      "Batch 74/387 ━━━━━━━━━━━━━━━━━━━━ 21:12:41\n",
      "Accuracy: 0.9973 - Precision: 0.8630 - Recall: 0.8674 - Specificity: 0.9987 - F1: 0.8476 - Loss: 0.1704\n",
      "\n",
      "Batch 75/387 ━━━━━━━━━━━━━━━━━━━━ 21:14:16\n",
      "Accuracy: 0.9973 - Precision: 0.8630 - Recall: 0.8675 - Specificity: 0.9987 - F1: 0.8479 - Loss: 0.1701\n",
      "\n",
      "Batch 76/387 ━━━━━━━━━━━━━━━━━━━━ 21:15:54\n",
      "Accuracy: 0.9972 - Precision: 0.8612 - Recall: 0.8689 - Specificity: 0.9987 - F1: 0.8477 - Loss: 0.1704\n",
      "\n",
      "Batch 77/387 ━━━━━━━━━━━━━━━━━━━━ 21:17:17\n",
      "Accuracy: 0.9972 - Precision: 0.8593 - Recall: 0.8703 - Specificity: 0.9986 - F1: 0.8474 - Loss: 0.1708\n",
      "\n",
      "Batch 78/387 ━━━━━━━━━━━━━━━━━━━━ 21:18:50\n",
      "Accuracy: 0.9972 - Precision: 0.8590 - Recall: 0.8706 - Specificity: 0.9986 - F1: 0.8476 - Loss: 0.1706\n",
      "\n",
      "Batch 79/387 ━━━━━━━━━━━━━━━━━━━━ 21:20:15\n",
      "Accuracy: 0.9972 - Precision: 0.8602 - Recall: 0.8713 - Specificity: 0.9986 - F1: 0.8488 - Loss: 0.1694\n",
      "\n",
      "Batch 80/387 ━━━━━━━━━━━━━━━━━━━━ 21:21:39\n",
      "Accuracy: 0.9971 - Precision: 0.8532 - Recall: 0.8704 - Specificity: 0.9985 - F1: 0.8437 - Loss: 0.1749\n",
      "\n",
      "Batch 81/387 ━━━━━━━━━━━━━━━━━━━━ 21:23:06\n",
      "Accuracy: 0.9971 - Precision: 0.8546 - Recall: 0.8708 - Specificity: 0.9985 - F1: 0.8448 - Loss: 0.1736\n",
      "\n",
      "Batch 82/387 ━━━━━━━━━━━━━━━━━━━━ 21:24:38\n",
      "Accuracy: 0.9971 - Precision: 0.8516 - Recall: 0.8706 - Specificity: 0.9985 - F1: 0.8432 - Loss: 0.1753\n",
      "\n",
      "Batch 83/387 ━━━━━━━━━━━━━━━━━━━━ 21:26:14\n",
      "Accuracy: 0.9971 - Precision: 0.8531 - Recall: 0.8696 - Specificity: 0.9985 - F1: 0.8435 - Loss: 0.1750\n",
      "\n",
      "Batch 84/387 ━━━━━━━━━━━━━━━━━━━━ 21:27:53\n",
      "Accuracy: 0.9971 - Precision: 0.8545 - Recall: 0.8693 - Specificity: 0.9986 - F1: 0.8442 - Loss: 0.1744\n",
      "\n",
      "Batch 85/387 ━━━━━━━━━━━━━━━━━━━━ 21:29:29\n",
      "Accuracy: 0.9971 - Precision: 0.8559 - Recall: 0.8695 - Specificity: 0.9986 - F1: 0.8452 - Loss: 0.1733\n",
      "\n",
      "Batch 86/387 ━━━━━━━━━━━━━━━━━━━━ 21:31:00\n",
      "Accuracy: 0.9971 - Precision: 0.8561 - Recall: 0.8704 - Specificity: 0.9986 - F1: 0.8460 - Loss: 0.1724\n",
      "\n",
      "Batch 87/387 ━━━━━━━━━━━━━━━━━━━━ 21:32:20\n",
      "Accuracy: 0.9972 - Precision: 0.8577 - Recall: 0.8693 - Specificity: 0.9986 - F1: 0.8462 - Loss: 0.1721\n",
      "\n",
      "Batch 88/387 ━━━━━━━━━━━━━━━━━━━━ 21:33:47\n",
      "Accuracy: 0.9972 - Precision: 0.8587 - Recall: 0.8677 - Specificity: 0.9986 - F1: 0.8460 - Loss: 0.1722\n",
      "\n",
      "Batch 89/387 ━━━━━━━━━━━━━━━━━━━━ 21:35:12\n",
      "Accuracy: 0.9972 - Precision: 0.8592 - Recall: 0.8684 - Specificity: 0.9986 - F1: 0.8468 - Loss: 0.1713\n",
      "\n",
      "Batch 90/387 ━━━━━━━━━━━━━━━━━━━━ 21:36:46\n",
      "Accuracy: 0.9972 - Precision: 0.8603 - Recall: 0.8670 - Specificity: 0.9986 - F1: 0.8467 - Loss: 0.1714\n",
      "\n",
      "Batch 91/387 ━━━━━━━━━━━━━━━━━━━━ 21:38:08\n",
      "Accuracy: 0.9972 - Precision: 0.8610 - Recall: 0.8674 - Specificity: 0.9986 - F1: 0.8474 - Loss: 0.1706\n",
      "\n",
      "Batch 92/387 ━━━━━━━━━━━━━━━━━━━━ 21:39:34\n",
      "Accuracy: 0.9972 - Precision: 0.8611 - Recall: 0.8684 - Specificity: 0.9986 - F1: 0.8481 - Loss: 0.1699\n",
      "\n",
      "Batch 93/387 ━━━━━━━━━━━━━━━━━━━━ 21:41:05\n",
      "Accuracy: 0.9972 - Precision: 0.8622 - Recall: 0.8692 - Specificity: 0.9986 - F1: 0.8492 - Loss: 0.1686\n",
      "\n",
      "Batch 94/387 ━━━━━━━━━━━━━━━━━━━━ 21:42:36\n",
      "Accuracy: 0.9972 - Precision: 0.8631 - Recall: 0.8699 - Specificity: 0.9986 - F1: 0.8502 - Loss: 0.1676\n",
      "\n",
      "Batch 95/387 ━━━━━━━━━━━━━━━━━━━━ 21:44:01\n",
      "Accuracy: 0.9973 - Precision: 0.8638 - Recall: 0.8698 - Specificity: 0.9986 - F1: 0.8507 - Loss: 0.1671\n",
      "\n",
      "Batch 96/387 ━━━━━━━━━━━━━━━━━━━━ 21:45:31\n",
      "Accuracy: 0.9973 - Precision: 0.8646 - Recall: 0.8707 - Specificity: 0.9987 - F1: 0.8517 - Loss: 0.1660\n",
      "\n",
      "Batch 97/387 ━━━━━━━━━━━━━━━━━━━━ 21:47:07\n",
      "Accuracy: 0.9973 - Precision: 0.8639 - Recall: 0.8714 - Specificity: 0.9987 - F1: 0.8517 - Loss: 0.1658\n",
      "\n",
      "Batch 98/387 ━━━━━━━━━━━━━━━━━━━━ 21:48:40\n",
      "Accuracy: 0.9973 - Precision: 0.8647 - Recall: 0.8713 - Specificity: 0.9987 - F1: 0.8523 - Loss: 0.1653\n",
      "\n",
      "Batch 99/387 ━━━━━━━━━━━━━━━━━━━━ 21:50:07\n",
      "Accuracy: 0.9973 - Precision: 0.8659 - Recall: 0.8718 - Specificity: 0.9987 - F1: 0.8533 - Loss: 0.1642\n",
      "\n",
      "Batch 100/387 ━━━━━━━━━━━━━━━━━━━━ 21:51:35\n",
      "Accuracy: 0.9973 - Precision: 0.8651 - Recall: 0.8722 - Specificity: 0.9987 - F1: 0.8532 - Loss: 0.1643\n",
      "\n",
      "Batch 101/387 ━━━━━━━━━━━━━━━━━━━━ 21:53:07\n",
      "Accuracy: 0.9973 - Precision: 0.8654 - Recall: 0.8733 - Specificity: 0.9987 - F1: 0.8540 - Loss: 0.1634\n",
      "\n",
      "Batch 102/387 ━━━━━━━━━━━━━━━━━━━━ 21:54:31\n",
      "Accuracy: 0.9972 - Precision: 0.8640 - Recall: 0.8713 - Specificity: 0.9986 - F1: 0.8525 - Loss: 0.1654\n",
      "\n",
      "Batch 103/387 ━━━━━━━━━━━━━━━━━━━━ 21:56:02\n",
      "Accuracy: 0.9972 - Precision: 0.8581 - Recall: 0.8720 - Specificity: 0.9986 - F1: 0.8481 - Loss: 0.1699\n",
      "\n",
      "Batch 104/387 ━━━━━━━━━━━━━━━━━━━━ 21:57:38\n",
      "Accuracy: 0.9972 - Precision: 0.8592 - Recall: 0.8718 - Specificity: 0.9986 - F1: 0.8487 - Loss: 0.1693\n",
      "\n",
      "Batch 105/387 ━━━━━━━━━━━━━━━━━━━━ 21:59:14\n",
      "Accuracy: 0.9972 - Precision: 0.8603 - Recall: 0.8712 - Specificity: 0.9986 - F1: 0.8490 - Loss: 0.1691\n",
      "\n",
      "Batch 106/387 ━━━━━━━━━━━━━━━━━━━━ 22:00:54\n",
      "Accuracy: 0.9972 - Precision: 0.8597 - Recall: 0.8724 - Specificity: 0.9986 - F1: 0.8494 - Loss: 0.1687\n",
      "\n",
      "Batch 107/387 ━━━━━━━━━━━━━━━━━━━━ 22:02:17\n",
      "Accuracy: 0.9972 - Precision: 0.8602 - Recall: 0.8732 - Specificity: 0.9986 - F1: 0.8501 - Loss: 0.1678\n",
      "\n",
      "Batch 108/387 ━━━━━━━━━━━━━━━━━━━━ 22:03:58\n",
      "Accuracy: 0.9972 - Precision: 0.8614 - Recall: 0.8729 - Specificity: 0.9987 - F1: 0.8507 - Loss: 0.1674\n",
      "\n",
      "Batch 109/387 ━━━━━━━━━━━━━━━━━━━━ 22:05:37\n",
      "Accuracy: 0.9972 - Precision: 0.8622 - Recall: 0.8732 - Specificity: 0.9987 - F1: 0.8514 - Loss: 0.1666\n",
      "\n",
      "Batch 110/387 ━━━━━━━━━━━━━━━━━━━━ 22:07:09\n",
      "Accuracy: 0.9972 - Precision: 0.8631 - Recall: 0.8733 - Specificity: 0.9987 - F1: 0.8521 - Loss: 0.1659\n",
      "\n",
      "Batch 111/387 ━━━━━━━━━━━━━━━━━━━━ 22:08:27\n",
      "Accuracy: 0.9972 - Precision: 0.8633 - Recall: 0.8743 - Specificity: 0.9987 - F1: 0.8528 - Loss: 0.1650\n",
      "\n",
      "Batch 112/387 ━━━━━━━━━━━━━━━━━━━━ 22:09:59\n",
      "Accuracy: 0.9972 - Precision: 0.8643 - Recall: 0.8735 - Specificity: 0.9987 - F1: 0.8529 - Loss: 0.1650\n",
      "\n",
      "Batch 113/387 ━━━━━━━━━━━━━━━━━━━━ 22:11:46\n",
      "Accuracy: 0.9972 - Precision: 0.8650 - Recall: 0.8739 - Specificity: 0.9987 - F1: 0.8536 - Loss: 0.1643\n",
      "\n",
      "Batch 114/387 ━━━━━━━━━━━━━━━━━━━━ 22:13:20\n",
      "Accuracy: 0.9972 - Precision: 0.8659 - Recall: 0.8746 - Specificity: 0.9987 - F1: 0.8546 - Loss: 0.1633\n",
      "\n",
      "Batch 115/387 ━━━━━━━━━━━━━━━━━━━━ 22:14:58\n",
      "Accuracy: 0.9972 - Precision: 0.8664 - Recall: 0.8750 - Specificity: 0.9987 - F1: 0.8551 - Loss: 0.1628\n",
      "\n",
      "Batch 116/387 ━━━━━━━━━━━━━━━━━━━━ 22:16:38\n",
      "Accuracy: 0.9972 - Precision: 0.8668 - Recall: 0.8755 - Specificity: 0.9987 - F1: 0.8557 - Loss: 0.1620\n",
      "\n",
      "Batch 117/387 ━━━━━━━━━━━━━━━━━━━━ 22:18:18\n",
      "Accuracy: 0.9972 - Precision: 0.8676 - Recall: 0.8761 - Specificity: 0.9987 - F1: 0.8565 - Loss: 0.1611\n",
      "\n",
      "Batch 118/387 ━━━━━━━━━━━━━━━━━━━━ 22:20:05\n",
      "Accuracy: 0.9972 - Precision: 0.8681 - Recall: 0.8763 - Specificity: 0.9987 - F1: 0.8570 - Loss: 0.1607\n",
      "\n",
      "Batch 119/387 ━━━━━━━━━━━━━━━━━━━━ 22:21:40\n",
      "Accuracy: 0.9972 - Precision: 0.8673 - Recall: 0.8770 - Specificity: 0.9987 - F1: 0.8570 - Loss: 0.1607\n",
      "\n",
      "Batch 120/387 ━━━━━━━━━━━━━━━━━━━━ 22:23:02\n",
      "Accuracy: 0.9972 - Precision: 0.8665 - Recall: 0.8778 - Specificity: 0.9987 - F1: 0.8570 - Loss: 0.1606\n",
      "\n",
      "Batch 121/387 ━━━━━━━━━━━━━━━━━━━━ 22:24:25\n",
      "Accuracy: 0.9972 - Precision: 0.8675 - Recall: 0.8780 - Specificity: 0.9987 - F1: 0.8577 - Loss: 0.1599\n",
      "\n",
      "Batch 122/387 ━━━━━━━━━━━━━━━━━━━━ 22:25:51\n",
      "Accuracy: 0.9973 - Precision: 0.8671 - Recall: 0.8788 - Specificity: 0.9987 - F1: 0.8580 - Loss: 0.1595\n",
      "\n",
      "Batch 123/387 ━━━━━━━━━━━━━━━━━━━━ 22:27:12\n",
      "Accuracy: 0.9973 - Precision: 0.8678 - Recall: 0.8790 - Specificity: 0.9987 - F1: 0.8586 - Loss: 0.1588\n",
      "\n",
      "Batch 124/387 ━━━━━━━━━━━━━━━━━━━━ 22:28:38\n",
      "Accuracy: 0.9973 - Precision: 0.8687 - Recall: 0.8776 - Specificity: 0.9987 - F1: 0.8582 - Loss: 0.1592\n",
      "\n",
      "Batch 125/387 ━━━━━━━━━━━━━━━━━━━━ 22:30:04\n",
      "Accuracy: 0.9973 - Precision: 0.8692 - Recall: 0.8782 - Specificity: 0.9987 - F1: 0.8589 - Loss: 0.1585\n",
      "\n",
      "Batch 126/387 ━━━━━━━━━━━━━━━━━━━━ 22:31:30\n",
      "Accuracy: 0.9973 - Precision: 0.8685 - Recall: 0.8787 - Specificity: 0.9987 - F1: 0.8589 - Loss: 0.1584\n",
      "\n",
      "Batch 127/387 ━━━━━━━━━━━━━━━━━━━━ 22:32:59\n",
      "Accuracy: 0.9973 - Precision: 0.8690 - Recall: 0.8791 - Specificity: 0.9987 - F1: 0.8595 - Loss: 0.1578\n",
      "\n",
      "Batch 128/387 ━━━━━━━━━━━━━━━━━━━━ 22:34:24\n",
      "Accuracy: 0.9973 - Precision: 0.8698 - Recall: 0.8773 - Specificity: 0.9987 - F1: 0.8588 - Loss: 0.1586\n",
      "\n",
      "Batch 129/387 ━━━━━━━━━━━━━━━━━━━━ 22:35:54\n",
      "Accuracy: 0.9973 - Precision: 0.8706 - Recall: 0.8775 - Specificity: 0.9987 - F1: 0.8594 - Loss: 0.1579\n",
      "\n",
      "Batch 130/387 ━━━━━━━━━━━━━━━━━━━━ 22:37:19\n",
      "Accuracy: 0.9973 - Precision: 0.8715 - Recall: 0.8777 - Specificity: 0.9987 - F1: 0.8601 - Loss: 0.1573\n",
      "\n",
      "Batch 131/387 ━━━━━━━━━━━━━━━━━━━━ 22:39:02\n",
      "Accuracy: 0.9973 - Precision: 0.8720 - Recall: 0.8785 - Specificity: 0.9987 - F1: 0.8608 - Loss: 0.1564\n",
      "\n",
      "Batch 132/387 ━━━━━━━━━━━━━━━━━━━━ 22:40:37\n",
      "Accuracy: 0.9973 - Precision: 0.8728 - Recall: 0.8785 - Specificity: 0.9988 - F1: 0.8613 - Loss: 0.1560\n",
      "\n",
      "Batch 133/387 ━━━━━━━━━━━━━━━━━━━━ 22:42:13\n",
      "Accuracy: 0.9973 - Precision: 0.8726 - Recall: 0.8791 - Specificity: 0.9988 - F1: 0.8616 - Loss: 0.1556\n",
      "\n",
      "Batch 134/387 ━━━━━━━━━━━━━━━━━━━━ 22:43:40\n",
      "Accuracy: 0.9973 - Precision: 0.8730 - Recall: 0.8799 - Specificity: 0.9988 - F1: 0.8623 - Loss: 0.1548\n",
      "\n",
      "Batch 135/387 ━━━━━━━━━━━━━━━━━━━━ 22:45:04\n",
      "Accuracy: 0.9973 - Precision: 0.8737 - Recall: 0.8803 - Specificity: 0.9988 - F1: 0.8629 - Loss: 0.1541\n",
      "\n",
      "Batch 136/387 ━━━━━━━━━━━━━━━━━━━━ 22:46:18\n",
      "Accuracy: 0.9973 - Precision: 0.8740 - Recall: 0.8791 - Specificity: 0.9988 - F1: 0.8625 - Loss: 0.1546\n",
      "\n",
      "Batch 137/387 ━━━━━━━━━━━━━━━━━━━━ 22:47:47\n",
      "Accuracy: 0.9973 - Precision: 0.8747 - Recall: 0.8794 - Specificity: 0.9988 - F1: 0.8631 - Loss: 0.1539\n",
      "\n",
      "Batch 138/387 ━━━━━━━━━━━━━━━━━━━━ 22:49:15\n",
      "Accuracy: 0.9974 - Precision: 0.8751 - Recall: 0.8800 - Specificity: 0.9988 - F1: 0.8637 - Loss: 0.1533\n",
      "\n",
      "Batch 139/387 ━━━━━━━━━━━━━━━━━━━━ 22:50:31\n",
      "Accuracy: 0.9974 - Precision: 0.8758 - Recall: 0.8801 - Specificity: 0.9988 - F1: 0.8642 - Loss: 0.1528\n",
      "\n",
      "Batch 140/387 ━━━━━━━━━━━━━━━━━━━━ 22:52:13\n",
      "Accuracy: 0.9973 - Precision: 0.8760 - Recall: 0.8807 - Specificity: 0.9988 - F1: 0.8647 - Loss: 0.1523\n",
      "\n",
      "Batch 141/387 ━━━━━━━━━━━━━━━━━━━━ 22:53:37\n",
      "Accuracy: 0.9974 - Precision: 0.8763 - Recall: 0.8813 - Specificity: 0.9988 - F1: 0.8652 - Loss: 0.1517\n",
      "\n",
      "Batch 142/387 ━━━━━━━━━━━━━━━━━━━━ 22:55:04\n",
      "Accuracy: 0.9974 - Precision: 0.8768 - Recall: 0.8819 - Specificity: 0.9988 - F1: 0.8658 - Loss: 0.1510\n",
      "\n",
      "Batch 143/387 ━━━━━━━━━━━━━━━━━━━━ 22:56:25\n",
      "Accuracy: 0.9974 - Precision: 0.8759 - Recall: 0.8826 - Specificity: 0.9988 - F1: 0.8657 - Loss: 0.1510\n",
      "\n",
      "Batch 144/387 ━━━━━━━━━━━━━━━━━━━━ 22:57:50\n",
      "Accuracy: 0.9974 - Precision: 0.8756 - Recall: 0.8828 - Specificity: 0.9988 - F1: 0.8658 - Loss: 0.1510\n",
      "\n",
      "Batch 145/387 ━━━━━━━━━━━━━━━━━━━━ 22:59:12\n",
      "Accuracy: 0.9974 - Precision: 0.8748 - Recall: 0.8827 - Specificity: 0.9988 - F1: 0.8654 - Loss: 0.1514\n",
      "\n",
      "Batch 146/387 ━━━━━━━━━━━━━━━━━━━━ 23:00:47\n",
      "Accuracy: 0.9974 - Precision: 0.8752 - Recall: 0.8825 - Specificity: 0.9988 - F1: 0.8656 - Loss: 0.1513\n",
      "\n",
      "Batch 147/387 ━━━━━━━━━━━━━━━━━━━━ 23:02:20\n",
      "Accuracy: 0.9974 - Precision: 0.8757 - Recall: 0.8817 - Specificity: 0.9988 - F1: 0.8655 - Loss: 0.1515\n",
      "\n",
      "Batch 148/387 ━━━━━━━━━━━━━━━━━━━━ 23:03:54\n",
      "Accuracy: 0.9973 - Precision: 0.8764 - Recall: 0.8797 - Specificity: 0.9988 - F1: 0.8646 - Loss: 0.1526\n",
      "\n",
      "Batch 149/387 ━━━━━━━━━━━━━━━━━━━━ 23:05:14\n",
      "Accuracy: 0.9973 - Precision: 0.8762 - Recall: 0.8796 - Specificity: 0.9988 - F1: 0.8645 - Loss: 0.1527\n",
      "\n",
      "Batch 150/387 ━━━━━━━━━━━━━━━━━━━━ 23:06:39\n",
      "Accuracy: 0.9973 - Precision: 0.8768 - Recall: 0.8803 - Specificity: 0.9988 - F1: 0.8652 - Loss: 0.1519\n",
      "\n",
      "Batch 151/387 ━━━━━━━━━━━━━━━━━━━━ 23:08:15\n",
      "Accuracy: 0.9973 - Precision: 0.8775 - Recall: 0.8803 - Specificity: 0.9988 - F1: 0.8657 - Loss: 0.1513\n",
      "\n",
      "Batch 152/387 ━━━━━━━━━━━━━━━━━━━━ 23:09:53\n",
      "Accuracy: 0.9974 - Precision: 0.8782 - Recall: 0.8805 - Specificity: 0.9988 - F1: 0.8662 - Loss: 0.1508\n",
      "\n",
      "Batch 153/387 ━━━━━━━━━━━━━━━━━━━━ 23:11:26\n",
      "Accuracy: 0.9974 - Precision: 0.8788 - Recall: 0.8808 - Specificity: 0.9988 - F1: 0.8667 - Loss: 0.1502\n",
      "\n",
      "Batch 154/387 ━━━━━━━━━━━━━━━━━━━━ 23:13:01\n",
      "Accuracy: 0.9974 - Precision: 0.8787 - Recall: 0.8811 - Specificity: 0.9988 - F1: 0.8669 - Loss: 0.1500\n",
      "\n",
      "Batch 155/387 ━━━━━━━━━━━━━━━━━━━━ 23:14:31\n",
      "Accuracy: 0.9974 - Precision: 0.8782 - Recall: 0.8813 - Specificity: 0.9988 - F1: 0.8668 - Loss: 0.1502\n",
      "\n",
      "Batch 156/387 ━━━━━━━━━━━━━━━━━━━━ 23:15:51\n",
      "Accuracy: 0.9974 - Precision: 0.8783 - Recall: 0.8816 - Specificity: 0.9988 - F1: 0.8671 - Loss: 0.1498\n",
      "\n",
      "Batch 157/387 ━━━━━━━━━━━━━━━━━━━━ 23:17:21\n",
      "Accuracy: 0.9974 - Precision: 0.8787 - Recall: 0.8821 - Specificity: 0.9988 - F1: 0.8676 - Loss: 0.1493\n",
      "\n",
      "Batch 158/387 ━━━━━━━━━━━━━━━━━━━━ 23:18:41\n",
      "Accuracy: 0.9974 - Precision: 0.8786 - Recall: 0.8820 - Specificity: 0.9988 - F1: 0.8676 - Loss: 0.1492\n",
      "\n",
      "Batch 159/387 ━━━━━━━━━━━━━━━━━━━━ 23:20:20\n",
      "Accuracy: 0.9974 - Precision: 0.8778 - Recall: 0.8821 - Specificity: 0.9988 - F1: 0.8673 - Loss: 0.1495\n",
      "\n",
      "Batch 160/387 ━━━━━━━━━━━━━━━━━━━━ 23:22:06\n",
      "Accuracy: 0.9974 - Precision: 0.8783 - Recall: 0.8825 - Specificity: 0.9988 - F1: 0.8678 - Loss: 0.1490\n",
      "\n",
      "Batch 161/387 ━━━━━━━━━━━━━━━━━━━━ 23:23:30\n",
      "Accuracy: 0.9974 - Precision: 0.8785 - Recall: 0.8828 - Specificity: 0.9988 - F1: 0.8682 - Loss: 0.1485\n",
      "\n",
      "Batch 162/387 ━━━━━━━━━━━━━━━━━━━━ 23:24:46\n",
      "Accuracy: 0.9974 - Precision: 0.8791 - Recall: 0.8827 - Specificity: 0.9988 - F1: 0.8684 - Loss: 0.1483\n",
      "\n",
      "Batch 163/387 ━━━━━━━━━━━━━━━━━━━━ 23:26:17\n",
      "Accuracy: 0.9974 - Precision: 0.8783 - Recall: 0.8823 - Specificity: 0.9988 - F1: 0.8679 - Loss: 0.1489\n",
      "\n",
      "Batch 164/387 ━━━━━━━━━━━━━━━━━━━━ 23:27:44\n",
      "Accuracy: 0.9974 - Precision: 0.8789 - Recall: 0.8819 - Specificity: 0.9988 - F1: 0.8680 - Loss: 0.1487\n",
      "\n",
      "Batch 165/387 ━━━━━━━━━━━━━━━━━━━━ 23:29:09\n",
      "Accuracy: 0.9974 - Precision: 0.8785 - Recall: 0.8824 - Specificity: 0.9988 - F1: 0.8681 - Loss: 0.1486\n",
      "\n",
      "Batch 166/387 ━━━━━━━━━━━━━━━━━━━━ 23:30:42\n",
      "Accuracy: 0.9974 - Precision: 0.8787 - Recall: 0.8829 - Specificity: 0.9988 - F1: 0.8686 - Loss: 0.1481\n",
      "\n",
      "Batch 167/387 ━━━━━━━━━━━━━━━━━━━━ 23:32:03\n",
      "Accuracy: 0.9974 - Precision: 0.8793 - Recall: 0.8831 - Specificity: 0.9988 - F1: 0.8690 - Loss: 0.1476\n",
      "\n",
      "Batch 168/387 ━━━━━━━━━━━━━━━━━━━━ 23:33:21\n",
      "Accuracy: 0.9974 - Precision: 0.8793 - Recall: 0.8824 - Specificity: 0.9988 - F1: 0.8687 - Loss: 0.1479\n",
      "\n",
      "Batch 169/387 ━━━━━━━━━━━━━━━━━━━━ 23:34:49\n",
      "Accuracy: 0.9974 - Precision: 0.8792 - Recall: 0.8824 - Specificity: 0.9988 - F1: 0.8688 - Loss: 0.1478\n",
      "\n",
      "Batch 170/387 ━━━━━━━━━━━━━━━━━━━━ 23:36:27\n",
      "Accuracy: 0.9974 - Precision: 0.8794 - Recall: 0.8819 - Specificity: 0.9988 - F1: 0.8686 - Loss: 0.1479\n",
      "\n",
      "Batch 171/387 ━━━━━━━━━━━━━━━━━━━━ 23:37:51\n",
      "Accuracy: 0.9974 - Precision: 0.8798 - Recall: 0.8809 - Specificity: 0.9988 - F1: 0.8683 - Loss: 0.1481\n",
      "\n",
      "Batch 172/387 ━━━━━━━━━━━━━━━━━━━━ 23:39:14\n",
      "Accuracy: 0.9974 - Precision: 0.8803 - Recall: 0.8813 - Specificity: 0.9988 - F1: 0.8688 - Loss: 0.1476\n",
      "\n",
      "Batch 173/387 ━━━━━━━━━━━━━━━━━━━━ 23:40:41\n",
      "Accuracy: 0.9975 - Precision: 0.8808 - Recall: 0.8815 - Specificity: 0.9988 - F1: 0.8692 - Loss: 0.1471\n",
      "\n",
      "Batch 174/387 ━━━━━━━━━━━━━━━━━━━━ 23:42:16\n",
      "Accuracy: 0.9975 - Precision: 0.8798 - Recall: 0.8819 - Specificity: 0.9988 - F1: 0.8689 - Loss: 0.1473\n",
      "\n",
      "Batch 175/387 ━━━━━━━━━━━━━━━━━━━━ 23:43:38\n",
      "Accuracy: 0.9975 - Precision: 0.8805 - Recall: 0.8819 - Specificity: 0.9988 - F1: 0.8693 - Loss: 0.1470\n",
      "\n",
      "Batch 176/387 ━━━━━━━━━━━━━━━━━━━━ 23:45:04\n",
      "Accuracy: 0.9975 - Precision: 0.8805 - Recall: 0.8821 - Specificity: 0.9988 - F1: 0.8695 - Loss: 0.1468\n",
      "\n",
      "Batch 177/387 ━━━━━━━━━━━━━━━━━━━━ 23:46:34\n",
      "Accuracy: 0.9975 - Precision: 0.8805 - Recall: 0.8827 - Specificity: 0.9988 - F1: 0.8698 - Loss: 0.1464\n",
      "\n",
      "Batch 178/387 ━━━━━━━━━━━━━━━━━━━━ 23:47:53\n",
      "Accuracy: 0.9975 - Precision: 0.8800 - Recall: 0.8831 - Specificity: 0.9988 - F1: 0.8698 - Loss: 0.1463\n",
      "\n",
      "Batch 179/387 ━━━━━━━━━━━━━━━━━━━━ 23:49:08\n",
      "Accuracy: 0.9975 - Precision: 0.8796 - Recall: 0.8837 - Specificity: 0.9988 - F1: 0.8699 - Loss: 0.1463\n",
      "\n",
      "Batch 180/387 ━━━━━━━━━━━━━━━━━━━━ 23:50:28\n",
      "Accuracy: 0.9975 - Precision: 0.8800 - Recall: 0.8841 - Specificity: 0.9988 - F1: 0.8704 - Loss: 0.1457\n",
      "\n",
      "Batch 181/387 ━━━━━━━━━━━━━━━━━━━━ 23:52:08\n",
      "Accuracy: 0.9975 - Precision: 0.8806 - Recall: 0.8844 - Specificity: 0.9988 - F1: 0.8709 - Loss: 0.1452\n",
      "\n",
      "Batch 182/387 ━━━━━━━━━━━━━━━━━━━━ 23:53:31\n",
      "Accuracy: 0.9975 - Precision: 0.8807 - Recall: 0.8848 - Specificity: 0.9988 - F1: 0.8712 - Loss: 0.1449\n",
      "\n",
      "Batch 183/387 ━━━━━━━━━━━━━━━━━━━━ 23:54:50\n",
      "Accuracy: 0.9975 - Precision: 0.8806 - Recall: 0.8851 - Specificity: 0.9988 - F1: 0.8714 - Loss: 0.1446\n",
      "\n",
      "Batch 184/387 ━━━━━━━━━━━━━━━━━━━━ 23:56:30\n",
      "Accuracy: 0.9975 - Precision: 0.8809 - Recall: 0.8856 - Specificity: 0.9988 - F1: 0.8718 - Loss: 0.1441\n",
      "\n",
      "Batch 185/387 ━━━━━━━━━━━━━━━━━━━━ 23:57:54\n",
      "Accuracy: 0.9975 - Precision: 0.8812 - Recall: 0.8856 - Specificity: 0.9988 - F1: 0.8720 - Loss: 0.1439\n",
      "\n",
      "Batch 186/387 ━━━━━━━━━━━━━━━━━━━━ 23:59:28\n",
      "Accuracy: 0.9975 - Precision: 0.8816 - Recall: 0.8847 - Specificity: 0.9988 - F1: 0.8718 - Loss: 0.1442\n",
      "\n",
      "Batch 187/387 ━━━━━━━━━━━━━━━━━━━━ 00:00:57\n",
      "Accuracy: 0.9975 - Precision: 0.8812 - Recall: 0.8851 - Specificity: 0.9988 - F1: 0.8718 - Loss: 0.1442\n",
      "\n",
      "Batch 188/387 ━━━━━━━━━━━━━━━━━━━━ 00:02:38\n",
      "Accuracy: 0.9975 - Precision: 0.8814 - Recall: 0.8850 - Specificity: 0.9989 - F1: 0.8719 - Loss: 0.1440\n",
      "\n",
      "Batch 189/387 ━━━━━━━━━━━━━━━━━━━━ 00:04:07\n",
      "Accuracy: 0.9975 - Precision: 0.8811 - Recall: 0.8850 - Specificity: 0.9989 - F1: 0.8718 - Loss: 0.1441\n",
      "\n",
      "Batch 190/387 ━━━━━━━━━━━━━━━━━━━━ 00:05:26\n",
      "Accuracy: 0.9975 - Precision: 0.8816 - Recall: 0.8852 - Specificity: 0.9989 - F1: 0.8722 - Loss: 0.1436\n",
      "\n",
      "Batch 191/387 ━━━━━━━━━━━━━━━━━━━━ 00:06:58\n",
      "Accuracy: 0.9975 - Precision: 0.8814 - Recall: 0.8855 - Specificity: 0.9989 - F1: 0.8723 - Loss: 0.1436\n",
      "\n",
      "Batch 192/387 ━━━━━━━━━━━━━━━━━━━━ 00:08:30\n",
      "Accuracy: 0.9975 - Precision: 0.8818 - Recall: 0.8847 - Specificity: 0.9989 - F1: 0.8721 - Loss: 0.1439\n",
      "\n",
      "Batch 193/387 ━━━━━━━━━━━━━━━━━━━━ 00:09:58\n",
      "Accuracy: 0.9975 - Precision: 0.8819 - Recall: 0.8845 - Specificity: 0.9989 - F1: 0.8721 - Loss: 0.1439\n",
      "\n",
      "Batch 194/387 ━━━━━━━━━━━━━━━━━━━━ 00:11:44\n",
      "Accuracy: 0.9975 - Precision: 0.8823 - Recall: 0.8846 - Specificity: 0.9989 - F1: 0.8724 - Loss: 0.1436\n",
      "\n",
      "Batch 195/387 ━━━━━━━━━━━━━━━━━━━━ 00:13:22\n",
      "Accuracy: 0.9975 - Precision: 0.8826 - Recall: 0.8844 - Specificity: 0.9989 - F1: 0.8725 - Loss: 0.1435\n",
      "\n",
      "Batch 196/387 ━━━━━━━━━━━━━━━━━━━━ 00:14:47\n",
      "Accuracy: 0.9975 - Precision: 0.8819 - Recall: 0.8845 - Specificity: 0.9989 - F1: 0.8721 - Loss: 0.1438\n",
      "\n",
      "Batch 197/387 ━━━━━━━━━━━━━━━━━━━━ 00:16:22\n",
      "Accuracy: 0.9975 - Precision: 0.8821 - Recall: 0.8848 - Specificity: 0.9989 - F1: 0.8725 - Loss: 0.1434\n",
      "\n",
      "Batch 198/387 ━━━━━━━━━━━━━━━━━━━━ 00:17:49\n",
      "Accuracy: 0.9975 - Precision: 0.8825 - Recall: 0.8852 - Specificity: 0.9989 - F1: 0.8729 - Loss: 0.1429\n",
      "\n",
      "Batch 199/387 ━━━━━━━━━━━━━━━━━━━━ 00:19:09\n",
      "Accuracy: 0.9975 - Precision: 0.8826 - Recall: 0.8855 - Specificity: 0.9989 - F1: 0.8732 - Loss: 0.1426\n",
      "\n",
      "Batch 200/387 ━━━━━━━━━━━━━━━━━━━━ 00:20:41\n",
      "Accuracy: 0.9975 - Precision: 0.8831 - Recall: 0.8850 - Specificity: 0.9989 - F1: 0.8732 - Loss: 0.1426\n",
      "\n",
      "Batch 201/387 ━━━━━━━━━━━━━━━━━━━━ 00:21:59\n",
      "Accuracy: 0.9975 - Precision: 0.8831 - Recall: 0.8854 - Specificity: 0.9989 - F1: 0.8734 - Loss: 0.1423\n",
      "\n",
      "Batch 202/387 ━━━━━━━━━━━━━━━━━━━━ 00:23:24\n",
      "Accuracy: 0.9975 - Precision: 0.8830 - Recall: 0.8844 - Specificity: 0.9989 - F1: 0.8729 - Loss: 0.1429\n",
      "\n",
      "Batch 203/387 ━━━━━━━━━━━━━━━━━━━━ 00:24:59\n",
      "Accuracy: 0.9975 - Precision: 0.8824 - Recall: 0.8850 - Specificity: 0.9989 - F1: 0.8729 - Loss: 0.1429\n",
      "\n",
      "Batch 204/387 ━━━━━━━━━━━━━━━━━━━━ 00:26:35\n",
      "Accuracy: 0.9975 - Precision: 0.8822 - Recall: 0.8853 - Specificity: 0.9989 - F1: 0.8730 - Loss: 0.1428\n",
      "\n",
      "Batch 205/387 ━━━━━━━━━━━━━━━━━━━━ 00:28:12\n",
      "Accuracy: 0.9975 - Precision: 0.8820 - Recall: 0.8857 - Specificity: 0.9989 - F1: 0.8731 - Loss: 0.1427\n",
      "\n",
      "Batch 206/387 ━━━━━━━━━━━━━━━━━━━━ 00:29:49\n",
      "Accuracy: 0.9975 - Precision: 0.8807 - Recall: 0.8848 - Specificity: 0.9988 - F1: 0.8720 - Loss: 0.1439\n",
      "\n",
      "Batch 207/387 ━━━━━━━━━━━━━━━━━━━━ 00:31:09\n",
      "Accuracy: 0.9975 - Precision: 0.8810 - Recall: 0.8851 - Specificity: 0.9988 - F1: 0.8724 - Loss: 0.1435\n",
      "\n",
      "Batch 208/387 ━━━━━━━━━━━━━━━━━━━━ 00:32:45\n",
      "Accuracy: 0.9975 - Precision: 0.8811 - Recall: 0.8854 - Specificity: 0.9988 - F1: 0.8726 - Loss: 0.1432\n",
      "\n",
      "Batch 209/387 ━━━━━━━━━━━━━━━━━━━━ 00:34:17\n",
      "Accuracy: 0.9975 - Precision: 0.8812 - Recall: 0.8857 - Specificity: 0.9988 - F1: 0.8729 - Loss: 0.1429\n",
      "\n",
      "Batch 210/387 ━━━━━━━━━━━━━━━━━━━━ 00:35:44\n",
      "Accuracy: 0.9975 - Precision: 0.8816 - Recall: 0.8858 - Specificity: 0.9988 - F1: 0.8731 - Loss: 0.1426\n",
      "\n",
      "Batch 211/387 ━━━━━━━━━━━━━━━━━━━━ 00:37:33\n",
      "Accuracy: 0.9975 - Precision: 0.8815 - Recall: 0.8846 - Specificity: 0.9988 - F1: 0.8725 - Loss: 0.1434\n",
      "\n",
      "Batch 212/387 ━━━━━━━━━━━━━━━━━━━━ 00:38:57\n",
      "Accuracy: 0.9975 - Precision: 0.8817 - Recall: 0.8848 - Specificity: 0.9988 - F1: 0.8727 - Loss: 0.1431\n",
      "\n",
      "Batch 213/387 ━━━━━━━━━━━━━━━━━━━━ 00:40:30\n",
      "Accuracy: 0.9975 - Precision: 0.8819 - Recall: 0.8843 - Specificity: 0.9989 - F1: 0.8726 - Loss: 0.1432\n",
      "\n",
      "Batch 214/387 ━━━━━━━━━━━━━━━━━━━━ 00:42:16\n",
      "Accuracy: 0.9975 - Precision: 0.8822 - Recall: 0.8846 - Specificity: 0.9989 - F1: 0.8730 - Loss: 0.1428\n",
      "\n",
      "Batch 215/387 ━━━━━━━━━━━━━━━━━━━━ 00:43:51\n",
      "Accuracy: 0.9975 - Precision: 0.8811 - Recall: 0.8843 - Specificity: 0.9988 - F1: 0.8723 - Loss: 0.1436\n",
      "\n",
      "Batch 216/387 ━━━━━━━━━━━━━━━━━━━━ 00:45:29\n",
      "Accuracy: 0.9975 - Precision: 0.8813 - Recall: 0.8846 - Specificity: 0.9988 - F1: 0.8726 - Loss: 0.1432\n",
      "\n",
      "Batch 217/387 ━━━━━━━━━━━━━━━━━━━━ 00:47:02\n",
      "Accuracy: 0.9975 - Precision: 0.8815 - Recall: 0.8841 - Specificity: 0.9988 - F1: 0.8724 - Loss: 0.1433\n",
      "\n",
      "Batch 218/387 ━━━━━━━━━━━━━━━━━━━━ 00:48:26\n",
      "Accuracy: 0.9975 - Precision: 0.8798 - Recall: 0.8841 - Specificity: 0.9988 - F1: 0.8714 - Loss: 0.1444\n",
      "\n",
      "Batch 219/387 ━━━━━━━━━━━━━━━━━━━━ 00:49:47\n",
      "Accuracy: 0.9975 - Precision: 0.8796 - Recall: 0.8845 - Specificity: 0.9988 - F1: 0.8715 - Loss: 0.1442\n",
      "\n",
      "Batch 220/387 ━━━━━━━━━━━━━━━━━━━━ 00:51:15\n",
      "Accuracy: 0.9975 - Precision: 0.8791 - Recall: 0.8849 - Specificity: 0.9988 - F1: 0.8714 - Loss: 0.1443\n",
      "\n",
      "Batch 221/387 ━━━━━━━━━━━━━━━━━━━━ 00:52:40\n",
      "Accuracy: 0.9975 - Precision: 0.8790 - Recall: 0.8853 - Specificity: 0.9988 - F1: 0.8716 - Loss: 0.1440\n",
      "\n",
      "Batch 222/387 ━━━━━━━━━━━━━━━━━━━━ 00:54:18\n",
      "Accuracy: 0.9975 - Precision: 0.8792 - Recall: 0.8856 - Specificity: 0.9988 - F1: 0.8719 - Loss: 0.1438\n",
      "\n",
      "Batch 223/387 ━━━━━━━━━━━━━━━━━━━━ 00:55:57\n",
      "Accuracy: 0.9975 - Precision: 0.8782 - Recall: 0.8852 - Specificity: 0.9988 - F1: 0.8712 - Loss: 0.1445\n",
      "\n",
      "Batch 224/387 ━━━━━━━━━━━━━━━━━━━━ 00:57:39\n",
      "Accuracy: 0.9975 - Precision: 0.8787 - Recall: 0.8853 - Specificity: 0.9988 - F1: 0.8716 - Loss: 0.1442\n",
      "\n",
      "Batch 225/387 ━━━━━━━━━━━━━━━━━━━━ 00:59:05\n",
      "Accuracy: 0.9975 - Precision: 0.8790 - Recall: 0.8848 - Specificity: 0.9988 - F1: 0.8715 - Loss: 0.1442\n",
      "\n",
      "Batch 226/387 ━━━━━━━━━━━━━━━━━━━━ 01:00:38\n",
      "Accuracy: 0.9975 - Precision: 0.8784 - Recall: 0.8852 - Specificity: 0.9988 - F1: 0.8714 - Loss: 0.1443\n",
      "\n",
      "Batch 227/387 ━━━━━━━━━━━━━━━━━━━━ 01:02:14\n",
      "Accuracy: 0.9975 - Precision: 0.8789 - Recall: 0.8845 - Specificity: 0.9988 - F1: 0.8712 - Loss: 0.1444\n",
      "\n",
      "Batch 228/387 ━━━━━━━━━━━━━━━━━━━━ 01:03:44\n",
      "Accuracy: 0.9975 - Precision: 0.8791 - Recall: 0.8846 - Specificity: 0.9988 - F1: 0.8714 - Loss: 0.1442\n",
      "\n",
      "Batch 229/387 ━━━━━━━━━━━━━━━━━━━━ 01:05:08\n",
      "Accuracy: 0.9975 - Precision: 0.8794 - Recall: 0.8839 - Specificity: 0.9988 - F1: 0.8712 - Loss: 0.1445\n",
      "\n",
      "Batch 230/387 ━━━━━━━━━━━━━━━━━━━━ 01:06:40\n",
      "Accuracy: 0.9975 - Precision: 0.8798 - Recall: 0.8834 - Specificity: 0.9988 - F1: 0.8712 - Loss: 0.1445\n",
      "\n",
      "Batch 231/387 ━━━━━━━━━━━━━━━━━━━━ 01:08:06\n",
      "Accuracy: 0.9975 - Precision: 0.8799 - Recall: 0.8835 - Specificity: 0.9989 - F1: 0.8713 - Loss: 0.1443\n",
      "\n",
      "Batch 232/387 ━━━━━━━━━━━━━━━━━━━━ 01:09:23\n",
      "Accuracy: 0.9975 - Precision: 0.8803 - Recall: 0.8836 - Specificity: 0.9989 - F1: 0.8716 - Loss: 0.1440\n",
      "\n",
      "Batch 233/387 ━━━━━━━━━━━━━━━━━━━━ 01:11:19\n",
      "Accuracy: 0.9976 - Precision: 0.8808 - Recall: 0.8838 - Specificity: 0.9989 - F1: 0.8720 - Loss: 0.1436\n",
      "\n",
      "Batch 234/387 ━━━━━━━━━━━━━━━━━━━━ 01:12:52\n",
      "Accuracy: 0.9976 - Precision: 0.8813 - Recall: 0.8840 - Specificity: 0.9989 - F1: 0.8723 - Loss: 0.1432\n",
      "\n",
      "Batch 235/387 ━━━━━━━━━━━━━━━━━━━━ 01:14:28\n",
      "Accuracy: 0.9976 - Precision: 0.8815 - Recall: 0.8842 - Specificity: 0.9989 - F1: 0.8726 - Loss: 0.1429\n",
      "\n",
      "Batch 236/387 ━━━━━━━━━━━━━━━━━━━━ 01:15:59\n",
      "Accuracy: 0.9976 - Precision: 0.8816 - Recall: 0.8845 - Specificity: 0.9989 - F1: 0.8729 - Loss: 0.1426\n",
      "\n",
      "Batch 237/387 ━━━━━━━━━━━━━━━━━━━━ 01:17:19\n",
      "Accuracy: 0.9975 - Precision: 0.8820 - Recall: 0.8836 - Specificity: 0.9989 - F1: 0.8725 - Loss: 0.1430\n",
      "\n",
      "Batch 238/387 ━━━━━━━━━━━━━━━━━━━━ 01:18:46\n",
      "Accuracy: 0.9975 - Precision: 0.8814 - Recall: 0.8838 - Specificity: 0.9988 - F1: 0.8723 - Loss: 0.1434\n",
      "\n",
      "Batch 239/387 ━━━━━━━━━━━━━━━━━━━━ 01:20:01\n",
      "Accuracy: 0.9975 - Precision: 0.8816 - Recall: 0.8841 - Specificity: 0.9988 - F1: 0.8726 - Loss: 0.1431\n",
      "\n",
      "Batch 240/387 ━━━━━━━━━━━━━━━━━━━━ 01:21:43\n",
      "Accuracy: 0.9975 - Precision: 0.8814 - Recall: 0.8845 - Specificity: 0.9988 - F1: 0.8727 - Loss: 0.1429\n",
      "\n",
      "Batch 241/387 ━━━━━━━━━━━━━━━━━━━━ 01:23:21\n",
      "Accuracy: 0.9975 - Precision: 0.8794 - Recall: 0.8833 - Specificity: 0.9988 - F1: 0.8711 - Loss: 0.1446\n",
      "\n",
      "Batch 242/387 ━━━━━━━━━━━━━━━━━━━━ 01:24:55\n",
      "Accuracy: 0.9975 - Precision: 0.8787 - Recall: 0.8838 - Specificity: 0.9988 - F1: 0.8709 - Loss: 0.1448\n",
      "\n",
      "Batch 243/387 ━━━━━━━━━━━━━━━━━━━━ 01:26:18\n",
      "Accuracy: 0.9975 - Precision: 0.8790 - Recall: 0.8837 - Specificity: 0.9988 - F1: 0.8710 - Loss: 0.1446\n",
      "\n",
      "Batch 244/387 ━━━━━━━━━━━━━━━━━━━━ 01:27:39\n",
      "Accuracy: 0.9975 - Precision: 0.8781 - Recall: 0.8839 - Specificity: 0.9988 - F1: 0.8706 - Loss: 0.1450\n",
      "\n",
      "Batch 245/387 ━━━━━━━━━━━━━━━━━━━━ 01:28:57\n",
      "Accuracy: 0.9975 - Precision: 0.8784 - Recall: 0.8842 - Specificity: 0.9988 - F1: 0.8710 - Loss: 0.1447\n",
      "\n",
      "Batch 246/387 ━━━━━━━━━━━━━━━━━━━━ 01:30:17\n",
      "Accuracy: 0.9975 - Precision: 0.8782 - Recall: 0.8841 - Specificity: 0.9988 - F1: 0.8709 - Loss: 0.1447\n",
      "\n",
      "Batch 247/387 ━━━━━━━━━━━━━━━━━━━━ 01:31:33\n",
      "Accuracy: 0.9975 - Precision: 0.8785 - Recall: 0.8841 - Specificity: 0.9988 - F1: 0.8711 - Loss: 0.1446\n",
      "\n",
      "Batch 248/387 ━━━━━━━━━━━━━━━━━━━━ 01:32:57\n",
      "Accuracy: 0.9975 - Precision: 0.8775 - Recall: 0.8846 - Specificity: 0.9988 - F1: 0.8707 - Loss: 0.1449\n",
      "\n",
      "Batch 249/387 ━━━━━━━━━━━━━━━━━━━━ 01:34:12\n",
      "Accuracy: 0.9975 - Precision: 0.8778 - Recall: 0.8833 - Specificity: 0.9988 - F1: 0.8700 - Loss: 0.1457\n",
      "\n",
      "Batch 250/387 ━━━━━━━━━━━━━━━━━━━━ 01:35:40\n",
      "Accuracy: 0.9975 - Precision: 0.8771 - Recall: 0.8836 - Specificity: 0.9988 - F1: 0.8698 - Loss: 0.1459\n",
      "\n",
      "Batch 251/387 ━━━━━━━━━━━━━━━━━━━━ 01:37:07\n",
      "Accuracy: 0.9975 - Precision: 0.8770 - Recall: 0.8839 - Specificity: 0.9988 - F1: 0.8700 - Loss: 0.1457\n",
      "\n",
      "Batch 252/387 ━━━━━━━━━━━━━━━━━━━━ 01:38:37\n",
      "Accuracy: 0.9975 - Precision: 0.8773 - Recall: 0.8841 - Specificity: 0.9988 - F1: 0.8703 - Loss: 0.1454\n",
      "\n",
      "Batch 253/387 ━━━━━━━━━━━━━━━━━━━━ 01:39:59\n",
      "Accuracy: 0.9975 - Precision: 0.8776 - Recall: 0.8843 - Specificity: 0.9988 - F1: 0.8706 - Loss: 0.1450\n",
      "\n",
      "Batch 254/387 ━━━━━━━━━━━━━━━━━━━━ 01:41:19\n",
      "Accuracy: 0.9975 - Precision: 0.8781 - Recall: 0.8831 - Specificity: 0.9988 - F1: 0.8700 - Loss: 0.1457\n",
      "\n",
      "Batch 255/387 ━━━━━━━━━━━━━━━━━━━━ 01:42:49\n",
      "Accuracy: 0.9975 - Precision: 0.8785 - Recall: 0.8820 - Specificity: 0.9988 - F1: 0.8695 - Loss: 0.1462\n",
      "\n",
      "Batch 256/387 ━━━━━━━━━━━━━━━━━━━━ 01:44:10\n",
      "Accuracy: 0.9975 - Precision: 0.8789 - Recall: 0.8821 - Specificity: 0.9988 - F1: 0.8698 - Loss: 0.1459\n",
      "\n",
      "Batch 257/387 ━━━━━━━━━━━━━━━━━━━━ 01:45:33\n",
      "Accuracy: 0.9975 - Precision: 0.8790 - Recall: 0.8823 - Specificity: 0.9988 - F1: 0.8700 - Loss: 0.1457\n",
      "\n",
      "Batch 258/387 ━━━━━━━━━━━━━━━━━━━━ 01:46:49\n",
      "Accuracy: 0.9975 - Precision: 0.8794 - Recall: 0.8823 - Specificity: 0.9989 - F1: 0.8702 - Loss: 0.1454\n",
      "\n",
      "Batch 259/387 ━━━━━━━━━━━━━━━━━━━━ 01:48:11\n",
      "Accuracy: 0.9975 - Precision: 0.8797 - Recall: 0.8825 - Specificity: 0.9989 - F1: 0.8705 - Loss: 0.1451\n",
      "\n",
      "Batch 260/387 ━━━━━━━━━━━━━━━━━━━━ 01:49:32\n",
      "Accuracy: 0.9975 - Precision: 0.8800 - Recall: 0.8821 - Specificity: 0.9989 - F1: 0.8705 - Loss: 0.1451\n",
      "\n",
      "Batch 261/387 ━━━━━━━━━━━━━━━━━━━━ 01:50:52\n",
      "Accuracy: 0.9975 - Precision: 0.8794 - Recall: 0.8821 - Specificity: 0.9989 - F1: 0.8702 - Loss: 0.1454\n",
      "\n",
      "Batch 262/387 ━━━━━━━━━━━━━━━━━━━━ 01:52:19\n",
      "Accuracy: 0.9975 - Precision: 0.8798 - Recall: 0.8811 - Specificity: 0.9989 - F1: 0.8698 - Loss: 0.1460\n",
      "\n",
      "Batch 263/387 ━━━━━━━━━━━━━━━━━━━━ 01:53:44\n",
      "Accuracy: 0.9975 - Precision: 0.8799 - Recall: 0.8814 - Specificity: 0.9989 - F1: 0.8700 - Loss: 0.1457\n",
      "\n",
      "Batch 264/387 ━━━━━━━━━━━━━━━━━━━━ 01:55:21\n",
      "Accuracy: 0.9975 - Precision: 0.8793 - Recall: 0.8815 - Specificity: 0.9989 - F1: 0.8698 - Loss: 0.1460\n",
      "\n",
      "Batch 265/387 ━━━━━━━━━━━━━━━━━━━━ 01:56:47\n",
      "Accuracy: 0.9975 - Precision: 0.8796 - Recall: 0.8817 - Specificity: 0.9989 - F1: 0.8701 - Loss: 0.1456\n",
      "\n",
      "Batch 266/387 ━━━━━━━━━━━━━━━━━━━━ 01:58:07\n",
      "Accuracy: 0.9975 - Precision: 0.8800 - Recall: 0.8815 - Specificity: 0.9989 - F1: 0.8702 - Loss: 0.1455\n",
      "\n",
      "Batch 267/387 ━━━━━━━━━━━━━━━━━━━━ 01:59:38\n",
      "Accuracy: 0.9975 - Precision: 0.8799 - Recall: 0.8818 - Specificity: 0.9989 - F1: 0.8703 - Loss: 0.1454\n",
      "\n",
      "Batch 268/387 ━━━━━━━━━━━━━━━━━━━━ 02:00:59\n",
      "Accuracy: 0.9975 - Precision: 0.8795 - Recall: 0.8822 - Specificity: 0.9989 - F1: 0.8703 - Loss: 0.1454\n",
      "\n",
      "Batch 269/387 ━━━━━━━━━━━━━━━━━━━━ 02:02:28\n",
      "Accuracy: 0.9975 - Precision: 0.8799 - Recall: 0.8821 - Specificity: 0.9989 - F1: 0.8705 - Loss: 0.1452\n",
      "\n",
      "Batch 270/387 ━━━━━━━━━━━━━━━━━━━━ 02:03:51\n",
      "Accuracy: 0.9975 - Precision: 0.8785 - Recall: 0.8825 - Specificity: 0.9989 - F1: 0.8697 - Loss: 0.1460\n",
      "\n",
      "Batch 271/387 ━━━━━━━━━━━━━━━━━━━━ 02:05:19\n",
      "Accuracy: 0.9975 - Precision: 0.8787 - Recall: 0.8828 - Specificity: 0.9989 - F1: 0.8700 - Loss: 0.1457\n",
      "\n",
      "Batch 272/387 ━━━━━━━━━━━━━━━━━━━━ 02:06:52\n",
      "Accuracy: 0.9975 - Precision: 0.8789 - Recall: 0.8831 - Specificity: 0.9989 - F1: 0.8703 - Loss: 0.1453\n",
      "\n",
      "Batch 273/387 ━━━━━━━━━━━━━━━━━━━━ 02:08:14\n",
      "Accuracy: 0.9975 - Precision: 0.8786 - Recall: 0.8832 - Specificity: 0.9989 - F1: 0.8702 - Loss: 0.1454\n",
      "\n",
      "Batch 274/387 ━━━━━━━━━━━━━━━━━━━━ 02:09:41\n",
      "Accuracy: 0.9975 - Precision: 0.8775 - Recall: 0.8835 - Specificity: 0.9988 - F1: 0.8697 - Loss: 0.1460\n",
      "\n",
      "Batch 275/387 ━━━━━━━━━━━━━━━━━━━━ 02:11:03\n",
      "Accuracy: 0.9975 - Precision: 0.8778 - Recall: 0.8837 - Specificity: 0.9988 - F1: 0.8699 - Loss: 0.1457\n",
      "\n",
      "Batch 276/387 ━━━━━━━━━━━━━━━━━━━━ 02:12:27\n",
      "Accuracy: 0.9975 - Precision: 0.8778 - Recall: 0.8838 - Specificity: 0.9988 - F1: 0.8701 - Loss: 0.1455\n",
      "\n",
      "Batch 277/387 ━━━━━━━━━━━━━━━━━━━━ 02:13:58\n",
      "Accuracy: 0.9975 - Precision: 0.8782 - Recall: 0.8836 - Specificity: 0.9988 - F1: 0.8702 - Loss: 0.1454\n",
      "\n",
      "Batch 278/387 ━━━━━━━━━━━━━━━━━━━━ 02:15:27\n",
      "Accuracy: 0.9975 - Precision: 0.8773 - Recall: 0.8830 - Specificity: 0.9988 - F1: 0.8694 - Loss: 0.1462\n",
      "\n",
      "Batch 279/387 ━━━━━━━━━━━━━━━━━━━━ 02:16:47\n",
      "Accuracy: 0.9975 - Precision: 0.8775 - Recall: 0.8831 - Specificity: 0.9988 - F1: 0.8697 - Loss: 0.1460\n",
      "\n",
      "Batch 280/387 ━━━━━━━━━━━━━━━━━━━━ 02:18:15\n",
      "Accuracy: 0.9975 - Precision: 0.8778 - Recall: 0.8833 - Specificity: 0.9988 - F1: 0.8700 - Loss: 0.1457\n",
      "\n",
      "Batch 281/387 ━━━━━━━━━━━━━━━━━━━━ 02:19:50\n",
      "Accuracy: 0.9975 - Precision: 0.8777 - Recall: 0.8837 - Specificity: 0.9988 - F1: 0.8701 - Loss: 0.1455\n",
      "\n",
      "Batch 282/387 ━━━━━━━━━━━━━━━━━━━━ 02:21:18\n",
      "Accuracy: 0.9975 - Precision: 0.8780 - Recall: 0.8837 - Specificity: 0.9988 - F1: 0.8703 - Loss: 0.1453\n",
      "\n",
      "Batch 283/387 ━━━━━━━━━━━━━━━━━━━━ 02:22:45\n",
      "Accuracy: 0.9975 - Precision: 0.8783 - Recall: 0.8837 - Specificity: 0.9988 - F1: 0.8704 - Loss: 0.1451\n",
      "\n",
      "Batch 284/387 ━━━━━━━━━━━━━━━━━━━━ 02:23:59\n",
      "Accuracy: 0.9975 - Precision: 0.8784 - Recall: 0.8840 - Specificity: 0.9988 - F1: 0.8707 - Loss: 0.1449\n",
      "\n",
      "Batch 285/387 ━━━━━━━━━━━━━━━━━━━━ 02:25:20\n",
      "Accuracy: 0.9975 - Precision: 0.8787 - Recall: 0.8840 - Specificity: 0.9989 - F1: 0.8709 - Loss: 0.1447\n",
      "\n",
      "Batch 286/387 ━━━━━━━━━━━━━━━━━━━━ 02:26:54\n",
      "Accuracy: 0.9975 - Precision: 0.8790 - Recall: 0.8840 - Specificity: 0.9989 - F1: 0.8711 - Loss: 0.1445\n",
      "\n",
      "Batch 287/387 ━━━━━━━━━━━━━━━━━━━━ 02:28:18\n",
      "Accuracy: 0.9975 - Precision: 0.8793 - Recall: 0.8838 - Specificity: 0.9989 - F1: 0.8712 - Loss: 0.1444\n",
      "\n",
      "Batch 288/387 ━━━━━━━━━━━━━━━━━━━━ 02:29:59\n",
      "Accuracy: 0.9975 - Precision: 0.8797 - Recall: 0.8839 - Specificity: 0.9989 - F1: 0.8714 - Loss: 0.1441\n",
      "\n",
      "Batch 289/387 ━━━━━━━━━━━━━━━━━━━━ 02:31:16\n",
      "Accuracy: 0.9975 - Precision: 0.8798 - Recall: 0.8840 - Specificity: 0.9989 - F1: 0.8715 - Loss: 0.1440\n",
      "\n",
      "Batch 290/387 ━━━━━━━━━━━━━━━━━━━━ 02:32:49\n",
      "Accuracy: 0.9975 - Precision: 0.8800 - Recall: 0.8841 - Specificity: 0.9989 - F1: 0.8717 - Loss: 0.1438\n",
      "\n",
      "Batch 291/387 ━━━━━━━━━━━━━━━━━━━━ 02:34:13\n",
      "Accuracy: 0.9976 - Precision: 0.8802 - Recall: 0.8842 - Specificity: 0.9989 - F1: 0.8720 - Loss: 0.1435\n",
      "\n",
      "Batch 292/387 ━━━━━━━━━━━━━━━━━━━━ 02:35:40\n",
      "Accuracy: 0.9976 - Precision: 0.8806 - Recall: 0.8844 - Specificity: 0.9989 - F1: 0.8722 - Loss: 0.1433\n",
      "\n",
      "Batch 293/387 ━━━━━━━━━━━━━━━━━━━━ 02:37:05\n",
      "Accuracy: 0.9976 - Precision: 0.8802 - Recall: 0.8843 - Specificity: 0.9989 - F1: 0.8720 - Loss: 0.1434\n",
      "\n",
      "Batch 294/387 ━━━━━━━━━━━━━━━━━━━━ 02:38:26\n",
      "Accuracy: 0.9976 - Precision: 0.8800 - Recall: 0.8841 - Specificity: 0.9989 - F1: 0.8719 - Loss: 0.1436\n",
      "\n",
      "Batch 295/387 ━━━━━━━━━━━━━━━━━━━━ 02:39:48\n",
      "Accuracy: 0.9976 - Precision: 0.8801 - Recall: 0.8844 - Specificity: 0.9989 - F1: 0.8721 - Loss: 0.1433\n",
      "\n",
      "Batch 296/387 ━━━━━━━━━━━━━━━━━━━━ 02:41:12\n",
      "Accuracy: 0.9976 - Precision: 0.8803 - Recall: 0.8847 - Specificity: 0.9989 - F1: 0.8724 - Loss: 0.1430\n",
      "\n",
      "Batch 297/387 ━━━━━━━━━━━━━━━━━━━━ 02:42:27\n",
      "Accuracy: 0.9976 - Precision: 0.8802 - Recall: 0.8850 - Specificity: 0.9989 - F1: 0.8725 - Loss: 0.1429\n",
      "\n",
      "Batch 298/387 ━━━━━━━━━━━━━━━━━━━━ 02:43:55\n",
      "Accuracy: 0.9976 - Precision: 0.8803 - Recall: 0.8852 - Specificity: 0.9989 - F1: 0.8727 - Loss: 0.1427\n",
      "\n",
      "Batch 299/387 ━━━━━━━━━━━━━━━━━━━━ 02:45:21\n",
      "Accuracy: 0.9976 - Precision: 0.8806 - Recall: 0.8854 - Specificity: 0.9989 - F1: 0.8730 - Loss: 0.1424\n",
      "\n",
      "Batch 300/387 ━━━━━━━━━━━━━━━━━━━━ 02:46:40\n",
      "Accuracy: 0.9976 - Precision: 0.8808 - Recall: 0.8857 - Specificity: 0.9989 - F1: 0.8732 - Loss: 0.1421\n",
      "\n",
      "Batch 301/387 ━━━━━━━━━━━━━━━━━━━━ 02:48:01\n",
      "Accuracy: 0.9976 - Precision: 0.8807 - Recall: 0.8857 - Specificity: 0.9989 - F1: 0.8733 - Loss: 0.1421\n",
      "\n",
      "Batch 302/387 ━━━━━━━━━━━━━━━━━━━━ 02:49:12\n",
      "Accuracy: 0.9976 - Precision: 0.8809 - Recall: 0.8858 - Specificity: 0.9989 - F1: 0.8734 - Loss: 0.1419\n",
      "\n",
      "Batch 303/387 ━━━━━━━━━━━━━━━━━━━━ 02:50:42\n",
      "Accuracy: 0.9976 - Precision: 0.8812 - Recall: 0.8860 - Specificity: 0.9989 - F1: 0.8737 - Loss: 0.1417\n",
      "\n",
      "Batch 304/387 ━━━━━━━━━━━━━━━━━━━━ 02:52:11\n",
      "Accuracy: 0.9976 - Precision: 0.8813 - Recall: 0.8855 - Specificity: 0.9989 - F1: 0.8735 - Loss: 0.1418\n",
      "\n",
      "Batch 305/387 ━━━━━━━━━━━━━━━━━━━━ 02:53:34\n",
      "Accuracy: 0.9976 - Precision: 0.8810 - Recall: 0.8857 - Specificity: 0.9989 - F1: 0.8735 - Loss: 0.1419\n",
      "\n",
      "Batch 306/387 ━━━━━━━━━━━━━━━━━━━━ 02:54:58\n",
      "Accuracy: 0.9976 - Precision: 0.8810 - Recall: 0.8859 - Specificity: 0.9989 - F1: 0.8735 - Loss: 0.1417\n",
      "\n",
      "Batch 307/387 ━━━━━━━━━━━━━━━━━━━━ 02:56:35\n",
      "Accuracy: 0.9976 - Precision: 0.8802 - Recall: 0.8855 - Specificity: 0.9989 - F1: 0.8730 - Loss: 0.1423\n",
      "\n",
      "Batch 308/387 ━━━━━━━━━━━━━━━━━━━━ 02:57:57\n",
      "Accuracy: 0.9976 - Precision: 0.8805 - Recall: 0.8850 - Specificity: 0.9989 - F1: 0.8729 - Loss: 0.1425\n",
      "\n",
      "Batch 309/387 ━━━━━━━━━━━━━━━━━━━━ 02:59:15\n",
      "Accuracy: 0.9976 - Precision: 0.8808 - Recall: 0.8851 - Specificity: 0.9989 - F1: 0.8731 - Loss: 0.1422\n",
      "\n",
      "Batch 310/387 ━━━━━━━━━━━━━━━━━━━━ 03:00:40\n",
      "Accuracy: 0.9976 - Precision: 0.8812 - Recall: 0.8847 - Specificity: 0.9989 - F1: 0.8731 - Loss: 0.1423\n",
      "\n",
      "Batch 311/387 ━━━━━━━━━━━━━━━━━━━━ 03:01:58\n",
      "Accuracy: 0.9976 - Precision: 0.8813 - Recall: 0.8849 - Specificity: 0.9989 - F1: 0.8733 - Loss: 0.1421\n",
      "\n",
      "Batch 312/387 ━━━━━━━━━━━━━━━━━━━━ 03:03:11\n",
      "Accuracy: 0.9976 - Precision: 0.8815 - Recall: 0.8848 - Specificity: 0.9989 - F1: 0.8733 - Loss: 0.1420\n",
      "\n",
      "Batch 313/387 ━━━━━━━━━━━━━━━━━━━━ 03:04:33\n",
      "Accuracy: 0.9976 - Precision: 0.8817 - Recall: 0.8851 - Specificity: 0.9989 - F1: 0.8736 - Loss: 0.1417\n",
      "\n",
      "Batch 314/387 ━━━━━━━━━━━━━━━━━━━━ 03:06:05\n",
      "Accuracy: 0.9976 - Precision: 0.8819 - Recall: 0.8854 - Specificity: 0.9989 - F1: 0.8739 - Loss: 0.1415\n",
      "\n",
      "Batch 315/387 ━━━━━━━━━━━━━━━━━━━━ 03:07:26\n",
      "Accuracy: 0.9976 - Precision: 0.8816 - Recall: 0.8853 - Specificity: 0.9989 - F1: 0.8737 - Loss: 0.1416\n",
      "\n",
      "Batch 316/387 ━━━━━━━━━━━━━━━━━━━━ 03:08:46\n",
      "Accuracy: 0.9976 - Precision: 0.8813 - Recall: 0.8857 - Specificity: 0.9989 - F1: 0.8737 - Loss: 0.1416\n",
      "\n",
      "Batch 317/387 ━━━━━━━━━━━━━━━━━━━━ 03:10:13\n",
      "Accuracy: 0.9976 - Precision: 0.8816 - Recall: 0.8859 - Specificity: 0.9989 - F1: 0.8740 - Loss: 0.1413\n",
      "\n",
      "Batch 318/387 ━━━━━━━━━━━━━━━━━━━━ 03:11:28\n",
      "Accuracy: 0.9976 - Precision: 0.8818 - Recall: 0.8859 - Specificity: 0.9989 - F1: 0.8742 - Loss: 0.1411\n",
      "\n",
      "Batch 319/387 ━━━━━━━━━━━━━━━━━━━━ 03:12:44\n",
      "Accuracy: 0.9976 - Precision: 0.8821 - Recall: 0.8860 - Specificity: 0.9989 - F1: 0.8744 - Loss: 0.1409\n",
      "\n",
      "Batch 320/387 ━━━━━━━━━━━━━━━━━━━━ 03:14:01\n",
      "Accuracy: 0.9976 - Precision: 0.8822 - Recall: 0.8862 - Specificity: 0.9989 - F1: 0.8745 - Loss: 0.1407\n",
      "\n",
      "Batch 321/387 ━━━━━━━━━━━━━━━━━━━━ 03:15:34\n",
      "Accuracy: 0.9976 - Precision: 0.8823 - Recall: 0.8862 - Specificity: 0.9989 - F1: 0.8746 - Loss: 0.1406\n",
      "\n",
      "Batch 322/387 ━━━━━━━━━━━━━━━━━━━━ 03:16:47\n",
      "Accuracy: 0.9976 - Precision: 0.8826 - Recall: 0.8864 - Specificity: 0.9989 - F1: 0.8749 - Loss: 0.1403\n",
      "\n",
      "Batch 323/387 ━━━━━━━━━━━━━━━━━━━━ 03:18:14\n",
      "Accuracy: 0.9976 - Precision: 0.8829 - Recall: 0.8858 - Specificity: 0.9989 - F1: 0.8747 - Loss: 0.1406\n",
      "\n",
      "Batch 324/387 ━━━━━━━━━━━━━━━━━━━━ 03:19:37\n",
      "Accuracy: 0.9976 - Precision: 0.8825 - Recall: 0.8861 - Specificity: 0.9989 - F1: 0.8746 - Loss: 0.1407\n",
      "\n",
      "Batch 325/387 ━━━━━━━━━━━━━━━━━━━━ 03:21:02\n",
      "Accuracy: 0.9976 - Precision: 0.8823 - Recall: 0.8861 - Specificity: 0.9989 - F1: 0.8746 - Loss: 0.1407\n",
      "\n",
      "Batch 326/387 ━━━━━━━━━━━━━━━━━━━━ 03:22:30\n",
      "Accuracy: 0.9976 - Precision: 0.8822 - Recall: 0.8863 - Specificity: 0.9989 - F1: 0.8746 - Loss: 0.1406\n",
      "\n",
      "Batch 327/387 ━━━━━━━━━━━━━━━━━━━━ 03:23:55\n",
      "Accuracy: 0.9976 - Precision: 0.8821 - Recall: 0.8866 - Specificity: 0.9989 - F1: 0.8748 - Loss: 0.1405\n",
      "\n",
      "Batch 328/387 ━━━━━━━━━━━━━━━━━━━━ 03:25:19\n",
      "Accuracy: 0.9976 - Precision: 0.8824 - Recall: 0.8862 - Specificity: 0.9989 - F1: 0.8747 - Loss: 0.1406\n",
      "\n",
      "Batch 329/387 ━━━━━━━━━━━━━━━━━━━━ 03:26:48\n",
      "Accuracy: 0.9976 - Precision: 0.8827 - Recall: 0.8860 - Specificity: 0.9989 - F1: 0.8748 - Loss: 0.1405\n",
      "\n",
      "Batch 330/387 ━━━━━━━━━━━━━━━━━━━━ 03:28:13\n",
      "Accuracy: 0.9976 - Precision: 0.8830 - Recall: 0.8861 - Specificity: 0.9989 - F1: 0.8750 - Loss: 0.1403\n",
      "\n",
      "Batch 331/387 ━━━━━━━━━━━━━━━━━━━━ 03:29:34\n",
      "Accuracy: 0.9976 - Precision: 0.8824 - Recall: 0.8859 - Specificity: 0.9989 - F1: 0.8746 - Loss: 0.1406\n",
      "\n",
      "Batch 332/387 ━━━━━━━━━━━━━━━━━━━━ 03:30:59\n",
      "Accuracy: 0.9976 - Precision: 0.8826 - Recall: 0.8848 - Specificity: 0.9989 - F1: 0.8740 - Loss: 0.1413\n",
      "\n",
      "Batch 333/387 ━━━━━━━━━━━━━━━━━━━━ 03:32:29\n",
      "Accuracy: 0.9976 - Precision: 0.8821 - Recall: 0.8850 - Specificity: 0.9989 - F1: 0.8738 - Loss: 0.1415\n",
      "\n",
      "Batch 334/387 ━━━━━━━━━━━━━━━━━━━━ 03:33:38\n",
      "Accuracy: 0.9976 - Precision: 0.8823 - Recall: 0.8847 - Specificity: 0.9989 - F1: 0.8738 - Loss: 0.1416\n",
      "\n",
      "Batch 335/387 ━━━━━━━━━━━━━━━━━━━━ 03:34:59\n",
      "Accuracy: 0.9976 - Precision: 0.8824 - Recall: 0.8850 - Specificity: 0.9989 - F1: 0.8740 - Loss: 0.1414\n",
      "\n",
      "Batch 336/387 ━━━━━━━━━━━━━━━━━━━━ 03:36:21\n",
      "Accuracy: 0.9976 - Precision: 0.8824 - Recall: 0.8852 - Specificity: 0.9989 - F1: 0.8741 - Loss: 0.1412\n",
      "\n",
      "Batch 337/387 ━━━━━━━━━━━━━━━━━━━━ 03:37:45\n",
      "Accuracy: 0.9976 - Precision: 0.8825 - Recall: 0.8854 - Specificity: 0.9989 - F1: 0.8743 - Loss: 0.1411\n",
      "\n",
      "Batch 338/387 ━━━━━━━━━━━━━━━━━━━━ 03:39:02\n",
      "Accuracy: 0.9976 - Precision: 0.8824 - Recall: 0.8855 - Specificity: 0.9989 - F1: 0.8743 - Loss: 0.1410\n",
      "\n",
      "Batch 339/387 ━━━━━━━━━━━━━━━━━━━━ 03:40:21\n",
      "Accuracy: 0.9976 - Precision: 0.8826 - Recall: 0.8858 - Specificity: 0.9989 - F1: 0.8746 - Loss: 0.1408\n",
      "\n",
      "Batch 340/387 ━━━━━━━━━━━━━━━━━━━━ 03:41:46\n",
      "Accuracy: 0.9976 - Precision: 0.8826 - Recall: 0.8859 - Specificity: 0.9989 - F1: 0.8747 - Loss: 0.1406\n",
      "\n",
      "Batch 341/387 ━━━━━━━━━━━━━━━━━━━━ 03:43:20\n",
      "Accuracy: 0.9976 - Precision: 0.8824 - Recall: 0.8862 - Specificity: 0.9989 - F1: 0.8747 - Loss: 0.1407\n",
      "\n",
      "Batch 342/387 ━━━━━━━━━━━━━━━━━━━━ 03:44:39\n",
      "Accuracy: 0.9976 - Precision: 0.8818 - Recall: 0.8865 - Specificity: 0.9989 - F1: 0.8745 - Loss: 0.1409\n",
      "\n",
      "Batch 343/387 ━━━━━━━━━━━━━━━━━━━━ 03:46:18\n",
      "Accuracy: 0.9976 - Precision: 0.8819 - Recall: 0.8861 - Specificity: 0.9989 - F1: 0.8743 - Loss: 0.1410\n",
      "\n",
      "Batch 344/387 ━━━━━━━━━━━━━━━━━━━━ 03:48:14\n",
      "Accuracy: 0.9976 - Precision: 0.8820 - Recall: 0.8861 - Specificity: 0.9989 - F1: 0.8744 - Loss: 0.1409\n",
      "\n",
      "Batch 345/387 ━━━━━━━━━━━━━━━━━━━━ 03:49:38\n",
      "Accuracy: 0.9976 - Precision: 0.8823 - Recall: 0.8861 - Specificity: 0.9989 - F1: 0.8746 - Loss: 0.1407\n",
      "\n",
      "Batch 346/387 ━━━━━━━━━━━━━━━━━━━━ 03:51:00\n",
      "Accuracy: 0.9976 - Precision: 0.8824 - Recall: 0.8862 - Specificity: 0.9989 - F1: 0.8748 - Loss: 0.1405\n",
      "\n",
      "Batch 347/387 ━━━━━━━━━━━━━━━━━━━━ 03:52:11\n",
      "Accuracy: 0.9976 - Precision: 0.8826 - Recall: 0.8857 - Specificity: 0.9989 - F1: 0.8746 - Loss: 0.1407\n",
      "\n",
      "Batch 348/387 ━━━━━━━━━━━━━━━━━━━━ 03:53:46\n",
      "Accuracy: 0.9976 - Precision: 0.8826 - Recall: 0.8860 - Specificity: 0.9989 - F1: 0.8747 - Loss: 0.1406\n",
      "\n",
      "Batch 349/387 ━━━━━━━━━━━━━━━━━━━━ 03:55:23\n",
      "Accuracy: 0.9976 - Precision: 0.8828 - Recall: 0.8861 - Specificity: 0.9989 - F1: 0.8749 - Loss: 0.1403\n",
      "\n",
      "Batch 350/387 ━━━━━━━━━━━━━━━━━━━━ 03:56:45\n",
      "Accuracy: 0.9976 - Precision: 0.8827 - Recall: 0.8862 - Specificity: 0.9989 - F1: 0.8749 - Loss: 0.1403\n",
      "\n",
      "Batch 351/387 ━━━━━━━━━━━━━━━━━━━━ 03:58:13\n",
      "Accuracy: 0.9976 - Precision: 0.8828 - Recall: 0.8864 - Specificity: 0.9989 - F1: 0.8751 - Loss: 0.1401\n",
      "\n",
      "Batch 352/387 ━━━━━━━━━━━━━━━━━━━━ 03:59:25\n",
      "Accuracy: 0.9976 - Precision: 0.8829 - Recall: 0.8866 - Specificity: 0.9989 - F1: 0.8753 - Loss: 0.1399\n",
      "\n",
      "Batch 353/387 ━━━━━━━━━━━━━━━━━━━━ 04:00:53\n",
      "Accuracy: 0.9976 - Precision: 0.8831 - Recall: 0.8867 - Specificity: 0.9989 - F1: 0.8755 - Loss: 0.1397\n",
      "\n",
      "Batch 354/387 ━━━━━━━━━━━━━━━━━━━━ 04:02:20\n",
      "Accuracy: 0.9976 - Precision: 0.8832 - Recall: 0.8870 - Specificity: 0.9989 - F1: 0.8757 - Loss: 0.1395\n",
      "\n",
      "Batch 355/387 ━━━━━━━━━━━━━━━━━━━━ 04:03:55\n",
      "Accuracy: 0.9976 - Precision: 0.8833 - Recall: 0.8871 - Specificity: 0.9989 - F1: 0.8758 - Loss: 0.1393\n",
      "\n",
      "Batch 356/387 ━━━━━━━━━━━━━━━━━━━━ 04:05:18\n",
      "Accuracy: 0.9976 - Precision: 0.8836 - Recall: 0.8870 - Specificity: 0.9989 - F1: 0.8759 - Loss: 0.1393\n",
      "\n",
      "Batch 357/387 ━━━━━━━━━━━━━━━━━━━━ 04:06:34\n",
      "Accuracy: 0.9976 - Precision: 0.8818 - Recall: 0.8868 - Specificity: 0.9989 - F1: 0.8745 - Loss: 0.1408\n",
      "\n",
      "Batch 358/387 ━━━━━━━━━━━━━━━━━━━━ 04:08:09\n",
      "Accuracy: 0.9976 - Precision: 0.8820 - Recall: 0.8870 - Specificity: 0.9989 - F1: 0.8747 - Loss: 0.1405\n",
      "\n",
      "Batch 359/387 ━━━━━━━━━━━━━━━━━━━━ 04:09:32\n",
      "Accuracy: 0.9976 - Precision: 0.8820 - Recall: 0.8873 - Specificity: 0.9989 - F1: 0.8749 - Loss: 0.1403\n",
      "\n",
      "Batch 360/387 ━━━━━━━━━━━━━━━━━━━━ 04:10:50\n",
      "Accuracy: 0.9976 - Precision: 0.8822 - Recall: 0.8871 - Specificity: 0.9989 - F1: 0.8749 - Loss: 0.1403\n",
      "\n",
      "Batch 361/387 ━━━━━━━━━━━━━━━━━━━━ 09:35:09\n",
      "Accuracy: 0.9976 - Precision: 0.8824 - Recall: 0.8872 - Specificity: 0.9989 - F1: 0.8751 - Loss: 0.1401\n",
      "\n",
      "Batch 362/387 ━━━━━━━━━━━━━━━━━━━━ 09:36:45\n",
      "Accuracy: 0.9976 - Precision: 0.8826 - Recall: 0.8869 - Specificity: 0.9989 - F1: 0.8750 - Loss: 0.1401\n",
      "\n",
      "Batch 363/387 ━━━━━━━━━━━━━━━━━━━━ 09:38:14\n",
      "Accuracy: 0.9976 - Precision: 0.8826 - Recall: 0.8866 - Specificity: 0.9989 - F1: 0.8749 - Loss: 0.1403\n",
      "\n",
      "Batch 364/387 ━━━━━━━━━━━━━━━━━━━━ 09:39:49\n",
      "Accuracy: 0.9976 - Precision: 0.8828 - Recall: 0.8865 - Specificity: 0.9989 - F1: 0.8750 - Loss: 0.1401\n",
      "\n",
      "Batch 365/387 ━━━━━━━━━━━━━━━━━━━━ 09:41:27\n",
      "Accuracy: 0.9976 - Precision: 0.8829 - Recall: 0.8867 - Specificity: 0.9989 - F1: 0.8752 - Loss: 0.1400\n",
      "\n",
      "Batch 366/387 ━━━━━━━━━━━━━━━━━━━━ 09:42:59\n",
      "Accuracy: 0.9976 - Precision: 0.8832 - Recall: 0.8866 - Specificity: 0.9989 - F1: 0.8753 - Loss: 0.1398\n",
      "\n",
      "Batch 367/387 ━━━━━━━━━━━━━━━━━━━━ 09:44:28\n",
      "Accuracy: 0.9976 - Precision: 0.8832 - Recall: 0.8868 - Specificity: 0.9989 - F1: 0.8754 - Loss: 0.1397\n",
      "\n",
      "Batch 368/387 ━━━━━━━━━━━━━━━━━━━━ 09:46:01\n",
      "Accuracy: 0.9976 - Precision: 0.8830 - Recall: 0.8866 - Specificity: 0.9989 - F1: 0.8752 - Loss: 0.1399\n",
      "\n",
      "Batch 369/387 ━━━━━━━━━━━━━━━━━━━━ 09:47:32\n",
      "Accuracy: 0.9976 - Precision: 0.8833 - Recall: 0.8864 - Specificity: 0.9989 - F1: 0.8753 - Loss: 0.1398\n",
      "\n",
      "Batch 370/387 ━━━━━━━━━━━━━━━━━━━━ 09:49:04\n",
      "Accuracy: 0.9976 - Precision: 0.8836 - Recall: 0.8864 - Specificity: 0.9989 - F1: 0.8754 - Loss: 0.1397\n",
      "\n",
      "Batch 371/387 ━━━━━━━━━━━━━━━━━━━━ 09:50:46\n",
      "Accuracy: 0.9976 - Precision: 0.8838 - Recall: 0.8864 - Specificity: 0.9989 - F1: 0.8755 - Loss: 0.1396\n",
      "\n",
      "Batch 372/387 ━━━━━━━━━━━━━━━━━━━━ 09:52:22\n",
      "Accuracy: 0.9976 - Precision: 0.8837 - Recall: 0.8861 - Specificity: 0.9989 - F1: 0.8754 - Loss: 0.1397\n",
      "\n",
      "Batch 373/387 ━━━━━━━━━━━━━━━━━━━━ 09:53:55\n",
      "Accuracy: 0.9976 - Precision: 0.8840 - Recall: 0.8863 - Specificity: 0.9989 - F1: 0.8757 - Loss: 0.1394\n",
      "\n",
      "Batch 374/387 ━━━━━━━━━━━━━━━━━━━━ 09:55:28\n",
      "Accuracy: 0.9976 - Precision: 0.8841 - Recall: 0.8863 - Specificity: 0.9989 - F1: 0.8758 - Loss: 0.1393\n",
      "\n",
      "Batch 375/387 ━━━━━━━━━━━━━━━━━━━━ 09:56:56\n",
      "Accuracy: 0.9976 - Precision: 0.8843 - Recall: 0.8863 - Specificity: 0.9989 - F1: 0.8758 - Loss: 0.1393\n",
      "\n",
      "Batch 376/387 ━━━━━━━━━━━━━━━━━━━━ 09:58:24\n",
      "Accuracy: 0.9976 - Precision: 0.8842 - Recall: 0.8862 - Specificity: 0.9989 - F1: 0.8758 - Loss: 0.1393\n",
      "\n",
      "Batch 377/387 ━━━━━━━━━━━━━━━━━━━━ 09:59:49\n",
      "Accuracy: 0.9976 - Precision: 0.8839 - Recall: 0.8864 - Specificity: 0.9989 - F1: 0.8757 - Loss: 0.1394\n",
      "\n",
      "Batch 378/387 ━━━━━━━━━━━━━━━━━━━━ 10:01:18\n",
      "Accuracy: 0.9976 - Precision: 0.8839 - Recall: 0.8864 - Specificity: 0.9989 - F1: 0.8757 - Loss: 0.1394\n",
      "\n",
      "Batch 379/387 ━━━━━━━━━━━━━━━━━━━━ 10:02:46\n",
      "Accuracy: 0.9976 - Precision: 0.8824 - Recall: 0.8865 - Specificity: 0.9989 - F1: 0.8747 - Loss: 0.1405\n",
      "\n",
      "Batch 380/387 ━━━━━━━━━━━━━━━━━━━━ 10:04:11\n",
      "Accuracy: 0.9976 - Precision: 0.8819 - Recall: 0.8859 - Specificity: 0.9989 - F1: 0.8742 - Loss: 0.1411\n",
      "\n",
      "Batch 381/387 ━━━━━━━━━━━━━━━━━━━━ 10:05:49\n",
      "Accuracy: 0.9976 - Precision: 0.8814 - Recall: 0.8861 - Specificity: 0.9989 - F1: 0.8740 - Loss: 0.1413\n",
      "\n",
      "Batch 382/387 ━━━━━━━━━━━━━━━━━━━━ 10:07:26\n",
      "Accuracy: 0.9976 - Precision: 0.8814 - Recall: 0.8861 - Specificity: 0.9989 - F1: 0.8740 - Loss: 0.1413\n",
      "\n",
      "Batch 383/387 ━━━━━━━━━━━━━━━━━━━━ 10:08:52\n",
      "Accuracy: 0.9976 - Precision: 0.8815 - Recall: 0.8861 - Specificity: 0.9989 - F1: 0.8741 - Loss: 0.1412\n",
      "\n",
      "Batch 384/387 ━━━━━━━━━━━━━━━━━━━━ 10:10:17\n",
      "Accuracy: 0.9976 - Precision: 0.8817 - Recall: 0.8858 - Specificity: 0.9989 - F1: 0.8740 - Loss: 0.1413\n",
      "\n",
      "Batch 385/387 ━━━━━━━━━━━━━━━━━━━━ 10:11:54\n",
      "Accuracy: 0.9976 - Precision: 0.8814 - Recall: 0.8847 - Specificity: 0.9989 - F1: 0.8733 - Loss: 0.1420\n",
      "\n",
      "Batch 386/387 ━━━━━━━━━━━━━━━━━━━━ 10:13:37\n",
      "Accuracy: 0.9976 - Precision: 0.8815 - Recall: 0.8842 - Specificity: 0.9989 - F1: 0.8731 - Loss: 0.1423\n",
      "\n",
      "Batch 387/387 ━━━━━━━━━━━━━━━━━━━━ 10:14:57\n",
      "Accuracy: 0.9976 - Precision: 0.8814 - Recall: 0.8842 - Specificity: 0.9989 - F1: 0.8730 - Loss: 0.1423\n",
      "\n",
      "End of Epoch 10\n",
      "\n",
      "Epoch 11/50\n",
      "Batch 1/387 ━━━━━━━━━━━━━━━━━━━━ 10:36:49\n",
      "Accuracy: 0.9958 - Precision: 0.9493 - Recall: 0.8234 - Specificity: 0.9991 - F1: 0.8819 - Loss: 0.1401\n",
      "\n",
      "Batch 2/387 ━━━━━━━━━━━━━━━━━━━━ 10:38:24\n",
      "Accuracy: 0.9973 - Precision: 0.9620 - Recall: 0.8918 - Specificity: 0.9993 - F1: 0.9246 - Loss: 0.0898\n",
      "\n",
      "Batch 3/387 ━━━━━━━━━━━━━━━━━━━━ 10:39:48\n",
      "Accuracy: 0.9976 - Precision: 0.9298 - Recall: 0.9254 - Specificity: 0.9990 - F1: 0.9246 - Loss: 0.0875\n",
      "\n",
      "Batch 4/387 ━━━━━━━━━━━━━━━━━━━━ 10:41:21\n",
      "Accuracy: 0.9975 - Precision: 0.9249 - Recall: 0.9345 - Specificity: 0.9987 - F1: 0.9273 - Loss: 0.0851\n",
      "\n",
      "Batch 5/387 ━━━━━━━━━━━━━━━━━━━━ 10:42:37\n",
      "Accuracy: 0.9976 - Precision: 0.9220 - Recall: 0.9403 - Specificity: 0.9987 - F1: 0.9291 - Loss: 0.0828\n",
      "\n",
      "Batch 6/387 ━━━━━━━━━━━━━━━━━━━━ 10:43:58\n",
      "Accuracy: 0.9978 - Precision: 0.9145 - Recall: 0.9459 - Specificity: 0.9987 - F1: 0.9281 - Loss: 0.0834\n",
      "\n",
      "Batch 7/387 ━━━━━━━━━━━━━━━━━━━━ 10:45:23\n",
      "Accuracy: 0.9977 - Precision: 0.9188 - Recall: 0.9432 - Specificity: 0.9987 - F1: 0.9292 - Loss: 0.0824\n",
      "\n",
      "Batch 8/387 ━━━━━━━━━━━━━━━━━━━━ 10:47:03\n",
      "Accuracy: 0.9973 - Precision: 0.9063 - Recall: 0.9143 - Specificity: 0.9987 - F1: 0.9082 - Loss: 0.1062\n",
      "\n",
      "Batch 9/387 ━━━━━━━━━━━━━━━━━━━━ 10:48:30\n",
      "Accuracy: 0.9975 - Precision: 0.9103 - Recall: 0.9185 - Specificity: 0.9987 - F1: 0.9125 - Loss: 0.1012\n",
      "\n",
      "Batch 10/387 ━━━━━━━━━━━━━━━━━━━━ 10:50:01\n",
      "Accuracy: 0.9974 - Precision: 0.9002 - Recall: 0.9240 - Specificity: 0.9986 - F1: 0.9097 - Loss: 0.1042\n",
      "\n",
      "Batch 11/387 ━━━━━━━━━━━━━━━━━━━━ 10:51:37\n",
      "Accuracy: 0.9974 - Precision: 0.8896 - Recall: 0.9227 - Specificity: 0.9985 - F1: 0.9036 - Loss: 0.1105\n",
      "\n",
      "Batch 12/387 ━━━━━━━━━━━━━━━━━━━━ 10:53:09\n",
      "Accuracy: 0.9974 - Precision: 0.8823 - Recall: 0.9186 - Specificity: 0.9985 - F1: 0.8979 - Loss: 0.1165\n",
      "\n",
      "Batch 13/387 ━━━━━━━━━━━━━━━━━━━━ 10:54:44\n",
      "Accuracy: 0.9975 - Precision: 0.8893 - Recall: 0.9152 - Specificity: 0.9986 - F1: 0.8997 - Loss: 0.1147\n",
      "\n",
      "Batch 14/387 ━━━━━━━━━━━━━━━━━━━━ 10:56:21\n",
      "Accuracy: 0.9975 - Precision: 0.8900 - Recall: 0.9174 - Specificity: 0.9986 - F1: 0.9013 - Loss: 0.1129\n",
      "\n",
      "Batch 15/387 ━━━━━━━━━━━━━━━━━━━━ 10:57:52\n",
      "Accuracy: 0.9975 - Precision: 0.8786 - Recall: 0.9141 - Specificity: 0.9986 - F1: 0.8936 - Loss: 0.1206\n",
      "\n",
      "Batch 16/387 ━━━━━━━━━━━━━━━━━━━━ 10:59:24\n",
      "Accuracy: 0.9974 - Precision: 0.8859 - Recall: 0.9112 - Specificity: 0.9986 - F1: 0.8958 - Loss: 0.1187\n",
      "\n",
      "Batch 17/387 ━━━━━━━━━━━━━━━━━━━━ 11:00:55\n",
      "Accuracy: 0.9975 - Precision: 0.8794 - Recall: 0.9094 - Specificity: 0.9987 - F1: 0.8915 - Loss: 0.1227\n",
      "\n",
      "Batch 18/387 ━━━━━━━━━━━━━━━━━━━━ 11:02:28\n",
      "Accuracy: 0.9976 - Precision: 0.8852 - Recall: 0.9065 - Specificity: 0.9987 - F1: 0.8929 - Loss: 0.1211\n",
      "\n",
      "Batch 19/387 ━━━━━━━━━━━━━━━━━━━━ 11:04:00\n",
      "Accuracy: 0.9976 - Precision: 0.8740 - Recall: 0.9007 - Specificity: 0.9987 - F1: 0.8843 - Loss: 0.1298\n",
      "\n",
      "Batch 20/387 ━━━━━━━━━━━━━━━━━━━━ 11:05:31\n",
      "Accuracy: 0.9976 - Precision: 0.8788 - Recall: 0.9004 - Specificity: 0.9988 - F1: 0.8866 - Loss: 0.1278\n",
      "\n",
      "Batch 21/387 ━━━━━━━━━━━━━━━━━━━━ 11:07:02\n",
      "Accuracy: 0.9976 - Precision: 0.8820 - Recall: 0.8992 - Specificity: 0.9988 - F1: 0.8877 - Loss: 0.1263\n",
      "\n",
      "Batch 22/387 ━━━━━━━━━━━━━━━━━━━━ 11:08:20\n",
      "Accuracy: 0.9977 - Precision: 0.8813 - Recall: 0.9014 - Specificity: 0.9989 - F1: 0.8885 - Loss: 0.1251\n",
      "\n",
      "Batch 23/387 ━━━━━━━━━━━━━━━━━━━━ 11:10:02\n",
      "Accuracy: 0.9978 - Precision: 0.8704 - Recall: 0.9046 - Specificity: 0.9989 - F1: 0.8832 - Loss: 0.1303\n",
      "\n",
      "Batch 24/387 ━━━━━━━━━━━━━━━━━━━━ 11:11:37\n",
      "Accuracy: 0.9978 - Precision: 0.8755 - Recall: 0.9017 - Specificity: 0.9989 - F1: 0.8842 - Loss: 0.1297\n",
      "\n",
      "Batch 25/387 ━━━━━━━━━━━━━━━━━━━━ 11:13:00\n",
      "Accuracy: 0.9978 - Precision: 0.8769 - Recall: 0.9025 - Specificity: 0.9989 - F1: 0.8854 - Loss: 0.1282\n",
      "\n",
      "Batch 26/387 ━━━━━━━━━━━━━━━━━━━━ 11:14:22\n",
      "Accuracy: 0.9977 - Precision: 0.8812 - Recall: 0.9002 - Specificity: 0.9990 - F1: 0.8864 - Loss: 0.1277\n",
      "\n",
      "Batch 27/387 ━━━━━━━━━━━━━━━━━━━━ 11:16:12\n",
      "Accuracy: 0.9977 - Precision: 0.8802 - Recall: 0.8933 - Specificity: 0.9990 - F1: 0.8823 - Loss: 0.1321\n",
      "\n",
      "Batch 28/387 ━━━━━━━━━━━━━━━━━━━━ 11:17:51\n",
      "Accuracy: 0.9977 - Precision: 0.8835 - Recall: 0.8947 - Specificity: 0.9990 - F1: 0.8849 - Loss: 0.1293\n",
      "\n",
      "Batch 29/387 ━━━━━━━━━━━━━━━━━━━━ 11:19:18\n",
      "Accuracy: 0.9977 - Precision: 0.8869 - Recall: 0.8959 - Specificity: 0.9990 - F1: 0.8873 - Loss: 0.1268\n",
      "\n",
      "Batch 30/387 ━━━━━━━━━━━━━━━━━━━━ 11:20:36\n",
      "Accuracy: 0.9978 - Precision: 0.8874 - Recall: 0.8959 - Specificity: 0.9990 - F1: 0.8877 - Loss: 0.1261\n",
      "\n",
      "Batch 31/387 ━━━━━━━━━━━━━━━━━━━━ 11:22:19\n",
      "Accuracy: 0.9978 - Precision: 0.8899 - Recall: 0.8978 - Specificity: 0.9991 - F1: 0.8900 - Loss: 0.1235\n",
      "\n",
      "Batch 32/387 ━━━━━━━━━━━━━━━━━━━━ 11:24:12\n",
      "Accuracy: 0.9978 - Precision: 0.8928 - Recall: 0.8918 - Specificity: 0.9991 - F1: 0.8878 - Loss: 0.1259\n",
      "\n",
      "Batch 33/387 ━━━━━━━━━━━━━━━━━━━━ 11:25:46\n",
      "Accuracy: 0.9978 - Precision: 0.8866 - Recall: 0.8947 - Specificity: 0.9991 - F1: 0.8855 - Loss: 0.1284\n",
      "\n",
      "Batch 34/387 ━━━━━━━━━━━━━━━━━━━━ 11:27:04\n",
      "Accuracy: 0.9978 - Precision: 0.8893 - Recall: 0.8920 - Specificity: 0.9991 - F1: 0.8854 - Loss: 0.1284\n",
      "\n",
      "Batch 35/387 ━━━━━━━━━━━━━━━━━━━━ 11:28:44\n",
      "Accuracy: 0.9979 - Precision: 0.8915 - Recall: 0.8927 - Specificity: 0.9991 - F1: 0.8870 - Loss: 0.1267\n",
      "\n",
      "Batch 36/387 ━━━━━━━━━━━━━━━━━━━━ 11:30:02\n",
      "Accuracy: 0.9978 - Precision: 0.8927 - Recall: 0.8911 - Specificity: 0.9991 - F1: 0.8869 - Loss: 0.1271\n",
      "\n",
      "Batch 37/387 ━━━━━━━━━━━━━━━━━━━━ 11:31:27\n",
      "Accuracy: 0.9978 - Precision: 0.8865 - Recall: 0.8931 - Specificity: 0.9991 - F1: 0.8842 - Loss: 0.1297\n",
      "\n",
      "Batch 38/387 ━━━━━━━━━━━━━━━━━━━━ 11:32:48\n",
      "Accuracy: 0.9978 - Precision: 0.8836 - Recall: 0.8946 - Specificity: 0.9991 - F1: 0.8834 - Loss: 0.1305\n",
      "\n",
      "Batch 39/387 ━━━━━━━━━━━━━━━━━━━━ 11:34:34\n",
      "Accuracy: 0.9978 - Precision: 0.8861 - Recall: 0.8957 - Specificity: 0.9991 - F1: 0.8853 - Loss: 0.1284\n",
      "\n",
      "Batch 40/387 ━━━━━━━━━━━━━━━━━━━━ 11:36:10\n",
      "Accuracy: 0.9978 - Precision: 0.8881 - Recall: 0.8947 - Specificity: 0.9991 - F1: 0.8858 - Loss: 0.1279\n",
      "\n",
      "Batch 41/387 ━━━━━━━━━━━━━━━━━━━━ 11:37:35\n",
      "Accuracy: 0.9978 - Precision: 0.8901 - Recall: 0.8942 - Specificity: 0.9991 - F1: 0.8867 - Loss: 0.1269\n",
      "\n",
      "Batch 42/387 ━━━━━━━━━━━━━━━━━━━━ 11:39:15\n",
      "Accuracy: 0.9979 - Precision: 0.8885 - Recall: 0.8961 - Specificity: 0.9991 - F1: 0.8868 - Loss: 0.1266\n",
      "\n",
      "Batch 43/387 ━━━━━━━━━━━━━━━━━━━━ 11:40:47\n",
      "Accuracy: 0.9979 - Precision: 0.8908 - Recall: 0.8969 - Specificity: 0.9991 - F1: 0.8884 - Loss: 0.1249\n",
      "\n",
      "Batch 44/387 ━━━━━━━━━━━━━━━━━━━━ 11:42:13\n",
      "Accuracy: 0.9979 - Precision: 0.8903 - Recall: 0.8960 - Specificity: 0.9991 - F1: 0.8879 - Loss: 0.1255\n",
      "\n",
      "Batch 45/387 ━━━━━━━━━━━━━━━━━━━━ 11:43:38\n",
      "Accuracy: 0.9979 - Precision: 0.8924 - Recall: 0.8964 - Specificity: 0.9991 - F1: 0.8892 - Loss: 0.1240\n",
      "\n",
      "Batch 46/387 ━━━━━━━━━━━━━━━━━━━━ 11:45:08\n",
      "Accuracy: 0.9979 - Precision: 0.8942 - Recall: 0.8958 - Specificity: 0.9991 - F1: 0.8899 - Loss: 0.1233\n",
      "\n",
      "Batch 47/387 ━━━━━━━━━━━━━━━━━━━━ 11:46:48\n",
      "Accuracy: 0.9979 - Precision: 0.8934 - Recall: 0.8973 - Specificity: 0.9991 - F1: 0.8902 - Loss: 0.1229\n",
      "\n",
      "Batch 48/387 ━━━━━━━━━━━━━━━━━━━━ 11:48:24\n",
      "Accuracy: 0.9979 - Precision: 0.8946 - Recall: 0.8988 - Specificity: 0.9991 - F1: 0.8917 - Loss: 0.1213\n",
      "\n",
      "Batch 49/387 ━━━━━━━━━━━━━━━━━━━━ 11:49:57\n",
      "Accuracy: 0.9980 - Precision: 0.8959 - Recall: 0.8998 - Specificity: 0.9992 - F1: 0.8929 - Loss: 0.1199\n",
      "\n",
      "Batch 50/387 ━━━━━━━━━━━━━━━━━━━━ 11:51:29\n",
      "Accuracy: 0.9980 - Precision: 0.8972 - Recall: 0.9002 - Specificity: 0.9992 - F1: 0.8939 - Loss: 0.1189\n",
      "\n",
      "Batch 51/387 ━━━━━━━━━━━━━━━━━━━━ 11:52:48\n",
      "Accuracy: 0.9980 - Precision: 0.8981 - Recall: 0.9010 - Specificity: 0.9992 - F1: 0.8948 - Loss: 0.1179\n",
      "\n",
      "Batch 52/387 ━━━━━━━━━━━━━━━━━━━━ 11:54:18\n",
      "Accuracy: 0.9980 - Precision: 0.8976 - Recall: 0.9015 - Specificity: 0.9992 - F1: 0.8949 - Loss: 0.1177\n",
      "\n",
      "Batch 53/387 ━━━━━━━━━━━━━━━━━━━━ 11:55:47\n",
      "Accuracy: 0.9979 - Precision: 0.8959 - Recall: 0.9021 - Specificity: 0.9991 - F1: 0.8944 - Loss: 0.1185\n",
      "\n",
      "Batch 54/387 ━━━━━━━━━━━━━━━━━━━━ 11:57:24\n",
      "Accuracy: 0.9979 - Precision: 0.8976 - Recall: 0.8996 - Specificity: 0.9991 - F1: 0.8937 - Loss: 0.1196\n",
      "\n",
      "Batch 55/387 ━━━━━━━━━━━━━━━━━━━━ 11:59:11\n",
      "Accuracy: 0.9979 - Precision: 0.8976 - Recall: 0.9003 - Specificity: 0.9991 - F1: 0.8942 - Loss: 0.1191\n",
      "\n",
      "Batch 56/387 ━━━━━━━━━━━━━━━━━━━━ 12:00:41\n",
      "Accuracy: 0.9979 - Precision: 0.8985 - Recall: 0.9010 - Specificity: 0.9991 - F1: 0.8951 - Loss: 0.1181\n",
      "\n",
      "Batch 57/387 ━━━━━━━━━━━━━━━━━━━━ 12:02:15\n",
      "Accuracy: 0.9979 - Precision: 0.8997 - Recall: 0.8998 - Specificity: 0.9991 - F1: 0.8951 - Loss: 0.1180\n",
      "\n",
      "Batch 58/387 ━━━━━━━━━━━━━━━━━━━━ 12:03:36\n",
      "Accuracy: 0.9979 - Precision: 0.8990 - Recall: 0.9012 - Specificity: 0.9991 - F1: 0.8954 - Loss: 0.1177\n",
      "\n",
      "Batch 59/387 ━━━━━━━━━━━━━━━━━━━━ 12:05:15\n",
      "Accuracy: 0.9979 - Precision: 0.8997 - Recall: 0.9014 - Specificity: 0.9991 - F1: 0.8960 - Loss: 0.1172\n",
      "\n",
      "Batch 60/387 ━━━━━━━━━━━━━━━━━━━━ 12:06:51\n",
      "Accuracy: 0.9979 - Precision: 0.8962 - Recall: 0.8970 - Specificity: 0.9991 - F1: 0.8921 - Loss: 0.1210\n",
      "\n",
      "Batch 61/387 ━━━━━━━━━━━━━━━━━━━━ 12:08:30\n",
      "Accuracy: 0.9979 - Precision: 0.8960 - Recall: 0.8972 - Specificity: 0.9991 - F1: 0.8921 - Loss: 0.1209\n",
      "\n",
      "Batch 62/387 ━━━━━━━━━━━━━━━━━━━━ 12:10:16\n",
      "Accuracy: 0.9978 - Precision: 0.8966 - Recall: 0.8971 - Specificity: 0.9991 - F1: 0.8924 - Loss: 0.1208\n",
      "\n",
      "Batch 63/387 ━━━━━━━━━━━━━━━━━━━━ 12:11:50\n",
      "Accuracy: 0.9979 - Precision: 0.8970 - Recall: 0.8972 - Specificity: 0.9991 - F1: 0.8928 - Loss: 0.1204\n",
      "\n",
      "Batch 64/387 ━━━━━━━━━━━━━━━━━━━━ 12:13:25\n",
      "Accuracy: 0.9978 - Precision: 0.8973 - Recall: 0.8975 - Specificity: 0.9991 - F1: 0.8931 - Loss: 0.1201\n",
      "\n",
      "Batch 65/387 ━━━━━━━━━━━━━━━━━━━━ 12:14:59\n",
      "Accuracy: 0.9979 - Precision: 0.8983 - Recall: 0.8983 - Specificity: 0.9991 - F1: 0.8941 - Loss: 0.1191\n",
      "\n",
      "Batch 66/387 ━━━━━━━━━━━━━━━━━━━━ 12:16:38\n",
      "Accuracy: 0.9978 - Precision: 0.8995 - Recall: 0.8936 - Specificity: 0.9991 - F1: 0.8917 - Loss: 0.1216\n",
      "\n",
      "Batch 67/387 ━━━━━━━━━━━━━━━━━━━━ 12:18:14\n",
      "Accuracy: 0.9978 - Precision: 0.8972 - Recall: 0.8906 - Specificity: 0.9991 - F1: 0.8891 - Loss: 0.1244\n",
      "\n",
      "Batch 68/387 ━━━━━━━━━━━━━━━━━━━━ 12:19:41\n",
      "Accuracy: 0.9978 - Precision: 0.8980 - Recall: 0.8888 - Specificity: 0.9991 - F1: 0.8885 - Loss: 0.1252\n",
      "\n",
      "Batch 69/387 ━━━━━━━━━━━━━━━━━━━━ 12:21:08\n",
      "Accuracy: 0.9978 - Precision: 0.8987 - Recall: 0.8900 - Specificity: 0.9991 - F1: 0.8895 - Loss: 0.1241\n",
      "\n",
      "Batch 70/387 ━━━━━━━━━━━━━━━━━━━━ 12:22:45\n",
      "Accuracy: 0.9978 - Precision: 0.8994 - Recall: 0.8890 - Specificity: 0.9991 - F1: 0.8894 - Loss: 0.1243\n",
      "\n",
      "Batch 71/387 ━━━━━━━━━━━━━━━━━━━━ 12:24:17\n",
      "Accuracy: 0.9978 - Precision: 0.8997 - Recall: 0.8896 - Specificity: 0.9991 - F1: 0.8899 - Loss: 0.1238\n",
      "\n",
      "Batch 72/387 ━━━━━━━━━━━━━━━━━━━━ 12:25:52\n",
      "Accuracy: 0.9977 - Precision: 0.8980 - Recall: 0.8906 - Specificity: 0.9991 - F1: 0.8895 - Loss: 0.1243\n",
      "\n",
      "Batch 73/387 ━━━━━━━━━━━━━━━━━━━━ 12:27:16\n",
      "Accuracy: 0.9977 - Precision: 0.8954 - Recall: 0.8917 - Specificity: 0.9990 - F1: 0.8886 - Loss: 0.1253\n",
      "\n",
      "Batch 74/387 ━━━━━━━━━━━━━━━━━━━━ 12:28:39\n",
      "Accuracy: 0.9977 - Precision: 0.8946 - Recall: 0.8919 - Specificity: 0.9990 - F1: 0.8883 - Loss: 0.1256\n",
      "\n",
      "Batch 75/387 ━━━━━━━━━━━━━━━━━━━━ 12:30:17\n",
      "Accuracy: 0.9977 - Precision: 0.8939 - Recall: 0.8931 - Specificity: 0.9990 - F1: 0.8885 - Loss: 0.1254\n",
      "\n",
      "Batch 76/387 ━━━━━━━━━━━━━━━━━━━━ 12:32:19\n",
      "Accuracy: 0.9977 - Precision: 0.8934 - Recall: 0.8942 - Specificity: 0.9990 - F1: 0.8888 - Loss: 0.1250\n",
      "\n",
      "Batch 77/387 ━━━━━━━━━━━━━━━━━━━━ 12:33:54\n",
      "Accuracy: 0.9977 - Precision: 0.8885 - Recall: 0.8954 - Specificity: 0.9989 - F1: 0.8861 - Loss: 0.1280\n",
      "\n",
      "Batch 78/387 ━━━━━━━━━━━━━━━━━━━━ 12:50:15\n",
      "Accuracy: 0.9977 - Precision: 0.8871 - Recall: 0.8963 - Specificity: 0.9989 - F1: 0.8858 - Loss: 0.1283\n",
      "\n",
      "Batch 79/387 ━━━━━━━━━━━━━━━━━━━━ 12:51:51\n",
      "Accuracy: 0.9977 - Precision: 0.8874 - Recall: 0.8972 - Specificity: 0.9989 - F1: 0.8865 - Loss: 0.1276\n",
      "\n",
      "Batch 80/387 ━━━━━━━━━━━━━━━━━━━━ 12:53:28\n",
      "Accuracy: 0.9977 - Precision: 0.8869 - Recall: 0.8976 - Specificity: 0.9989 - F1: 0.8865 - Loss: 0.1275\n",
      "\n",
      "Batch 81/387 ━━━━━━━━━━━━━━━━━━━━ 12:54:51\n",
      "Accuracy: 0.9977 - Precision: 0.8877 - Recall: 0.8967 - Specificity: 0.9989 - F1: 0.8864 - Loss: 0.1277\n",
      "\n",
      "Batch 82/387 ━━━━━━━━━━━━━━━━━━━━ 12:56:34\n",
      "Accuracy: 0.9977 - Precision: 0.8886 - Recall: 0.8962 - Specificity: 0.9989 - F1: 0.8867 - Loss: 0.1275\n",
      "\n",
      "Batch 83/387 ━━━━━━━━━━━━━━━━━━━━ 12:58:26\n",
      "Accuracy: 0.9976 - Precision: 0.8829 - Recall: 0.8966 - Specificity: 0.9989 - F1: 0.8828 - Loss: 0.1314\n",
      "\n",
      "Batch 84/387 ━━━━━━━━━━━━━━━━━━━━ 13:00:00\n",
      "Accuracy: 0.9977 - Precision: 0.8836 - Recall: 0.8977 - Specificity: 0.9989 - F1: 0.8838 - Loss: 0.1304\n",
      "\n",
      "Batch 85/387 ━━━━━━━━━━━━━━━━━━━━ 13:01:38\n",
      "Accuracy: 0.9977 - Precision: 0.8844 - Recall: 0.8977 - Specificity: 0.9989 - F1: 0.8843 - Loss: 0.1298\n",
      "\n",
      "Batch 86/387 ━━━━━━━━━━━━━━━━━━━━ 13:03:18\n",
      "Accuracy: 0.9977 - Precision: 0.8853 - Recall: 0.8980 - Specificity: 0.9989 - F1: 0.8850 - Loss: 0.1291\n",
      "\n",
      "Batch 87/387 ━━━━━━━━━━━━━━━━━━━━ 13:04:53\n",
      "Accuracy: 0.9977 - Precision: 0.8865 - Recall: 0.8976 - Specificity: 0.9989 - F1: 0.8854 - Loss: 0.1286\n",
      "\n",
      "Batch 88/387 ━━━━━━━━━━━━━━━━━━━━ 13:06:23\n",
      "Accuracy: 0.9977 - Precision: 0.8877 - Recall: 0.8964 - Specificity: 0.9989 - F1: 0.8853 - Loss: 0.1286\n",
      "\n",
      "Batch 89/387 ━━━━━━━━━━━━━━━━━━━━ 13:07:50\n",
      "Accuracy: 0.9977 - Precision: 0.8889 - Recall: 0.8958 - Specificity: 0.9989 - F1: 0.8856 - Loss: 0.1284\n",
      "\n",
      "Batch 90/387 ━━━━━━━━━━━━━━━━━━━━ 13:09:21\n",
      "Accuracy: 0.9977 - Precision: 0.8902 - Recall: 0.8943 - Specificity: 0.9990 - F1: 0.8854 - Loss: 0.1287\n",
      "\n",
      "Batch 91/387 ━━━━━━━━━━━━━━━━━━━━ 13:10:49\n",
      "Accuracy: 0.9977 - Precision: 0.8911 - Recall: 0.8944 - Specificity: 0.9990 - F1: 0.8860 - Loss: 0.1281\n",
      "\n",
      "Batch 92/387 ━━━━━━━━━━━━━━━━━━━━ 13:12:22\n",
      "Accuracy: 0.9977 - Precision: 0.8918 - Recall: 0.8941 - Specificity: 0.9990 - F1: 0.8863 - Loss: 0.1278\n",
      "\n",
      "Batch 93/387 ━━━━━━━━━━━━━━━━━━━━ 13:13:50\n",
      "Accuracy: 0.9977 - Precision: 0.8887 - Recall: 0.8944 - Specificity: 0.9990 - F1: 0.8846 - Loss: 0.1296\n",
      "\n",
      "Batch 94/387 ━━━━━━━━━━━━━━━━━━━━ 13:15:25\n",
      "Accuracy: 0.9977 - Precision: 0.8880 - Recall: 0.8952 - Specificity: 0.9989 - F1: 0.8846 - Loss: 0.1295\n",
      "\n",
      "Batch 95/387 ━━━━━━━━━━━━━━━━━━━━ 13:16:55\n",
      "Accuracy: 0.9977 - Precision: 0.8890 - Recall: 0.8956 - Specificity: 0.9990 - F1: 0.8854 - Loss: 0.1286\n",
      "\n",
      "Batch 96/387 ━━━━━━━━━━━━━━━━━━━━ 13:18:26\n",
      "Accuracy: 0.9977 - Precision: 0.8880 - Recall: 0.8950 - Specificity: 0.9989 - F1: 0.8847 - Loss: 0.1295\n",
      "\n",
      "Batch 97/387 ━━━━━━━━━━━━━━━━━━━━ 13:20:07\n",
      "Accuracy: 0.9977 - Precision: 0.8888 - Recall: 0.8951 - Specificity: 0.9990 - F1: 0.8852 - Loss: 0.1289\n",
      "\n",
      "Batch 98/387 ━━━━━━━━━━━━━━━━━━━━ 13:21:44\n",
      "Accuracy: 0.9977 - Precision: 0.8882 - Recall: 0.8954 - Specificity: 0.9990 - F1: 0.8851 - Loss: 0.1289\n",
      "\n",
      "Batch 99/387 ━━━━━━━━━━━━━━━━━━━━ 13:23:14\n",
      "Accuracy: 0.9977 - Precision: 0.8891 - Recall: 0.8943 - Specificity: 0.9990 - F1: 0.8849 - Loss: 0.1291\n",
      "\n",
      "Batch 100/387 ━━━━━━━━━━━━━━━━━━━━ 13:24:55\n",
      "Accuracy: 0.9977 - Precision: 0.8900 - Recall: 0.8934 - Specificity: 0.9990 - F1: 0.8850 - Loss: 0.1291\n",
      "\n",
      "Batch 101/387 ━━━━━━━━━━━━━━━━━━━━ 13:26:43\n",
      "Accuracy: 0.9977 - Precision: 0.8909 - Recall: 0.8937 - Specificity: 0.9990 - F1: 0.8856 - Loss: 0.1284\n",
      "\n",
      "Batch 102/387 ━━━━━━━━━━━━━━━━━━━━ 13:28:13\n",
      "Accuracy: 0.9977 - Precision: 0.8911 - Recall: 0.8945 - Specificity: 0.9990 - F1: 0.8861 - Loss: 0.1278\n",
      "\n",
      "Batch 103/387 ━━━━━━━━━━━━━━━━━━━━ 13:29:55\n",
      "Accuracy: 0.9977 - Precision: 0.8904 - Recall: 0.8946 - Specificity: 0.9990 - F1: 0.8859 - Loss: 0.1281\n",
      "\n",
      "Batch 104/387 ━━━━━━━━━━━━━━━━━━━━ 13:31:30\n",
      "Accuracy: 0.9977 - Precision: 0.8914 - Recall: 0.8939 - Specificity: 0.9990 - F1: 0.8860 - Loss: 0.1280\n",
      "\n",
      "Batch 105/387 ━━━━━━━━━━━━━━━━━━━━ 13:33:03\n",
      "Accuracy: 0.9977 - Precision: 0.8899 - Recall: 0.8905 - Specificity: 0.9990 - F1: 0.8835 - Loss: 0.1306\n",
      "\n",
      "Batch 106/387 ━━━━━━━━━━━━━━━━━━━━ 13:34:43\n",
      "Accuracy: 0.9977 - Precision: 0.8905 - Recall: 0.8911 - Specificity: 0.9990 - F1: 0.8841 - Loss: 0.1299\n",
      "\n",
      "Batch 107/387 ━━━━━━━━━━━━━━━━━━━━ 13:36:28\n",
      "Accuracy: 0.9977 - Precision: 0.8900 - Recall: 0.8918 - Specificity: 0.9990 - F1: 0.8843 - Loss: 0.1298\n",
      "\n",
      "Batch 108/387 ━━━━━━━━━━━━━━━━━━━━ 13:38:03\n",
      "Accuracy: 0.9977 - Precision: 0.8907 - Recall: 0.8922 - Specificity: 0.9990 - F1: 0.8849 - Loss: 0.1292\n",
      "\n",
      "Batch 109/387 ━━━━━━━━━━━━━━━━━━━━ 13:39:24\n",
      "Accuracy: 0.9977 - Precision: 0.8906 - Recall: 0.8927 - Specificity: 0.9989 - F1: 0.8851 - Loss: 0.1289\n",
      "\n",
      "Batch 110/387 ━━━━━━━━━━━━━━━━━━━━ 13:41:00\n",
      "Accuracy: 0.9977 - Precision: 0.8907 - Recall: 0.8931 - Specificity: 0.9989 - F1: 0.8854 - Loss: 0.1286\n",
      "\n",
      "Batch 111/387 ━━━━━━━━━━━━━━━━━━━━ 13:42:41\n",
      "Accuracy: 0.9977 - Precision: 0.8913 - Recall: 0.8931 - Specificity: 0.9989 - F1: 0.8858 - Loss: 0.1283\n",
      "\n",
      "Batch 112/387 ━━━━━━━━━━━━━━━━━━━━ 13:44:10\n",
      "Accuracy: 0.9977 - Precision: 0.8912 - Recall: 0.8939 - Specificity: 0.9989 - F1: 0.8861 - Loss: 0.1279\n",
      "\n",
      "Batch 113/387 ━━━━━━━━━━━━━━━━━━━━ 13:45:57\n",
      "Accuracy: 0.9977 - Precision: 0.8917 - Recall: 0.8945 - Specificity: 0.9989 - F1: 0.8868 - Loss: 0.1272\n",
      "\n",
      "Batch 114/387 ━━━━━━━━━━━━━━━━━━━━ 13:47:32\n",
      "Accuracy: 0.9977 - Precision: 0.8921 - Recall: 0.8935 - Specificity: 0.9989 - F1: 0.8865 - Loss: 0.1275\n",
      "\n",
      "Batch 115/387 ━━━━━━━━━━━━━━━━━━━━ 13:48:59\n",
      "Accuracy: 0.9976 - Precision: 0.8896 - Recall: 0.8936 - Specificity: 0.9989 - F1: 0.8850 - Loss: 0.1292\n",
      "\n",
      "Batch 116/387 ━━━━━━━━━━━━━━━━━━━━ 13:50:23\n",
      "Accuracy: 0.9976 - Precision: 0.8901 - Recall: 0.8942 - Specificity: 0.9989 - F1: 0.8856 - Loss: 0.1286\n",
      "\n",
      "Batch 117/387 ━━━━━━━━━━━━━━━━━━━━ 13:51:54\n",
      "Accuracy: 0.9976 - Precision: 0.8892 - Recall: 0.8949 - Specificity: 0.9989 - F1: 0.8855 - Loss: 0.1288\n",
      "\n",
      "Batch 118/387 ━━━━━━━━━━━━━━━━━━━━ 13:53:24\n",
      "Accuracy: 0.9976 - Precision: 0.8888 - Recall: 0.8955 - Specificity: 0.9989 - F1: 0.8856 - Loss: 0.1287\n",
      "\n",
      "Batch 119/387 ━━━━━━━━━━━━━━━━━━━━ 13:54:56\n",
      "Accuracy: 0.9976 - Precision: 0.8881 - Recall: 0.8958 - Specificity: 0.9989 - F1: 0.8854 - Loss: 0.1289\n",
      "\n",
      "Batch 120/387 ━━━━━━━━━━━━━━━━━━━━ 13:56:28\n",
      "Accuracy: 0.9976 - Precision: 0.8874 - Recall: 0.8965 - Specificity: 0.9989 - F1: 0.8854 - Loss: 0.1289\n",
      "\n",
      "Batch 121/387 ━━━━━━━━━━━━━━━━━━━━ 13:58:02\n",
      "Accuracy: 0.9976 - Precision: 0.8871 - Recall: 0.8971 - Specificity: 0.9989 - F1: 0.8856 - Loss: 0.1286\n",
      "\n",
      "Batch 122/387 ━━━━━━━━━━━━━━━━━━━━ 13:59:40\n",
      "Accuracy: 0.9976 - Precision: 0.8879 - Recall: 0.8970 - Specificity: 0.9989 - F1: 0.8860 - Loss: 0.1283\n",
      "\n",
      "Batch 123/387 ━━━━━━━━━━━━━━━━━━━━ 14:01:14\n",
      "Accuracy: 0.9976 - Precision: 0.8885 - Recall: 0.8974 - Specificity: 0.9989 - F1: 0.8865 - Loss: 0.1278\n",
      "\n",
      "Batch 124/387 ━━━━━━━━━━━━━━━━━━━━ 14:02:44\n",
      "Accuracy: 0.9976 - Precision: 0.8887 - Recall: 0.8972 - Specificity: 0.9989 - F1: 0.8866 - Loss: 0.1277\n",
      "\n",
      "Batch 125/387 ━━━━━━━━━━━━━━━━━━━━ 14:04:20\n",
      "Accuracy: 0.9976 - Precision: 0.8893 - Recall: 0.8977 - Specificity: 0.9989 - F1: 0.8872 - Loss: 0.1271\n",
      "\n",
      "Batch 126/387 ━━━━━━━━━━━━━━━━━━━━ 14:05:48\n",
      "Accuracy: 0.9976 - Precision: 0.8892 - Recall: 0.8975 - Specificity: 0.9989 - F1: 0.8870 - Loss: 0.1271\n",
      "\n",
      "Batch 127/387 ━━━━━━━━━━━━━━━━━━━━ 14:07:22\n",
      "Accuracy: 0.9976 - Precision: 0.8897 - Recall: 0.8978 - Specificity: 0.9989 - F1: 0.8875 - Loss: 0.1267\n",
      "\n",
      "Batch 128/387 ━━━━━━━━━━━━━━━━━━━━ 14:09:02\n",
      "Accuracy: 0.9976 - Precision: 0.8902 - Recall: 0.8941 - Specificity: 0.9989 - F1: 0.8852 - Loss: 0.1290\n",
      "\n",
      "Batch 129/387 ━━━━━━━━━━━━━━━━━━━━ 14:10:37\n",
      "Accuracy: 0.9976 - Precision: 0.8890 - Recall: 0.8929 - Specificity: 0.9989 - F1: 0.8841 - Loss: 0.1302\n",
      "\n",
      "Batch 130/387 ━━━━━━━━━━━━━━━━━━━━ 14:12:14\n",
      "Accuracy: 0.9976 - Precision: 0.8898 - Recall: 0.8931 - Specificity: 0.9989 - F1: 0.8846 - Loss: 0.1297\n",
      "\n",
      "Batch 131/387 ━━━━━━━━━━━━━━━━━━━━ 14:13:46\n",
      "Accuracy: 0.9976 - Precision: 0.8886 - Recall: 0.8935 - Specificity: 0.9989 - F1: 0.8841 - Loss: 0.1301\n",
      "\n",
      "Batch 132/387 ━━━━━━━━━━━━━━━━━━━━ 14:15:13\n",
      "Accuracy: 0.9976 - Precision: 0.8893 - Recall: 0.8932 - Specificity: 0.9989 - F1: 0.8844 - Loss: 0.1299\n",
      "\n",
      "Batch 133/387 ━━━━━━━━━━━━━━━━━━━━ 14:16:37\n",
      "Accuracy: 0.9976 - Precision: 0.8899 - Recall: 0.8931 - Specificity: 0.9989 - F1: 0.8846 - Loss: 0.1296\n",
      "\n",
      "Batch 134/387 ━━━━━━━━━━━━━━━━━━━━ 14:17:57\n",
      "Accuracy: 0.9976 - Precision: 0.8907 - Recall: 0.8920 - Specificity: 0.9989 - F1: 0.8844 - Loss: 0.1300\n",
      "\n",
      "Batch 135/387 ━━━━━━━━━━━━━━━━━━━━ 14:19:22\n",
      "Accuracy: 0.9976 - Precision: 0.8908 - Recall: 0.8918 - Specificity: 0.9989 - F1: 0.8844 - Loss: 0.1301\n",
      "\n",
      "Batch 136/387 ━━━━━━━━━━━━━━━━━━━━ 14:21:01\n",
      "Accuracy: 0.9976 - Precision: 0.8909 - Recall: 0.8918 - Specificity: 0.9989 - F1: 0.8845 - Loss: 0.1300\n",
      "\n",
      "Batch 137/387 ━━━━━━━━━━━━━━━━━━━━ 14:22:33\n",
      "Accuracy: 0.9976 - Precision: 0.8916 - Recall: 0.8914 - Specificity: 0.9989 - F1: 0.8846 - Loss: 0.1299\n",
      "\n",
      "Batch 138/387 ━━━━━━━━━━━━━━━━━━━━ 14:23:57\n",
      "Accuracy: 0.9976 - Precision: 0.8915 - Recall: 0.8917 - Specificity: 0.9989 - F1: 0.8848 - Loss: 0.1297\n",
      "\n",
      "Batch 139/387 ━━━━━━━━━━━━━━━━━━━━ 14:25:29\n",
      "Accuracy: 0.9976 - Precision: 0.8905 - Recall: 0.8924 - Specificity: 0.9989 - F1: 0.8846 - Loss: 0.1299\n",
      "\n",
      "Batch 140/387 ━━━━━━━━━━━━━━━━━━━━ 14:26:56\n",
      "Accuracy: 0.9976 - Precision: 0.8904 - Recall: 0.8929 - Specificity: 0.9989 - F1: 0.8848 - Loss: 0.1296\n",
      "\n",
      "Batch 141/387 ━━━━━━━━━━━━━━━━━━━━ 14:28:27\n",
      "Accuracy: 0.9976 - Precision: 0.8904 - Recall: 0.8935 - Specificity: 0.9989 - F1: 0.8851 - Loss: 0.1293\n",
      "\n",
      "Batch 142/387 ━━━━━━━━━━━━━━━━━━━━ 14:29:56\n",
      "Accuracy: 0.9976 - Precision: 0.8900 - Recall: 0.8935 - Specificity: 0.9989 - F1: 0.8850 - Loss: 0.1294\n",
      "\n",
      "Batch 143/387 ━━━━━━━━━━━━━━━━━━━━ 14:31:34\n",
      "Accuracy: 0.9976 - Precision: 0.8904 - Recall: 0.8941 - Specificity: 0.9989 - F1: 0.8856 - Loss: 0.1288\n",
      "\n",
      "Batch 144/387 ━━━━━━━━━━━━━━━━━━━━ 14:32:55\n",
      "Accuracy: 0.9976 - Precision: 0.8893 - Recall: 0.8946 - Specificity: 0.9989 - F1: 0.8852 - Loss: 0.1292\n",
      "\n",
      "Batch 145/387 ━━━━━━━━━━━━━━━━━━━━ 14:34:19\n",
      "Accuracy: 0.9976 - Precision: 0.8892 - Recall: 0.8950 - Specificity: 0.9989 - F1: 0.8854 - Loss: 0.1290\n",
      "\n",
      "Batch 146/387 ━━━━━━━━━━━━━━━━━━━━ 14:35:56\n",
      "Accuracy: 0.9976 - Precision: 0.8890 - Recall: 0.8955 - Specificity: 0.9989 - F1: 0.8855 - Loss: 0.1288\n",
      "\n",
      "Batch 147/387 ━━━━━━━━━━━━━━━━━━━━ 14:37:19\n",
      "Accuracy: 0.9976 - Precision: 0.8889 - Recall: 0.8955 - Specificity: 0.9989 - F1: 0.8855 - Loss: 0.1287\n",
      "\n",
      "Batch 148/387 ━━━━━━━━━━━━━━━━━━━━ 14:38:48\n",
      "Accuracy: 0.9976 - Precision: 0.8896 - Recall: 0.8943 - Specificity: 0.9989 - F1: 0.8851 - Loss: 0.1294\n",
      "\n",
      "Batch 149/387 ━━━━━━━━━━━━━━━━━━━━ 14:40:22\n",
      "Accuracy: 0.9976 - Precision: 0.8900 - Recall: 0.8938 - Specificity: 0.9989 - F1: 0.8851 - Loss: 0.1295\n",
      "\n",
      "Batch 150/387 ━━━━━━━━━━━━━━━━━━━━ 14:41:41\n",
      "Accuracy: 0.9976 - Precision: 0.8904 - Recall: 0.8931 - Specificity: 0.9989 - F1: 0.8850 - Loss: 0.1296\n",
      "\n",
      "Batch 151/387 ━━━━━━━━━━━━━━━━━━━━ 14:43:12\n",
      "Accuracy: 0.9976 - Precision: 0.8905 - Recall: 0.8933 - Specificity: 0.9989 - F1: 0.8851 - Loss: 0.1295\n",
      "\n",
      "Batch 152/387 ━━━━━━━━━━━━━━━━━━━━ 14:44:47\n",
      "Accuracy: 0.9976 - Precision: 0.8908 - Recall: 0.8933 - Specificity: 0.9989 - F1: 0.8853 - Loss: 0.1293\n",
      "\n",
      "Batch 153/387 ━━━━━━━━━━━━━━━━━━━━ 14:46:14\n",
      "Accuracy: 0.9976 - Precision: 0.8912 - Recall: 0.8936 - Specificity: 0.9989 - F1: 0.8857 - Loss: 0.1288\n",
      "\n",
      "Batch 154/387 ━━━━━━━━━━━━━━━━━━━━ 14:47:37\n",
      "Accuracy: 0.9976 - Precision: 0.8897 - Recall: 0.8939 - Specificity: 0.9989 - F1: 0.8850 - Loss: 0.1296\n",
      "\n",
      "Batch 155/387 ━━━━━━━━━━━━━━━━━━━━ 14:49:08\n",
      "Accuracy: 0.9976 - Precision: 0.8902 - Recall: 0.8941 - Specificity: 0.9989 - F1: 0.8854 - Loss: 0.1291\n",
      "\n",
      "Batch 156/387 ━━━━━━━━━━━━━━━━━━━━ 14:50:53\n",
      "Accuracy: 0.9976 - Precision: 0.8907 - Recall: 0.8944 - Specificity: 0.9989 - F1: 0.8858 - Loss: 0.1287\n",
      "\n",
      "Batch 157/387 ━━━━━━━━━━━━━━━━━━━━ 14:52:13\n",
      "Accuracy: 0.9976 - Precision: 0.8911 - Recall: 0.8946 - Specificity: 0.9989 - F1: 0.8862 - Loss: 0.1283\n",
      "\n",
      "Batch 158/387 ━━━━━━━━━━━━━━━━━━━━ 14:53:46\n",
      "Accuracy: 0.9976 - Precision: 0.8914 - Recall: 0.8940 - Specificity: 0.9989 - F1: 0.8860 - Loss: 0.1285\n",
      "\n",
      "Batch 159/387 ━━━━━━━━━━━━━━━━━━━━ 14:55:15\n",
      "Accuracy: 0.9976 - Precision: 0.8910 - Recall: 0.8940 - Specificity: 0.9989 - F1: 0.8859 - Loss: 0.1286\n",
      "\n",
      "Batch 160/387 ━━━━━━━━━━━━━━━━━━━━ 14:56:44\n",
      "Accuracy: 0.9976 - Precision: 0.8901 - Recall: 0.8930 - Specificity: 0.9989 - F1: 0.8850 - Loss: 0.1297\n",
      "\n",
      "Batch 161/387 ━━━━━━━━━━━━━━━━━━━━ 14:58:07\n",
      "Accuracy: 0.9976 - Precision: 0.8908 - Recall: 0.8932 - Specificity: 0.9989 - F1: 0.8854 - Loss: 0.1292\n",
      "\n",
      "Batch 162/387 ━━━━━━━━━━━━━━━━━━━━ 14:59:24\n",
      "Accuracy: 0.9976 - Precision: 0.8912 - Recall: 0.8920 - Specificity: 0.9989 - F1: 0.8850 - Loss: 0.1297\n",
      "\n",
      "Batch 163/387 ━━━━━━━━━━━━━━━━━━━━ 15:00:55\n",
      "Accuracy: 0.9976 - Precision: 0.8914 - Recall: 0.8923 - Specificity: 0.9989 - F1: 0.8852 - Loss: 0.1294\n",
      "\n",
      "Batch 164/387 ━━━━━━━━━━━━━━━━━━━━ 15:02:28\n",
      "Accuracy: 0.9976 - Precision: 0.8917 - Recall: 0.8923 - Specificity: 0.9989 - F1: 0.8854 - Loss: 0.1292\n",
      "\n",
      "Batch 165/387 ━━━━━━━━━━━━━━━━━━━━ 15:04:09\n",
      "Accuracy: 0.9976 - Precision: 0.8917 - Recall: 0.8927 - Specificity: 0.9989 - F1: 0.8857 - Loss: 0.1289\n",
      "\n",
      "Batch 166/387 ━━━━━━━━━━━━━━━━━━━━ 15:06:06\n",
      "Accuracy: 0.9976 - Precision: 0.8913 - Recall: 0.8931 - Specificity: 0.9989 - F1: 0.8857 - Loss: 0.1289\n",
      "\n",
      "Batch 167/387 ━━━━━━━━━━━━━━━━━━━━ 15:07:36\n",
      "Accuracy: 0.9976 - Precision: 0.8916 - Recall: 0.8932 - Specificity: 0.9989 - F1: 0.8859 - Loss: 0.1287\n",
      "\n",
      "Batch 168/387 ━━━━━━━━━━━━━━━━━━━━ 15:09:12\n",
      "Accuracy: 0.9976 - Precision: 0.8907 - Recall: 0.8936 - Specificity: 0.9989 - F1: 0.8856 - Loss: 0.1290\n",
      "\n",
      "Batch 169/387 ━━━━━━━━━━━━━━━━━━━━ 15:10:52\n",
      "Accuracy: 0.9976 - Precision: 0.8907 - Recall: 0.8930 - Specificity: 0.9989 - F1: 0.8854 - Loss: 0.1292\n",
      "\n",
      "Batch 170/387 ━━━━━━━━━━━━━━━━━━━━ 15:12:30\n",
      "Accuracy: 0.9976 - Precision: 0.8910 - Recall: 0.8930 - Specificity: 0.9989 - F1: 0.8855 - Loss: 0.1290\n",
      "\n",
      "Batch 171/387 ━━━━━━━━━━━━━━━━━━━━ 15:13:57\n",
      "Accuracy: 0.9976 - Precision: 0.8914 - Recall: 0.8932 - Specificity: 0.9989 - F1: 0.8858 - Loss: 0.1287\n",
      "\n",
      "Batch 172/387 ━━━━━━━━━━━━━━━━━━━━ 15:15:29\n",
      "Accuracy: 0.9976 - Precision: 0.8900 - Recall: 0.8934 - Specificity: 0.9989 - F1: 0.8852 - Loss: 0.1294\n",
      "\n",
      "Batch 173/387 ━━━━━━━━━━━━━━━━━━━━ 15:17:02\n",
      "Accuracy: 0.9976 - Precision: 0.8903 - Recall: 0.8933 - Specificity: 0.9989 - F1: 0.8853 - Loss: 0.1292\n",
      "\n",
      "Batch 174/387 ━━━━━━━━━━━━━━━━━━━━ 15:18:44\n",
      "Accuracy: 0.9976 - Precision: 0.8907 - Recall: 0.8935 - Specificity: 0.9989 - F1: 0.8856 - Loss: 0.1288\n",
      "\n",
      "Batch 175/387 ━━━━━━━━━━━━━━━━━━━━ 15:20:24\n",
      "Accuracy: 0.9976 - Precision: 0.8912 - Recall: 0.8939 - Specificity: 0.9989 - F1: 0.8861 - Loss: 0.1283\n",
      "\n",
      "Batch 176/387 ━━━━━━━━━━━━━━━━━━━━ 15:22:13\n",
      "Accuracy: 0.9976 - Precision: 0.8908 - Recall: 0.8937 - Specificity: 0.9989 - F1: 0.8858 - Loss: 0.1286\n",
      "\n",
      "Batch 177/387 ━━━━━━━━━━━━━━━━━━━━ 15:23:49\n",
      "Accuracy: 0.9976 - Precision: 0.8901 - Recall: 0.8929 - Specificity: 0.9989 - F1: 0.8851 - Loss: 0.1293\n",
      "\n",
      "Batch 178/387 ━━━━━━━━━━━━━━━━━━━━ 15:25:21\n",
      "Accuracy: 0.9976 - Precision: 0.8906 - Recall: 0.8916 - Specificity: 0.9989 - F1: 0.8846 - Loss: 0.1298\n",
      "\n",
      "Batch 179/387 ━━━━━━━━━━━━━━━━━━━━ 15:26:57\n",
      "Accuracy: 0.9976 - Precision: 0.8902 - Recall: 0.8919 - Specificity: 0.9989 - F1: 0.8845 - Loss: 0.1299\n",
      "\n",
      "Batch 180/387 ━━━━━━━━━━━━━━━━━━━━ 15:28:24\n",
      "Accuracy: 0.9976 - Precision: 0.8905 - Recall: 0.8915 - Specificity: 0.9989 - F1: 0.8845 - Loss: 0.1299\n",
      "\n",
      "Batch 181/387 ━━━━━━━━━━━━━━━━━━━━ 15:29:52\n",
      "Accuracy: 0.9976 - Precision: 0.8907 - Recall: 0.8915 - Specificity: 0.9989 - F1: 0.8846 - Loss: 0.1298\n",
      "\n",
      "Batch 182/387 ━━━━━━━━━━━━━━━━━━━━ 15:31:24\n",
      "Accuracy: 0.9976 - Precision: 0.8913 - Recall: 0.8905 - Specificity: 0.9989 - F1: 0.8843 - Loss: 0.1301\n",
      "\n",
      "Batch 183/387 ━━━━━━━━━━━━━━━━━━━━ 15:32:47\n",
      "Accuracy: 0.9976 - Precision: 0.8912 - Recall: 0.8905 - Specificity: 0.9989 - F1: 0.8843 - Loss: 0.1301\n",
      "\n",
      "Batch 184/387 ━━━━━━━━━━━━━━━━━━━━ 15:34:29\n",
      "Accuracy: 0.9976 - Precision: 0.8915 - Recall: 0.8896 - Specificity: 0.9989 - F1: 0.8840 - Loss: 0.1304\n",
      "\n",
      "Batch 185/387 ━━━━━━━━━━━━━━━━━━━━ 15:36:04\n",
      "Accuracy: 0.9976 - Precision: 0.8914 - Recall: 0.8901 - Specificity: 0.9989 - F1: 0.8842 - Loss: 0.1302\n",
      "\n",
      "Batch 186/387 ━━━━━━━━━━━━━━━━━━━━ 15:38:02\n",
      "Accuracy: 0.9976 - Precision: 0.8917 - Recall: 0.8901 - Specificity: 0.9989 - F1: 0.8844 - Loss: 0.1300\n",
      "\n",
      "Batch 187/387 ━━━━━━━━━━━━━━━━━━━━ 15:39:40\n",
      "Accuracy: 0.9976 - Precision: 0.8918 - Recall: 0.8902 - Specificity: 0.9989 - F1: 0.8846 - Loss: 0.1298\n",
      "\n",
      "Batch 188/387 ━━━━━━━━━━━━━━━━━━━━ 15:41:20\n",
      "Accuracy: 0.9976 - Precision: 0.8919 - Recall: 0.8902 - Specificity: 0.9989 - F1: 0.8847 - Loss: 0.1297\n",
      "\n",
      "Batch 189/387 ━━━━━━━━━━━━━━━━━━━━ 15:42:55\n",
      "Accuracy: 0.9976 - Precision: 0.8922 - Recall: 0.8901 - Specificity: 0.9989 - F1: 0.8847 - Loss: 0.1296\n",
      "\n",
      "Batch 190/387 ━━━━━━━━━━━━━━━━━━━━ 15:44:22\n",
      "Accuracy: 0.9976 - Precision: 0.8926 - Recall: 0.8901 - Specificity: 0.9989 - F1: 0.8850 - Loss: 0.1294\n",
      "\n",
      "Batch 191/387 ━━━━━━━━━━━━━━━━━━━━ 15:46:02\n",
      "Accuracy: 0.9976 - Precision: 0.8928 - Recall: 0.8886 - Specificity: 0.9989 - F1: 0.8842 - Loss: 0.1303\n",
      "\n",
      "Batch 192/387 ━━━━━━━━━━━━━━━━━━━━ 15:47:27\n",
      "Accuracy: 0.9976 - Precision: 0.8927 - Recall: 0.8892 - Specificity: 0.9989 - F1: 0.8844 - Loss: 0.1301\n",
      "\n",
      "Batch 193/387 ━━━━━━━━━━━━━━━━━━━━ 15:48:59\n",
      "Accuracy: 0.9976 - Precision: 0.8924 - Recall: 0.8896 - Specificity: 0.9989 - F1: 0.8845 - Loss: 0.1300\n",
      "\n",
      "Batch 194/387 ━━━━━━━━━━━━━━━━━━━━ 15:50:37\n",
      "Accuracy: 0.9976 - Precision: 0.8926 - Recall: 0.8898 - Specificity: 0.9989 - F1: 0.8848 - Loss: 0.1297\n",
      "\n",
      "Batch 195/387 ━━━━━━━━━━━━━━━━━━━━ 15:52:06\n",
      "Accuracy: 0.9976 - Precision: 0.8926 - Recall: 0.8900 - Specificity: 0.9989 - F1: 0.8849 - Loss: 0.1296\n",
      "\n",
      "Batch 196/387 ━━━━━━━━━━━━━━━━━━━━ 15:53:36\n",
      "Accuracy: 0.9976 - Precision: 0.8918 - Recall: 0.8905 - Specificity: 0.9989 - F1: 0.8847 - Loss: 0.1298\n",
      "\n",
      "Batch 197/387 ━━━━━━━━━━━━━━━━━━━━ 15:55:13\n",
      "Accuracy: 0.9976 - Precision: 0.8918 - Recall: 0.8909 - Specificity: 0.9989 - F1: 0.8849 - Loss: 0.1296\n",
      "\n",
      "Batch 198/387 ━━━━━━━━━━━━━━━━━━━━ 15:56:41\n",
      "Accuracy: 0.9976 - Precision: 0.8916 - Recall: 0.8906 - Specificity: 0.9989 - F1: 0.8847 - Loss: 0.1298\n",
      "\n",
      "Batch 199/387 ━━━━━━━━━━━━━━━━━━━━ 15:58:12\n",
      "Accuracy: 0.9976 - Precision: 0.8919 - Recall: 0.8899 - Specificity: 0.9989 - F1: 0.8845 - Loss: 0.1301\n",
      "\n",
      "Batch 200/387 ━━━━━━━━━━━━━━━━━━━━ 15:59:38\n",
      "Accuracy: 0.9976 - Precision: 0.8914 - Recall: 0.8903 - Specificity: 0.9989 - F1: 0.8844 - Loss: 0.1301\n",
      "\n",
      "Batch 201/387 ━━━━━━━━━━━━━━━━━━━━ 16:01:05\n",
      "Accuracy: 0.9976 - Precision: 0.8903 - Recall: 0.8909 - Specificity: 0.9989 - F1: 0.8840 - Loss: 0.1305\n",
      "\n",
      "Batch 202/387 ━━━━━━━━━━━━━━━━━━━━ 16:02:47\n",
      "Accuracy: 0.9976 - Precision: 0.8905 - Recall: 0.8909 - Specificity: 0.9989 - F1: 0.8841 - Loss: 0.1304\n",
      "\n",
      "Batch 203/387 ━━━━━━━━━━━━━━━━━━━━ 16:04:14\n",
      "Accuracy: 0.9976 - Precision: 0.8908 - Recall: 0.8912 - Specificity: 0.9989 - F1: 0.8845 - Loss: 0.1300\n",
      "\n",
      "Batch 204/387 ━━━━━━━━━━━━━━━━━━━━ 16:05:52\n",
      "Accuracy: 0.9976 - Precision: 0.8911 - Recall: 0.8916 - Specificity: 0.9989 - F1: 0.8848 - Loss: 0.1296\n",
      "\n",
      "Batch 205/387 ━━━━━━━━━━━━━━━━━━━━ 16:07:20\n",
      "Accuracy: 0.9976 - Precision: 0.8914 - Recall: 0.8919 - Specificity: 0.9989 - F1: 0.8852 - Loss: 0.1292\n",
      "\n",
      "Batch 206/387 ━━━━━━━━━━━━━━━━━━━━ 16:08:56\n",
      "Accuracy: 0.9976 - Precision: 0.8899 - Recall: 0.8922 - Specificity: 0.9989 - F1: 0.8844 - Loss: 0.1299\n",
      "\n",
      "Batch 207/387 ━━━━━━━━━━━━━━━━━━━━ 16:10:28\n",
      "Accuracy: 0.9976 - Precision: 0.8903 - Recall: 0.8921 - Specificity: 0.9989 - F1: 0.8846 - Loss: 0.1298\n",
      "\n",
      "Batch 208/387 ━━━━━━━━━━━━━━━━━━━━ 16:12:00\n",
      "Accuracy: 0.9976 - Precision: 0.8907 - Recall: 0.8921 - Specificity: 0.9989 - F1: 0.8847 - Loss: 0.1296\n",
      "\n",
      "Batch 209/387 ━━━━━━━━━━━━━━━━━━━━ 16:13:28\n",
      "Accuracy: 0.9977 - Precision: 0.8902 - Recall: 0.8924 - Specificity: 0.9989 - F1: 0.8847 - Loss: 0.1296\n",
      "\n",
      "Batch 210/387 ━━━━━━━━━━━━━━━━━━━━ 16:14:45\n",
      "Accuracy: 0.9977 - Precision: 0.8907 - Recall: 0.8924 - Specificity: 0.9989 - F1: 0.8850 - Loss: 0.1293\n",
      "\n",
      "Batch 211/387 ━━━━━━━━━━━━━━━━━━━━ 16:16:09\n",
      "Accuracy: 0.9977 - Precision: 0.8912 - Recall: 0.8923 - Specificity: 0.9989 - F1: 0.8852 - Loss: 0.1291\n",
      "\n",
      "Batch 212/387 ━━━━━━━━━━━━━━━━━━━━ 16:17:55\n",
      "Accuracy: 0.9977 - Precision: 0.8915 - Recall: 0.8922 - Specificity: 0.9989 - F1: 0.8853 - Loss: 0.1289\n",
      "\n",
      "Batch 213/387 ━━━━━━━━━━━━━━━━━━━━ 16:19:27\n",
      "Accuracy: 0.9977 - Precision: 0.8919 - Recall: 0.8922 - Specificity: 0.9990 - F1: 0.8855 - Loss: 0.1287\n",
      "\n",
      "Batch 214/387 ━━━━━━━━━━━━━━━━━━━━ 16:20:49\n",
      "Accuracy: 0.9977 - Precision: 0.8922 - Recall: 0.8920 - Specificity: 0.9990 - F1: 0.8856 - Loss: 0.1286\n",
      "\n",
      "Batch 215/387 ━━━━━━━━━━━━━━━━━━━━ 16:22:21\n",
      "Accuracy: 0.9977 - Precision: 0.8927 - Recall: 0.8922 - Specificity: 0.9990 - F1: 0.8859 - Loss: 0.1282\n",
      "\n",
      "Batch 216/387 ━━━━━━━━━━━━━━━━━━━━ 16:23:46\n",
      "Accuracy: 0.9977 - Precision: 0.8928 - Recall: 0.8914 - Specificity: 0.9990 - F1: 0.8856 - Loss: 0.1286\n",
      "\n",
      "Batch 217/387 ━━━━━━━━━━━━━━━━━━━━ 16:25:13\n",
      "Accuracy: 0.9977 - Precision: 0.8931 - Recall: 0.8915 - Specificity: 0.9990 - F1: 0.8859 - Loss: 0.1282\n",
      "\n",
      "Batch 218/387 ━━━━━━━━━━━━━━━━━━━━ 16:26:51\n",
      "Accuracy: 0.9977 - Precision: 0.8936 - Recall: 0.8911 - Specificity: 0.9990 - F1: 0.8858 - Loss: 0.1283\n",
      "\n",
      "Batch 219/387 ━━━━━━━━━━━━━━━━━━━━ 16:28:27\n",
      "Accuracy: 0.9977 - Precision: 0.8934 - Recall: 0.8896 - Specificity: 0.9990 - F1: 0.8849 - Loss: 0.1293\n",
      "\n",
      "Batch 220/387 ━━━━━━━━━━━━━━━━━━━━ 16:29:50\n",
      "Accuracy: 0.9977 - Precision: 0.8923 - Recall: 0.8898 - Specificity: 0.9990 - F1: 0.8843 - Loss: 0.1299\n",
      "\n",
      "Batch 221/387 ━━━━━━━━━━━━━━━━━━━━ 16:31:15\n",
      "Accuracy: 0.9977 - Precision: 0.8917 - Recall: 0.8903 - Specificity: 0.9990 - F1: 0.8842 - Loss: 0.1300\n",
      "\n",
      "Batch 222/387 ━━━━━━━━━━━━━━━━━━━━ 16:32:40\n",
      "Accuracy: 0.9977 - Precision: 0.8921 - Recall: 0.8903 - Specificity: 0.9990 - F1: 0.8844 - Loss: 0.1298\n",
      "\n",
      "Batch 223/387 ━━━━━━━━━━━━━━━━━━━━ 16:34:18\n",
      "Accuracy: 0.9977 - Precision: 0.8921 - Recall: 0.8907 - Specificity: 0.9990 - F1: 0.8847 - Loss: 0.1295\n",
      "\n",
      "Batch 224/387 ━━━━━━━━━━━━━━━━━━━━ 16:35:54\n",
      "Accuracy: 0.9977 - Precision: 0.8925 - Recall: 0.8907 - Specificity: 0.9990 - F1: 0.8849 - Loss: 0.1292\n",
      "\n",
      "Batch 225/387 ━━━━━━━━━━━━━━━━━━━━ 16:37:33\n",
      "Accuracy: 0.9977 - Precision: 0.8929 - Recall: 0.8902 - Specificity: 0.9990 - F1: 0.8848 - Loss: 0.1294\n",
      "\n",
      "Batch 226/387 ━━━━━━━━━━━━━━━━━━━━ 16:38:55\n",
      "Accuracy: 0.9977 - Precision: 0.8930 - Recall: 0.8899 - Specificity: 0.9990 - F1: 0.8847 - Loss: 0.1295\n",
      "\n",
      "Batch 227/387 ━━━━━━━━━━━━━━━━━━━━ 16:40:25\n",
      "Accuracy: 0.9977 - Precision: 0.8930 - Recall: 0.8903 - Specificity: 0.9990 - F1: 0.8849 - Loss: 0.1292\n",
      "\n",
      "Batch 228/387 ━━━━━━━━━━━━━━━━━━━━ 16:42:04\n",
      "Accuracy: 0.9977 - Precision: 0.8928 - Recall: 0.8907 - Specificity: 0.9990 - F1: 0.8851 - Loss: 0.1291\n",
      "\n",
      "Batch 229/387 ━━━━━━━━━━━━━━━━━━━━ 16:43:51\n",
      "Accuracy: 0.9977 - Precision: 0.8928 - Recall: 0.8910 - Specificity: 0.9990 - F1: 0.8852 - Loss: 0.1289\n",
      "\n",
      "Batch 230/387 ━━━━━━━━━━━━━━━━━━━━ 16:45:30\n",
      "Accuracy: 0.9977 - Precision: 0.8923 - Recall: 0.8911 - Specificity: 0.9990 - F1: 0.8850 - Loss: 0.1291\n",
      "\n",
      "Batch 231/387 ━━━━━━━━━━━━━━━━━━━━ 16:47:06\n",
      "Accuracy: 0.9977 - Precision: 0.8916 - Recall: 0.8914 - Specificity: 0.9989 - F1: 0.8848 - Loss: 0.1295\n",
      "\n",
      "Batch 232/387 ━━━━━━━━━━━━━━━━━━━━ 16:48:43\n",
      "Accuracy: 0.9977 - Precision: 0.8905 - Recall: 0.8915 - Specificity: 0.9989 - F1: 0.8843 - Loss: 0.1300\n",
      "\n",
      "Batch 233/387 ━━━━━━━━━━━━━━━━━━━━ 16:50:09\n",
      "Accuracy: 0.9977 - Precision: 0.8896 - Recall: 0.8913 - Specificity: 0.9989 - F1: 0.8836 - Loss: 0.1306\n",
      "\n",
      "Batch 234/387 ━━━━━━━━━━━━━━━━━━━━ 16:51:41\n",
      "Accuracy: 0.9977 - Precision: 0.8893 - Recall: 0.8910 - Specificity: 0.9989 - F1: 0.8834 - Loss: 0.1309\n",
      "\n",
      "Batch 235/387 ━━━━━━━━━━━━━━━━━━━━ 16:53:15\n",
      "Accuracy: 0.9977 - Precision: 0.8896 - Recall: 0.8913 - Specificity: 0.9989 - F1: 0.8837 - Loss: 0.1305\n",
      "\n",
      "Batch 236/387 ━━━━━━━━━━━━━━━━━━━━ 16:54:52\n",
      "Accuracy: 0.9977 - Precision: 0.8897 - Recall: 0.8915 - Specificity: 0.9990 - F1: 0.8839 - Loss: 0.1302\n",
      "\n",
      "Batch 237/387 ━━━━━━━━━━━━━━━━━━━━ 16:56:22\n",
      "Accuracy: 0.9977 - Precision: 0.8898 - Recall: 0.8915 - Specificity: 0.9990 - F1: 0.8840 - Loss: 0.1302\n",
      "\n",
      "Batch 238/387 ━━━━━━━━━━━━━━━━━━━━ 16:57:59\n",
      "Accuracy: 0.9977 - Precision: 0.8900 - Recall: 0.8901 - Specificity: 0.9990 - F1: 0.8832 - Loss: 0.1309\n",
      "\n",
      "Batch 239/387 ━━━━━━━━━━━━━━━━━━━━ 16:59:42\n",
      "Accuracy: 0.9977 - Precision: 0.8902 - Recall: 0.8892 - Specificity: 0.9990 - F1: 0.8828 - Loss: 0.1314\n",
      "\n",
      "Batch 240/387 ━━━━━━━━━━━━━━━━━━━━ 17:01:14\n",
      "Accuracy: 0.9977 - Precision: 0.8906 - Recall: 0.8890 - Specificity: 0.9990 - F1: 0.8829 - Loss: 0.1312\n",
      "\n",
      "Batch 241/387 ━━━━━━━━━━━━━━━━━━━━ 17:02:44\n",
      "Accuracy: 0.9977 - Precision: 0.8903 - Recall: 0.8887 - Specificity: 0.9990 - F1: 0.8826 - Loss: 0.1315\n",
      "\n",
      "Batch 242/387 ━━━━━━━━━━━━━━━━━━━━ 17:04:12\n",
      "Accuracy: 0.9977 - Precision: 0.8899 - Recall: 0.8887 - Specificity: 0.9990 - F1: 0.8825 - Loss: 0.1316\n",
      "\n",
      "Batch 243/387 ━━━━━━━━━━━━━━━━━━━━ 17:05:38\n",
      "Accuracy: 0.9977 - Precision: 0.8901 - Recall: 0.8881 - Specificity: 0.9990 - F1: 0.8823 - Loss: 0.1318\n",
      "\n",
      "Batch 244/387 ━━━━━━━━━━━━━━━━━━━━ 17:07:12\n",
      "Accuracy: 0.9977 - Precision: 0.8904 - Recall: 0.8872 - Specificity: 0.9990 - F1: 0.8819 - Loss: 0.1322\n",
      "\n",
      "Batch 245/387 ━━━━━━━━━━━━━━━━━━━━ 17:08:39\n",
      "Accuracy: 0.9977 - Precision: 0.8908 - Recall: 0.8855 - Specificity: 0.9990 - F1: 0.8809 - Loss: 0.1333\n",
      "\n",
      "Batch 246/387 ━━━━━━━━━━━━━━━━━━━━ 17:10:06\n",
      "Accuracy: 0.9977 - Precision: 0.8901 - Recall: 0.8855 - Specificity: 0.9990 - F1: 0.8805 - Loss: 0.1336\n",
      "\n",
      "Batch 247/387 ━━━━━━━━━━━━━━━━━━━━ 17:11:32\n",
      "Accuracy: 0.9977 - Precision: 0.8906 - Recall: 0.8857 - Specificity: 0.9990 - F1: 0.8808 - Loss: 0.1333\n",
      "\n",
      "Batch 248/387 ━━━━━━━━━━━━━━━━━━━━ 17:13:08\n",
      "Accuracy: 0.9977 - Precision: 0.8908 - Recall: 0.8854 - Specificity: 0.9990 - F1: 0.8808 - Loss: 0.1333\n",
      "\n",
      "Batch 249/387 ━━━━━━━━━━━━━━━━━━━━ 17:14:52\n",
      "Accuracy: 0.9977 - Precision: 0.8908 - Recall: 0.8856 - Specificity: 0.9990 - F1: 0.8810 - Loss: 0.1332\n",
      "\n",
      "Batch 250/387 ━━━━━━━━━━━━━━━━━━━━ 17:16:33\n",
      "Accuracy: 0.9977 - Precision: 0.8908 - Recall: 0.8859 - Specificity: 0.9990 - F1: 0.8812 - Loss: 0.1329\n",
      "\n",
      "Batch 251/387 ━━━━━━━━━━━━━━━━━━━━ 17:18:03\n",
      "Accuracy: 0.9977 - Precision: 0.8907 - Recall: 0.8856 - Specificity: 0.9990 - F1: 0.8809 - Loss: 0.1332\n",
      "\n",
      "Batch 252/387 ━━━━━━━━━━━━━━━━━━━━ 17:19:39\n",
      "Accuracy: 0.9977 - Precision: 0.8907 - Recall: 0.8860 - Specificity: 0.9990 - F1: 0.8811 - Loss: 0.1330\n",
      "\n",
      "Batch 253/387 ━━━━━━━━━━━━━━━━━━━━ 17:21:10\n",
      "Accuracy: 0.9977 - Precision: 0.8904 - Recall: 0.8861 - Specificity: 0.9990 - F1: 0.8811 - Loss: 0.1331\n",
      "\n",
      "Batch 254/387 ━━━━━━━━━━━━━━━━━━━━ 17:22:40\n",
      "Accuracy: 0.9977 - Precision: 0.8895 - Recall: 0.8862 - Specificity: 0.9990 - F1: 0.8807 - Loss: 0.1335\n",
      "\n",
      "Batch 255/387 ━━━━━━━━━━━━━━━━━━━━ 17:24:11\n",
      "Accuracy: 0.9977 - Precision: 0.8893 - Recall: 0.8866 - Specificity: 0.9990 - F1: 0.8808 - Loss: 0.1334\n",
      "\n",
      "Batch 256/387 ━━━━━━━━━━━━━━━━━━━━ 17:25:35\n",
      "Accuracy: 0.9977 - Precision: 0.8892 - Recall: 0.8866 - Specificity: 0.9990 - F1: 0.8807 - Loss: 0.1334\n",
      "\n",
      "Batch 257/387 ━━━━━━━━━━━━━━━━━━━━ 17:27:07\n",
      "Accuracy: 0.9977 - Precision: 0.8895 - Recall: 0.8869 - Specificity: 0.9990 - F1: 0.8811 - Loss: 0.1331\n",
      "\n",
      "Batch 258/387 ━━━━━━━━━━━━━━━━━━━━ 17:28:27\n",
      "Accuracy: 0.9977 - Precision: 0.8896 - Recall: 0.8873 - Specificity: 0.9990 - F1: 0.8813 - Loss: 0.1328\n",
      "\n",
      "Batch 259/387 ━━━━━━━━━━━━━━━━━━━━ 17:29:46\n",
      "Accuracy: 0.9977 - Precision: 0.8899 - Recall: 0.8875 - Specificity: 0.9990 - F1: 0.8816 - Loss: 0.1325\n",
      "\n",
      "Batch 260/387 ━━━━━━━━━━━━━━━━━━━━ 17:31:20\n",
      "Accuracy: 0.9977 - Precision: 0.8899 - Recall: 0.8878 - Specificity: 0.9990 - F1: 0.8818 - Loss: 0.1323\n",
      "\n",
      "Batch 261/387 ━━━━━━━━━━━━━━━━━━━━ 17:32:39\n",
      "Accuracy: 0.9977 - Precision: 0.8902 - Recall: 0.8880 - Specificity: 0.9990 - F1: 0.8821 - Loss: 0.1320\n",
      "\n",
      "Batch 262/387 ━━━━━━━━━━━━━━━━━━━━ 17:34:14\n",
      "Accuracy: 0.9977 - Precision: 0.8902 - Recall: 0.8880 - Specificity: 0.9990 - F1: 0.8821 - Loss: 0.1319\n",
      "\n",
      "Batch 263/387 ━━━━━━━━━━━━━━━━━━━━ 17:35:44\n",
      "Accuracy: 0.9977 - Precision: 0.8903 - Recall: 0.8880 - Specificity: 0.9990 - F1: 0.8821 - Loss: 0.1319\n",
      "\n",
      "Batch 264/387 ━━━━━━━━━━━━━━━━━━━━ 17:37:12\n",
      "Accuracy: 0.9977 - Precision: 0.8903 - Recall: 0.8882 - Specificity: 0.9990 - F1: 0.8823 - Loss: 0.1317\n",
      "\n",
      "Batch 265/387 ━━━━━━━━━━━━━━━━━━━━ 17:38:52\n",
      "Accuracy: 0.9977 - Precision: 0.8906 - Recall: 0.8884 - Specificity: 0.9990 - F1: 0.8826 - Loss: 0.1314\n",
      "\n",
      "Batch 266/387 ━━━━━━━━━━━━━━━━━━━━ 17:40:29\n",
      "Accuracy: 0.9977 - Precision: 0.8909 - Recall: 0.8883 - Specificity: 0.9990 - F1: 0.8827 - Loss: 0.1313\n",
      "\n",
      "Batch 267/387 ━━━━━━━━━━━━━━━━━━━━ 17:42:05\n",
      "Accuracy: 0.9977 - Precision: 0.8910 - Recall: 0.8885 - Specificity: 0.9990 - F1: 0.8829 - Loss: 0.1312\n",
      "\n",
      "Batch 268/387 ━━━━━━━━━━━━━━━━━━━━ 17:43:39\n",
      "Accuracy: 0.9977 - Precision: 0.8913 - Recall: 0.8882 - Specificity: 0.9990 - F1: 0.8828 - Loss: 0.1312\n",
      "\n",
      "Batch 269/387 ━━━━━━━━━━━━━━━━━━━━ 17:45:16\n",
      "Accuracy: 0.9977 - Precision: 0.8914 - Recall: 0.8883 - Specificity: 0.9990 - F1: 0.8830 - Loss: 0.1311\n",
      "\n",
      "Batch 270/387 ━━━━━━━━━━━━━━━━━━━━ 17:46:49\n",
      "Accuracy: 0.9977 - Precision: 0.8910 - Recall: 0.8886 - Specificity: 0.9990 - F1: 0.8829 - Loss: 0.1311\n",
      "\n",
      "Batch 271/387 ━━━━━━━━━━━━━━━━━━━━ 17:48:28\n",
      "Accuracy: 0.9977 - Precision: 0.8914 - Recall: 0.8888 - Specificity: 0.9990 - F1: 0.8832 - Loss: 0.1308\n",
      "\n",
      "Batch 272/387 ━━━━━━━━━━━━━━━━━━━━ 17:50:03\n",
      "Accuracy: 0.9977 - Precision: 0.8911 - Recall: 0.8889 - Specificity: 0.9990 - F1: 0.8832 - Loss: 0.1309\n",
      "\n",
      "Batch 273/387 ━━━━━━━━━━━━━━━━━━━━ 17:51:43\n",
      "Accuracy: 0.9977 - Precision: 0.8910 - Recall: 0.8891 - Specificity: 0.9990 - F1: 0.8832 - Loss: 0.1308\n",
      "\n",
      "Batch 274/387 ━━━━━━━━━━━━━━━━━━━━ 17:53:23\n",
      "Accuracy: 0.9977 - Precision: 0.8909 - Recall: 0.8894 - Specificity: 0.9990 - F1: 0.8833 - Loss: 0.1307\n",
      "\n",
      "Batch 275/387 ━━━━━━━━━━━━━━━━━━━━ 17:54:42\n",
      "Accuracy: 0.9977 - Precision: 0.8912 - Recall: 0.8896 - Specificity: 0.9990 - F1: 0.8836 - Loss: 0.1304\n",
      "\n",
      "Batch 276/387 ━━━━━━━━━━━━━━━━━━━━ 17:56:14\n",
      "Accuracy: 0.9977 - Precision: 0.8909 - Recall: 0.8899 - Specificity: 0.9990 - F1: 0.8836 - Loss: 0.1303\n",
      "\n",
      "Batch 277/387 ━━━━━━━━━━━━━━━━━━━━ 17:57:52\n",
      "Accuracy: 0.9977 - Precision: 0.8910 - Recall: 0.8901 - Specificity: 0.9990 - F1: 0.8838 - Loss: 0.1302\n",
      "\n",
      "Batch 278/387 ━━━━━━━━━━━━━━━━━━━━ 17:59:23\n",
      "Accuracy: 0.9977 - Precision: 0.8913 - Recall: 0.8897 - Specificity: 0.9990 - F1: 0.8837 - Loss: 0.1303\n",
      "\n",
      "Batch 279/387 ━━━━━━━━━━━━━━━━━━━━ 18:00:43\n",
      "Accuracy: 0.9977 - Precision: 0.8915 - Recall: 0.8897 - Specificity: 0.9990 - F1: 0.8839 - Loss: 0.1302\n",
      "\n",
      "Batch 280/387 ━━━━━━━━━━━━━━━━━━━━ 18:02:22\n",
      "Accuracy: 0.9977 - Precision: 0.8916 - Recall: 0.8898 - Specificity: 0.9990 - F1: 0.8840 - Loss: 0.1300\n",
      "\n",
      "Batch 281/387 ━━━━━━━━━━━━━━━━━━━━ 18:03:49\n",
      "Accuracy: 0.9977 - Precision: 0.8917 - Recall: 0.8894 - Specificity: 0.9990 - F1: 0.8838 - Loss: 0.1301\n",
      "\n",
      "Batch 282/387 ━━━━━━━━━━━━━━━━━━━━ 18:05:22\n",
      "Accuracy: 0.9977 - Precision: 0.8917 - Recall: 0.8895 - Specificity: 0.9990 - F1: 0.8839 - Loss: 0.1301\n",
      "\n",
      "Batch 283/387 ━━━━━━━━━━━━━━━━━━━━ 18:06:49\n",
      "Accuracy: 0.9977 - Precision: 0.8916 - Recall: 0.8885 - Specificity: 0.9990 - F1: 0.8833 - Loss: 0.1308\n",
      "\n",
      "Batch 284/387 ━━━━━━━━━━━━━━━━━━━━ 18:08:21\n",
      "Accuracy: 0.9977 - Precision: 0.8919 - Recall: 0.8874 - Specificity: 0.9990 - F1: 0.8827 - Loss: 0.1314\n",
      "\n",
      "Batch 285/387 ━━━━━━━━━━━━━━━━━━━━ 18:09:58\n",
      "Accuracy: 0.9977 - Precision: 0.8922 - Recall: 0.8869 - Specificity: 0.9990 - F1: 0.8826 - Loss: 0.1316\n",
      "\n",
      "Batch 286/387 ━━━━━━━━━━━━━━━━━━━━ 18:11:21\n",
      "Accuracy: 0.9977 - Precision: 0.8921 - Recall: 0.8871 - Specificity: 0.9990 - F1: 0.8827 - Loss: 0.1315\n",
      "\n",
      "Batch 287/387 ━━━━━━━━━━━━━━━━━━━━ 18:12:58\n",
      "Accuracy: 0.9977 - Precision: 0.8923 - Recall: 0.8871 - Specificity: 0.9990 - F1: 0.8828 - Loss: 0.1314\n",
      "\n",
      "Batch 288/387 ━━━━━━━━━━━━━━━━━━━━ 18:14:19\n",
      "Accuracy: 0.9977 - Precision: 0.8923 - Recall: 0.8873 - Specificity: 0.9990 - F1: 0.8829 - Loss: 0.1312\n",
      "\n",
      "Batch 289/387 ━━━━━━━━━━━━━━━━━━━━ 18:15:50\n",
      "Accuracy: 0.9977 - Precision: 0.8924 - Recall: 0.8876 - Specificity: 0.9990 - F1: 0.8832 - Loss: 0.1310\n",
      "\n",
      "Batch 290/387 ━━━━━━━━━━━━━━━━━━━━ 18:17:42\n",
      "Accuracy: 0.9977 - Precision: 0.8924 - Recall: 0.8879 - Specificity: 0.9990 - F1: 0.8833 - Loss: 0.1308\n",
      "\n",
      "Batch 291/387 ━━━━━━━━━━━━━━━━━━━━ 18:19:12\n",
      "Accuracy: 0.9977 - Precision: 0.8926 - Recall: 0.8881 - Specificity: 0.9990 - F1: 0.8835 - Loss: 0.1306\n",
      "\n",
      "Batch 292/387 ━━━━━━━━━━━━━━━━━━━━ 18:20:45\n",
      "Accuracy: 0.9977 - Precision: 0.8928 - Recall: 0.8884 - Specificity: 0.9990 - F1: 0.8838 - Loss: 0.1303\n",
      "\n",
      "Batch 293/387 ━━━━━━━━━━━━━━━━━━━━ 18:22:24\n",
      "Accuracy: 0.9977 - Precision: 0.8926 - Recall: 0.8882 - Specificity: 0.9990 - F1: 0.8836 - Loss: 0.1305\n",
      "\n",
      "Batch 294/387 ━━━━━━━━━━━━━━━━━━━━ 18:24:00\n",
      "Accuracy: 0.9977 - Precision: 0.8928 - Recall: 0.8880 - Specificity: 0.9990 - F1: 0.8837 - Loss: 0.1304\n",
      "\n",
      "Batch 295/387 ━━━━━━━━━━━━━━━━━━━━ 18:25:34\n",
      "Accuracy: 0.9977 - Precision: 0.8930 - Recall: 0.8882 - Specificity: 0.9990 - F1: 0.8838 - Loss: 0.1302\n",
      "\n",
      "Batch 296/387 ━━━━━━━━━━━━━━━━━━━━ 18:27:00\n",
      "Accuracy: 0.9977 - Precision: 0.8932 - Recall: 0.8884 - Specificity: 0.9990 - F1: 0.8841 - Loss: 0.1300\n",
      "\n",
      "Batch 297/387 ━━━━━━━━━━━━━━━━━━━━ 18:28:39\n",
      "Accuracy: 0.9977 - Precision: 0.8916 - Recall: 0.8886 - Specificity: 0.9990 - F1: 0.8831 - Loss: 0.1310\n",
      "\n",
      "Batch 298/387 ━━━━━━━━━━━━━━━━━━━━ 18:30:10\n",
      "Accuracy: 0.9977 - Precision: 0.8919 - Recall: 0.8887 - Specificity: 0.9990 - F1: 0.8833 - Loss: 0.1308\n",
      "\n",
      "Batch 299/387 ━━━━━━━━━━━━━━━━━━━━ 18:31:38\n",
      "Accuracy: 0.9977 - Precision: 0.8921 - Recall: 0.8889 - Specificity: 0.9990 - F1: 0.8836 - Loss: 0.1305\n",
      "\n",
      "Batch 300/387 ━━━━━━━━━━━━━━━━━━━━ 18:32:57\n",
      "Accuracy: 0.9977 - Precision: 0.8925 - Recall: 0.8887 - Specificity: 0.9990 - F1: 0.8836 - Loss: 0.1305\n",
      "\n",
      "Batch 301/387 ━━━━━━━━━━━━━━━━━━━━ 18:34:27\n",
      "Accuracy: 0.9977 - Precision: 0.8926 - Recall: 0.8888 - Specificity: 0.9990 - F1: 0.8838 - Loss: 0.1303\n",
      "\n",
      "Batch 302/387 ━━━━━━━━━━━━━━━━━━━━ 18:35:51\n",
      "Accuracy: 0.9977 - Precision: 0.8926 - Recall: 0.8891 - Specificity: 0.9990 - F1: 0.8839 - Loss: 0.1301\n",
      "\n",
      "Batch 303/387 ━━━━━━━━━━━━━━━━━━━━ 18:37:23\n",
      "Accuracy: 0.9977 - Precision: 0.8928 - Recall: 0.8886 - Specificity: 0.9990 - F1: 0.8838 - Loss: 0.1303\n",
      "\n",
      "Batch 304/387 ━━━━━━━━━━━━━━━━━━━━ 18:38:57\n",
      "Accuracy: 0.9977 - Precision: 0.8930 - Recall: 0.8886 - Specificity: 0.9990 - F1: 0.8839 - Loss: 0.1302\n",
      "\n",
      "Batch 305/387 ━━━━━━━━━━━━━━━━━━━━ 18:40:13\n",
      "Accuracy: 0.9977 - Precision: 0.8933 - Recall: 0.8887 - Specificity: 0.9990 - F1: 0.8841 - Loss: 0.1300\n",
      "\n",
      "Batch 306/387 ━━━━━━━━━━━━━━━━━━━━ 18:41:53\n",
      "Accuracy: 0.9977 - Precision: 0.8934 - Recall: 0.8883 - Specificity: 0.9990 - F1: 0.8839 - Loss: 0.1301\n",
      "\n",
      "Batch 307/387 ━━━━━━━━━━━━━━━━━━━━ 18:43:26\n",
      "Accuracy: 0.9977 - Precision: 0.8937 - Recall: 0.8885 - Specificity: 0.9990 - F1: 0.8842 - Loss: 0.1298\n",
      "\n",
      "Batch 308/387 ━━━━━━━━━━━━━━━━━━━━ 18:45:00\n",
      "Accuracy: 0.9977 - Precision: 0.8939 - Recall: 0.8885 - Specificity: 0.9990 - F1: 0.8843 - Loss: 0.1297\n",
      "\n",
      "Batch 309/387 ━━━━━━━━━━━━━━━━━━━━ 18:46:16\n",
      "Accuracy: 0.9977 - Precision: 0.8938 - Recall: 0.8886 - Specificity: 0.9990 - F1: 0.8844 - Loss: 0.1297\n",
      "\n",
      "Batch 310/387 ━━━━━━━━━━━━━━━━━━━━ 18:48:06\n",
      "Accuracy: 0.9977 - Precision: 0.8932 - Recall: 0.8889 - Specificity: 0.9990 - F1: 0.8842 - Loss: 0.1299\n",
      "\n",
      "Batch 311/387 ━━━━━━━━━━━━━━━━━━━━ 18:49:26\n",
      "Accuracy: 0.9977 - Precision: 0.8928 - Recall: 0.8892 - Specificity: 0.9990 - F1: 0.8841 - Loss: 0.1300\n",
      "\n",
      "Batch 312/387 ━━━━━━━━━━━━━━━━━━━━ 18:51:02\n",
      "Accuracy: 0.9977 - Precision: 0.8923 - Recall: 0.8892 - Specificity: 0.9990 - F1: 0.8839 - Loss: 0.1302\n",
      "\n",
      "Batch 313/387 ━━━━━━━━━━━━━━━━━━━━ 18:52:25\n",
      "Accuracy: 0.9977 - Precision: 0.8926 - Recall: 0.8893 - Specificity: 0.9990 - F1: 0.8840 - Loss: 0.1300\n",
      "\n",
      "Batch 314/387 ━━━━━━━━━━━━━━━━━━━━ 18:53:59\n",
      "Accuracy: 0.9977 - Precision: 0.8924 - Recall: 0.8895 - Specificity: 0.9990 - F1: 0.8841 - Loss: 0.1300\n",
      "\n",
      "Batch 315/387 ━━━━━━━━━━━━━━━━━━━━ 18:55:29\n",
      "Accuracy: 0.9977 - Precision: 0.8925 - Recall: 0.8886 - Specificity: 0.9990 - F1: 0.8836 - Loss: 0.1305\n",
      "\n",
      "Batch 316/387 ━━━━━━━━━━━━━━━━━━━━ 18:56:57\n",
      "Accuracy: 0.9977 - Precision: 0.8926 - Recall: 0.8887 - Specificity: 0.9990 - F1: 0.8837 - Loss: 0.1303\n",
      "\n",
      "Batch 317/387 ━━━━━━━━━━━━━━━━━━━━ 18:58:29\n",
      "Accuracy: 0.9977 - Precision: 0.8929 - Recall: 0.8889 - Specificity: 0.9990 - F1: 0.8840 - Loss: 0.1301\n",
      "\n",
      "Batch 318/387 ━━━━━━━━━━━━━━━━━━━━ 18:59:54\n",
      "Accuracy: 0.9977 - Precision: 0.8930 - Recall: 0.8891 - Specificity: 0.9990 - F1: 0.8842 - Loss: 0.1298\n",
      "\n",
      "Batch 319/387 ━━━━━━━━━━━━━━━━━━━━ 19:01:28\n",
      "Accuracy: 0.9977 - Precision: 0.8932 - Recall: 0.8893 - Specificity: 0.9990 - F1: 0.8844 - Loss: 0.1296\n",
      "\n",
      "Batch 320/387 ━━━━━━━━━━━━━━━━━━━━ 19:02:59\n",
      "Accuracy: 0.9977 - Precision: 0.8934 - Recall: 0.8892 - Specificity: 0.9990 - F1: 0.8844 - Loss: 0.1296\n",
      "\n",
      "Batch 321/387 ━━━━━━━━━━━━━━━━━━━━ 19:04:31\n",
      "Accuracy: 0.9977 - Precision: 0.8936 - Recall: 0.8885 - Specificity: 0.9990 - F1: 0.8841 - Loss: 0.1298\n",
      "\n",
      "Batch 322/387 ━━━━━━━━━━━━━━━━━━━━ 19:06:06\n",
      "Accuracy: 0.9977 - Precision: 0.8936 - Recall: 0.8888 - Specificity: 0.9990 - F1: 0.8843 - Loss: 0.1297\n",
      "\n",
      "Batch 323/387 ━━━━━━━━━━━━━━━━━━━━ 19:07:34\n",
      "Accuracy: 0.9977 - Precision: 0.8937 - Recall: 0.8885 - Specificity: 0.9990 - F1: 0.8842 - Loss: 0.1297\n",
      "\n",
      "Batch 324/387 ━━━━━━━━━━━━━━━━━━━━ 19:08:57\n",
      "Accuracy: 0.9977 - Precision: 0.8936 - Recall: 0.8888 - Specificity: 0.9990 - F1: 0.8843 - Loss: 0.1296\n",
      "\n",
      "Batch 325/387 ━━━━━━━━━━━━━━━━━━━━ 19:10:22\n",
      "Accuracy: 0.9977 - Precision: 0.8927 - Recall: 0.8887 - Specificity: 0.9990 - F1: 0.8838 - Loss: 0.1302\n",
      "\n",
      "Batch 326/387 ━━━━━━━━━━━━━━━━━━━━ 19:11:53\n",
      "Accuracy: 0.9977 - Precision: 0.8924 - Recall: 0.8889 - Specificity: 0.9990 - F1: 0.8837 - Loss: 0.1303\n",
      "\n",
      "Batch 327/387 ━━━━━━━━━━━━━━━━━━━━ 19:13:28\n",
      "Accuracy: 0.9977 - Precision: 0.8923 - Recall: 0.8890 - Specificity: 0.9990 - F1: 0.8837 - Loss: 0.1303\n",
      "\n",
      "Batch 328/387 ━━━━━━━━━━━━━━━━━━━━ 19:14:43\n",
      "Accuracy: 0.9977 - Precision: 0.8923 - Recall: 0.8892 - Specificity: 0.9990 - F1: 0.8838 - Loss: 0.1301\n",
      "\n",
      "Batch 329/387 ━━━━━━━━━━━━━━━━━━━━ 19:16:14\n",
      "Accuracy: 0.9977 - Precision: 0.8926 - Recall: 0.8893 - Specificity: 0.9990 - F1: 0.8841 - Loss: 0.1299\n",
      "\n",
      "Batch 330/387 ━━━━━━━━━━━━━━━━━━━━ 19:17:41\n",
      "Accuracy: 0.9977 - Precision: 0.8921 - Recall: 0.8892 - Specificity: 0.9990 - F1: 0.8838 - Loss: 0.1302\n",
      "\n",
      "Batch 331/387 ━━━━━━━━━━━━━━━━━━━━ 19:19:14\n",
      "Accuracy: 0.9977 - Precision: 0.8922 - Recall: 0.8892 - Specificity: 0.9990 - F1: 0.8839 - Loss: 0.1301\n",
      "\n",
      "Batch 332/387 ━━━━━━━━━━━━━━━━━━━━ 19:20:47\n",
      "Accuracy: 0.9977 - Precision: 0.8924 - Recall: 0.8894 - Specificity: 0.9990 - F1: 0.8841 - Loss: 0.1298\n",
      "\n",
      "Batch 333/387 ━━━━━━━━━━━━━━━━━━━━ 19:22:22\n",
      "Accuracy: 0.9977 - Precision: 0.8928 - Recall: 0.8888 - Specificity: 0.9990 - F1: 0.8839 - Loss: 0.1300\n",
      "\n",
      "Batch 334/387 ━━━━━━━━━━━━━━━━━━━━ 19:23:51\n",
      "Accuracy: 0.9978 - Precision: 0.8930 - Recall: 0.8888 - Specificity: 0.9990 - F1: 0.8840 - Loss: 0.1299\n",
      "\n",
      "Batch 335/387 ━━━━━━━━━━━━━━━━━━━━ 19:25:26\n",
      "Accuracy: 0.9978 - Precision: 0.8927 - Recall: 0.8891 - Specificity: 0.9990 - F1: 0.8840 - Loss: 0.1299\n",
      "\n",
      "Batch 336/387 ━━━━━━━━━━━━━━━━━━━━ 19:27:10\n",
      "Accuracy: 0.9978 - Precision: 0.8927 - Recall: 0.8889 - Specificity: 0.9990 - F1: 0.8839 - Loss: 0.1300\n",
      "\n",
      "Batch 337/387 ━━━━━━━━━━━━━━━━━━━━ 19:28:32\n",
      "Accuracy: 0.9978 - Precision: 0.8929 - Recall: 0.8891 - Specificity: 0.9990 - F1: 0.8841 - Loss: 0.1298\n",
      "\n",
      "Batch 338/387 ━━━━━━━━━━━━━━━━━━━━ 19:29:54\n",
      "Accuracy: 0.9978 - Precision: 0.8926 - Recall: 0.8892 - Specificity: 0.9990 - F1: 0.8841 - Loss: 0.1298\n",
      "\n",
      "Batch 339/387 ━━━━━━━━━━━━━━━━━━━━ 19:31:41\n",
      "Accuracy: 0.9978 - Precision: 0.8929 - Recall: 0.8893 - Specificity: 0.9990 - F1: 0.8842 - Loss: 0.1296\n",
      "\n",
      "Batch 340/387 ━━━━━━━━━━━━━━━━━━━━ 19:33:16\n",
      "Accuracy: 0.9978 - Precision: 0.8929 - Recall: 0.8892 - Specificity: 0.9990 - F1: 0.8842 - Loss: 0.1296\n",
      "\n",
      "Batch 341/387 ━━━━━━━━━━━━━━━━━━━━ 19:34:42\n",
      "Accuracy: 0.9978 - Precision: 0.8928 - Recall: 0.8892 - Specificity: 0.9990 - F1: 0.8842 - Loss: 0.1296\n",
      "\n",
      "Batch 342/387 ━━━━━━━━━━━━━━━━━━━━ 19:36:20\n",
      "Accuracy: 0.9978 - Precision: 0.8930 - Recall: 0.8895 - Specificity: 0.9990 - F1: 0.8845 - Loss: 0.1294\n",
      "\n",
      "Batch 343/387 ━━━━━━━━━━━━━━━━━━━━ 19:38:01\n",
      "Accuracy: 0.9978 - Precision: 0.8932 - Recall: 0.8889 - Specificity: 0.9990 - F1: 0.8842 - Loss: 0.1297\n",
      "\n",
      "Batch 344/387 ━━━━━━━━━━━━━━━━━━━━ 19:39:33\n",
      "Accuracy: 0.9978 - Precision: 0.8934 - Recall: 0.8889 - Specificity: 0.9990 - F1: 0.8843 - Loss: 0.1295\n",
      "\n",
      "Batch 345/387 ━━━━━━━━━━━━━━━━━━━━ 19:40:57\n",
      "Accuracy: 0.9978 - Precision: 0.8936 - Recall: 0.8890 - Specificity: 0.9990 - F1: 0.8845 - Loss: 0.1293\n",
      "\n",
      "Batch 346/387 ━━━━━━━━━━━━━━━━━━━━ 19:42:17\n",
      "Accuracy: 0.9978 - Precision: 0.8935 - Recall: 0.8892 - Specificity: 0.9990 - F1: 0.8846 - Loss: 0.1292\n",
      "\n",
      "Batch 347/387 ━━━━━━━━━━━━━━━━━━━━ 19:43:43\n",
      "Accuracy: 0.9978 - Precision: 0.8933 - Recall: 0.8891 - Specificity: 0.9990 - F1: 0.8845 - Loss: 0.1294\n",
      "\n",
      "Batch 348/387 ━━━━━━━━━━━━━━━━━━━━ 19:45:09\n",
      "Accuracy: 0.9978 - Precision: 0.8936 - Recall: 0.8890 - Specificity: 0.9990 - F1: 0.8845 - Loss: 0.1293\n",
      "\n",
      "Batch 349/387 ━━━━━━━━━━━━━━━━━━━━ 19:46:45\n",
      "Accuracy: 0.9978 - Precision: 0.8938 - Recall: 0.8891 - Specificity: 0.9990 - F1: 0.8847 - Loss: 0.1291\n",
      "\n",
      "Batch 350/387 ━━━━━━━━━━━━━━━━━━━━ 19:48:23\n",
      "Accuracy: 0.9978 - Precision: 0.8937 - Recall: 0.8891 - Specificity: 0.9990 - F1: 0.8847 - Loss: 0.1291\n",
      "\n",
      "Batch 351/387 ━━━━━━━━━━━━━━━━━━━━ 19:49:57\n",
      "Accuracy: 0.9978 - Precision: 0.8938 - Recall: 0.8889 - Specificity: 0.9990 - F1: 0.8846 - Loss: 0.1292\n",
      "\n",
      "Batch 352/387 ━━━━━━━━━━━━━━━━━━━━ 19:51:29\n",
      "Accuracy: 0.9978 - Precision: 0.8940 - Recall: 0.8886 - Specificity: 0.9990 - F1: 0.8846 - Loss: 0.1292\n",
      "\n",
      "Batch 353/387 ━━━━━━━━━━━━━━━━━━━━ 19:52:49\n",
      "Accuracy: 0.9978 - Precision: 0.8942 - Recall: 0.8888 - Specificity: 0.9990 - F1: 0.8848 - Loss: 0.1290\n",
      "\n",
      "Batch 354/387 ━━━━━━━━━━━━━━━━━━━━ 19:54:19\n",
      "Accuracy: 0.9978 - Precision: 0.8942 - Recall: 0.8890 - Specificity: 0.9990 - F1: 0.8849 - Loss: 0.1289\n",
      "\n",
      "Batch 355/387 ━━━━━━━━━━━━━━━━━━━━ 19:55:45\n",
      "Accuracy: 0.9978 - Precision: 0.8939 - Recall: 0.8891 - Specificity: 0.9990 - F1: 0.8848 - Loss: 0.1290\n",
      "\n",
      "Batch 356/387 ━━━━━━━━━━━━━━━━━━━━ 19:57:22\n",
      "Accuracy: 0.9978 - Precision: 0.8941 - Recall: 0.8889 - Specificity: 0.9990 - F1: 0.8848 - Loss: 0.1290\n",
      "\n",
      "Batch 357/387 ━━━━━━━━━━━━━━━━━━━━ 19:59:00\n",
      "Accuracy: 0.9978 - Precision: 0.8937 - Recall: 0.8889 - Specificity: 0.9990 - F1: 0.8846 - Loss: 0.1292\n",
      "\n",
      "Batch 358/387 ━━━━━━━━━━━━━━━━━━━━ 20:00:26\n",
      "Accuracy: 0.9978 - Precision: 0.8937 - Recall: 0.8887 - Specificity: 0.9990 - F1: 0.8845 - Loss: 0.1293\n",
      "\n",
      "Batch 359/387 ━━━━━━━━━━━━━━━━━━━━ 20:01:54\n",
      "Accuracy: 0.9978 - Precision: 0.8937 - Recall: 0.8886 - Specificity: 0.9990 - F1: 0.8845 - Loss: 0.1293\n",
      "\n",
      "Batch 360/387 ━━━━━━━━━━━━━━━━━━━━ 20:03:29\n",
      "Accuracy: 0.9978 - Precision: 0.8934 - Recall: 0.8888 - Specificity: 0.9990 - F1: 0.8845 - Loss: 0.1293\n",
      "\n",
      "Batch 361/387 ━━━━━━━━━━━━━━━━━━━━ 20:04:59\n",
      "Accuracy: 0.9978 - Precision: 0.8937 - Recall: 0.8887 - Specificity: 0.9990 - F1: 0.8845 - Loss: 0.1293\n",
      "\n",
      "Batch 362/387 ━━━━━━━━━━━━━━━━━━━━ 20:06:26\n",
      "Accuracy: 0.9978 - Precision: 0.8937 - Recall: 0.8889 - Specificity: 0.9990 - F1: 0.8847 - Loss: 0.1291\n",
      "\n",
      "Batch 363/387 ━━━━━━━━━━━━━━━━━━━━ 20:08:00\n",
      "Accuracy: 0.9978 - Precision: 0.8937 - Recall: 0.8892 - Specificity: 0.9990 - F1: 0.8848 - Loss: 0.1289\n",
      "\n",
      "Batch 364/387 ━━━━━━━━━━━━━━━━━━━━ 20:09:31\n",
      "Accuracy: 0.9978 - Precision: 0.8937 - Recall: 0.8893 - Specificity: 0.9990 - F1: 0.8849 - Loss: 0.1289\n",
      "\n",
      "Batch 365/387 ━━━━━━━━━━━━━━━━━━━━ 20:11:00\n",
      "Accuracy: 0.9978 - Precision: 0.8938 - Recall: 0.8895 - Specificity: 0.9990 - F1: 0.8851 - Loss: 0.1286\n",
      "\n",
      "Batch 366/387 ━━━━━━━━━━━━━━━━━━━━ 20:12:41\n",
      "Accuracy: 0.9978 - Precision: 0.8939 - Recall: 0.8897 - Specificity: 0.9990 - F1: 0.8852 - Loss: 0.1285\n",
      "\n",
      "Batch 367/387 ━━━━━━━━━━━━━━━━━━━━ 20:14:20\n",
      "Accuracy: 0.9978 - Precision: 0.8940 - Recall: 0.8898 - Specificity: 0.9990 - F1: 0.8853 - Loss: 0.1284\n",
      "\n",
      "Batch 368/387 ━━━━━━━━━━━━━━━━━━━━ 20:15:44\n",
      "Accuracy: 0.9978 - Precision: 0.8942 - Recall: 0.8898 - Specificity: 0.9990 - F1: 0.8855 - Loss: 0.1282\n",
      "\n",
      "Batch 369/387 ━━━━━━━━━━━━━━━━━━━━ 20:17:13\n",
      "Accuracy: 0.9978 - Precision: 0.8938 - Recall: 0.8901 - Specificity: 0.9990 - F1: 0.8854 - Loss: 0.1283\n",
      "\n",
      "Batch 370/387 ━━━━━━━━━━━━━━━━━━━━ 20:18:51\n",
      "Accuracy: 0.9978 - Precision: 0.8939 - Recall: 0.8899 - Specificity: 0.9990 - F1: 0.8853 - Loss: 0.1284\n",
      "\n",
      "Batch 371/387 ━━━━━━━━━━━━━━━━━━━━ 20:20:37\n",
      "Accuracy: 0.9978 - Precision: 0.8938 - Recall: 0.8897 - Specificity: 0.9990 - F1: 0.8852 - Loss: 0.1285\n",
      "\n",
      "Batch 372/387 ━━━━━━━━━━━━━━━━━━━━ 20:22:13\n",
      "Accuracy: 0.9978 - Precision: 0.8940 - Recall: 0.8897 - Specificity: 0.9990 - F1: 0.8853 - Loss: 0.1284\n",
      "\n",
      "Batch 373/387 ━━━━━━━━━━━━━━━━━━━━ 20:23:44\n",
      "Accuracy: 0.9978 - Precision: 0.8941 - Recall: 0.8894 - Specificity: 0.9990 - F1: 0.8852 - Loss: 0.1285\n",
      "\n",
      "Batch 374/387 ━━━━━━━━━━━━━━━━━━━━ 20:25:16\n",
      "Accuracy: 0.9978 - Precision: 0.8943 - Recall: 0.8893 - Specificity: 0.9990 - F1: 0.8853 - Loss: 0.1284\n",
      "\n",
      "Batch 375/387 ━━━━━━━━━━━━━━━━━━━━ 20:26:58\n",
      "Accuracy: 0.9978 - Precision: 0.8943 - Recall: 0.8891 - Specificity: 0.9990 - F1: 0.8852 - Loss: 0.1285\n",
      "\n",
      "Batch 376/387 ━━━━━━━━━━━━━━━━━━━━ 20:28:48\n",
      "Accuracy: 0.9978 - Precision: 0.8933 - Recall: 0.8894 - Specificity: 0.9990 - F1: 0.8846 - Loss: 0.1291\n",
      "\n",
      "Batch 377/387 ━━━━━━━━━━━━━━━━━━━━ 20:30:21\n",
      "Accuracy: 0.9978 - Precision: 0.8935 - Recall: 0.8894 - Specificity: 0.9990 - F1: 0.8847 - Loss: 0.1290\n",
      "\n",
      "Batch 378/387 ━━━━━━━━━━━━━━━━━━━━ 20:31:49\n",
      "Accuracy: 0.9978 - Precision: 0.8936 - Recall: 0.8894 - Specificity: 0.9990 - F1: 0.8848 - Loss: 0.1289\n",
      "\n",
      "Batch 379/387 ━━━━━━━━━━━━━━━━━━━━ 20:33:13\n",
      "Accuracy: 0.9978 - Precision: 0.8937 - Recall: 0.8895 - Specificity: 0.9990 - F1: 0.8849 - Loss: 0.1288\n",
      "\n",
      "Batch 380/387 ━━━━━━━━━━━━━━━━━━━━ 20:34:51\n",
      "Accuracy: 0.9978 - Precision: 0.8935 - Recall: 0.8897 - Specificity: 0.9990 - F1: 0.8849 - Loss: 0.1288\n",
      "\n",
      "Batch 381/387 ━━━━━━━━━━━━━━━━━━━━ 20:36:17\n",
      "Accuracy: 0.9978 - Precision: 0.8934 - Recall: 0.8898 - Specificity: 0.9990 - F1: 0.8849 - Loss: 0.1288\n",
      "\n",
      "Batch 382/387 ━━━━━━━━━━━━━━━━━━━━ 20:37:34\n",
      "Accuracy: 0.9978 - Precision: 0.8933 - Recall: 0.8900 - Specificity: 0.9990 - F1: 0.8850 - Loss: 0.1287\n",
      "\n",
      "Batch 383/387 ━━━━━━━━━━━━━━━━━━━━ 20:39:05\n",
      "Accuracy: 0.9978 - Precision: 0.8932 - Recall: 0.8901 - Specificity: 0.9990 - F1: 0.8850 - Loss: 0.1287\n",
      "\n",
      "Batch 384/387 ━━━━━━━━━━━━━━━━━━━━ 20:40:26\n",
      "Accuracy: 0.9978 - Precision: 0.8934 - Recall: 0.8900 - Specificity: 0.9990 - F1: 0.8851 - Loss: 0.1286\n",
      "\n",
      "Batch 385/387 ━━━━━━━━━━━━━━━━━━━━ 20:41:53\n",
      "Accuracy: 0.9978 - Precision: 0.8936 - Recall: 0.8900 - Specificity: 0.9990 - F1: 0.8852 - Loss: 0.1285\n",
      "\n",
      "Batch 386/387 ━━━━━━━━━━━━━━━━━━━━ 20:43:26\n",
      "Accuracy: 0.9978 - Precision: 0.8938 - Recall: 0.8899 - Specificity: 0.9990 - F1: 0.8853 - Loss: 0.1284\n",
      "\n",
      "Batch 387/387 ━━━━━━━━━━━━━━━━━━━━ 20:44:47\n",
      "Accuracy: 0.9978 - Precision: 0.8940 - Recall: 0.8902 - Specificity: 0.9990 - F1: 0.8855 - Loss: 0.1281\n",
      "\n",
      "End of Epoch 11\n",
      "\n",
      "Epoch 12/50\n",
      "Batch 1/387 ━━━━━━━━━━━━━━━━━━━━ 21:06:55\n",
      "Accuracy: 0.9977 - Precision: 0.9195 - Recall: 0.9336 - Specificity: 0.9987 - F1: 0.9265 - Loss: 0.0846\n",
      "\n",
      "Batch 2/387 ━━━━━━━━━━━━━━━━━━━━ 21:08:29\n",
      "Accuracy: 0.9982 - Precision: 0.9523 - Recall: 0.9087 - Specificity: 0.9993 - F1: 0.9291 - Loss: 0.0802\n",
      "\n",
      "Batch 3/387 ━━━━━━━━━━━━━━━━━━━━ 21:09:58\n",
      "Accuracy: 0.9978 - Precision: 0.9669 - Recall: 0.8819 - Specificity: 0.9995 - F1: 0.9209 - Loss: 0.0912\n",
      "\n",
      "Batch 4/387 ━━━━━━━━━━━━━━━━━━━━ 21:11:24\n",
      "Accuracy: 0.9979 - Precision: 0.8882 - Recall: 0.9064 - Specificity: 0.9992 - F1: 0.8864 - Loss: 0.1257\n",
      "\n",
      "Batch 5/387 ━━━━━━━━━━━━━━━━━━━━ 21:12:46\n",
      "Accuracy: 0.9976 - Precision: 0.9088 - Recall: 0.8824 - Specificity: 0.9993 - F1: 0.8845 - Loss: 0.1301\n",
      "\n",
      "Batch 6/387 ━━━━━━━━━━━━━━━━━━━━ 21:14:12\n",
      "Accuracy: 0.9980 - Precision: 0.9113 - Recall: 0.8675 - Specificity: 0.9994 - F1: 0.8794 - Loss: 0.1342\n",
      "\n",
      "Batch 7/387 ━━━━━━━━━━━━━━━━━━━━ 21:15:40\n",
      "Accuracy: 0.9981 - Precision: 0.9227 - Recall: 0.8787 - Specificity: 0.9995 - F1: 0.8920 - Loss: 0.1205\n",
      "\n",
      "Batch 8/387 ━━━━━━━━━━━━━━━━━━━━ 21:17:17\n",
      "Accuracy: 0.9981 - Precision: 0.9213 - Recall: 0.8839 - Specificity: 0.9994 - F1: 0.8950 - Loss: 0.1172\n",
      "\n",
      "Batch 9/387 ━━━━━━━━━━━━━━━━━━━━ 21:21:56\n",
      "Accuracy: 0.9981 - Precision: 0.9278 - Recall: 0.8874 - Specificity: 0.9995 - F1: 0.9007 - Loss: 0.1112\n",
      "\n",
      "Batch 10/387 ━━━━━━━━━━━━━━━━━━━━ 21:23:35\n",
      "Accuracy: 0.9981 - Precision: 0.9328 - Recall: 0.8760 - Specificity: 0.9995 - F1: 0.8970 - Loss: 0.1152\n",
      "\n",
      "Batch 11/387 ━━━━━━━━━━━━━━━━━━━━ 21:24:57\n",
      "Accuracy: 0.9982 - Precision: 0.9254 - Recall: 0.8774 - Specificity: 0.9995 - F1: 0.8946 - Loss: 0.1171\n",
      "\n",
      "Batch 12/387 ━━━━━━━━━━━━━━━━━━━━ 21:26:21\n",
      "Accuracy: 0.9982 - Precision: 0.9048 - Recall: 0.8806 - Specificity: 0.9994 - F1: 0.8850 - Loss: 0.1267\n",
      "\n",
      "Batch 13/387 ━━━━━━━━━━━━━━━━━━━━ 21:27:51\n",
      "Accuracy: 0.9979 - Precision: 0.8985 - Recall: 0.8635 - Specificity: 0.9994 - F1: 0.8732 - Loss: 0.1400\n",
      "\n",
      "Batch 14/387 ━━━━━━━━━━━━━━━━━━━━ 21:29:25\n",
      "Accuracy: 0.9980 - Precision: 0.9006 - Recall: 0.8632 - Specificity: 0.9994 - F1: 0.8745 - Loss: 0.1381\n",
      "\n",
      "Batch 15/387 ━━━━━━━━━━━━━━━━━━━━ 21:30:50\n",
      "Accuracy: 0.9980 - Precision: 0.9024 - Recall: 0.8654 - Specificity: 0.9993 - F1: 0.8770 - Loss: 0.1358\n",
      "\n",
      "Batch 16/387 ━━━━━━━━━━━━━━━━━━━━ 21:32:18\n",
      "Accuracy: 0.9980 - Precision: 0.8992 - Recall: 0.8633 - Specificity: 0.9994 - F1: 0.8748 - Loss: 0.1378\n",
      "\n",
      "Batch 17/387 ━━━━━━━━━━━━━━━━━━━━ 21:33:57\n",
      "Accuracy: 0.9981 - Precision: 0.8949 - Recall: 0.8658 - Specificity: 0.9994 - F1: 0.8741 - Loss: 0.1381\n",
      "\n",
      "Batch 18/387 ━━━━━━━━━━━━━━━━━━━━ 21:35:29\n",
      "Accuracy: 0.9981 - Precision: 0.8870 - Recall: 0.8732 - Specificity: 0.9993 - F1: 0.8733 - Loss: 0.1388\n",
      "\n",
      "Batch 19/387 ━━━━━━━━━━━━━━━━━━━━ 21:36:56\n",
      "Accuracy: 0.9981 - Precision: 0.8910 - Recall: 0.8782 - Specificity: 0.9993 - F1: 0.8781 - Loss: 0.1338\n",
      "\n",
      "Batch 20/387 ━━━━━━━━━━━━━━━━━━━━ 21:38:33\n",
      "Accuracy: 0.9980 - Precision: 0.8826 - Recall: 0.8704 - Specificity: 0.9992 - F1: 0.8704 - Loss: 0.1424\n",
      "\n",
      "Batch 21/387 ━━━━━━━━━━━━━━━━━━━━ 21:39:58\n",
      "Accuracy: 0.9979 - Precision: 0.8860 - Recall: 0.8658 - Specificity: 0.9992 - F1: 0.8696 - Loss: 0.1433\n",
      "\n",
      "Batch 22/387 ━━━━━━━━━━━━━━━━━━━━ 21:41:17\n",
      "Accuracy: 0.9979 - Precision: 0.8838 - Recall: 0.8540 - Specificity: 0.9992 - F1: 0.8621 - Loss: 0.1514\n",
      "\n",
      "Batch 23/387 ━━━━━━━━━━━━━━━━━━━━ 21:42:55\n",
      "Accuracy: 0.9979 - Precision: 0.8849 - Recall: 0.8581 - Specificity: 0.9992 - F1: 0.8649 - Loss: 0.1483\n",
      "\n",
      "Batch 24/387 ━━━━━━━━━━━━━━━━━━━━ 21:44:34\n",
      "Accuracy: 0.9977 - Precision: 0.8685 - Recall: 0.8639 - Specificity: 0.9989 - F1: 0.8564 - Loss: 0.1580\n",
      "\n",
      "Batch 25/387 ━━━━━━━━━━━━━━━━━━━━ 21:45:54\n",
      "Accuracy: 0.9977 - Precision: 0.8718 - Recall: 0.8679 - Specificity: 0.9989 - F1: 0.8604 - Loss: 0.1537\n",
      "\n",
      "Batch 26/387 ━━━━━━━━━━━━━━━━━━━━ 21:47:12\n",
      "Accuracy: 0.9976 - Precision: 0.8751 - Recall: 0.8614 - Specificity: 0.9990 - F1: 0.8584 - Loss: 0.1566\n",
      "\n",
      "Batch 27/387 ━━━━━━━━━━━━━━━━━━━━ 21:48:34\n",
      "Accuracy: 0.9976 - Precision: 0.8783 - Recall: 0.8653 - Specificity: 0.9990 - F1: 0.8623 - Loss: 0.1523\n",
      "\n",
      "Batch 28/387 ━━━━━━━━━━━━━━━━━━━━ 21:49:59\n",
      "Accuracy: 0.9976 - Precision: 0.8759 - Recall: 0.8657 - Specificity: 0.9989 - F1: 0.8616 - Loss: 0.1532\n",
      "\n",
      "Batch 29/387 ━━━━━━━━━━━━━━━━━━━━ 21:51:37\n",
      "Accuracy: 0.9976 - Precision: 0.8794 - Recall: 0.8684 - Specificity: 0.9990 - F1: 0.8650 - Loss: 0.1495\n",
      "\n",
      "Batch 30/387 ━━━━━━━━━━━━━━━━━━━━ 21:53:09\n",
      "Accuracy: 0.9977 - Precision: 0.8806 - Recall: 0.8712 - Specificity: 0.9990 - F1: 0.8673 - Loss: 0.1470\n",
      "\n",
      "Batch 31/387 ━━━━━━━━━━━━━━━━━━━━ 21:54:43\n",
      "Accuracy: 0.9978 - Precision: 0.8800 - Recall: 0.8743 - Specificity: 0.9990 - F1: 0.8687 - Loss: 0.1453\n",
      "\n",
      "Batch 32/387 ━━━━━━━━━━━━━━━━━━━━ 21:56:17\n",
      "Accuracy: 0.9978 - Precision: 0.8734 - Recall: 0.8760 - Specificity: 0.9990 - F1: 0.8659 - Loss: 0.1480\n",
      "\n",
      "Batch 33/387 ━━━━━━━━━━━━━━━━━━━━ 21:57:42\n",
      "Accuracy: 0.9978 - Precision: 0.8631 - Recall: 0.8782 - Specificity: 0.9990 - F1: 0.8604 - Loss: 0.1535\n",
      "\n",
      "Batch 34/387 ━━━━━━━━━━━━━━━━━━━━ 21:59:18\n",
      "Accuracy: 0.9978 - Precision: 0.8597 - Recall: 0.8773 - Specificity: 0.9990 - F1: 0.8584 - Loss: 0.1554\n",
      "\n",
      "Batch 35/387 ━━━━━━━━━━━━━━━━━━━━ 22:00:47\n",
      "Accuracy: 0.9979 - Precision: 0.8608 - Recall: 0.8785 - Specificity: 0.9990 - F1: 0.8598 - Loss: 0.1537\n",
      "\n",
      "Batch 36/387 ━━━━━━━━━━━━━━━━━━━━ 22:02:14\n",
      "Accuracy: 0.9978 - Precision: 0.8619 - Recall: 0.8662 - Specificity: 0.9990 - F1: 0.8523 - Loss: 0.1617\n",
      "\n",
      "Batch 37/387 ━━━━━━━━━━━━━━━━━━━━ 22:03:50\n",
      "Accuracy: 0.9978 - Precision: 0.8652 - Recall: 0.8574 - Specificity: 0.9991 - F1: 0.8481 - Loss: 0.1662\n",
      "\n",
      "Batch 38/387 ━━━━━━━━━━━━━━━━━━━━ 22:05:23\n",
      "Accuracy: 0.9978 - Precision: 0.8662 - Recall: 0.8548 - Specificity: 0.9991 - F1: 0.8475 - Loss: 0.1668\n",
      "\n",
      "Batch 39/387 ━━━━━━━━━━━━━━━━━━━━ 22:06:47\n",
      "Accuracy: 0.9978 - Precision: 0.8691 - Recall: 0.8545 - Specificity: 0.9991 - F1: 0.8490 - Loss: 0.1654\n",
      "\n",
      "Batch 40/387 ━━━━━━━━━━━━━━━━━━━━ 22:08:21\n",
      "Accuracy: 0.9978 - Precision: 0.8719 - Recall: 0.8562 - Specificity: 0.9991 - F1: 0.8515 - Loss: 0.1627\n",
      "\n",
      "Batch 41/387 ━━━━━━━━━━━━━━━━━━━━ 22:09:43\n",
      "Accuracy: 0.9978 - Precision: 0.8714 - Recall: 0.8589 - Specificity: 0.9991 - F1: 0.8528 - Loss: 0.1613\n",
      "\n",
      "Batch 42/387 ━━━━━━━━━━━━━━━━━━━━ 22:11:14\n",
      "Accuracy: 0.9978 - Precision: 0.8694 - Recall: 0.8614 - Specificity: 0.9990 - F1: 0.8531 - Loss: 0.1611\n",
      "\n",
      "Batch 43/387 ━━━━━━━━━━━━━━━━━━━━ 22:12:30\n",
      "Accuracy: 0.9977 - Precision: 0.8711 - Recall: 0.8625 - Specificity: 0.9990 - F1: 0.8548 - Loss: 0.1595\n",
      "\n",
      "Batch 44/387 ━━━━━━━━━━━━━━━━━━━━ 22:14:00\n",
      "Accuracy: 0.9977 - Precision: 0.8740 - Recall: 0.8626 - Specificity: 0.9991 - F1: 0.8565 - Loss: 0.1578\n",
      "\n",
      "Batch 45/387 ━━━━━━━━━━━━━━━━━━━━ 22:15:27\n",
      "Accuracy: 0.9977 - Precision: 0.8761 - Recall: 0.8607 - Specificity: 0.9991 - F1: 0.8567 - Loss: 0.1577\n",
      "\n",
      "Batch 46/387 ━━━━━━━━━━━━━━━━━━━━ 22:17:02\n",
      "Accuracy: 0.9977 - Precision: 0.8785 - Recall: 0.8623 - Specificity: 0.9991 - F1: 0.8589 - Loss: 0.1554\n",
      "\n",
      "Batch 47/387 ━━━━━━━━━━━━━━━━━━━━ 22:18:33\n",
      "Accuracy: 0.9977 - Precision: 0.8794 - Recall: 0.8620 - Specificity: 0.9991 - F1: 0.8594 - Loss: 0.1551\n",
      "\n",
      "Batch 48/387 ━━━━━━━━━━━━━━━━━━━━ 22:19:53\n",
      "Accuracy: 0.9977 - Precision: 0.8796 - Recall: 0.8633 - Specificity: 0.9991 - F1: 0.8603 - Loss: 0.1543\n",
      "\n",
      "Batch 49/387 ━━━━━━━━━━━━━━━━━━━━ 22:21:26\n",
      "Accuracy: 0.9977 - Precision: 0.8795 - Recall: 0.8624 - Specificity: 0.9991 - F1: 0.8601 - Loss: 0.1546\n",
      "\n",
      "Batch 50/387 ━━━━━━━━━━━━━━━━━━━━ 22:22:53\n",
      "Accuracy: 0.9977 - Precision: 0.8767 - Recall: 0.8646 - Specificity: 0.9991 - F1: 0.8597 - Loss: 0.1549\n",
      "\n",
      "Batch 51/387 ━━━━━━━━━━━━━━━━━━━━ 22:24:21\n",
      "Accuracy: 0.9977 - Precision: 0.8767 - Recall: 0.8666 - Specificity: 0.9991 - F1: 0.8608 - Loss: 0.1537\n",
      "\n",
      "Batch 52/387 ━━━━━━━━━━━━━━━━━━━━ 22:25:50\n",
      "Accuracy: 0.9978 - Precision: 0.8757 - Recall: 0.8668 - Specificity: 0.9991 - F1: 0.8606 - Loss: 0.1539\n",
      "\n",
      "Batch 53/387 ━━━━━━━━━━━━━━━━━━━━ 22:27:16\n",
      "Accuracy: 0.9978 - Precision: 0.8731 - Recall: 0.8675 - Specificity: 0.9990 - F1: 0.8598 - Loss: 0.1548\n",
      "\n",
      "Batch 54/387 ━━━━━━━━━━━━━━━━━━━━ 22:28:38\n",
      "Accuracy: 0.9978 - Precision: 0.8700 - Recall: 0.8699 - Specificity: 0.9990 - F1: 0.8592 - Loss: 0.1553\n",
      "\n",
      "Batch 55/387 ━━━━━━━━━━━━━━━━━━━━ 22:30:03\n",
      "Accuracy: 0.9978 - Precision: 0.8706 - Recall: 0.8695 - Specificity: 0.9991 - F1: 0.8595 - Loss: 0.1549\n",
      "\n",
      "Batch 56/387 ━━━━━━━━━━━━━━━━━━━━ 22:31:21\n",
      "Accuracy: 0.9978 - Precision: 0.8721 - Recall: 0.8705 - Specificity: 0.9991 - F1: 0.8608 - Loss: 0.1534\n",
      "\n",
      "Batch 57/387 ━━━━━━━━━━━━━━━━━━━━ 22:32:54\n",
      "Accuracy: 0.9978 - Precision: 0.8716 - Recall: 0.8723 - Specificity: 0.9991 - F1: 0.8616 - Loss: 0.1525\n",
      "\n",
      "Batch 58/387 ━━━━━━━━━━━━━━━━━━━━ 22:34:20\n",
      "Accuracy: 0.9978 - Precision: 0.8716 - Recall: 0.8724 - Specificity: 0.9990 - F1: 0.8618 - Loss: 0.1526\n",
      "\n",
      "Batch 59/387 ━━━━━━━━━━━━━━━━━━━━ 22:35:52\n",
      "Accuracy: 0.9978 - Precision: 0.8737 - Recall: 0.8730 - Specificity: 0.9990 - F1: 0.8633 - Loss: 0.1511\n",
      "\n",
      "Batch 60/387 ━━━━━━━━━━━━━━━━━━━━ 22:37:25\n",
      "Accuracy: 0.9978 - Precision: 0.8741 - Recall: 0.8745 - Specificity: 0.9990 - F1: 0.8644 - Loss: 0.1499\n",
      "\n",
      "Batch 61/387 ━━━━━━━━━━━━━━━━━━━━ 22:38:46\n",
      "Accuracy: 0.9978 - Precision: 0.8758 - Recall: 0.8752 - Specificity: 0.9990 - F1: 0.8658 - Loss: 0.1485\n",
      "\n",
      "Batch 62/387 ━━━━━━━━━━━━━━━━━━━━ 22:40:16\n",
      "Accuracy: 0.9977 - Precision: 0.8777 - Recall: 0.8739 - Specificity: 0.9991 - F1: 0.8661 - Loss: 0.1485\n",
      "\n",
      "Batch 63/387 ━━━━━━━━━━━━━━━━━━━━ 22:41:50\n",
      "Accuracy: 0.9978 - Precision: 0.8794 - Recall: 0.8727 - Specificity: 0.9991 - F1: 0.8663 - Loss: 0.1482\n",
      "\n",
      "Batch 64/387 ━━━━━━━━━━━━━━━━━━━━ 22:43:08\n",
      "Accuracy: 0.9978 - Precision: 0.8805 - Recall: 0.8734 - Specificity: 0.9991 - F1: 0.8673 - Loss: 0.1471\n",
      "\n",
      "Batch 65/387 ━━━━━━━━━━━━━━━━━━━━ 22:44:41\n",
      "Accuracy: 0.9978 - Precision: 0.8795 - Recall: 0.8707 - Specificity: 0.9991 - F1: 0.8656 - Loss: 0.1488\n",
      "\n",
      "Batch 66/387 ━━━━━━━━━━━━━━━━━━━━ 22:46:05\n",
      "Accuracy: 0.9978 - Precision: 0.8805 - Recall: 0.8714 - Specificity: 0.9991 - F1: 0.8666 - Loss: 0.1477\n",
      "\n",
      "Batch 67/387 ━━━━━━━━━━━━━━━━━━━━ 22:47:26\n",
      "Accuracy: 0.9978 - Precision: 0.8810 - Recall: 0.8711 - Specificity: 0.9991 - F1: 0.8668 - Loss: 0.1476\n",
      "\n",
      "Batch 68/387 ━━━━━━━━━━━━━━━━━━━━ 22:49:06\n",
      "Accuracy: 0.9978 - Precision: 0.8798 - Recall: 0.8724 - Specificity: 0.9991 - F1: 0.8669 - Loss: 0.1475\n",
      "\n",
      "Batch 69/387 ━━━━━━━━━━━━━━━━━━━━ 22:50:42\n",
      "Accuracy: 0.9978 - Precision: 0.8800 - Recall: 0.8736 - Specificity: 0.9991 - F1: 0.8677 - Loss: 0.1466\n",
      "\n",
      "Batch 70/387 ━━━━━━━━━━━━━━━━━━━━ 22:52:12\n",
      "Accuracy: 0.9978 - Precision: 0.8804 - Recall: 0.8749 - Specificity: 0.9990 - F1: 0.8686 - Loss: 0.1456\n",
      "\n",
      "Batch 71/387 ━━━━━━━━━━━━━━━━━━━━ 22:53:50\n",
      "Accuracy: 0.9978 - Precision: 0.8815 - Recall: 0.8759 - Specificity: 0.9990 - F1: 0.8699 - Loss: 0.1443\n",
      "\n",
      "Batch 72/387 ━━━━━━━━━━━━━━━━━━━━ 22:55:16\n",
      "Accuracy: 0.9978 - Precision: 0.8824 - Recall: 0.8774 - Specificity: 0.9991 - F1: 0.8711 - Loss: 0.1429\n",
      "\n",
      "Batch 73/387 ━━━━━━━━━━━━━━━━━━━━ 22:56:40\n",
      "Accuracy: 0.9978 - Precision: 0.8834 - Recall: 0.8770 - Specificity: 0.9991 - F1: 0.8715 - Loss: 0.1425\n",
      "\n",
      "Batch 74/387 ━━━━━━━━━━━━━━━━━━━━ 22:58:05\n",
      "Accuracy: 0.9978 - Precision: 0.8841 - Recall: 0.8776 - Specificity: 0.9991 - F1: 0.8723 - Loss: 0.1415\n",
      "\n",
      "Batch 75/387 ━━━━━━━━━━━━━━━━━━━━ 22:59:29\n",
      "Accuracy: 0.9978 - Precision: 0.8781 - Recall: 0.8783 - Specificity: 0.9990 - F1: 0.8686 - Loss: 0.1454\n",
      "\n",
      "Batch 76/387 ━━━━━━━━━━━━━━━━━━━━ 23:00:58\n",
      "Accuracy: 0.9978 - Precision: 0.8788 - Recall: 0.8775 - Specificity: 0.9990 - F1: 0.8686 - Loss: 0.1453\n",
      "\n",
      "Batch 77/387 ━━━━━━━━━━━━━━━━━━━━ 23:02:30\n",
      "Accuracy: 0.9978 - Precision: 0.8797 - Recall: 0.8774 - Specificity: 0.9991 - F1: 0.8691 - Loss: 0.1448\n",
      "\n",
      "Batch 78/387 ━━━━━━━━━━━━━━━━━━━━ 23:03:46\n",
      "Accuracy: 0.9978 - Precision: 0.8801 - Recall: 0.8787 - Specificity: 0.9990 - F1: 0.8700 - Loss: 0.1437\n",
      "\n",
      "Batch 79/387 ━━━━━━━━━━━━━━━━━━━━ 23:05:31\n",
      "Accuracy: 0.9978 - Precision: 0.8805 - Recall: 0.8801 - Specificity: 0.9990 - F1: 0.8710 - Loss: 0.1427\n",
      "\n",
      "Batch 80/387 ━━━━━━━━━━━━━━━━━━━━ 23:06:51\n",
      "Accuracy: 0.9978 - Precision: 0.8785 - Recall: 0.8779 - Specificity: 0.9990 - F1: 0.8691 - Loss: 0.1448\n",
      "\n",
      "Batch 81/387 ━━━━━━━━━━━━━━━━━━━━ 23:08:09\n",
      "Accuracy: 0.9978 - Precision: 0.8784 - Recall: 0.8788 - Specificity: 0.9990 - F1: 0.8695 - Loss: 0.1443\n",
      "\n",
      "Batch 82/387 ━━━━━━━━━━━━━━━━━━━━ 23:09:31\n",
      "Accuracy: 0.9978 - Precision: 0.8793 - Recall: 0.8773 - Specificity: 0.9990 - F1: 0.8692 - Loss: 0.1446\n",
      "\n",
      "Batch 83/387 ━━━━━━━━━━━━━━━━━━━━ 23:10:57\n",
      "Accuracy: 0.9979 - Precision: 0.8806 - Recall: 0.8771 - Specificity: 0.9990 - F1: 0.8698 - Loss: 0.1439\n",
      "\n",
      "Batch 84/387 ━━━━━━━━━━━━━━━━━━━━ 23:12:15\n",
      "Accuracy: 0.9979 - Precision: 0.8812 - Recall: 0.8749 - Specificity: 0.9991 - F1: 0.8689 - Loss: 0.1448\n",
      "\n",
      "Batch 85/387 ━━━━━━━━━━━━━━━━━━━━ 23:13:32\n",
      "Accuracy: 0.9978 - Precision: 0.8821 - Recall: 0.8745 - Specificity: 0.9991 - F1: 0.8693 - Loss: 0.1445\n",
      "\n",
      "Batch 86/387 ━━━━━━━━━━━━━━━━━━━━ 23:14:58\n",
      "Accuracy: 0.9978 - Precision: 0.8833 - Recall: 0.8740 - Specificity: 0.9991 - F1: 0.8696 - Loss: 0.1443\n",
      "\n",
      "Batch 87/387 ━━━━━━━━━━━━━━━━━━━━ 23:16:17\n",
      "Accuracy: 0.9978 - Precision: 0.8834 - Recall: 0.8713 - Specificity: 0.9991 - F1: 0.8682 - Loss: 0.1457\n",
      "\n",
      "Batch 88/387 ━━━━━━━━━━━━━━━━━━━━ 23:17:42\n",
      "Accuracy: 0.9978 - Precision: 0.8833 - Recall: 0.8703 - Specificity: 0.9991 - F1: 0.8677 - Loss: 0.1463\n",
      "\n",
      "Batch 89/387 ━━━━━━━━━━━━━━━━━━━━ 23:19:12\n",
      "Accuracy: 0.9978 - Precision: 0.8836 - Recall: 0.8706 - Specificity: 0.9991 - F1: 0.8681 - Loss: 0.1458\n",
      "\n",
      "Batch 90/387 ━━━━━━━━━━━━━━━━━━━━ 23:20:30\n",
      "Accuracy: 0.9978 - Precision: 0.8839 - Recall: 0.8705 - Specificity: 0.9991 - F1: 0.8683 - Loss: 0.1456\n",
      "\n",
      "Batch 91/387 ━━━━━━━━━━━━━━━━━━━━ 23:22:05\n",
      "Accuracy: 0.9978 - Precision: 0.8840 - Recall: 0.8716 - Specificity: 0.9991 - F1: 0.8690 - Loss: 0.1448\n",
      "\n",
      "Batch 92/387 ━━━━━━━━━━━━━━━━━━━━ 23:23:28\n",
      "Accuracy: 0.9978 - Precision: 0.8843 - Recall: 0.8719 - Specificity: 0.9991 - F1: 0.8693 - Loss: 0.1445\n",
      "\n",
      "Batch 93/387 ━━━━━━━━━━━━━━━━━━━━ 23:25:03\n",
      "Accuracy: 0.9978 - Precision: 0.8826 - Recall: 0.8731 - Specificity: 0.9991 - F1: 0.8690 - Loss: 0.1448\n",
      "\n",
      "Batch 94/387 ━━━━━━━━━━━━━━━━━━━━ 23:26:23\n",
      "Accuracy: 0.9978 - Precision: 0.8815 - Recall: 0.8741 - Specificity: 0.9990 - F1: 0.8690 - Loss: 0.1449\n",
      "\n",
      "Batch 95/387 ━━━━━━━━━━━━━━━━━━━━ 23:27:43\n",
      "Accuracy: 0.9978 - Precision: 0.8813 - Recall: 0.8749 - Specificity: 0.9990 - F1: 0.8693 - Loss: 0.1445\n",
      "\n",
      "Batch 96/387 ━━━━━━━━━━━━━━━━━━━━ 23:29:11\n",
      "Accuracy: 0.9978 - Precision: 0.8823 - Recall: 0.8750 - Specificity: 0.9990 - F1: 0.8699 - Loss: 0.1439\n",
      "\n",
      "Batch 97/387 ━━━━━━━━━━━━━━━━━━━━ 23:30:38\n",
      "Accuracy: 0.9978 - Precision: 0.8831 - Recall: 0.8746 - Specificity: 0.9991 - F1: 0.8702 - Loss: 0.1435\n",
      "\n",
      "Batch 98/387 ━━━━━━━━━━━━━━━━━━━━ 23:31:52\n",
      "Accuracy: 0.9978 - Precision: 0.8835 - Recall: 0.8754 - Specificity: 0.9991 - F1: 0.8708 - Loss: 0.1429\n",
      "\n",
      "Batch 99/387 ━━━━━━━━━━━━━━━━━━━━ 23:33:28\n",
      "Accuracy: 0.9979 - Precision: 0.8835 - Recall: 0.8763 - Specificity: 0.9991 - F1: 0.8714 - Loss: 0.1423\n",
      "\n",
      "Batch 100/387 ━━━━━━━━━━━━━━━━━━━━ 23:35:05\n",
      "Accuracy: 0.9979 - Precision: 0.8840 - Recall: 0.8773 - Specificity: 0.9991 - F1: 0.8722 - Loss: 0.1414\n",
      "\n",
      "Batch 101/387 ━━━━━━━━━━━━━━━━━━━━ 23:36:31\n",
      "Accuracy: 0.9979 - Precision: 0.8819 - Recall: 0.8779 - Specificity: 0.9991 - F1: 0.8714 - Loss: 0.1423\n",
      "\n",
      "Batch 102/387 ━━━━━━━━━━━━━━━━━━━━ 23:37:55\n",
      "Accuracy: 0.9979 - Precision: 0.8813 - Recall: 0.8788 - Specificity: 0.9990 - F1: 0.8715 - Loss: 0.1421\n",
      "\n",
      "Batch 103/387 ━━━━━━━━━━━━━━━━━━━━ 23:39:26\n",
      "Accuracy: 0.9979 - Precision: 0.8818 - Recall: 0.8786 - Specificity: 0.9991 - F1: 0.8717 - Loss: 0.1419\n",
      "\n",
      "Batch 104/387 ━━━━━━━━━━━━━━━━━━━━ 23:40:55\n",
      "Accuracy: 0.9979 - Precision: 0.8824 - Recall: 0.8793 - Specificity: 0.9991 - F1: 0.8725 - Loss: 0.1411\n",
      "\n",
      "Batch 105/387 ━━━━━━━━━━━━━━━━━━━━ 23:42:18\n",
      "Accuracy: 0.9979 - Precision: 0.8835 - Recall: 0.8787 - Specificity: 0.9991 - F1: 0.8727 - Loss: 0.1410\n",
      "\n",
      "Batch 106/387 ━━━━━━━━━━━━━━━━━━━━ 23:43:50\n",
      "Accuracy: 0.9979 - Precision: 0.8846 - Recall: 0.8785 - Specificity: 0.9991 - F1: 0.8732 - Loss: 0.1406\n",
      "\n",
      "Batch 107/387 ━━━━━━━━━━━━━━━━━━━━ 23:45:17\n",
      "Accuracy: 0.9979 - Precision: 0.8853 - Recall: 0.8769 - Specificity: 0.9991 - F1: 0.8727 - Loss: 0.1411\n",
      "\n",
      "Batch 108/387 ━━━━━━━━━━━━━━━━━━━━ 23:46:33\n",
      "Accuracy: 0.9979 - Precision: 0.8857 - Recall: 0.8773 - Specificity: 0.9991 - F1: 0.8731 - Loss: 0.1405\n",
      "\n",
      "Batch 109/387 ━━━━━━━━━━━━━━━━━━━━ 23:48:01\n",
      "Accuracy: 0.9978 - Precision: 0.8865 - Recall: 0.8756 - Specificity: 0.9991 - F1: 0.8726 - Loss: 0.1413\n",
      "\n",
      "Batch 110/387 ━━━━━━━━━━━━━━━━━━━━ 23:49:30\n",
      "Accuracy: 0.9978 - Precision: 0.8872 - Recall: 0.8760 - Specificity: 0.9991 - F1: 0.8732 - Loss: 0.1407\n",
      "\n",
      "Batch 111/387 ━━━━━━━━━━━━━━━━━━━━ 23:50:44\n",
      "Accuracy: 0.9978 - Precision: 0.8880 - Recall: 0.8761 - Specificity: 0.9991 - F1: 0.8737 - Loss: 0.1401\n",
      "\n",
      "Batch 112/387 ━━━━━━━━━━━━━━━━━━━━ 23:52:16\n",
      "Accuracy: 0.9979 - Precision: 0.8879 - Recall: 0.8762 - Specificity: 0.9991 - F1: 0.8737 - Loss: 0.1400\n",
      "\n",
      "Batch 113/387 ━━━━━━━━━━━━━━━━━━━━ 23:53:32\n",
      "Accuracy: 0.9979 - Precision: 0.8888 - Recall: 0.8754 - Specificity: 0.9991 - F1: 0.8737 - Loss: 0.1400\n",
      "\n",
      "Batch 114/387 ━━━━━━━━━━━━━━━━━━━━ 23:54:55\n",
      "Accuracy: 0.9979 - Precision: 0.8880 - Recall: 0.8763 - Specificity: 0.9991 - F1: 0.8738 - Loss: 0.1399\n",
      "\n",
      "Batch 115/387 ━━━━━━━━━━━━━━━━━━━━ 23:56:19\n",
      "Accuracy: 0.9978 - Precision: 0.8889 - Recall: 0.8760 - Specificity: 0.9991 - F1: 0.8741 - Loss: 0.1396\n",
      "\n",
      "Batch 116/387 ━━━━━━━━━━━━━━━━━━━━ 23:57:59\n",
      "Accuracy: 0.9978 - Precision: 0.8882 - Recall: 0.8760 - Specificity: 0.9991 - F1: 0.8739 - Loss: 0.1400\n",
      "\n",
      "Batch 117/387 ━━━━━━━━━━━━━━━━━━━━ 23:59:24\n",
      "Accuracy: 0.9978 - Precision: 0.8887 - Recall: 0.8754 - Specificity: 0.9991 - F1: 0.8738 - Loss: 0.1401\n",
      "\n",
      "Batch 118/387 ━━━━━━━━━━━━━━━━━━━━ 00:00:59\n",
      "Accuracy: 0.9978 - Precision: 0.8881 - Recall: 0.8763 - Specificity: 0.9991 - F1: 0.8740 - Loss: 0.1399\n",
      "\n",
      "Batch 119/387 ━━━━━━━━━━━━━━━━━━━━ 00:02:19\n",
      "Accuracy: 0.9978 - Precision: 0.8884 - Recall: 0.8772 - Specificity: 0.9991 - F1: 0.8747 - Loss: 0.1392\n",
      "\n",
      "Batch 120/387 ━━━━━━━━━━━━━━━━━━━━ 00:04:01\n",
      "Accuracy: 0.9978 - Precision: 0.8877 - Recall: 0.8774 - Specificity: 0.9991 - F1: 0.8745 - Loss: 0.1395\n",
      "\n",
      "Batch 121/387 ━━━━━━━━━━━━━━━━━━━━ 00:05:38\n",
      "Accuracy: 0.9978 - Precision: 0.8882 - Recall: 0.8781 - Specificity: 0.9991 - F1: 0.8751 - Loss: 0.1388\n",
      "\n",
      "Batch 122/387 ━━━━━━━━━━━━━━━━━━━━ 00:07:11\n",
      "Accuracy: 0.9978 - Precision: 0.8870 - Recall: 0.8789 - Specificity: 0.9991 - F1: 0.8748 - Loss: 0.1391\n",
      "\n",
      "Batch 123/387 ━━━━━━━━━━━━━━━━━━━━ 00:08:39\n",
      "Accuracy: 0.9978 - Precision: 0.8867 - Recall: 0.8795 - Specificity: 0.9991 - F1: 0.8750 - Loss: 0.1388\n",
      "\n",
      "Batch 124/387 ━━━━━━━━━━━━━━━━━━━━ 00:10:08\n",
      "Accuracy: 0.9978 - Precision: 0.8860 - Recall: 0.8803 - Specificity: 0.9991 - F1: 0.8751 - Loss: 0.1387\n",
      "\n",
      "Batch 125/387 ━━━━━━━━━━━━━━━━━━━━ 00:11:36\n",
      "Accuracy: 0.9978 - Precision: 0.8861 - Recall: 0.8808 - Specificity: 0.9991 - F1: 0.8755 - Loss: 0.1383\n",
      "\n",
      "Batch 126/387 ━━━━━━━━━━━━━━━━━━━━ 00:13:15\n",
      "Accuracy: 0.9979 - Precision: 0.8858 - Recall: 0.8816 - Specificity: 0.9991 - F1: 0.8757 - Loss: 0.1380\n",
      "\n",
      "Batch 127/387 ━━━━━━━━━━━━━━━━━━━━ 00:14:48\n",
      "Accuracy: 0.9979 - Precision: 0.8863 - Recall: 0.8822 - Specificity: 0.9991 - F1: 0.8763 - Loss: 0.1374\n",
      "\n",
      "Batch 128/387 ━━━━━━━━━━━━━━━━━━━━ 00:16:14\n",
      "Accuracy: 0.9979 - Precision: 0.8870 - Recall: 0.8813 - Specificity: 0.9991 - F1: 0.8762 - Loss: 0.1376\n",
      "\n",
      "Batch 129/387 ━━━━━━━━━━━━━━━━━━━━ 00:17:37\n",
      "Accuracy: 0.9978 - Precision: 0.8878 - Recall: 0.8811 - Specificity: 0.9991 - F1: 0.8765 - Loss: 0.1373\n",
      "\n",
      "Batch 130/387 ━━━━━━━━━━━━━━━━━━━━ 00:19:03\n",
      "Accuracy: 0.9979 - Precision: 0.8882 - Recall: 0.8814 - Specificity: 0.9991 - F1: 0.8770 - Loss: 0.1368\n",
      "\n",
      "Batch 131/387 ━━━━━━━━━━━━━━━━━━━━ 00:20:30\n",
      "Accuracy: 0.9978 - Precision: 0.8886 - Recall: 0.8808 - Specificity: 0.9991 - F1: 0.8769 - Loss: 0.1370\n",
      "\n",
      "Batch 132/387 ━━━━━━━━━━━━━━━━━━━━ 00:21:58\n",
      "Accuracy: 0.9979 - Precision: 0.8892 - Recall: 0.8812 - Specificity: 0.9991 - F1: 0.8774 - Loss: 0.1364\n",
      "\n",
      "Batch 133/387 ━━━━━━━━━━━━━━━━━━━━ 00:23:28\n",
      "Accuracy: 0.9979 - Precision: 0.8899 - Recall: 0.8814 - Specificity: 0.9991 - F1: 0.8779 - Loss: 0.1359\n",
      "\n",
      "Batch 134/387 ━━━━━━━━━━━━━━━━━━━━ 00:24:57\n",
      "Accuracy: 0.9979 - Precision: 0.8891 - Recall: 0.8821 - Specificity: 0.9991 - F1: 0.8778 - Loss: 0.1359\n",
      "\n",
      "Batch 135/387 ━━━━━━━━━━━━━━━━━━━━ 00:26:20\n",
      "Accuracy: 0.9979 - Precision: 0.8894 - Recall: 0.8820 - Specificity: 0.9991 - F1: 0.8780 - Loss: 0.1358\n",
      "\n",
      "Batch 136/387 ━━━━━━━━━━━━━━━━━━━━ 00:27:47\n",
      "Accuracy: 0.9978 - Precision: 0.8898 - Recall: 0.8816 - Specificity: 0.9991 - F1: 0.8780 - Loss: 0.1358\n",
      "\n",
      "Batch 137/387 ━━━━━━━━━━━━━━━━━━━━ 00:29:16\n",
      "Accuracy: 0.9978 - Precision: 0.8902 - Recall: 0.8807 - Specificity: 0.9991 - F1: 0.8778 - Loss: 0.1361\n",
      "\n",
      "Batch 138/387 ━━━━━━━━━━━━━━━━━━━━ 00:30:43\n",
      "Accuracy: 0.9978 - Precision: 0.8908 - Recall: 0.8802 - Specificity: 0.9991 - F1: 0.8778 - Loss: 0.1362\n",
      "\n",
      "Batch 139/387 ━━━━━━━━━━━━━━━━━━━━ 00:32:16\n",
      "Accuracy: 0.9978 - Precision: 0.8914 - Recall: 0.8807 - Specificity: 0.9991 - F1: 0.8784 - Loss: 0.1355\n",
      "\n",
      "Batch 140/387 ━━━━━━━━━━━━━━━━━━━━ 00:33:39\n",
      "Accuracy: 0.9978 - Precision: 0.8920 - Recall: 0.8808 - Specificity: 0.9991 - F1: 0.8788 - Loss: 0.1352\n",
      "\n",
      "Batch 141/387 ━━━━━━━━━━━━━━━━━━━━ 00:35:10\n",
      "Accuracy: 0.9978 - Precision: 0.8924 - Recall: 0.8812 - Specificity: 0.9991 - F1: 0.8792 - Loss: 0.1347\n",
      "\n",
      "Batch 142/387 ━━━━━━━━━━━━━━━━━━━━ 00:36:32\n",
      "Accuracy: 0.9978 - Precision: 0.8925 - Recall: 0.8816 - Specificity: 0.9991 - F1: 0.8795 - Loss: 0.1344\n",
      "\n",
      "Batch 143/387 ━━━━━━━━━━━━━━━━━━━━ 00:38:06\n",
      "Accuracy: 0.9978 - Precision: 0.8919 - Recall: 0.8818 - Specificity: 0.9991 - F1: 0.8794 - Loss: 0.1346\n",
      "\n",
      "Batch 144/387 ━━━━━━━━━━━━━━━━━━━━ 00:39:44\n",
      "Accuracy: 0.9978 - Precision: 0.8911 - Recall: 0.8819 - Specificity: 0.9991 - F1: 0.8791 - Loss: 0.1349\n",
      "\n",
      "Batch 145/387 ━━━━━━━━━━━━━━━━━━━━ 00:41:17\n",
      "Accuracy: 0.9978 - Precision: 0.8917 - Recall: 0.8813 - Specificity: 0.9991 - F1: 0.8790 - Loss: 0.1349\n",
      "\n",
      "Batch 146/387 ━━━━━━━━━━━━━━━━━━━━ 00:42:40\n",
      "Accuracy: 0.9978 - Precision: 0.8910 - Recall: 0.8818 - Specificity: 0.9991 - F1: 0.8790 - Loss: 0.1350\n",
      "\n",
      "Batch 147/387 ━━━━━━━━━━━━━━━━━━━━ 00:44:08\n",
      "Accuracy: 0.9978 - Precision: 0.8911 - Recall: 0.8826 - Specificity: 0.9991 - F1: 0.8794 - Loss: 0.1345\n",
      "\n",
      "Batch 148/387 ━━━━━━━━━━━━━━━━━━━━ 00:45:29\n",
      "Accuracy: 0.9978 - Precision: 0.8908 - Recall: 0.8826 - Specificity: 0.9991 - F1: 0.8793 - Loss: 0.1346\n",
      "\n",
      "Batch 149/387 ━━━━━━━━━━━━━━━━━━━━ 00:46:49\n",
      "Accuracy: 0.9978 - Precision: 0.8901 - Recall: 0.8833 - Specificity: 0.9991 - F1: 0.8793 - Loss: 0.1346\n",
      "\n",
      "Batch 150/387 ━━━━━━━━━━━━━━━━━━━━ 00:48:14\n",
      "Accuracy: 0.9978 - Precision: 0.8905 - Recall: 0.8837 - Specificity: 0.9991 - F1: 0.8798 - Loss: 0.1342\n",
      "\n",
      "Batch 151/387 ━━━━━━━━━━━━━━━━━━━━ 00:49:35\n",
      "Accuracy: 0.9978 - Precision: 0.8906 - Recall: 0.8838 - Specificity: 0.9991 - F1: 0.8799 - Loss: 0.1340\n",
      "\n",
      "Batch 152/387 ━━━━━━━━━━━━━━━━━━━━ 00:50:54\n",
      "Accuracy: 0.9978 - Precision: 0.8907 - Recall: 0.8841 - Specificity: 0.9991 - F1: 0.8802 - Loss: 0.1337\n",
      "\n",
      "Batch 153/387 ━━━━━━━━━━━━━━━━━━━━ 00:52:15\n",
      "Accuracy: 0.9978 - Precision: 0.8913 - Recall: 0.8845 - Specificity: 0.9991 - F1: 0.8807 - Loss: 0.1332\n",
      "\n",
      "Batch 154/387 ━━━━━━━━━━━━━━━━━━━━ 00:53:54\n",
      "Accuracy: 0.9978 - Precision: 0.8919 - Recall: 0.8850 - Specificity: 0.9991 - F1: 0.8813 - Loss: 0.1326\n",
      "\n",
      "Batch 155/387 ━━━━━━━━━━━━━━━━━━━━ 00:55:09\n",
      "Accuracy: 0.9978 - Precision: 0.8922 - Recall: 0.8853 - Specificity: 0.9991 - F1: 0.8816 - Loss: 0.1322\n",
      "\n",
      "Batch 156/387 ━━━━━━━━━━━━━━━━━━━━ 00:56:48\n",
      "Accuracy: 0.9978 - Precision: 0.8926 - Recall: 0.8856 - Specificity: 0.9991 - F1: 0.8821 - Loss: 0.1317\n",
      "\n",
      "Batch 157/387 ━━━━━━━━━━━━━━━━━━━━ 00:58:14\n",
      "Accuracy: 0.9978 - Precision: 0.8928 - Recall: 0.8860 - Specificity: 0.9991 - F1: 0.8824 - Loss: 0.1313\n",
      "\n",
      "Batch 158/387 ━━━━━━━━━━━━━━━━━━━━ 00:59:53\n",
      "Accuracy: 0.9978 - Precision: 0.8924 - Recall: 0.8855 - Specificity: 0.9991 - F1: 0.8820 - Loss: 0.1317\n",
      "\n",
      "Batch 159/387 ━━━━━━━━━━━━━━━━━━━━ 01:01:28\n",
      "Accuracy: 0.9978 - Precision: 0.8929 - Recall: 0.8858 - Specificity: 0.9991 - F1: 0.8824 - Loss: 0.1313\n",
      "\n",
      "Batch 160/387 ━━━━━━━━━━━━━━━━━━━━ 01:02:39\n",
      "Accuracy: 0.9978 - Precision: 0.8932 - Recall: 0.8859 - Specificity: 0.9991 - F1: 0.8827 - Loss: 0.1310\n",
      "\n",
      "Batch 161/387 ━━━━━━━━━━━━━━━━━━━━ 01:04:00\n",
      "Accuracy: 0.9979 - Precision: 0.8937 - Recall: 0.8859 - Specificity: 0.9991 - F1: 0.8829 - Loss: 0.1307\n",
      "\n",
      "Batch 162/387 ━━━━━━━━━━━━━━━━━━━━ 01:05:25\n",
      "Accuracy: 0.9979 - Precision: 0.8938 - Recall: 0.8859 - Specificity: 0.9991 - F1: 0.8831 - Loss: 0.1305\n",
      "\n",
      "Batch 163/387 ━━━━━━━━━━━━━━━━━━━━ 01:06:54\n",
      "Accuracy: 0.9979 - Precision: 0.8942 - Recall: 0.8858 - Specificity: 0.9991 - F1: 0.8832 - Loss: 0.1303\n",
      "\n",
      "Batch 164/387 ━━━━━━━━━━━━━━━━━━━━ 01:08:29\n",
      "Accuracy: 0.9979 - Precision: 0.8946 - Recall: 0.8856 - Specificity: 0.9991 - F1: 0.8833 - Loss: 0.1301\n",
      "\n",
      "Batch 165/387 ━━━━━━━━━━━━━━━━━━━━ 01:09:50\n",
      "Accuracy: 0.9979 - Precision: 0.8948 - Recall: 0.8856 - Specificity: 0.9991 - F1: 0.8835 - Loss: 0.1300\n",
      "\n",
      "Batch 166/387 ━━━━━━━━━━━━━━━━━━━━ 01:11:14\n",
      "Accuracy: 0.9979 - Precision: 0.8936 - Recall: 0.8851 - Specificity: 0.9991 - F1: 0.8826 - Loss: 0.1309\n",
      "\n",
      "Batch 167/387 ━━━━━━━━━━━━━━━━━━━━ 01:12:52\n",
      "Accuracy: 0.9979 - Precision: 0.8940 - Recall: 0.8853 - Specificity: 0.9991 - F1: 0.8830 - Loss: 0.1305\n",
      "\n",
      "Batch 168/387 ━━━━━━━━━━━━━━━━━━━━ 01:14:11\n",
      "Accuracy: 0.9979 - Precision: 0.8924 - Recall: 0.8857 - Specificity: 0.9991 - F1: 0.8822 - Loss: 0.1313\n",
      "\n",
      "Batch 169/387 ━━━━━━━━━━━━━━━━━━━━ 01:15:35\n",
      "Accuracy: 0.9979 - Precision: 0.8927 - Recall: 0.8862 - Specificity: 0.9991 - F1: 0.8826 - Loss: 0.1308\n",
      "\n",
      "Batch 170/387 ━━━━━━━━━━━━━━━━━━━━ 01:17:16\n",
      "Accuracy: 0.9979 - Precision: 0.8933 - Recall: 0.8851 - Specificity: 0.9991 - F1: 0.8823 - Loss: 0.1313\n",
      "\n",
      "Batch 171/387 ━━━━━━━━━━━━━━━━━━━━ 01:18:45\n",
      "Accuracy: 0.9979 - Precision: 0.8927 - Recall: 0.8853 - Specificity: 0.9991 - F1: 0.8821 - Loss: 0.1314\n",
      "\n",
      "Batch 172/387 ━━━━━━━━━━━━━━━━━━━━ 01:20:11\n",
      "Accuracy: 0.9979 - Precision: 0.8921 - Recall: 0.8859 - Specificity: 0.9991 - F1: 0.8821 - Loss: 0.1314\n",
      "\n",
      "Batch 173/387 ━━━━━━━━━━━━━━━━━━━━ 01:21:40\n",
      "Accuracy: 0.9979 - Precision: 0.8915 - Recall: 0.8859 - Specificity: 0.9991 - F1: 0.8818 - Loss: 0.1317\n",
      "\n",
      "Batch 174/387 ━━━━━━━━━━━━━━━━━━━━ 01:23:21\n",
      "Accuracy: 0.9979 - Precision: 0.8920 - Recall: 0.8863 - Specificity: 0.9991 - F1: 0.8822 - Loss: 0.1312\n",
      "\n",
      "Batch 175/387 ━━━━━━━━━━━━━━━━━━━━ 01:24:57\n",
      "Accuracy: 0.9979 - Precision: 0.8925 - Recall: 0.8862 - Specificity: 0.9991 - F1: 0.8825 - Loss: 0.1309\n",
      "\n",
      "Batch 176/387 ━━━━━━━━━━━━━━━━━━━━ 01:26:23\n",
      "Accuracy: 0.9979 - Precision: 0.8928 - Recall: 0.8849 - Specificity: 0.9991 - F1: 0.8819 - Loss: 0.1315\n",
      "\n",
      "Batch 177/387 ━━━━━━━━━━━━━━━━━━━━ 01:27:45\n",
      "Accuracy: 0.9979 - Precision: 0.8927 - Recall: 0.8854 - Specificity: 0.9991 - F1: 0.8821 - Loss: 0.1313\n",
      "\n",
      "Batch 178/387 ━━━━━━━━━━━━━━━━━━━━ 01:29:06\n",
      "Accuracy: 0.9979 - Precision: 0.8932 - Recall: 0.8850 - Specificity: 0.9991 - F1: 0.8822 - Loss: 0.1312\n",
      "\n",
      "Batch 179/387 ━━━━━━━━━━━━━━━━━━━━ 01:30:33\n",
      "Accuracy: 0.9979 - Precision: 0.8935 - Recall: 0.8846 - Specificity: 0.9991 - F1: 0.8821 - Loss: 0.1313\n",
      "\n",
      "Batch 180/387 ━━━━━━━━━━━━━━━━━━━━ 01:31:59\n",
      "Accuracy: 0.9979 - Precision: 0.8939 - Recall: 0.8848 - Specificity: 0.9991 - F1: 0.8825 - Loss: 0.1309\n",
      "\n",
      "Batch 181/387 ━━━━━━━━━━━━━━━━━━━━ 01:33:28\n",
      "Accuracy: 0.9979 - Precision: 0.8943 - Recall: 0.8853 - Specificity: 0.9991 - F1: 0.8829 - Loss: 0.1304\n",
      "\n",
      "Batch 182/387 ━━━━━━━━━━━━━━━━━━━━ 01:34:47\n",
      "Accuracy: 0.9979 - Precision: 0.8948 - Recall: 0.8842 - Specificity: 0.9991 - F1: 0.8826 - Loss: 0.1308\n",
      "\n",
      "Batch 183/387 ━━━━━━━━━━━━━━━━━━━━ 01:36:05\n",
      "Accuracy: 0.9979 - Precision: 0.8951 - Recall: 0.8845 - Specificity: 0.9991 - F1: 0.8829 - Loss: 0.1304\n",
      "\n",
      "Batch 184/387 ━━━━━━━━━━━━━━━━━━━━ 01:37:35\n",
      "Accuracy: 0.9979 - Precision: 0.8953 - Recall: 0.8850 - Specificity: 0.9991 - F1: 0.8833 - Loss: 0.1300\n",
      "\n",
      "Batch 185/387 ━━━━━━━━━━━━━━━━━━━━ 01:38:54\n",
      "Accuracy: 0.9979 - Precision: 0.8957 - Recall: 0.8853 - Specificity: 0.9991 - F1: 0.8837 - Loss: 0.1296\n",
      "\n",
      "Batch 186/387 ━━━━━━━━━━━━━━━━━━━━ 01:40:10\n",
      "Accuracy: 0.9979 - Precision: 0.8943 - Recall: 0.8858 - Specificity: 0.9991 - F1: 0.8830 - Loss: 0.1303\n",
      "\n",
      "Batch 187/387 ━━━━━━━━━━━━━━━━━━━━ 01:41:28\n",
      "Accuracy: 0.9979 - Precision: 0.8936 - Recall: 0.8862 - Specificity: 0.9991 - F1: 0.8829 - Loss: 0.1304\n",
      "\n",
      "Batch 188/387 ━━━━━━━━━━━━━━━━━━━━ 01:42:46\n",
      "Accuracy: 0.9979 - Precision: 0.8920 - Recall: 0.8867 - Specificity: 0.9991 - F1: 0.8821 - Loss: 0.1313\n",
      "\n",
      "Batch 189/387 ━━━━━━━━━━━━━━━━━━━━ 01:44:12\n",
      "Accuracy: 0.9979 - Precision: 0.8908 - Recall: 0.8866 - Specificity: 0.9991 - F1: 0.8814 - Loss: 0.1320\n",
      "\n",
      "Batch 190/387 ━━━━━━━━━━━━━━━━━━━━ 01:45:31\n",
      "Accuracy: 0.9979 - Precision: 0.8911 - Recall: 0.8870 - Specificity: 0.9991 - F1: 0.8818 - Loss: 0.1316\n",
      "\n",
      "Batch 191/387 ━━━━━━━━━━━━━━━━━━━━ 01:46:56\n",
      "Accuracy: 0.9979 - Precision: 0.8915 - Recall: 0.8861 - Specificity: 0.9991 - F1: 0.8816 - Loss: 0.1318\n",
      "\n",
      "Batch 192/387 ━━━━━━━━━━━━━━━━━━━━ 01:48:09\n",
      "Accuracy: 0.9979 - Precision: 0.8919 - Recall: 0.8862 - Specificity: 0.9991 - F1: 0.8818 - Loss: 0.1316\n",
      "\n",
      "Batch 193/387 ━━━━━━━━━━━━━━━━━━━━ 01:49:29\n",
      "Accuracy: 0.9979 - Precision: 0.8923 - Recall: 0.8864 - Specificity: 0.9991 - F1: 0.8821 - Loss: 0.1312\n",
      "\n",
      "Batch 194/387 ━━━━━━━━━━━━━━━━━━━━ 01:50:48\n",
      "Accuracy: 0.9979 - Precision: 0.8925 - Recall: 0.8864 - Specificity: 0.9991 - F1: 0.8823 - Loss: 0.1311\n",
      "\n",
      "Batch 195/387 ━━━━━━━━━━━━━━━━━━━━ 01:52:12\n",
      "Accuracy: 0.9979 - Precision: 0.8926 - Recall: 0.8849 - Specificity: 0.9991 - F1: 0.8814 - Loss: 0.1319\n",
      "\n",
      "Batch 196/387 ━━━━━━━━━━━━━━━━━━━━ 01:53:38\n",
      "Accuracy: 0.9979 - Precision: 0.8931 - Recall: 0.8851 - Specificity: 0.9991 - F1: 0.8818 - Loss: 0.1315\n",
      "\n",
      "Batch 197/387 ━━━━━━━━━━━━━━━━━━━━ 01:55:12\n",
      "Accuracy: 0.9979 - Precision: 0.8935 - Recall: 0.8841 - Specificity: 0.9991 - F1: 0.8814 - Loss: 0.1321\n",
      "\n",
      "Batch 198/387 ━━━━━━━━━━━━━━━━━━━━ 01:56:28\n",
      "Accuracy: 0.9979 - Precision: 0.8937 - Recall: 0.8843 - Specificity: 0.9991 - F1: 0.8817 - Loss: 0.1318\n",
      "\n",
      "Batch 199/387 ━━━━━━━━━━━━━━━━━━━━ 01:57:46\n",
      "Accuracy: 0.9979 - Precision: 0.8936 - Recall: 0.8847 - Specificity: 0.9991 - F1: 0.8819 - Loss: 0.1316\n",
      "\n",
      "Batch 200/387 ━━━━━━━━━━━━━━━━━━━━ 01:59:13\n",
      "Accuracy: 0.9979 - Precision: 0.8939 - Recall: 0.8843 - Specificity: 0.9991 - F1: 0.8818 - Loss: 0.1316\n",
      "\n",
      "Batch 201/387 ━━━━━━━━━━━━━━━━━━━━ 02:00:47\n",
      "Accuracy: 0.9979 - Precision: 0.8937 - Recall: 0.8847 - Specificity: 0.9991 - F1: 0.8819 - Loss: 0.1315\n",
      "\n",
      "Batch 202/387 ━━━━━━━━━━━━━━━━━━━━ 02:02:21\n",
      "Accuracy: 0.9979 - Precision: 0.8938 - Recall: 0.8849 - Specificity: 0.9991 - F1: 0.8821 - Loss: 0.1312\n",
      "\n",
      "Batch 203/387 ━━━━━━━━━━━━━━━━━━━━ 02:03:35\n",
      "Accuracy: 0.9979 - Precision: 0.8939 - Recall: 0.8852 - Specificity: 0.9991 - F1: 0.8824 - Loss: 0.1310\n",
      "\n",
      "Batch 204/387 ━━━━━━━━━━━━━━━━━━━━ 02:05:07\n",
      "Accuracy: 0.9979 - Precision: 0.8942 - Recall: 0.8855 - Specificity: 0.9991 - F1: 0.8827 - Loss: 0.1307\n",
      "\n",
      "Batch 205/387 ━━━━━━━━━━━━━━━━━━━━ 02:06:45\n",
      "Accuracy: 0.9979 - Precision: 0.8943 - Recall: 0.8854 - Specificity: 0.9991 - F1: 0.8827 - Loss: 0.1307\n",
      "\n",
      "Batch 206/387 ━━━━━━━━━━━━━━━━━━━━ 02:08:02\n",
      "Accuracy: 0.9979 - Precision: 0.8943 - Recall: 0.8856 - Specificity: 0.9991 - F1: 0.8828 - Loss: 0.1305\n",
      "\n",
      "Batch 207/387 ━━━━━━━━━━━━━━━━━━━━ 02:09:26\n",
      "Accuracy: 0.9979 - Precision: 0.8943 - Recall: 0.8858 - Specificity: 0.9991 - F1: 0.8830 - Loss: 0.1304\n",
      "\n",
      "Batch 208/387 ━━━━━━━━━━━━━━━━━━━━ 02:10:54\n",
      "Accuracy: 0.9979 - Precision: 0.8943 - Recall: 0.8861 - Specificity: 0.9991 - F1: 0.8832 - Loss: 0.1302\n",
      "\n",
      "Batch 209/387 ━━━━━━━━━━━━━━━━━━━━ 02:12:13\n",
      "Accuracy: 0.9979 - Precision: 0.8938 - Recall: 0.8867 - Specificity: 0.9991 - F1: 0.8832 - Loss: 0.1301\n",
      "\n",
      "Batch 210/387 ━━━━━━━━━━━━━━━━━━━━ 02:13:37\n",
      "Accuracy: 0.9979 - Precision: 0.8929 - Recall: 0.8870 - Specificity: 0.9991 - F1: 0.8828 - Loss: 0.1306\n",
      "\n",
      "Batch 211/387 ━━━━━━━━━━━━━━━━━━━━ 02:14:55\n",
      "Accuracy: 0.9979 - Precision: 0.8931 - Recall: 0.8872 - Specificity: 0.9991 - F1: 0.8830 - Loss: 0.1304\n",
      "\n",
      "Batch 212/387 ━━━━━━━━━━━━━━━━━━━━ 02:16:28\n",
      "Accuracy: 0.9979 - Precision: 0.8932 - Recall: 0.8876 - Specificity: 0.9991 - F1: 0.8833 - Loss: 0.1301\n",
      "\n",
      "Batch 213/387 ━━━━━━━━━━━━━━━━━━━━ 02:18:03\n",
      "Accuracy: 0.9979 - Precision: 0.8928 - Recall: 0.8876 - Specificity: 0.9991 - F1: 0.8832 - Loss: 0.1302\n",
      "\n",
      "Batch 214/387 ━━━━━━━━━━━━━━━━━━━━ 02:19:34\n",
      "Accuracy: 0.9979 - Precision: 0.8924 - Recall: 0.8879 - Specificity: 0.9991 - F1: 0.8831 - Loss: 0.1303\n",
      "\n",
      "Batch 215/387 ━━━━━━━━━━━━━━━━━━━━ 02:20:55\n",
      "Accuracy: 0.9979 - Precision: 0.8927 - Recall: 0.8883 - Specificity: 0.9991 - F1: 0.8835 - Loss: 0.1299\n",
      "\n",
      "Batch 216/387 ━━━━━━━━━━━━━━━━━━━━ 02:22:18\n",
      "Accuracy: 0.9979 - Precision: 0.8931 - Recall: 0.8884 - Specificity: 0.9991 - F1: 0.8837 - Loss: 0.1296\n",
      "\n",
      "Batch 217/387 ━━━━━━━━━━━━━━━━━━━━ 02:23:44\n",
      "Accuracy: 0.9979 - Precision: 0.8932 - Recall: 0.8886 - Specificity: 0.9991 - F1: 0.8840 - Loss: 0.1294\n",
      "\n",
      "Batch 218/387 ━━━━━━━━━━━━━━━━━━━━ 02:25:13\n",
      "Accuracy: 0.9979 - Precision: 0.8935 - Recall: 0.8888 - Specificity: 0.9991 - F1: 0.8842 - Loss: 0.1291\n",
      "\n",
      "Batch 219/387 ━━━━━━━━━━━━━━━━━━━━ 02:26:33\n",
      "Accuracy: 0.9979 - Precision: 0.8938 - Recall: 0.8873 - Specificity: 0.9991 - F1: 0.8834 - Loss: 0.1300\n",
      "\n",
      "Batch 220/387 ━━━━━━━━━━━━━━━━━━━━ 02:27:54\n",
      "Accuracy: 0.9979 - Precision: 0.8938 - Recall: 0.8875 - Specificity: 0.9991 - F1: 0.8835 - Loss: 0.1299\n",
      "\n",
      "Batch 221/387 ━━━━━━━━━━━━━━━━━━━━ 02:29:32\n",
      "Accuracy: 0.9979 - Precision: 0.8942 - Recall: 0.8876 - Specificity: 0.9991 - F1: 0.8838 - Loss: 0.1295\n",
      "\n",
      "Batch 222/387 ━━━━━━━━━━━━━━━━━━━━ 02:31:10\n",
      "Accuracy: 0.9979 - Precision: 0.8947 - Recall: 0.8875 - Specificity: 0.9991 - F1: 0.8840 - Loss: 0.1293\n",
      "\n",
      "Batch 223/387 ━━━━━━━━━━━━━━━━━━━━ 02:32:40\n",
      "Accuracy: 0.9979 - Precision: 0.8939 - Recall: 0.8868 - Specificity: 0.9991 - F1: 0.8833 - Loss: 0.1302\n",
      "\n",
      "Batch 224/387 ━━━━━━━━━━━━━━━━━━━━ 02:34:15\n",
      "Accuracy: 0.9979 - Precision: 0.8939 - Recall: 0.8867 - Specificity: 0.9991 - F1: 0.8833 - Loss: 0.1301\n",
      "\n",
      "Batch 225/387 ━━━━━━━━━━━━━━━━━━━━ 02:35:41\n",
      "Accuracy: 0.9979 - Precision: 0.8943 - Recall: 0.8869 - Specificity: 0.9991 - F1: 0.8836 - Loss: 0.1298\n",
      "\n",
      "Batch 226/387 ━━━━━━━━━━━━━━━━━━━━ 02:37:01\n",
      "Accuracy: 0.9979 - Precision: 0.8946 - Recall: 0.8871 - Specificity: 0.9991 - F1: 0.8839 - Loss: 0.1295\n",
      "\n",
      "Batch 227/387 ━━━━━━━━━━━━━━━━━━━━ 02:38:18\n",
      "Accuracy: 0.9979 - Precision: 0.8950 - Recall: 0.8873 - Specificity: 0.9991 - F1: 0.8842 - Loss: 0.1292\n",
      "\n",
      "Batch 228/387 ━━━━━━━━━━━━━━━━━━━━ 02:39:37\n",
      "Accuracy: 0.9979 - Precision: 0.8952 - Recall: 0.8869 - Specificity: 0.9991 - F1: 0.8842 - Loss: 0.1293\n",
      "\n",
      "Batch 229/387 ━━━━━━━━━━━━━━━━━━━━ 02:40:54\n",
      "Accuracy: 0.9979 - Precision: 0.8955 - Recall: 0.8873 - Specificity: 0.9991 - F1: 0.8845 - Loss: 0.1289\n",
      "\n",
      "Batch 230/387 ━━━━━━━━━━━━━━━━━━━━ 02:42:10\n",
      "Accuracy: 0.9979 - Precision: 0.8953 - Recall: 0.8875 - Specificity: 0.9991 - F1: 0.8846 - Loss: 0.1288\n",
      "\n",
      "Batch 231/387 ━━━━━━━━━━━━━━━━━━━━ 02:43:38\n",
      "Accuracy: 0.9979 - Precision: 0.8940 - Recall: 0.8877 - Specificity: 0.9991 - F1: 0.8838 - Loss: 0.1296\n",
      "\n",
      "Batch 232/387 ━━━━━━━━━━━━━━━━━━━━ 02:44:56\n",
      "Accuracy: 0.9979 - Precision: 0.8936 - Recall: 0.8878 - Specificity: 0.9991 - F1: 0.8837 - Loss: 0.1298\n",
      "\n",
      "Batch 233/387 ━━━━━━━━━━━━━━━━━━━━ 02:46:19\n",
      "Accuracy: 0.9979 - Precision: 0.8931 - Recall: 0.8880 - Specificity: 0.9991 - F1: 0.8836 - Loss: 0.1299\n",
      "\n",
      "Batch 234/387 ━━━━━━━━━━━━━━━━━━━━ 02:47:40\n",
      "Accuracy: 0.9979 - Precision: 0.8931 - Recall: 0.8884 - Specificity: 0.9991 - F1: 0.8838 - Loss: 0.1297\n",
      "\n",
      "Batch 235/387 ━━━━━━━━━━━━━━━━━━━━ 02:49:16\n",
      "Accuracy: 0.9979 - Precision: 0.8933 - Recall: 0.8886 - Specificity: 0.9991 - F1: 0.8840 - Loss: 0.1294\n",
      "\n",
      "Batch 236/387 ━━━━━━━━━━━━━━━━━━━━ 02:50:38\n",
      "Accuracy: 0.9979 - Precision: 0.8930 - Recall: 0.8889 - Specificity: 0.9991 - F1: 0.8840 - Loss: 0.1294\n",
      "\n",
      "Batch 237/387 ━━━━━━━━━━━━━━━━━━━━ 02:52:05\n",
      "Accuracy: 0.9979 - Precision: 0.8932 - Recall: 0.8890 - Specificity: 0.9991 - F1: 0.8842 - Loss: 0.1292\n",
      "\n",
      "Batch 238/387 ━━━━━━━━━━━━━━━━━━━━ 02:53:27\n",
      "Accuracy: 0.9979 - Precision: 0.8935 - Recall: 0.8890 - Specificity: 0.9991 - F1: 0.8844 - Loss: 0.1291\n",
      "\n",
      "Batch 239/387 ━━━━━━━━━━━━━━━━━━━━ 02:54:56\n",
      "Accuracy: 0.9979 - Precision: 0.8938 - Recall: 0.8890 - Specificity: 0.9991 - F1: 0.8846 - Loss: 0.1289\n",
      "\n",
      "Batch 240/387 ━━━━━━━━━━━━━━━━━━━━ 02:56:16\n",
      "Accuracy: 0.9979 - Precision: 0.8941 - Recall: 0.8890 - Specificity: 0.9991 - F1: 0.8847 - Loss: 0.1288\n",
      "\n",
      "Batch 241/387 ━━━━━━━━━━━━━━━━━━━━ 02:57:46\n",
      "Accuracy: 0.9979 - Precision: 0.8941 - Recall: 0.8893 - Specificity: 0.9991 - F1: 0.8849 - Loss: 0.1285\n",
      "\n",
      "Batch 242/387 ━━━━━━━━━━━━━━━━━━━━ 02:59:05\n",
      "Accuracy: 0.9979 - Precision: 0.8944 - Recall: 0.8886 - Specificity: 0.9991 - F1: 0.8846 - Loss: 0.1288\n",
      "\n",
      "Batch 243/387 ━━━━━━━━━━━━━━━━━━━━ 09:10:40\n",
      "Accuracy: 0.9979 - Precision: 0.8947 - Recall: 0.8881 - Specificity: 0.9991 - F1: 0.8845 - Loss: 0.1290\n",
      "\n",
      "Batch 244/387 ━━━━━━━━━━━━━━━━━━━━ 09:12:12\n",
      "Accuracy: 0.9979 - Precision: 0.8950 - Recall: 0.8881 - Specificity: 0.9991 - F1: 0.8847 - Loss: 0.1288\n",
      "\n",
      "Batch 245/387 ━━━━━━━━━━━━━━━━━━━━ 09:13:38\n",
      "Accuracy: 0.9979 - Precision: 0.8949 - Recall: 0.8883 - Specificity: 0.9991 - F1: 0.8848 - Loss: 0.1287\n",
      "\n",
      "Batch 246/387 ━━━━━━━━━━━━━━━━━━━━ 09:15:07\n",
      "Accuracy: 0.9979 - Precision: 0.8953 - Recall: 0.8885 - Specificity: 0.9991 - F1: 0.8851 - Loss: 0.1284\n",
      "\n",
      "Batch 247/387 ━━━━━━━━━━━━━━━━━━━━ 09:16:31\n",
      "Accuracy: 0.9979 - Precision: 0.8956 - Recall: 0.8882 - Specificity: 0.9991 - F1: 0.8851 - Loss: 0.1284\n",
      "\n",
      "Batch 248/387 ━━━━━━━━━━━━━━━━━━━━ 09:17:48\n",
      "Accuracy: 0.9979 - Precision: 0.8957 - Recall: 0.8880 - Specificity: 0.9991 - F1: 0.8851 - Loss: 0.1285\n",
      "\n",
      "Batch 249/387 ━━━━━━━━━━━━━━━━━━━━ 09:19:22\n",
      "Accuracy: 0.9979 - Precision: 0.8958 - Recall: 0.8882 - Specificity: 0.9991 - F1: 0.8852 - Loss: 0.1283\n",
      "\n",
      "Batch 250/387 ━━━━━━━━━━━━━━━━━━━━ 09:20:51\n",
      "Accuracy: 0.9979 - Precision: 0.8952 - Recall: 0.8883 - Specificity: 0.9991 - F1: 0.8850 - Loss: 0.1285\n",
      "\n",
      "Batch 251/387 ━━━━━━━━━━━━━━━━━━━━ 09:22:26\n",
      "Accuracy: 0.9979 - Precision: 0.8956 - Recall: 0.8880 - Specificity: 0.9991 - F1: 0.8851 - Loss: 0.1285\n",
      "\n",
      "Batch 252/387 ━━━━━━━━━━━━━━━━━━━━ 09:23:49\n",
      "Accuracy: 0.9979 - Precision: 0.8955 - Recall: 0.8882 - Specificity: 0.9991 - F1: 0.8852 - Loss: 0.1284\n",
      "\n",
      "Batch 253/387 ━━━━━━━━━━━━━━━━━━━━ 09:25:26\n",
      "Accuracy: 0.9979 - Precision: 0.8957 - Recall: 0.8885 - Specificity: 0.9991 - F1: 0.8854 - Loss: 0.1282\n",
      "\n",
      "Batch 254/387 ━━━━━━━━━━━━━━━━━━━━ 09:26:45\n",
      "Accuracy: 0.9979 - Precision: 0.8958 - Recall: 0.8889 - Specificity: 0.9991 - F1: 0.8857 - Loss: 0.1279\n",
      "\n",
      "Batch 255/387 ━━━━━━━━━━━━━━━━━━━━ 09:28:24\n",
      "Accuracy: 0.9979 - Precision: 0.8960 - Recall: 0.8892 - Specificity: 0.9991 - F1: 0.8859 - Loss: 0.1276\n",
      "\n",
      "Batch 256/387 ━━━━━━━━━━━━━━━━━━━━ 09:29:45\n",
      "Accuracy: 0.9979 - Precision: 0.8960 - Recall: 0.8893 - Specificity: 0.9991 - F1: 0.8860 - Loss: 0.1275\n",
      "\n",
      "Batch 257/387 ━━━━━━━━━━━━━━━━━━━━ 09:31:09\n",
      "Accuracy: 0.9979 - Precision: 0.8952 - Recall: 0.8894 - Specificity: 0.9991 - F1: 0.8856 - Loss: 0.1279\n",
      "\n",
      "Batch 258/387 ━━━━━━━━━━━━━━━━━━━━ 09:32:30\n",
      "Accuracy: 0.9979 - Precision: 0.8951 - Recall: 0.8894 - Specificity: 0.9991 - F1: 0.8856 - Loss: 0.1279\n",
      "\n",
      "Batch 259/387 ━━━━━━━━━━━━━━━━━━━━ 09:33:59\n",
      "Accuracy: 0.9979 - Precision: 0.8943 - Recall: 0.8894 - Specificity: 0.9991 - F1: 0.8852 - Loss: 0.1283\n",
      "\n",
      "Batch 260/387 ━━━━━━━━━━━━━━━━━━━━ 09:35:28\n",
      "Accuracy: 0.9978 - Precision: 0.8933 - Recall: 0.8897 - Specificity: 0.9990 - F1: 0.8847 - Loss: 0.1289\n",
      "\n",
      "Batch 261/387 ━━━━━━━━━━━━━━━━━━━━ 09:37:09\n",
      "Accuracy: 0.9979 - Precision: 0.8935 - Recall: 0.8899 - Specificity: 0.9990 - F1: 0.8850 - Loss: 0.1286\n",
      "\n",
      "Batch 262/387 ━━━━━━━━━━━━━━━━━━━━ 09:38:36\n",
      "Accuracy: 0.9979 - Precision: 0.8937 - Recall: 0.8900 - Specificity: 0.9990 - F1: 0.8852 - Loss: 0.1284\n",
      "\n",
      "Batch 263/387 ━━━━━━━━━━━━━━━━━━━━ 09:40:02\n",
      "Accuracy: 0.9979 - Precision: 0.8941 - Recall: 0.8898 - Specificity: 0.9991 - F1: 0.8852 - Loss: 0.1283\n",
      "\n",
      "Batch 264/387 ━━━━━━━━━━━━━━━━━━━━ 09:41:29\n",
      "Accuracy: 0.9979 - Precision: 0.8935 - Recall: 0.8901 - Specificity: 0.9990 - F1: 0.8851 - Loss: 0.1285\n",
      "\n",
      "Batch 265/387 ━━━━━━━━━━━━━━━━━━━━ 09:42:49\n",
      "Accuracy: 0.9979 - Precision: 0.8937 - Recall: 0.8902 - Specificity: 0.9991 - F1: 0.8853 - Loss: 0.1282\n",
      "\n",
      "Batch 266/387 ━━━━━━━━━━━━━━━━━━━━ 09:44:15\n",
      "Accuracy: 0.9979 - Precision: 0.8938 - Recall: 0.8904 - Specificity: 0.9990 - F1: 0.8854 - Loss: 0.1281\n",
      "\n",
      "Batch 267/387 ━━━━━━━━━━━━━━━━━━━━ 09:45:50\n",
      "Accuracy: 0.9979 - Precision: 0.8940 - Recall: 0.8896 - Specificity: 0.9991 - F1: 0.8851 - Loss: 0.1284\n",
      "\n",
      "Batch 268/387 ━━━━━━━━━━━━━━━━━━━━ 09:47:13\n",
      "Accuracy: 0.9979 - Precision: 0.8935 - Recall: 0.8897 - Specificity: 0.9991 - F1: 0.8849 - Loss: 0.1286\n",
      "\n",
      "Batch 269/387 ━━━━━━━━━━━━━━━━━━━━ 09:48:38\n",
      "Accuracy: 0.9978 - Precision: 0.8939 - Recall: 0.8889 - Specificity: 0.9991 - F1: 0.8845 - Loss: 0.1291\n",
      "\n",
      "Batch 270/387 ━━━━━━━━━━━━━━━━━━━━ 09:49:56\n",
      "Accuracy: 0.9979 - Precision: 0.8942 - Recall: 0.8891 - Specificity: 0.9991 - F1: 0.8848 - Loss: 0.1288\n",
      "\n",
      "Batch 271/387 ━━━━━━━━━━━━━━━━━━━━ 09:51:32\n",
      "Accuracy: 0.9979 - Precision: 0.8943 - Recall: 0.8893 - Specificity: 0.9991 - F1: 0.8850 - Loss: 0.1286\n",
      "\n",
      "Batch 272/387 ━━━━━━━━━━━━━━━━━━━━ 09:53:03\n",
      "Accuracy: 0.9979 - Precision: 0.8943 - Recall: 0.8890 - Specificity: 0.9991 - F1: 0.8849 - Loss: 0.1287\n",
      "\n",
      "Batch 273/387 ━━━━━━━━━━━━━━━━━━━━ 09:54:31\n",
      "Accuracy: 0.9979 - Precision: 0.8939 - Recall: 0.8894 - Specificity: 0.9991 - F1: 0.8848 - Loss: 0.1287\n",
      "\n",
      "Batch 274/387 ━━━━━━━━━━━━━━━━━━━━ 09:56:04\n",
      "Accuracy: 0.9979 - Precision: 0.8939 - Recall: 0.8889 - Specificity: 0.9991 - F1: 0.8846 - Loss: 0.1290\n",
      "\n",
      "Batch 275/387 ━━━━━━━━━━━━━━━━━━━━ 09:57:28\n",
      "Accuracy: 0.9978 - Precision: 0.8943 - Recall: 0.8884 - Specificity: 0.9991 - F1: 0.8845 - Loss: 0.1291\n",
      "\n",
      "Batch 276/387 ━━━━━━━━━━━━━━━━━━━━ 09:58:53\n",
      "Accuracy: 0.9978 - Precision: 0.8939 - Recall: 0.8887 - Specificity: 0.9991 - F1: 0.8844 - Loss: 0.1292\n",
      "\n",
      "Batch 277/387 ━━━━━━━━━━━━━━━━━━━━ 10:00:22\n",
      "Accuracy: 0.9978 - Precision: 0.8937 - Recall: 0.8890 - Specificity: 0.9990 - F1: 0.8845 - Loss: 0.1291\n",
      "\n",
      "Batch 278/387 ━━━━━━━━━━━━━━━━━━━━ 10:02:00\n",
      "Accuracy: 0.9978 - Precision: 0.8941 - Recall: 0.8889 - Specificity: 0.9990 - F1: 0.8847 - Loss: 0.1290\n",
      "\n",
      "Batch 279/387 ━━━━━━━━━━━━━━━━━━━━ 10:03:28\n",
      "Accuracy: 0.9978 - Precision: 0.8939 - Recall: 0.8893 - Specificity: 0.9990 - F1: 0.8848 - Loss: 0.1288\n",
      "\n",
      "Batch 280/387 ━━━━━━━━━━━━━━━━━━━━ 10:04:46\n",
      "Accuracy: 0.9978 - Precision: 0.8941 - Recall: 0.8891 - Specificity: 0.9990 - F1: 0.8848 - Loss: 0.1288\n",
      "\n",
      "Batch 281/387 ━━━━━━━━━━━━━━━━━━━━ 10:06:04\n",
      "Accuracy: 0.9978 - Precision: 0.8943 - Recall: 0.8894 - Specificity: 0.9990 - F1: 0.8851 - Loss: 0.1285\n",
      "\n",
      "Batch 282/387 ━━━━━━━━━━━━━━━━━━━━ 10:07:27\n",
      "Accuracy: 0.9978 - Precision: 0.8945 - Recall: 0.8892 - Specificity: 0.9990 - F1: 0.8851 - Loss: 0.1286\n",
      "\n",
      "Batch 283/387 ━━━━━━━━━━━━━━━━━━━━ 10:08:42\n",
      "Accuracy: 0.9978 - Precision: 0.8946 - Recall: 0.8894 - Specificity: 0.9990 - F1: 0.8853 - Loss: 0.1284\n",
      "\n",
      "Batch 284/387 ━━━━━━━━━━━━━━━━━━━━ 10:10:11\n",
      "Accuracy: 0.9978 - Precision: 0.8947 - Recall: 0.8895 - Specificity: 0.9990 - F1: 0.8854 - Loss: 0.1283\n",
      "\n",
      "Batch 285/387 ━━━━━━━━━━━━━━━━━━━━ 10:11:30\n",
      "Accuracy: 0.9978 - Precision: 0.8939 - Recall: 0.8895 - Specificity: 0.9990 - F1: 0.8849 - Loss: 0.1288\n",
      "\n",
      "Batch 286/387 ━━━━━━━━━━━━━━━━━━━━ 10:12:53\n",
      "Accuracy: 0.9978 - Precision: 0.8941 - Recall: 0.8897 - Specificity: 0.9990 - F1: 0.8852 - Loss: 0.1285\n",
      "\n",
      "Batch 287/387 ━━━━━━━━━━━━━━━━━━━━ 10:14:13\n",
      "Accuracy: 0.9978 - Precision: 0.8942 - Recall: 0.8899 - Specificity: 0.9990 - F1: 0.8854 - Loss: 0.1284\n",
      "\n",
      "Batch 288/387 ━━━━━━━━━━━━━━━━━━━━ 10:15:36\n",
      "Accuracy: 0.9978 - Precision: 0.8943 - Recall: 0.8903 - Specificity: 0.9990 - F1: 0.8856 - Loss: 0.1281\n",
      "\n",
      "Batch 289/387 ━━━━━━━━━━━━━━━━━━━━ 10:16:57\n",
      "Accuracy: 0.9978 - Precision: 0.8945 - Recall: 0.8904 - Specificity: 0.9990 - F1: 0.8858 - Loss: 0.1279\n",
      "\n",
      "Batch 290/387 ━━━━━━━━━━━━━━━━━━━━ 10:18:19\n",
      "Accuracy: 0.9978 - Precision: 0.8943 - Recall: 0.8903 - Specificity: 0.9990 - F1: 0.8857 - Loss: 0.1280\n",
      "\n",
      "Batch 291/387 ━━━━━━━━━━━━━━━━━━━━ 10:19:49\n",
      "Accuracy: 0.9978 - Precision: 0.8943 - Recall: 0.8904 - Specificity: 0.9990 - F1: 0.8858 - Loss: 0.1279\n",
      "\n",
      "Batch 292/387 ━━━━━━━━━━━━━━━━━━━━ 10:21:22\n",
      "Accuracy: 0.9978 - Precision: 0.8939 - Recall: 0.8906 - Specificity: 0.9990 - F1: 0.8856 - Loss: 0.1282\n",
      "\n",
      "Batch 293/387 ━━━━━━━━━━━━━━━━━━━━ 10:22:49\n",
      "Accuracy: 0.9978 - Precision: 0.8942 - Recall: 0.8907 - Specificity: 0.9990 - F1: 0.8859 - Loss: 0.1279\n",
      "\n",
      "Batch 294/387 ━━━━━━━━━━━━━━━━━━━━ 10:24:11\n",
      "Accuracy: 0.9978 - Precision: 0.8944 - Recall: 0.8905 - Specificity: 0.9990 - F1: 0.8859 - Loss: 0.1279\n",
      "\n",
      "Batch 295/387 ━━━━━━━━━━━━━━━━━━━━ 10:25:39\n",
      "Accuracy: 0.9978 - Precision: 0.8946 - Recall: 0.8908 - Specificity: 0.9990 - F1: 0.8861 - Loss: 0.1276\n",
      "\n",
      "Batch 296/387 ━━━━━━━━━━━━━━━━━━━━ 10:27:20\n",
      "Accuracy: 0.9978 - Precision: 0.8947 - Recall: 0.8908 - Specificity: 0.9990 - F1: 0.8862 - Loss: 0.1276\n",
      "\n",
      "Batch 297/387 ━━━━━━━━━━━━━━━━━━━━ 10:28:48\n",
      "Accuracy: 0.9978 - Precision: 0.8951 - Recall: 0.8907 - Specificity: 0.9990 - F1: 0.8864 - Loss: 0.1274\n",
      "\n",
      "Batch 298/387 ━━━━━━━━━━━━━━━━━━━━ 10:30:14\n",
      "Accuracy: 0.9978 - Precision: 0.8953 - Recall: 0.8902 - Specificity: 0.9990 - F1: 0.8862 - Loss: 0.1276\n",
      "\n",
      "Batch 299/387 ━━━━━━━━━━━━━━━━━━━━ 10:31:35\n",
      "Accuracy: 0.9978 - Precision: 0.8954 - Recall: 0.8905 - Specificity: 0.9990 - F1: 0.8864 - Loss: 0.1273\n",
      "\n",
      "Batch 300/387 ━━━━━━━━━━━━━━━━━━━━ 10:32:58\n",
      "Accuracy: 0.9978 - Precision: 0.8944 - Recall: 0.8902 - Specificity: 0.9990 - F1: 0.8857 - Loss: 0.1280\n",
      "\n",
      "Batch 301/387 ━━━━━━━━━━━━━━━━━━━━ 10:34:26\n",
      "Accuracy: 0.9978 - Precision: 0.8945 - Recall: 0.8895 - Specificity: 0.9990 - F1: 0.8854 - Loss: 0.1284\n",
      "\n",
      "Batch 302/387 ━━━━━━━━━━━━━━━━━━━━ 10:35:51\n",
      "Accuracy: 0.9978 - Precision: 0.8945 - Recall: 0.8896 - Specificity: 0.9990 - F1: 0.8855 - Loss: 0.1283\n",
      "\n",
      "Batch 303/387 ━━━━━━━━━━━━━━━━━━━━ 10:37:26\n",
      "Accuracy: 0.9978 - Precision: 0.8948 - Recall: 0.8898 - Specificity: 0.9990 - F1: 0.8857 - Loss: 0.1280\n",
      "\n",
      "Batch 304/387 ━━━━━━━━━━━━━━━━━━━━ 10:38:55\n",
      "Accuracy: 0.9978 - Precision: 0.8950 - Recall: 0.8900 - Specificity: 0.9990 - F1: 0.8860 - Loss: 0.1278\n",
      "\n",
      "Batch 305/387 ━━━━━━━━━━━━━━━━━━━━ 10:40:20\n",
      "Accuracy: 0.9978 - Precision: 0.8946 - Recall: 0.8903 - Specificity: 0.9990 - F1: 0.8859 - Loss: 0.1278\n",
      "\n",
      "Batch 306/387 ━━━━━━━━━━━━━━━━━━━━ 10:42:03\n",
      "Accuracy: 0.9978 - Precision: 0.8947 - Recall: 0.8904 - Specificity: 0.9990 - F1: 0.8860 - Loss: 0.1277\n",
      "\n",
      "Batch 307/387 ━━━━━━━━━━━━━━━━━━━━ 10:43:35\n",
      "Accuracy: 0.9978 - Precision: 0.8948 - Recall: 0.8906 - Specificity: 0.9990 - F1: 0.8861 - Loss: 0.1275\n",
      "\n",
      "Batch 308/387 ━━━━━━━━━━━━━━━━━━━━ 10:45:00\n",
      "Accuracy: 0.9978 - Precision: 0.8948 - Recall: 0.8906 - Specificity: 0.9990 - F1: 0.8862 - Loss: 0.1275\n",
      "\n",
      "Batch 309/387 ━━━━━━━━━━━━━━━━━━━━ 10:46:27\n",
      "Accuracy: 0.9978 - Precision: 0.8943 - Recall: 0.8908 - Specificity: 0.9990 - F1: 0.8861 - Loss: 0.1276\n",
      "\n",
      "Batch 310/387 ━━━━━━━━━━━━━━━━━━━━ 10:47:56\n",
      "Accuracy: 0.9978 - Precision: 0.8942 - Recall: 0.8911 - Specificity: 0.9990 - F1: 0.8861 - Loss: 0.1276\n",
      "\n",
      "Batch 311/387 ━━━━━━━━━━━━━━━━━━━━ 10:49:25\n",
      "Accuracy: 0.9978 - Precision: 0.8945 - Recall: 0.8912 - Specificity: 0.9990 - F1: 0.8863 - Loss: 0.1273\n",
      "\n",
      "Batch 312/387 ━━━━━━━━━━━━━━━━━━━━ 10:50:57\n",
      "Accuracy: 0.9978 - Precision: 0.8946 - Recall: 0.8912 - Specificity: 0.9990 - F1: 0.8864 - Loss: 0.1272\n",
      "\n",
      "Batch 313/387 ━━━━━━━━━━━━━━━━━━━━ 10:52:17\n",
      "Accuracy: 0.9978 - Precision: 0.8936 - Recall: 0.8912 - Specificity: 0.9990 - F1: 0.8858 - Loss: 0.1279\n",
      "\n",
      "Batch 314/387 ━━━━━━━━━━━━━━━━━━━━ 10:53:49\n",
      "Accuracy: 0.9978 - Precision: 0.8939 - Recall: 0.8911 - Specificity: 0.9990 - F1: 0.8859 - Loss: 0.1278\n",
      "\n",
      "Batch 315/387 ━━━━━━━━━━━━━━━━━━━━ 10:55:30\n",
      "Accuracy: 0.9978 - Precision: 0.8941 - Recall: 0.8907 - Specificity: 0.9990 - F1: 0.8859 - Loss: 0.1279\n",
      "\n",
      "Batch 316/387 ━━━━━━━━━━━━━━━━━━━━ 10:56:52\n",
      "Accuracy: 0.9978 - Precision: 0.8944 - Recall: 0.8908 - Specificity: 0.9990 - F1: 0.8860 - Loss: 0.1276\n",
      "\n",
      "Batch 317/387 ━━━━━━━━━━━━━━━━━━━━ 10:58:18\n",
      "Accuracy: 0.9978 - Precision: 0.8945 - Recall: 0.8909 - Specificity: 0.9990 - F1: 0.8862 - Loss: 0.1275\n",
      "\n",
      "Batch 318/387 ━━━━━━━━━━━━━━━━━━━━ 10:59:54\n",
      "Accuracy: 0.9978 - Precision: 0.8949 - Recall: 0.8909 - Specificity: 0.9990 - F1: 0.8864 - Loss: 0.1273\n",
      "\n",
      "Batch 319/387 ━━━━━━━━━━━━━━━━━━━━ 11:01:21\n",
      "Accuracy: 0.9978 - Precision: 0.8950 - Recall: 0.8910 - Specificity: 0.9990 - F1: 0.8865 - Loss: 0.1272\n",
      "\n",
      "Batch 320/387 ━━━━━━━━━━━━━━━━━━━━ 11:02:40\n",
      "Accuracy: 0.9978 - Precision: 0.8952 - Recall: 0.8912 - Specificity: 0.9990 - F1: 0.8867 - Loss: 0.1269\n",
      "\n",
      "Batch 321/387 ━━━━━━━━━━━━━━━━━━━━ 11:04:11\n",
      "Accuracy: 0.9978 - Precision: 0.8952 - Recall: 0.8914 - Specificity: 0.9990 - F1: 0.8868 - Loss: 0.1268\n",
      "\n",
      "Batch 322/387 ━━━━━━━━━━━━━━━━━━━━ 11:05:31\n",
      "Accuracy: 0.9978 - Precision: 0.8951 - Recall: 0.8916 - Specificity: 0.9990 - F1: 0.8868 - Loss: 0.1268\n",
      "\n",
      "Batch 323/387 ━━━━━━━━━━━━━━━━━━━━ 11:06:48\n",
      "Accuracy: 0.9978 - Precision: 0.8952 - Recall: 0.8916 - Specificity: 0.9990 - F1: 0.8870 - Loss: 0.1266\n",
      "\n",
      "Batch 324/387 ━━━━━━━━━━━━━━━━━━━━ 11:08:17\n",
      "Accuracy: 0.9978 - Precision: 0.8951 - Recall: 0.8919 - Specificity: 0.9990 - F1: 0.8871 - Loss: 0.1265\n",
      "\n",
      "Batch 325/387 ━━━━━━━━━━━━━━━━━━━━ 11:09:39\n",
      "Accuracy: 0.9978 - Precision: 0.8953 - Recall: 0.8918 - Specificity: 0.9990 - F1: 0.8871 - Loss: 0.1265\n",
      "\n",
      "Batch 326/387 ━━━━━━━━━━━━━━━━━━━━ 11:11:13\n",
      "Accuracy: 0.9978 - Precision: 0.8952 - Recall: 0.8920 - Specificity: 0.9990 - F1: 0.8872 - Loss: 0.1264\n",
      "\n",
      "Batch 327/387 ━━━━━━━━━━━━━━━━━━━━ 11:12:40\n",
      "Accuracy: 0.9978 - Precision: 0.8947 - Recall: 0.8922 - Specificity: 0.9990 - F1: 0.8870 - Loss: 0.1266\n",
      "\n",
      "Batch 328/387 ━━━━━━━━━━━━━━━━━━━━ 11:14:03\n",
      "Accuracy: 0.9978 - Precision: 0.8947 - Recall: 0.8924 - Specificity: 0.9990 - F1: 0.8871 - Loss: 0.1265\n",
      "\n",
      "Batch 329/387 ━━━━━━━━━━━━━━━━━━━━ 11:15:24\n",
      "Accuracy: 0.9978 - Precision: 0.8950 - Recall: 0.8920 - Specificity: 0.9990 - F1: 0.8870 - Loss: 0.1266\n",
      "\n",
      "Batch 330/387 ━━━━━━━━━━━━━━━━━━━━ 11:16:47\n",
      "Accuracy: 0.9978 - Precision: 0.8952 - Recall: 0.8922 - Specificity: 0.9990 - F1: 0.8872 - Loss: 0.1264\n",
      "\n",
      "Batch 331/387 ━━━━━━━━━━━━━━━━━━━━ 11:18:03\n",
      "Accuracy: 0.9978 - Precision: 0.8953 - Recall: 0.8923 - Specificity: 0.9990 - F1: 0.8874 - Loss: 0.1262\n",
      "\n",
      "Batch 332/387 ━━━━━━━━━━━━━━━━━━━━ 11:19:34\n",
      "Accuracy: 0.9978 - Precision: 0.8954 - Recall: 0.8926 - Specificity: 0.9990 - F1: 0.8876 - Loss: 0.1260\n",
      "\n",
      "Batch 333/387 ━━━━━━━━━━━━━━━━━━━━ 11:20:56\n",
      "Accuracy: 0.9978 - Precision: 0.8955 - Recall: 0.8924 - Specificity: 0.9990 - F1: 0.8875 - Loss: 0.1261\n",
      "\n",
      "Batch 334/387 ━━━━━━━━━━━━━━━━━━━━ 11:22:16\n",
      "Accuracy: 0.9978 - Precision: 0.8957 - Recall: 0.8921 - Specificity: 0.9990 - F1: 0.8875 - Loss: 0.1261\n",
      "\n",
      "Batch 335/387 ━━━━━━━━━━━━━━━━━━━━ 11:23:43\n",
      "Accuracy: 0.9978 - Precision: 0.8958 - Recall: 0.8922 - Specificity: 0.9990 - F1: 0.8876 - Loss: 0.1260\n",
      "\n",
      "Batch 336/387 ━━━━━━━━━━━━━━━━━━━━ 11:25:02\n",
      "Accuracy: 0.9978 - Precision: 0.8959 - Recall: 0.8913 - Specificity: 0.9990 - F1: 0.8871 - Loss: 0.1264\n",
      "\n",
      "Batch 337/387 ━━━━━━━━━━━━━━━━━━━━ 11:26:28\n",
      "Accuracy: 0.9978 - Precision: 0.8961 - Recall: 0.8914 - Specificity: 0.9990 - F1: 0.8872 - Loss: 0.1263\n",
      "\n",
      "Batch 338/387 ━━━━━━━━━━━━━━━━━━━━ 11:27:56\n",
      "Accuracy: 0.9978 - Precision: 0.8962 - Recall: 0.8916 - Specificity: 0.9990 - F1: 0.8874 - Loss: 0.1261\n",
      "\n",
      "Batch 339/387 ━━━━━━━━━━━━━━━━━━━━ 11:29:22\n",
      "Accuracy: 0.9978 - Precision: 0.8958 - Recall: 0.8912 - Specificity: 0.9990 - F1: 0.8871 - Loss: 0.1264\n",
      "\n",
      "Batch 340/387 ━━━━━━━━━━━━━━━━━━━━ 11:30:59\n",
      "Accuracy: 0.9978 - Precision: 0.8952 - Recall: 0.8914 - Specificity: 0.9990 - F1: 0.8868 - Loss: 0.1267\n",
      "\n",
      "Batch 341/387 ━━━━━━━━━━━━━━━━━━━━ 11:32:41\n",
      "Accuracy: 0.9978 - Precision: 0.8954 - Recall: 0.8913 - Specificity: 0.9990 - F1: 0.8869 - Loss: 0.1266\n",
      "\n",
      "Batch 342/387 ━━━━━━━━━━━━━━━━━━━━ 11:34:03\n",
      "Accuracy: 0.9978 - Precision: 0.8955 - Recall: 0.8914 - Specificity: 0.9990 - F1: 0.8870 - Loss: 0.1265\n",
      "\n",
      "Batch 343/387 ━━━━━━━━━━━━━━━━━━━━ 11:35:23\n",
      "Accuracy: 0.9978 - Precision: 0.8957 - Recall: 0.8915 - Specificity: 0.9990 - F1: 0.8872 - Loss: 0.1263\n",
      "\n",
      "Batch 344/387 ━━━━━━━━━━━━━━━━━━━━ 11:36:42\n",
      "Accuracy: 0.9978 - Precision: 0.8959 - Recall: 0.8916 - Specificity: 0.9990 - F1: 0.8873 - Loss: 0.1262\n",
      "\n",
      "Batch 345/387 ━━━━━━━━━━━━━━━━━━━━ 11:38:01\n",
      "Accuracy: 0.9978 - Precision: 0.8959 - Recall: 0.8912 - Specificity: 0.9990 - F1: 0.8871 - Loss: 0.1264\n",
      "\n",
      "Batch 346/387 ━━━━━━━━━━━━━━━━━━━━ 11:39:47\n",
      "Accuracy: 0.9978 - Precision: 0.8953 - Recall: 0.8914 - Specificity: 0.9990 - F1: 0.8869 - Loss: 0.1266\n",
      "\n",
      "Batch 347/387 ━━━━━━━━━━━━━━━━━━━━ 11:41:23\n",
      "Accuracy: 0.9978 - Precision: 0.8955 - Recall: 0.8915 - Specificity: 0.9990 - F1: 0.8871 - Loss: 0.1264\n",
      "\n",
      "Batch 348/387 ━━━━━━━━━━━━━━━━━━━━ 11:42:44\n",
      "Accuracy: 0.9978 - Precision: 0.8955 - Recall: 0.8912 - Specificity: 0.9990 - F1: 0.8869 - Loss: 0.1265\n",
      "\n",
      "Batch 349/387 ━━━━━━━━━━━━━━━━━━━━ 11:44:15\n",
      "Accuracy: 0.9978 - Precision: 0.8956 - Recall: 0.8912 - Specificity: 0.9990 - F1: 0.8870 - Loss: 0.1265\n",
      "\n",
      "Batch 350/387 ━━━━━━━━━━━━━━━━━━━━ 11:45:40\n",
      "Accuracy: 0.9978 - Precision: 0.8959 - Recall: 0.8911 - Specificity: 0.9990 - F1: 0.8871 - Loss: 0.1264\n",
      "\n",
      "Batch 351/387 ━━━━━━━━━━━━━━━━━━━━ 11:47:03\n",
      "Accuracy: 0.9978 - Precision: 0.8960 - Recall: 0.8913 - Specificity: 0.9990 - F1: 0.8873 - Loss: 0.1262\n",
      "\n",
      "Batch 352/387 ━━━━━━━━━━━━━━━━━━━━ 11:48:24\n",
      "Accuracy: 0.9978 - Precision: 0.8959 - Recall: 0.8914 - Specificity: 0.9990 - F1: 0.8873 - Loss: 0.1262\n",
      "\n",
      "Batch 353/387 ━━━━━━━━━━━━━━━━━━━━ 11:49:46\n",
      "Accuracy: 0.9978 - Precision: 0.8960 - Recall: 0.8916 - Specificity: 0.9990 - F1: 0.8874 - Loss: 0.1261\n",
      "\n",
      "Batch 354/387 ━━━━━━━━━━━━━━━━━━━━ 11:51:08\n",
      "Accuracy: 0.9978 - Precision: 0.8962 - Recall: 0.8914 - Specificity: 0.9990 - F1: 0.8874 - Loss: 0.1260\n",
      "\n",
      "Batch 355/387 ━━━━━━━━━━━━━━━━━━━━ 11:52:42\n",
      "Accuracy: 0.9978 - Precision: 0.8963 - Recall: 0.8912 - Specificity: 0.9990 - F1: 0.8874 - Loss: 0.1261\n",
      "\n",
      "Batch 356/387 ━━━━━━━━━━━━━━━━━━━━ 11:54:21\n",
      "Accuracy: 0.9978 - Precision: 0.8961 - Recall: 0.8910 - Specificity: 0.9990 - F1: 0.8872 - Loss: 0.1263\n",
      "\n",
      "Batch 357/387 ━━━━━━━━━━━━━━━━━━━━ 11:55:41\n",
      "Accuracy: 0.9978 - Precision: 0.8962 - Recall: 0.8911 - Specificity: 0.9990 - F1: 0.8873 - Loss: 0.1262\n",
      "\n",
      "Batch 358/387 ━━━━━━━━━━━━━━━━━━━━ 11:57:17\n",
      "Accuracy: 0.9978 - Precision: 0.8955 - Recall: 0.8909 - Specificity: 0.9990 - F1: 0.8869 - Loss: 0.1266\n",
      "\n",
      "Batch 359/387 ━━━━━━━━━━━━━━━━━━━━ 11:58:40\n",
      "Accuracy: 0.9978 - Precision: 0.8952 - Recall: 0.8912 - Specificity: 0.9990 - F1: 0.8868 - Loss: 0.1267\n",
      "\n",
      "Batch 360/387 ━━━━━━━━━━━━━━━━━━━━ 12:00:05\n",
      "Accuracy: 0.9978 - Precision: 0.8952 - Recall: 0.8914 - Specificity: 0.9990 - F1: 0.8870 - Loss: 0.1265\n",
      "\n",
      "Batch 361/387 ━━━━━━━━━━━━━━━━━━━━ 12:01:25\n",
      "Accuracy: 0.9978 - Precision: 0.8951 - Recall: 0.8914 - Specificity: 0.9990 - F1: 0.8869 - Loss: 0.1266\n",
      "\n",
      "Batch 362/387 ━━━━━━━━━━━━━━━━━━━━ 12:02:55\n",
      "Accuracy: 0.9978 - Precision: 0.8952 - Recall: 0.8916 - Specificity: 0.9990 - F1: 0.8871 - Loss: 0.1264\n",
      "\n",
      "Batch 363/387 ━━━━━━━━━━━━━━━━━━━━ 12:04:17\n",
      "Accuracy: 0.9978 - Precision: 0.8948 - Recall: 0.8914 - Specificity: 0.9990 - F1: 0.8868 - Loss: 0.1267\n",
      "\n",
      "Batch 364/387 ━━━━━━━━━━━━━━━━━━━━ 12:05:52\n",
      "Accuracy: 0.9978 - Precision: 0.8948 - Recall: 0.8914 - Specificity: 0.9990 - F1: 0.8869 - Loss: 0.1267\n",
      "\n",
      "Batch 365/387 ━━━━━━━━━━━━━━━━━━━━ 12:07:09\n",
      "Accuracy: 0.9978 - Precision: 0.8943 - Recall: 0.8902 - Specificity: 0.9990 - F1: 0.8859 - Loss: 0.1276\n",
      "\n",
      "Batch 366/387 ━━━━━━━━━━━━━━━━━━━━ 12:08:33\n",
      "Accuracy: 0.9978 - Precision: 0.8941 - Recall: 0.8903 - Specificity: 0.9990 - F1: 0.8859 - Loss: 0.1276\n",
      "\n",
      "Batch 367/387 ━━━━━━━━━━━━━━━━━━━━ 12:10:06\n",
      "Accuracy: 0.9978 - Precision: 0.8942 - Recall: 0.8904 - Specificity: 0.9990 - F1: 0.8860 - Loss: 0.1275\n",
      "\n",
      "Batch 368/387 ━━━━━━━━━━━━━━━━━━━━ 12:11:33\n",
      "Accuracy: 0.9978 - Precision: 0.8943 - Recall: 0.8906 - Specificity: 0.9990 - F1: 0.8862 - Loss: 0.1273\n",
      "\n",
      "Batch 369/387 ━━━━━━━━━━━━━━━━━━━━ 12:13:02\n",
      "Accuracy: 0.9978 - Precision: 0.8944 - Recall: 0.8906 - Specificity: 0.9990 - F1: 0.8862 - Loss: 0.1273\n",
      "\n",
      "Batch 370/387 ━━━━━━━━━━━━━━━━━━━━ 12:14:35\n",
      "Accuracy: 0.9978 - Precision: 0.8943 - Recall: 0.8898 - Specificity: 0.9990 - F1: 0.8858 - Loss: 0.1277\n",
      "\n",
      "Batch 371/387 ━━━━━━━━━━━━━━━━━━━━ 12:16:02\n",
      "Accuracy: 0.9978 - Precision: 0.8946 - Recall: 0.8899 - Specificity: 0.9990 - F1: 0.8859 - Loss: 0.1276\n",
      "\n",
      "Batch 372/387 ━━━━━━━━━━━━━━━━━━━━ 12:17:29\n",
      "Accuracy: 0.9978 - Precision: 0.8939 - Recall: 0.8898 - Specificity: 0.9990 - F1: 0.8855 - Loss: 0.1281\n",
      "\n",
      "Batch 373/387 ━━━━━━━━━━━━━━━━━━━━ 12:19:03\n",
      "Accuracy: 0.9978 - Precision: 0.8939 - Recall: 0.8900 - Specificity: 0.9990 - F1: 0.8856 - Loss: 0.1279\n",
      "\n",
      "Batch 374/387 ━━━━━━━━━━━━━━━━━━━━ 12:20:36\n",
      "Accuracy: 0.9978 - Precision: 0.8935 - Recall: 0.8902 - Specificity: 0.9990 - F1: 0.8855 - Loss: 0.1280\n",
      "\n",
      "Batch 375/387 ━━━━━━━━━━━━━━━━━━━━ 12:22:26\n",
      "Accuracy: 0.9978 - Precision: 0.8936 - Recall: 0.8903 - Specificity: 0.9990 - F1: 0.8856 - Loss: 0.1280\n",
      "\n",
      "Batch 376/387 ━━━━━━━━━━━━━━━━━━━━ 12:24:00\n",
      "Accuracy: 0.9978 - Precision: 0.8936 - Recall: 0.8904 - Specificity: 0.9990 - F1: 0.8857 - Loss: 0.1278\n",
      "\n",
      "Batch 377/387 ━━━━━━━━━━━━━━━━━━━━ 12:25:39\n",
      "Accuracy: 0.9978 - Precision: 0.8931 - Recall: 0.8902 - Specificity: 0.9990 - F1: 0.8854 - Loss: 0.1282\n",
      "\n",
      "Batch 378/387 ━━━━━━━━━━━━━━━━━━━━ 12:27:20\n",
      "Accuracy: 0.9978 - Precision: 0.8932 - Recall: 0.8903 - Specificity: 0.9990 - F1: 0.8855 - Loss: 0.1280\n",
      "\n",
      "Batch 379/387 ━━━━━━━━━━━━━━━━━━━━ 12:28:52\n",
      "Accuracy: 0.9978 - Precision: 0.8931 - Recall: 0.8905 - Specificity: 0.9990 - F1: 0.8856 - Loss: 0.1280\n",
      "\n",
      "Batch 380/387 ━━━━━━━━━━━━━━━━━━━━ 12:30:29\n",
      "Accuracy: 0.9978 - Precision: 0.8933 - Recall: 0.8907 - Specificity: 0.9990 - F1: 0.8858 - Loss: 0.1278\n",
      "\n",
      "Batch 381/387 ━━━━━━━━━━━━━━━━━━━━ 12:32:01\n",
      "Accuracy: 0.9978 - Precision: 0.8935 - Recall: 0.8904 - Specificity: 0.9990 - F1: 0.8857 - Loss: 0.1278\n",
      "\n",
      "Batch 382/387 ━━━━━━━━━━━━━━━━━━━━ 12:33:25\n",
      "Accuracy: 0.9978 - Precision: 0.8934 - Recall: 0.8905 - Specificity: 0.9990 - F1: 0.8857 - Loss: 0.1278\n",
      "\n",
      "Batch 383/387 ━━━━━━━━━━━━━━━━━━━━ 12:34:54\n",
      "Accuracy: 0.9978 - Precision: 0.8936 - Recall: 0.8907 - Specificity: 0.9990 - F1: 0.8859 - Loss: 0.1276\n",
      "\n",
      "Batch 384/387 ━━━━━━━━━━━━━━━━━━━━ 12:36:34\n",
      "Accuracy: 0.9978 - Precision: 0.8935 - Recall: 0.8909 - Specificity: 0.9990 - F1: 0.8860 - Loss: 0.1275\n",
      "\n",
      "Batch 385/387 ━━━━━━━━━━━━━━━━━━━━ 12:38:18\n",
      "Accuracy: 0.9978 - Precision: 0.8937 - Recall: 0.8910 - Specificity: 0.9990 - F1: 0.8861 - Loss: 0.1274\n",
      "\n",
      "Batch 386/387 ━━━━━━━━━━━━━━━━━━━━ 12:39:46\n",
      "Accuracy: 0.9978 - Precision: 0.8938 - Recall: 0.8912 - Specificity: 0.9990 - F1: 0.8863 - Loss: 0.1272\n",
      "\n",
      "Batch 387/387 ━━━━━━━━━━━━━━━━━━━━ 12:41:01\n",
      "Accuracy: 0.9978 - Precision: 0.8939 - Recall: 0.8914 - Specificity: 0.9990 - F1: 0.8865 - Loss: 0.1270\n",
      "\n",
      "End of Epoch 12\n",
      "\n",
      "Epoch 13/50\n",
      "Batch 1/387 ━━━━━━━━━━━━━━━━━━━━ 13:03:14\n",
      "Accuracy: 0.9976 - Precision: 0.9747 - Recall: 0.9013 - Specificity: 0.9995 - F1: 0.9366 - Loss: 0.0763\n",
      "\n",
      "Batch 2/387 ━━━━━━━━━━━━━━━━━━━━ 13:04:47\n",
      "Accuracy: 0.9984 - Precision: 0.9769 - Recall: 0.9221 - Specificity: 0.9997 - F1: 0.9486 - Loss: 0.0609\n",
      "\n",
      "Batch 3/387 ━━━━━━━━━━━━━━━━━━━━ 13:06:10\n",
      "Accuracy: 0.9988 - Precision: 0.9362 - Recall: 0.9258 - Specificity: 0.9997 - F1: 0.9298 - Loss: 0.0794\n",
      "\n",
      "Batch 4/387 ━━━━━━━━━━━━━━━━━━━━ 13:07:44\n",
      "Accuracy: 0.9987 - Precision: 0.9450 - Recall: 0.9195 - Specificity: 0.9997 - F1: 0.9310 - Loss: 0.0786\n",
      "\n",
      "Batch 5/387 ━━━━━━━━━━━━━━━━━━━━ 13:09:12\n",
      "Accuracy: 0.9985 - Precision: 0.9514 - Recall: 0.9078 - Specificity: 0.9997 - F1: 0.9279 - Loss: 0.0824\n",
      "\n",
      "Batch 6/387 ━━━━━━━━━━━━━━━━━━━━ 13:10:41\n",
      "Accuracy: 0.9986 - Precision: 0.9491 - Recall: 0.9060 - Specificity: 0.9997 - F1: 0.9261 - Loss: 0.0838\n",
      "\n",
      "Batch 7/387 ━━━━━━━━━━━━━━━━━━━━ 13:12:09\n",
      "Accuracy: 0.9982 - Precision: 0.9513 - Recall: 0.8967 - Specificity: 0.9996 - F1: 0.9221 - Loss: 0.0902\n",
      "\n",
      "Batch 8/387 ━━━━━━━━━━━━━━━━━━━━ 13:13:41\n",
      "Accuracy: 0.9977 - Precision: 0.9556 - Recall: 0.8739 - Specificity: 0.9996 - F1: 0.9104 - Loss: 0.1044\n",
      "\n",
      "Batch 9/387 ━━━━━━━━━━━━━━━━━━━━ 13:15:16\n",
      "Accuracy: 0.9973 - Precision: 0.9590 - Recall: 0.8564 - Specificity: 0.9997 - F1: 0.9015 - Loss: 0.1151\n",
      "\n",
      "Batch 10/387 ━━━━━━━━━━━━━━━━━━━━ 13:16:47\n",
      "Accuracy: 0.9974 - Precision: 0.9616 - Recall: 0.8596 - Specificity: 0.9997 - F1: 0.9047 - Loss: 0.1115\n",
      "\n",
      "Batch 11/387 ━━━━━━━━━━━━━━━━━━━━ 13:18:23\n",
      "Accuracy: 0.9974 - Precision: 0.9575 - Recall: 0.8694 - Specificity: 0.9996 - F1: 0.9081 - Loss: 0.1076\n",
      "\n",
      "Batch 12/387 ━━━━━━━━━━━━━━━━━━━━ 13:19:58\n",
      "Accuracy: 0.9974 - Precision: 0.9501 - Recall: 0.8794 - Specificity: 0.9994 - F1: 0.9095 - Loss: 0.1059\n",
      "\n",
      "Batch 13/387 ━━━━━━━━━━━━━━━━━━━━ 13:21:37\n",
      "Accuracy: 0.9975 - Precision: 0.9494 - Recall: 0.8781 - Specificity: 0.9994 - F1: 0.9088 - Loss: 0.1062\n",
      "\n",
      "Batch 14/387 ━━━━━━━━━━━━━━━━━━━━ 13:23:13\n",
      "Accuracy: 0.9975 - Precision: 0.9391 - Recall: 0.8837 - Specificity: 0.9993 - F1: 0.9063 - Loss: 0.1087\n",
      "\n",
      "Batch 15/387 ━━━━━━━━━━━━━━━━━━━━ 13:25:04\n",
      "Accuracy: 0.9975 - Precision: 0.9396 - Recall: 0.8752 - Specificity: 0.9993 - F1: 0.9019 - Loss: 0.1133\n",
      "\n",
      "Batch 16/387 ━━━━━━━━━━━━━━━━━━━━ 13:26:43\n",
      "Accuracy: 0.9975 - Precision: 0.9374 - Recall: 0.8781 - Specificity: 0.9993 - F1: 0.9026 - Loss: 0.1125\n",
      "\n",
      "Batch 17/387 ━━━━━━━━━━━━━━━━━━━━ 13:28:14\n",
      "Accuracy: 0.9976 - Precision: 0.9386 - Recall: 0.8824 - Specificity: 0.9993 - F1: 0.9057 - Loss: 0.1090\n",
      "\n",
      "Batch 18/387 ━━━━━━━━━━━━━━━━━━━━ 13:29:48\n",
      "Accuracy: 0.9977 - Precision: 0.9255 - Recall: 0.8883 - Specificity: 0.9993 - F1: 0.9010 - Loss: 0.1134\n",
      "\n",
      "Batch 19/387 ━━━━━━━━━━━━━━━━━━━━ 13:31:21\n",
      "Accuracy: 0.9978 - Precision: 0.9258 - Recall: 0.8932 - Specificity: 0.9993 - F1: 0.9039 - Loss: 0.1102\n",
      "\n",
      "Batch 20/387 ━━━━━━━━━━━━━━━━━━━━ 13:32:54\n",
      "Accuracy: 0.9977 - Precision: 0.9141 - Recall: 0.8815 - Specificity: 0.9992 - F1: 0.8924 - Loss: 0.1223\n",
      "\n",
      "Batch 21/387 ━━━━━━━━━━━━━━━━━━━━ 13:34:19\n",
      "Accuracy: 0.9977 - Precision: 0.9004 - Recall: 0.8866 - Specificity: 0.9992 - F1: 0.8864 - Loss: 0.1282\n",
      "\n",
      "Batch 22/387 ━━━━━━━━━━━━━━━━━━━━ 13:35:53\n",
      "Accuracy: 0.9977 - Precision: 0.8950 - Recall: 0.8910 - Specificity: 0.9991 - F1: 0.8857 - Loss: 0.1287\n",
      "\n",
      "Batch 23/387 ━━━━━━━━━━━━━━━━━━━━ 13:37:18\n",
      "Accuracy: 0.9977 - Precision: 0.8975 - Recall: 0.8910 - Specificity: 0.9991 - F1: 0.8872 - Loss: 0.1274\n",
      "\n",
      "Batch 24/387 ━━━━━━━━━━━━━━━━━━━━ 13:38:40\n",
      "Accuracy: 0.9976 - Precision: 0.9014 - Recall: 0.8840 - Specificity: 0.9992 - F1: 0.8851 - Loss: 0.1302\n",
      "\n",
      "Batch 25/387 ━━━━━━━━━━━━━━━━━━━━ 13:40:16\n",
      "Accuracy: 0.9976 - Precision: 0.9042 - Recall: 0.8863 - Specificity: 0.9992 - F1: 0.8880 - Loss: 0.1270\n",
      "\n",
      "Batch 26/387 ━━━━━━━━━━━━━━━━━━━━ 13:41:38\n",
      "Accuracy: 0.9976 - Precision: 0.9055 - Recall: 0.8828 - Specificity: 0.9992 - F1: 0.8870 - Loss: 0.1278\n",
      "\n",
      "Batch 27/387 ━━━━━━━━━━━━━━━━━━━━ 13:42:57\n",
      "Accuracy: 0.9977 - Precision: 0.9075 - Recall: 0.8799 - Specificity: 0.9992 - F1: 0.8865 - Loss: 0.1279\n",
      "\n",
      "Batch 28/387 ━━━━━━━━━━━━━━━━━━━━ 13:44:24\n",
      "Accuracy: 0.9977 - Precision: 0.9107 - Recall: 0.8792 - Specificity: 0.9993 - F1: 0.8879 - Loss: 0.1264\n",
      "\n",
      "Batch 29/387 ━━━━━━━━━━━━━━━━━━━━ 13:45:52\n",
      "Accuracy: 0.9978 - Precision: 0.9083 - Recall: 0.8829 - Specificity: 0.9992 - F1: 0.8885 - Loss: 0.1256\n",
      "\n",
      "Batch 30/387 ━━━━━━━━━━━━━━━━━━━━ 13:47:12\n",
      "Accuracy: 0.9978 - Precision: 0.9108 - Recall: 0.8838 - Specificity: 0.9993 - F1: 0.8904 - Loss: 0.1235\n",
      "\n",
      "Batch 31/387 ━━━━━━━━━━━━━━━━━━━━ 13:48:57\n",
      "Accuracy: 0.9978 - Precision: 0.9119 - Recall: 0.8811 - Specificity: 0.9993 - F1: 0.8897 - Loss: 0.1243\n",
      "\n",
      "Batch 32/387 ━━━━━━━━━━━━━━━━━━━━ 13:50:21\n",
      "Accuracy: 0.9978 - Precision: 0.9144 - Recall: 0.8818 - Specificity: 0.9993 - F1: 0.8914 - Loss: 0.1225\n",
      "\n",
      "Batch 33/387 ━━━━━━━━━━━━━━━━━━━━ 13:51:57\n",
      "Accuracy: 0.9978 - Precision: 0.9165 - Recall: 0.8800 - Specificity: 0.9993 - F1: 0.8915 - Loss: 0.1224\n",
      "\n",
      "Batch 34/387 ━━━━━━━━━━━━━━━━━━━━ 13:53:37\n",
      "Accuracy: 0.9977 - Precision: 0.9175 - Recall: 0.8751 - Specificity: 0.9993 - F1: 0.8893 - Loss: 0.1251\n",
      "\n",
      "Batch 35/387 ━━━━━━━━━━━━━━━━━━━━ 13:55:18\n",
      "Accuracy: 0.9977 - Precision: 0.9178 - Recall: 0.8780 - Specificity: 0.9993 - F1: 0.8910 - Loss: 0.1231\n",
      "\n",
      "Batch 36/387 ━━━━━━━━━━━━━━━━━━━━ 13:56:52\n",
      "Accuracy: 0.9977 - Precision: 0.9187 - Recall: 0.8789 - Specificity: 0.9993 - F1: 0.8921 - Loss: 0.1219\n",
      "\n",
      "Batch 37/387 ━━━━━━━━━━━━━━━━━━━━ 13:58:19\n",
      "Accuracy: 0.9977 - Precision: 0.9153 - Recall: 0.8810 - Specificity: 0.9992 - F1: 0.8914 - Loss: 0.1228\n",
      "\n",
      "Batch 38/387 ━━━━━━━━━━━━━━━━━━━━ 13:59:53\n",
      "Accuracy: 0.9977 - Precision: 0.9138 - Recall: 0.8803 - Specificity: 0.9992 - F1: 0.8905 - Loss: 0.1235\n",
      "\n",
      "Batch 39/387 ━━━━━━━━━━━━━━━━━━━━ 14:01:20\n",
      "Accuracy: 0.9978 - Precision: 0.9150 - Recall: 0.8823 - Specificity: 0.9992 - F1: 0.8923 - Loss: 0.1216\n",
      "\n",
      "Batch 40/387 ━━━━━━━━━━━━━━━━━━━━ 14:02:47\n",
      "Accuracy: 0.9978 - Precision: 0.9152 - Recall: 0.8840 - Specificity: 0.9992 - F1: 0.8934 - Loss: 0.1204\n",
      "\n",
      "Batch 41/387 ━━━━━━━━━━━━━━━━━━━━ 14:04:15\n",
      "Accuracy: 0.9978 - Precision: 0.9098 - Recall: 0.8863 - Specificity: 0.9992 - F1: 0.8914 - Loss: 0.1223\n",
      "\n",
      "Batch 42/387 ━━━━━━━━━━━━━━━━━━━━ 14:05:52\n",
      "Accuracy: 0.9978 - Precision: 0.9102 - Recall: 0.8874 - Specificity: 0.9992 - F1: 0.8923 - Loss: 0.1213\n",
      "\n",
      "Batch 43/387 ━━━━━━━━━━━━━━━━━━━━ 14:07:41\n",
      "Accuracy: 0.9978 - Precision: 0.9102 - Recall: 0.8846 - Specificity: 0.9993 - F1: 0.8909 - Loss: 0.1226\n",
      "\n",
      "Batch 44/387 ━━━━━━━━━━━━━━━━━━━━ 14:09:11\n",
      "Accuracy: 0.9978 - Precision: 0.9106 - Recall: 0.8847 - Specificity: 0.9992 - F1: 0.8913 - Loss: 0.1223\n",
      "\n",
      "Batch 45/387 ━━━━━━━━━━━━━━━━━━━━ 14:10:49\n",
      "Accuracy: 0.9977 - Precision: 0.9057 - Recall: 0.8844 - Specificity: 0.9992 - F1: 0.8886 - Loss: 0.1255\n",
      "\n",
      "Batch 46/387 ━━━━━━━━━━━━━━━━━━━━ 14:12:27\n",
      "Accuracy: 0.9978 - Precision: 0.9055 - Recall: 0.8865 - Specificity: 0.9992 - F1: 0.8896 - Loss: 0.1243\n",
      "\n",
      "Batch 47/387 ━━━━━━━━━━━━━━━━━━━━ 14:13:56\n",
      "Accuracy: 0.9978 - Precision: 0.9060 - Recall: 0.8860 - Specificity: 0.9992 - F1: 0.8897 - Loss: 0.1240\n",
      "\n",
      "Batch 48/387 ━━━━━━━━━━━━━━━━━━━━ 14:15:39\n",
      "Accuracy: 0.9977 - Precision: 0.9070 - Recall: 0.8834 - Specificity: 0.9992 - F1: 0.8889 - Loss: 0.1252\n",
      "\n",
      "Batch 49/387 ━━━━━━━━━━━━━━━━━━━━ 14:16:58\n",
      "Accuracy: 0.9978 - Precision: 0.9081 - Recall: 0.8832 - Specificity: 0.9992 - F1: 0.8894 - Loss: 0.1245\n",
      "\n",
      "Batch 50/387 ━━━━━━━━━━━━━━━━━━━━ 14:18:23\n",
      "Accuracy: 0.9978 - Precision: 0.9058 - Recall: 0.8827 - Specificity: 0.9992 - F1: 0.8881 - Loss: 0.1257\n",
      "\n",
      "Batch 51/387 ━━━━━━━━━━━━━━━━━━━━ 14:19:53\n",
      "Accuracy: 0.9978 - Precision: 0.9065 - Recall: 0.8799 - Specificity: 0.9992 - F1: 0.8869 - Loss: 0.1270\n",
      "\n",
      "Batch 52/387 ━━━━━━━━━━━━━━━━━━━━ 14:21:37\n",
      "Accuracy: 0.9978 - Precision: 0.9079 - Recall: 0.8769 - Specificity: 0.9992 - F1: 0.8859 - Loss: 0.1281\n",
      "\n",
      "Batch 53/387 ━━━━━━━━━━━━━━━━━━━━ 14:23:01\n",
      "Accuracy: 0.9978 - Precision: 0.9063 - Recall: 0.8778 - Specificity: 0.9992 - F1: 0.8856 - Loss: 0.1284\n",
      "\n",
      "Batch 54/387 ━━━━━━━━━━━━━━━━━━━━ 14:24:35\n",
      "Accuracy: 0.9978 - Precision: 0.9029 - Recall: 0.8780 - Specificity: 0.9992 - F1: 0.8840 - Loss: 0.1300\n",
      "\n",
      "Batch 55/387 ━━━━━━━━━━━━━━━━━━━━ 14:26:09\n",
      "Accuracy: 0.9978 - Precision: 0.9036 - Recall: 0.8794 - Specificity: 0.9992 - F1: 0.8851 - Loss: 0.1286\n",
      "\n",
      "Batch 56/387 ━━━━━━━━━━━━━━━━━━━━ 14:27:51\n",
      "Accuracy: 0.9978 - Precision: 0.9047 - Recall: 0.8780 - Specificity: 0.9992 - F1: 0.8850 - Loss: 0.1287\n",
      "\n",
      "Batch 57/387 ━━━━━━━━━━━━━━━━━━━━ 14:29:21\n",
      "Accuracy: 0.9978 - Precision: 0.9053 - Recall: 0.8797 - Specificity: 0.9992 - F1: 0.8862 - Loss: 0.1274\n",
      "\n",
      "Batch 58/387 ━━━━━━━━━━━━━━━━━━━━ 14:30:50\n",
      "Accuracy: 0.9978 - Precision: 0.8993 - Recall: 0.8793 - Specificity: 0.9992 - F1: 0.8826 - Loss: 0.1310\n",
      "\n",
      "Batch 59/387 ━━━━━━━━━━━━━━━━━━━━ 14:32:09\n",
      "Accuracy: 0.9978 - Precision: 0.8994 - Recall: 0.8783 - Specificity: 0.9992 - F1: 0.8822 - Loss: 0.1314\n",
      "\n",
      "Batch 60/387 ━━━━━━━━━━━━━━━━━━━━ 14:33:55\n",
      "Accuracy: 0.9979 - Precision: 0.9005 - Recall: 0.8792 - Specificity: 0.9992 - F1: 0.8833 - Loss: 0.1302\n",
      "\n",
      "Batch 61/387 ━━━━━━━━━━━━━━━━━━━━ 14:35:32\n",
      "Accuracy: 0.9979 - Precision: 0.8981 - Recall: 0.8798 - Specificity: 0.9992 - F1: 0.8824 - Loss: 0.1310\n",
      "\n",
      "Batch 62/387 ━━━━━━━━━━━━━━━━━━━━ 14:37:13\n",
      "Accuracy: 0.9979 - Precision: 0.8988 - Recall: 0.8797 - Specificity: 0.9992 - F1: 0.8828 - Loss: 0.1306\n",
      "\n",
      "Batch 63/387 ━━━━━━━━━━━━━━━━━━━━ 14:38:42\n",
      "Accuracy: 0.9979 - Precision: 0.9004 - Recall: 0.8779 - Specificity: 0.9992 - F1: 0.8826 - Loss: 0.1311\n",
      "\n",
      "Batch 64/387 ━━━━━━━━━━━━━━━━━━━━ 14:40:21\n",
      "Accuracy: 0.9979 - Precision: 0.9010 - Recall: 0.8793 - Specificity: 0.9992 - F1: 0.8837 - Loss: 0.1299\n",
      "\n",
      "Batch 65/387 ━━━━━━━━━━━━━━━━━━━━ 14:41:45\n",
      "Accuracy: 0.9979 - Precision: 0.9010 - Recall: 0.8797 - Specificity: 0.9992 - F1: 0.8839 - Loss: 0.1295\n",
      "\n",
      "Batch 66/387 ━━━━━━━━━━━━━━━━━━━━ 14:43:18\n",
      "Accuracy: 0.9979 - Precision: 0.9019 - Recall: 0.8799 - Specificity: 0.9992 - F1: 0.8846 - Loss: 0.1290\n",
      "\n",
      "Batch 67/387 ━━━━━━━━━━━━━━━━━━━━ 14:44:47\n",
      "Accuracy: 0.9979 - Precision: 0.9022 - Recall: 0.8776 - Specificity: 0.9992 - F1: 0.8835 - Loss: 0.1300\n",
      "\n",
      "Batch 68/387 ━━━━━━━━━━━━━━━━━━━━ 14:46:13\n",
      "Accuracy: 0.9979 - Precision: 0.9027 - Recall: 0.8783 - Specificity: 0.9992 - F1: 0.8842 - Loss: 0.1292\n",
      "\n",
      "Batch 69/387 ━━━━━━━━━━━━━━━━━━━━ 14:47:34\n",
      "Accuracy: 0.9979 - Precision: 0.9011 - Recall: 0.8797 - Specificity: 0.9992 - F1: 0.8840 - Loss: 0.1294\n",
      "\n",
      "Batch 70/387 ━━━━━━━━━━━━━━━━━━━━ 14:49:13\n",
      "Accuracy: 0.9979 - Precision: 0.9007 - Recall: 0.8809 - Specificity: 0.9992 - F1: 0.8845 - Loss: 0.1288\n",
      "\n",
      "Batch 71/387 ━━━━━━━━━━━━━━━━━━━━ 14:50:48\n",
      "Accuracy: 0.9979 - Precision: 0.9009 - Recall: 0.8816 - Specificity: 0.9992 - F1: 0.8851 - Loss: 0.1282\n",
      "\n",
      "Batch 72/387 ━━━━━━━━━━━━━━━━━━━━ 14:52:30\n",
      "Accuracy: 0.9979 - Precision: 0.9011 - Recall: 0.8803 - Specificity: 0.9992 - F1: 0.8845 - Loss: 0.1288\n",
      "\n",
      "Batch 73/387 ━━━━━━━━━━━━━━━━━━━━ 14:54:11\n",
      "Accuracy: 0.9979 - Precision: 0.9016 - Recall: 0.8798 - Specificity: 0.9992 - F1: 0.8845 - Loss: 0.1288\n",
      "\n",
      "Batch 74/387 ━━━━━━━━━━━━━━━━━━━━ 14:55:47\n",
      "Accuracy: 0.9979 - Precision: 0.9021 - Recall: 0.8786 - Specificity: 0.9992 - F1: 0.8842 - Loss: 0.1291\n",
      "\n",
      "Batch 75/387 ━━━━━━━━━━━━━━━━━━━━ 14:57:22\n",
      "Accuracy: 0.9979 - Precision: 0.9019 - Recall: 0.8801 - Specificity: 0.9992 - F1: 0.8849 - Loss: 0.1283\n",
      "\n",
      "Batch 76/387 ━━━━━━━━━━━━━━━━━━━━ 14:58:55\n",
      "Accuracy: 0.9979 - Precision: 0.9007 - Recall: 0.8815 - Specificity: 0.9992 - F1: 0.8850 - Loss: 0.1282\n",
      "\n",
      "Batch 77/387 ━━━━━━━━━━━━━━━━━━━━ 15:00:29\n",
      "Accuracy: 0.9979 - Precision: 0.8994 - Recall: 0.8823 - Specificity: 0.9992 - F1: 0.8847 - Loss: 0.1284\n",
      "\n",
      "Batch 78/387 ━━━━━━━━━━━━━━━━━━━━ 15:02:00\n",
      "Accuracy: 0.9979 - Precision: 0.8988 - Recall: 0.8828 - Specificity: 0.9992 - F1: 0.8847 - Loss: 0.1284\n",
      "\n",
      "Batch 79/387 ━━━━━━━━━━━━━━━━━━━━ 15:03:30\n",
      "Accuracy: 0.9979 - Precision: 0.8988 - Recall: 0.8836 - Specificity: 0.9992 - F1: 0.8852 - Loss: 0.1279\n",
      "\n",
      "Batch 80/387 ━━━━━━━━━━━━━━━━━━━━ 15:05:05\n",
      "Accuracy: 0.9980 - Precision: 0.8992 - Recall: 0.8833 - Specificity: 0.9992 - F1: 0.8853 - Loss: 0.1277\n",
      "\n",
      "Batch 81/387 ━━━━━━━━━━━━━━━━━━━━ 15:06:28\n",
      "Accuracy: 0.9979 - Precision: 0.8999 - Recall: 0.8833 - Specificity: 0.9992 - F1: 0.8857 - Loss: 0.1275\n",
      "\n",
      "Batch 82/387 ━━━━━━━━━━━━━━━━━━━━ 15:07:53\n",
      "Accuracy: 0.9979 - Precision: 0.9010 - Recall: 0.8811 - Specificity: 0.9992 - F1: 0.8849 - Loss: 0.1283\n",
      "\n",
      "Batch 83/387 ━━━━━━━━━━━━━━━━━━━━ 15:09:40\n",
      "Accuracy: 0.9979 - Precision: 0.9015 - Recall: 0.8817 - Specificity: 0.9992 - F1: 0.8856 - Loss: 0.1276\n",
      "\n",
      "Batch 84/387 ━━━━━━━━━━━━━━━━━━━━ 15:11:18\n",
      "Accuracy: 0.9979 - Precision: 0.9006 - Recall: 0.8819 - Specificity: 0.9992 - F1: 0.8853 - Loss: 0.1279\n",
      "\n",
      "Batch 85/387 ━━━━━━━━━━━━━━━━━━━━ 15:12:49\n",
      "Accuracy: 0.9979 - Precision: 0.9010 - Recall: 0.8825 - Specificity: 0.9992 - F1: 0.8858 - Loss: 0.1273\n",
      "\n",
      "Batch 86/387 ━━━━━━━━━━━━━━━━━━━━ 15:14:09\n",
      "Accuracy: 0.9979 - Precision: 0.8979 - Recall: 0.8817 - Specificity: 0.9992 - F1: 0.8839 - Loss: 0.1293\n",
      "\n",
      "Batch 87/387 ━━━━━━━━━━━━━━━━━━━━ 15:15:49\n",
      "Accuracy: 0.9979 - Precision: 0.8966 - Recall: 0.8824 - Specificity: 0.9992 - F1: 0.8835 - Loss: 0.1298\n",
      "\n",
      "Batch 88/387 ━━━━━━━━━━━━━━━━━━━━ 15:17:36\n",
      "Accuracy: 0.9979 - Precision: 0.8973 - Recall: 0.8822 - Specificity: 0.9992 - F1: 0.8838 - Loss: 0.1295\n",
      "\n",
      "Batch 89/387 ━━━━━━━━━━━━━━━━━━━━ 15:19:09\n",
      "Accuracy: 0.9979 - Precision: 0.8967 - Recall: 0.8822 - Specificity: 0.9992 - F1: 0.8836 - Loss: 0.1297\n",
      "\n",
      "Batch 90/387 ━━━━━━━━━━━━━━━━━━━━ 15:20:36\n",
      "Accuracy: 0.9979 - Precision: 0.8976 - Recall: 0.8783 - Specificity: 0.9992 - F1: 0.8814 - Loss: 0.1321\n",
      "\n",
      "Batch 91/387 ━━━━━━━━━━━━━━━━━━━━ 15:22:09\n",
      "Accuracy: 0.9979 - Precision: 0.8985 - Recall: 0.8785 - Specificity: 0.9992 - F1: 0.8820 - Loss: 0.1315\n",
      "\n",
      "Batch 92/387 ━━━━━━━━━━━━━━━━━━━━ 15:23:39\n",
      "Accuracy: 0.9979 - Precision: 0.8993 - Recall: 0.8784 - Specificity: 0.9992 - F1: 0.8824 - Loss: 0.1310\n",
      "\n",
      "Batch 93/387 ━━━━━━━━━━━━━━━━━━━━ 15:25:10\n",
      "Accuracy: 0.9979 - Precision: 0.9003 - Recall: 0.8790 - Specificity: 0.9992 - F1: 0.8832 - Loss: 0.1301\n",
      "\n",
      "Batch 94/387 ━━━━━━━━━━━━━━━━━━━━ 15:26:47\n",
      "Accuracy: 0.9979 - Precision: 0.9008 - Recall: 0.8796 - Specificity: 0.9992 - F1: 0.8838 - Loss: 0.1295\n",
      "\n",
      "Batch 95/387 ━━━━━━━━━━━━━━━━━━━━ 15:28:24\n",
      "Accuracy: 0.9979 - Precision: 0.9003 - Recall: 0.8799 - Specificity: 0.9992 - F1: 0.8838 - Loss: 0.1295\n",
      "\n",
      "Batch 96/387 ━━━━━━━━━━━━━━━━━━━━ 15:30:03\n",
      "Accuracy: 0.9979 - Precision: 0.9009 - Recall: 0.8802 - Specificity: 0.9992 - F1: 0.8843 - Loss: 0.1290\n",
      "\n",
      "Batch 97/387 ━━━━━━━━━━━━━━━━━━━━ 15:31:27\n",
      "Accuracy: 0.9979 - Precision: 0.9015 - Recall: 0.8794 - Specificity: 0.9992 - F1: 0.8842 - Loss: 0.1290\n",
      "\n",
      "Batch 98/387 ━━━━━━━━━━━━━━━━━━━━ 15:33:04\n",
      "Accuracy: 0.9979 - Precision: 0.9016 - Recall: 0.8790 - Specificity: 0.9992 - F1: 0.8841 - Loss: 0.1291\n",
      "\n",
      "Batch 99/387 ━━━━━━━━━━━━━━━━━━━━ 15:35:08\n",
      "Accuracy: 0.9979 - Precision: 0.8999 - Recall: 0.8778 - Specificity: 0.9992 - F1: 0.8827 - Loss: 0.1305\n",
      "\n",
      "Batch 100/387 ━━━━━━━━━━━━━━━━━━━━ 15:36:54\n",
      "Accuracy: 0.9979 - Precision: 0.8999 - Recall: 0.8787 - Specificity: 0.9992 - F1: 0.8833 - Loss: 0.1299\n",
      "\n",
      "Batch 101/387 ━━━━━━━━━━━━━━━━━━━━ 15:38:26\n",
      "Accuracy: 0.9979 - Precision: 0.8983 - Recall: 0.8798 - Specificity: 0.9992 - F1: 0.8828 - Loss: 0.1303\n",
      "\n",
      "Batch 102/387 ━━━━━━━━━━━━━━━━━━━━ 15:40:15\n",
      "Accuracy: 0.9979 - Precision: 0.8984 - Recall: 0.8804 - Specificity: 0.9992 - F1: 0.8833 - Loss: 0.1298\n",
      "\n",
      "Batch 103/387 ━━━━━━━━━━━━━━━━━━━━ 15:41:54\n",
      "Accuracy: 0.9979 - Precision: 0.8969 - Recall: 0.8814 - Specificity: 0.9992 - F1: 0.8829 - Loss: 0.1302\n",
      "\n",
      "Batch 104/387 ━━━━━━━━━━━━━━━━━━━━ 15:43:26\n",
      "Accuracy: 0.9979 - Precision: 0.8973 - Recall: 0.8813 - Specificity: 0.9992 - F1: 0.8831 - Loss: 0.1300\n",
      "\n",
      "Batch 105/387 ━━━━━━━━━━━━━━━━━━━━ 15:45:00\n",
      "Accuracy: 0.9979 - Precision: 0.8977 - Recall: 0.8821 - Specificity: 0.9992 - F1: 0.8838 - Loss: 0.1293\n",
      "\n",
      "Batch 106/387 ━━━━━━━━━━━━━━━━━━━━ 15:46:30\n",
      "Accuracy: 0.9979 - Precision: 0.8983 - Recall: 0.8819 - Specificity: 0.9992 - F1: 0.8840 - Loss: 0.1290\n",
      "\n",
      "Batch 107/387 ━━━━━━━━━━━━━━━━━━━━ 15:48:06\n",
      "Accuracy: 0.9979 - Precision: 0.8961 - Recall: 0.8825 - Specificity: 0.9991 - F1: 0.8830 - Loss: 0.1300\n",
      "\n",
      "Batch 108/387 ━━━━━━━━━━━━━━━━━━━━ 15:49:25\n",
      "Accuracy: 0.9979 - Precision: 0.8967 - Recall: 0.8825 - Specificity: 0.9992 - F1: 0.8834 - Loss: 0.1296\n",
      "\n",
      "Batch 109/387 ━━━━━━━━━━━━━━━━━━━━ 15:50:46\n",
      "Accuracy: 0.9979 - Precision: 0.8969 - Recall: 0.8819 - Specificity: 0.9991 - F1: 0.8832 - Loss: 0.1299\n",
      "\n",
      "Batch 110/387 ━━━━━━━━━━━━━━━━━━━━ 15:52:12\n",
      "Accuracy: 0.9979 - Precision: 0.8971 - Recall: 0.8828 - Specificity: 0.9991 - F1: 0.8838 - Loss: 0.1292\n",
      "\n",
      "Batch 111/387 ━━━━━━━━━━━━━━━━━━━━ 15:53:50\n",
      "Accuracy: 0.9979 - Precision: 0.8975 - Recall: 0.8826 - Specificity: 0.9991 - F1: 0.8839 - Loss: 0.1290\n",
      "\n",
      "Batch 112/387 ━━━━━━━━━━━━━━━━━━━━ 15:55:15\n",
      "Accuracy: 0.9979 - Precision: 0.8969 - Recall: 0.8836 - Specificity: 0.9991 - F1: 0.8841 - Loss: 0.1289\n",
      "\n",
      "Batch 113/387 ━━━━━━━━━━━━━━━━━━━━ 15:56:49\n",
      "Accuracy: 0.9979 - Precision: 0.8968 - Recall: 0.8843 - Specificity: 0.9991 - F1: 0.8845 - Loss: 0.1285\n",
      "\n",
      "Batch 114/387 ━━━━━━━━━━━━━━━━━━━━ 15:58:23\n",
      "Accuracy: 0.9979 - Precision: 0.8970 - Recall: 0.8850 - Specificity: 0.9991 - F1: 0.8849 - Loss: 0.1280\n",
      "\n",
      "Batch 115/387 ━━━━━━━━━━━━━━━━━━━━ 15:59:55\n",
      "Accuracy: 0.9979 - Precision: 0.8974 - Recall: 0.8845 - Specificity: 0.9991 - F1: 0.8849 - Loss: 0.1281\n",
      "\n",
      "Batch 116/387 ━━━━━━━━━━━━━━━━━━━━ 16:01:38\n",
      "Accuracy: 0.9979 - Precision: 0.8973 - Recall: 0.8853 - Specificity: 0.9991 - F1: 0.8853 - Loss: 0.1277\n",
      "\n",
      "Batch 117/387 ━━━━━━━━━━━━━━━━━━━━ 16:03:11\n",
      "Accuracy: 0.9979 - Precision: 0.8962 - Recall: 0.8838 - Specificity: 0.9991 - F1: 0.8841 - Loss: 0.1289\n",
      "\n",
      "Batch 118/387 ━━━━━━━━━━━━━━━━━━━━ 16:04:32\n",
      "Accuracy: 0.9979 - Precision: 0.8967 - Recall: 0.8837 - Specificity: 0.9991 - F1: 0.8843 - Loss: 0.1287\n",
      "\n",
      "Batch 119/387 ━━━━━━━━━━━━━━━━━━━━ 16:06:02\n",
      "Accuracy: 0.9979 - Precision: 0.8974 - Recall: 0.8842 - Specificity: 0.9991 - F1: 0.8849 - Loss: 0.1280\n",
      "\n",
      "Batch 120/387 ━━━━━━━━━━━━━━━━━━━━ 16:07:29\n",
      "Accuracy: 0.9979 - Precision: 0.8980 - Recall: 0.8835 - Specificity: 0.9991 - F1: 0.8849 - Loss: 0.1282\n",
      "\n",
      "Batch 121/387 ━━━━━━━━━━━━━━━━━━━━ 16:09:01\n",
      "Accuracy: 0.9979 - Precision: 0.8974 - Recall: 0.8843 - Specificity: 0.9991 - F1: 0.8850 - Loss: 0.1281\n",
      "\n",
      "Batch 122/387 ━━━━━━━━━━━━━━━━━━━━ 16:10:30\n",
      "Accuracy: 0.9979 - Precision: 0.8970 - Recall: 0.8846 - Specificity: 0.9991 - F1: 0.8849 - Loss: 0.1281\n",
      "\n",
      "Batch 123/387 ━━━━━━━━━━━━━━━━━━━━ 16:12:11\n",
      "Accuracy: 0.9979 - Precision: 0.8967 - Recall: 0.8850 - Specificity: 0.9991 - F1: 0.8850 - Loss: 0.1279\n",
      "\n",
      "Batch 124/387 ━━━━━━━━━━━━━━━━━━━━ 16:13:54\n",
      "Accuracy: 0.9979 - Precision: 0.8970 - Recall: 0.8855 - Specificity: 0.9991 - F1: 0.8854 - Loss: 0.1275\n",
      "\n",
      "Batch 125/387 ━━━━━━━━━━━━━━━━━━━━ 16:15:22\n",
      "Accuracy: 0.9979 - Precision: 0.8964 - Recall: 0.8858 - Specificity: 0.9991 - F1: 0.8853 - Loss: 0.1276\n",
      "\n",
      "Batch 126/387 ━━━━━━━━━━━━━━━━━━━━ 16:16:45\n",
      "Accuracy: 0.9979 - Precision: 0.8965 - Recall: 0.8840 - Specificity: 0.9991 - F1: 0.8844 - Loss: 0.1286\n",
      "\n",
      "Batch 127/387 ━━━━━━━━━━━━━━━━━━━━ 16:18:31\n",
      "Accuracy: 0.9979 - Precision: 0.8959 - Recall: 0.8820 - Specificity: 0.9991 - F1: 0.8830 - Loss: 0.1301\n",
      "\n",
      "Batch 128/387 ━━━━━━━━━━━━━━━━━━━━ 16:20:07\n",
      "Accuracy: 0.9979 - Precision: 0.8964 - Recall: 0.8826 - Specificity: 0.9991 - F1: 0.8836 - Loss: 0.1294\n",
      "\n",
      "Batch 129/387 ━━━━━━━━━━━━━━━━━━━━ 16:21:32\n",
      "Accuracy: 0.9979 - Precision: 0.8965 - Recall: 0.8833 - Specificity: 0.9991 - F1: 0.8841 - Loss: 0.1289\n",
      "\n",
      "Batch 130/387 ━━━━━━━━━━━━━━━━━━━━ 16:23:07\n",
      "Accuracy: 0.9979 - Precision: 0.8968 - Recall: 0.8820 - Specificity: 0.9991 - F1: 0.8835 - Loss: 0.1295\n",
      "\n",
      "Batch 131/387 ━━━━━━━━━━━━━━━━━━━━ 16:24:41\n",
      "Accuracy: 0.9979 - Precision: 0.8971 - Recall: 0.8816 - Specificity: 0.9991 - F1: 0.8835 - Loss: 0.1296\n",
      "\n",
      "Batch 132/387 ━━━━━━━━━━━━━━━━━━━━ 16:26:23\n",
      "Accuracy: 0.9979 - Precision: 0.8977 - Recall: 0.8811 - Specificity: 0.9991 - F1: 0.8835 - Loss: 0.1296\n",
      "\n",
      "Batch 133/387 ━━━━━━━━━━━━━━━━━━━━ 16:27:51\n",
      "Accuracy: 0.9979 - Precision: 0.8983 - Recall: 0.8815 - Specificity: 0.9991 - F1: 0.8840 - Loss: 0.1290\n",
      "\n",
      "Batch 134/387 ━━━━━━━━━━━━━━━━━━━━ 16:29:22\n",
      "Accuracy: 0.9979 - Precision: 0.8953 - Recall: 0.8820 - Specificity: 0.9991 - F1: 0.8823 - Loss: 0.1307\n",
      "\n",
      "Batch 135/387 ━━━━━━━━━━━━━━━━━━━━ 16:31:02\n",
      "Accuracy: 0.9979 - Precision: 0.8955 - Recall: 0.8825 - Specificity: 0.9991 - F1: 0.8827 - Loss: 0.1303\n",
      "\n",
      "Batch 136/387 ━━━━━━━━━━━━━━━━━━━━ 16:32:39\n",
      "Accuracy: 0.9979 - Precision: 0.8961 - Recall: 0.8826 - Specificity: 0.9991 - F1: 0.8831 - Loss: 0.1300\n",
      "\n",
      "Batch 137/387 ━━━━━━━━━━━━━━━━━━━━ 16:34:19\n",
      "Accuracy: 0.9979 - Precision: 0.8945 - Recall: 0.8827 - Specificity: 0.9991 - F1: 0.8823 - Loss: 0.1308\n",
      "\n",
      "Batch 138/387 ━━━━━━━━━━━━━━━━━━━━ 16:35:34\n",
      "Accuracy: 0.9979 - Precision: 0.8943 - Recall: 0.8828 - Specificity: 0.9991 - F1: 0.8823 - Loss: 0.1309\n",
      "\n",
      "Batch 139/387 ━━━━━━━━━━━━━━━━━━━━ 16:37:03\n",
      "Accuracy: 0.9979 - Precision: 0.8947 - Recall: 0.8833 - Specificity: 0.9991 - F1: 0.8828 - Loss: 0.1304\n",
      "\n",
      "Batch 140/387 ━━━━━━━━━━━━━━━━━━━━ 16:38:26\n",
      "Accuracy: 0.9979 - Precision: 0.8954 - Recall: 0.8835 - Specificity: 0.9991 - F1: 0.8832 - Loss: 0.1299\n",
      "\n",
      "Batch 141/387 ━━━━━━━━━━━━━━━━━━━━ 16:39:51\n",
      "Accuracy: 0.9979 - Precision: 0.8958 - Recall: 0.8837 - Specificity: 0.9991 - F1: 0.8836 - Loss: 0.1295\n",
      "\n",
      "Batch 142/387 ━━━━━━━━━━━━━━━━━━━━ 16:41:27\n",
      "Accuracy: 0.9979 - Precision: 0.8963 - Recall: 0.8821 - Specificity: 0.9991 - F1: 0.8829 - Loss: 0.1303\n",
      "\n",
      "Batch 143/387 ━━━━━━━━━━━━━━━━━━━━ 16:43:00\n",
      "Accuracy: 0.9979 - Precision: 0.8965 - Recall: 0.8818 - Specificity: 0.9991 - F1: 0.8828 - Loss: 0.1303\n",
      "\n",
      "Batch 144/387 ━━━━━━━━━━━━━━━━━━━━ 16:44:33\n",
      "Accuracy: 0.9979 - Precision: 0.8969 - Recall: 0.8821 - Specificity: 0.9991 - F1: 0.8833 - Loss: 0.1298\n",
      "\n",
      "Batch 145/387 ━━━━━━━━━━━━━━━━━━━━ 16:45:49\n",
      "Accuracy: 0.9979 - Precision: 0.8969 - Recall: 0.8827 - Specificity: 0.9991 - F1: 0.8836 - Loss: 0.1295\n",
      "\n",
      "Batch 146/387 ━━━━━━━━━━━━━━━━━━━━ 16:47:20\n",
      "Accuracy: 0.9979 - Precision: 0.8963 - Recall: 0.8835 - Specificity: 0.9991 - F1: 0.8837 - Loss: 0.1294\n",
      "\n",
      "Batch 147/387 ━━━━━━━━━━━━━━━━━━━━ 16:48:39\n",
      "Accuracy: 0.9979 - Precision: 0.8967 - Recall: 0.8840 - Specificity: 0.9991 - F1: 0.8842 - Loss: 0.1289\n",
      "\n",
      "Batch 148/387 ━━━━━━━━━━━━━━━━━━━━ 16:50:08\n",
      "Accuracy: 0.9979 - Precision: 0.8971 - Recall: 0.8835 - Specificity: 0.9991 - F1: 0.8841 - Loss: 0.1290\n",
      "\n",
      "Batch 149/387 ━━━━━━━━━━━━━━━━━━━━ 16:51:29\n",
      "Accuracy: 0.9979 - Precision: 0.8972 - Recall: 0.8843 - Specificity: 0.9991 - F1: 0.8846 - Loss: 0.1285\n",
      "\n",
      "Batch 150/387 ━━━━━━━━━━━━━━━━━━━━ 16:53:05\n",
      "Accuracy: 0.9979 - Precision: 0.8969 - Recall: 0.8843 - Specificity: 0.9991 - F1: 0.8845 - Loss: 0.1286\n",
      "\n",
      "Batch 151/387 ━━━━━━━━━━━━━━━━━━━━ 16:54:38\n",
      "Accuracy: 0.9979 - Precision: 0.8974 - Recall: 0.8848 - Specificity: 0.9991 - F1: 0.8850 - Loss: 0.1280\n",
      "\n",
      "Batch 152/387 ━━━━━━━━━━━━━━━━━━━━ 16:56:43\n",
      "Accuracy: 0.9979 - Precision: 0.8974 - Recall: 0.8851 - Specificity: 0.9991 - F1: 0.8852 - Loss: 0.1278\n",
      "\n",
      "Batch 153/387 ━━━━━━━━━━━━━━━━━━━━ 16:58:09\n",
      "Accuracy: 0.9979 - Precision: 0.8962 - Recall: 0.8851 - Specificity: 0.9991 - F1: 0.8846 - Loss: 0.1284\n",
      "\n",
      "Batch 154/387 ━━━━━━━━━━━━━━━━━━━━ 16:59:53\n",
      "Accuracy: 0.9979 - Precision: 0.8966 - Recall: 0.8857 - Specificity: 0.9991 - F1: 0.8851 - Loss: 0.1279\n",
      "\n",
      "Batch 155/387 ━━━━━━━━━━━━━━━━━━━━ 17:01:30\n",
      "Accuracy: 0.9979 - Precision: 0.8968 - Recall: 0.8862 - Specificity: 0.9991 - F1: 0.8855 - Loss: 0.1274\n",
      "\n",
      "Batch 156/387 ━━━━━━━━━━━━━━━━━━━━ 17:03:06\n",
      "Accuracy: 0.9979 - Precision: 0.8958 - Recall: 0.8849 - Specificity: 0.9991 - F1: 0.8844 - Loss: 0.1286\n",
      "\n",
      "Batch 157/387 ━━━━━━━━━━━━━━━━━━━━ 17:04:38\n",
      "Accuracy: 0.9979 - Precision: 0.8959 - Recall: 0.8854 - Specificity: 0.9991 - F1: 0.8847 - Loss: 0.1283\n",
      "\n",
      "Batch 158/387 ━━━━━━━━━━━━━━━━━━━━ 17:06:01\n",
      "Accuracy: 0.9979 - Precision: 0.8963 - Recall: 0.8859 - Specificity: 0.9991 - F1: 0.8852 - Loss: 0.1278\n",
      "\n",
      "Batch 159/387 ━━━━━━━━━━━━━━━━━━━━ 17:07:39\n",
      "Accuracy: 0.9979 - Precision: 0.8963 - Recall: 0.8858 - Specificity: 0.9991 - F1: 0.8852 - Loss: 0.1278\n",
      "\n",
      "Batch 160/387 ━━━━━━━━━━━━━━━━━━━━ 17:09:20\n",
      "Accuracy: 0.9979 - Precision: 0.8968 - Recall: 0.8848 - Specificity: 0.9991 - F1: 0.8849 - Loss: 0.1281\n",
      "\n",
      "Batch 161/387 ━━━━━━━━━━━━━━━━━━━━ 17:10:55\n",
      "Accuracy: 0.9979 - Precision: 0.8971 - Recall: 0.8851 - Specificity: 0.9991 - F1: 0.8852 - Loss: 0.1277\n",
      "\n",
      "Batch 162/387 ━━━━━━━━━━━━━━━━━━━━ 17:12:36\n",
      "Accuracy: 0.9979 - Precision: 0.8967 - Recall: 0.8857 - Specificity: 0.9991 - F1: 0.8853 - Loss: 0.1276\n",
      "\n",
      "Batch 163/387 ━━━━━━━━━━━━━━━━━━━━ 17:14:10\n",
      "Accuracy: 0.9979 - Precision: 0.8970 - Recall: 0.8843 - Specificity: 0.9991 - F1: 0.8847 - Loss: 0.1283\n",
      "\n",
      "Batch 164/387 ━━━━━━━━━━━━━━━━━━━━ 17:15:40\n",
      "Accuracy: 0.9979 - Precision: 0.8976 - Recall: 0.8843 - Specificity: 0.9991 - F1: 0.8850 - Loss: 0.1281\n",
      "\n",
      "Batch 165/387 ━━━━━━━━━━━━━━━━━━━━ 17:17:21\n",
      "Accuracy: 0.9979 - Precision: 0.8979 - Recall: 0.8841 - Specificity: 0.9991 - F1: 0.8850 - Loss: 0.1281\n",
      "\n",
      "Batch 166/387 ━━━━━━━━━━━━━━━━━━━━ 17:19:00\n",
      "Accuracy: 0.9979 - Precision: 0.8984 - Recall: 0.8842 - Specificity: 0.9991 - F1: 0.8854 - Loss: 0.1277\n",
      "\n",
      "Batch 167/387 ━━━━━━━━━━━━━━━━━━━━ 17:20:33\n",
      "Accuracy: 0.9979 - Precision: 0.8989 - Recall: 0.8845 - Specificity: 0.9991 - F1: 0.8858 - Loss: 0.1272\n",
      "\n",
      "Batch 168/387 ━━━━━━━━━━━━━━━━━━━━ 17:22:07\n",
      "Accuracy: 0.9979 - Precision: 0.8990 - Recall: 0.8847 - Specificity: 0.9991 - F1: 0.8860 - Loss: 0.1271\n",
      "\n",
      "Batch 169/387 ━━━━━━━━━━━━━━━━━━━━ 17:23:39\n",
      "Accuracy: 0.9979 - Precision: 0.8978 - Recall: 0.8833 - Specificity: 0.9991 - F1: 0.8847 - Loss: 0.1287\n",
      "\n",
      "Batch 170/387 ━━━━━━━━━━━━━━━━━━━━ 17:25:15\n",
      "Accuracy: 0.9979 - Precision: 0.8981 - Recall: 0.8831 - Specificity: 0.9991 - F1: 0.8848 - Loss: 0.1286\n",
      "\n",
      "Batch 171/387 ━━━━━━━━━━━━━━━━━━━━ 17:26:45\n",
      "Accuracy: 0.9979 - Precision: 0.8977 - Recall: 0.8836 - Specificity: 0.9991 - F1: 0.8848 - Loss: 0.1286\n",
      "\n",
      "Batch 172/387 ━━━━━━━━━━━━━━━━━━━━ 17:28:04\n",
      "Accuracy: 0.9979 - Precision: 0.8978 - Recall: 0.8839 - Specificity: 0.9991 - F1: 0.8851 - Loss: 0.1283\n",
      "\n",
      "Batch 173/387 ━━━━━━━━━━━━━━━━━━━━ 17:29:40\n",
      "Accuracy: 0.9979 - Precision: 0.8981 - Recall: 0.8845 - Specificity: 0.9991 - F1: 0.8855 - Loss: 0.1278\n",
      "\n",
      "Batch 174/387 ━━━━━━━━━━━━━━━━━━━━ 17:31:11\n",
      "Accuracy: 0.9979 - Precision: 0.8983 - Recall: 0.8844 - Specificity: 0.9991 - F1: 0.8856 - Loss: 0.1277\n",
      "\n",
      "Batch 175/387 ━━━━━━━━━━━━━━━━━━━━ 17:32:36\n",
      "Accuracy: 0.9979 - Precision: 0.8985 - Recall: 0.8850 - Specificity: 0.9991 - F1: 0.8861 - Loss: 0.1272\n",
      "\n",
      "Batch 176/387 ━━━━━━━━━━━━━━━━━━━━ 17:34:08\n",
      "Accuracy: 0.9979 - Precision: 0.8989 - Recall: 0.8855 - Specificity: 0.9991 - F1: 0.8865 - Loss: 0.1267\n",
      "\n",
      "Batch 177/387 ━━━━━━━━━━━━━━━━━━━━ 17:35:40\n",
      "Accuracy: 0.9979 - Precision: 0.8992 - Recall: 0.8859 - Specificity: 0.9991 - F1: 0.8869 - Loss: 0.1263\n",
      "\n",
      "Batch 178/387 ━━━━━━━━━━━━━━━━━━━━ 17:37:10\n",
      "Accuracy: 0.9979 - Precision: 0.8978 - Recall: 0.8864 - Specificity: 0.9991 - F1: 0.8863 - Loss: 0.1269\n",
      "\n",
      "Batch 179/387 ━━━━━━━━━━━━━━━━━━━━ 17:38:42\n",
      "Accuracy: 0.9979 - Precision: 0.8973 - Recall: 0.8868 - Specificity: 0.9991 - F1: 0.8863 - Loss: 0.1270\n",
      "\n",
      "Batch 180/387 ━━━━━━━━━━━━━━━━━━━━ 17:40:09\n",
      "Accuracy: 0.9979 - Precision: 0.8964 - Recall: 0.8867 - Specificity: 0.9991 - F1: 0.8858 - Loss: 0.1275\n",
      "\n",
      "Batch 181/387 ━━━━━━━━━━━━━━━━━━━━ 17:41:39\n",
      "Accuracy: 0.9979 - Precision: 0.8965 - Recall: 0.8864 - Specificity: 0.9991 - F1: 0.8857 - Loss: 0.1276\n",
      "\n",
      "Batch 182/387 ━━━━━━━━━━━━━━━━━━━━ 17:43:00\n",
      "Accuracy: 0.9979 - Precision: 0.8969 - Recall: 0.8866 - Specificity: 0.9991 - F1: 0.8861 - Loss: 0.1272\n",
      "\n",
      "Batch 183/387 ━━━━━━━━━━━━━━━━━━━━ 17:44:27\n",
      "Accuracy: 0.9979 - Precision: 0.8973 - Recall: 0.8869 - Specificity: 0.9991 - F1: 0.8864 - Loss: 0.1268\n",
      "\n",
      "Batch 184/387 ━━━━━━━━━━━━━━━━━━━━ 17:46:02\n",
      "Accuracy: 0.9979 - Precision: 0.8966 - Recall: 0.8874 - Specificity: 0.9991 - F1: 0.8863 - Loss: 0.1269\n",
      "\n",
      "Batch 185/387 ━━━━━━━━━━━━━━━━━━━━ 17:47:21\n",
      "Accuracy: 0.9979 - Precision: 0.8969 - Recall: 0.8874 - Specificity: 0.9991 - F1: 0.8865 - Loss: 0.1267\n",
      "\n",
      "Batch 186/387 ━━━━━━━━━━━━━━━━━━━━ 17:48:48\n",
      "Accuracy: 0.9979 - Precision: 0.8971 - Recall: 0.8877 - Specificity: 0.9991 - F1: 0.8867 - Loss: 0.1264\n",
      "\n",
      "Batch 187/387 ━━━━━━━━━━━━━━━━━━━━ 17:50:17\n",
      "Accuracy: 0.9979 - Precision: 0.8968 - Recall: 0.8881 - Specificity: 0.9991 - F1: 0.8868 - Loss: 0.1263\n",
      "\n",
      "Batch 188/387 ━━━━━━━━━━━━━━━━━━━━ 17:51:47\n",
      "Accuracy: 0.9979 - Precision: 0.8970 - Recall: 0.8885 - Specificity: 0.9991 - F1: 0.8871 - Loss: 0.1260\n",
      "\n",
      "Batch 189/387 ━━━━━━━━━━━━━━━━━━━━ 17:53:18\n",
      "Accuracy: 0.9979 - Precision: 0.8974 - Recall: 0.8882 - Specificity: 0.9991 - F1: 0.8872 - Loss: 0.1259\n",
      "\n",
      "Batch 190/387 ━━━━━━━━━━━━━━━━━━━━ 17:54:52\n",
      "Accuracy: 0.9979 - Precision: 0.8971 - Recall: 0.8884 - Specificity: 0.9991 - F1: 0.8871 - Loss: 0.1259\n",
      "\n",
      "Batch 191/387 ━━━━━━━━━━━━━━━━━━━━ 17:56:26\n",
      "Accuracy: 0.9979 - Precision: 0.8974 - Recall: 0.8882 - Specificity: 0.9991 - F1: 0.8872 - Loss: 0.1259\n",
      "\n",
      "Batch 192/387 ━━━━━━━━━━━━━━━━━━━━ 17:57:59\n",
      "Accuracy: 0.9979 - Precision: 0.8978 - Recall: 0.8883 - Specificity: 0.9991 - F1: 0.8875 - Loss: 0.1257\n",
      "\n",
      "Batch 193/387 ━━━━━━━━━━━━━━━━━━━━ 17:59:30\n",
      "Accuracy: 0.9979 - Precision: 0.8981 - Recall: 0.8887 - Specificity: 0.9991 - F1: 0.8879 - Loss: 0.1252\n",
      "\n",
      "Batch 194/387 ━━━━━━━━━━━━━━━━━━━━ 18:01:11\n",
      "Accuracy: 0.9979 - Precision: 0.8980 - Recall: 0.8889 - Specificity: 0.9991 - F1: 0.8879 - Loss: 0.1251\n",
      "\n",
      "Batch 195/387 ━━━━━━━━━━━━━━━━━━━━ 18:02:31\n",
      "Accuracy: 0.9979 - Precision: 0.8985 - Recall: 0.8887 - Specificity: 0.9991 - F1: 0.8881 - Loss: 0.1250\n",
      "\n",
      "Batch 196/387 ━━━━━━━━━━━━━━━━━━━━ 18:03:56\n",
      "Accuracy: 0.9979 - Precision: 0.8987 - Recall: 0.8888 - Specificity: 0.9991 - F1: 0.8883 - Loss: 0.1248\n",
      "\n",
      "Batch 197/387 ━━━━━━━━━━━━━━━━━━━━ 18:05:32\n",
      "Accuracy: 0.9979 - Precision: 0.8992 - Recall: 0.8889 - Specificity: 0.9991 - F1: 0.8886 - Loss: 0.1245\n",
      "\n",
      "Batch 198/387 ━━━━━━━━━━━━━━━━━━━━ 18:07:17\n",
      "Accuracy: 0.9979 - Precision: 0.8995 - Recall: 0.8887 - Specificity: 0.9991 - F1: 0.8886 - Loss: 0.1244\n",
      "\n",
      "Batch 199/387 ━━━━━━━━━━━━━━━━━━━━ 18:08:47\n",
      "Accuracy: 0.9979 - Precision: 0.8998 - Recall: 0.8889 - Specificity: 0.9991 - F1: 0.8889 - Loss: 0.1241\n",
      "\n",
      "Batch 200/387 ━━━━━━━━━━━━━━━━━━━━ 18:10:21\n",
      "Accuracy: 0.9979 - Precision: 0.8997 - Recall: 0.8869 - Specificity: 0.9991 - F1: 0.8876 - Loss: 0.1254\n",
      "\n",
      "Batch 201/387 ━━━━━━━━━━━━━━━━━━━━ 18:11:56\n",
      "Accuracy: 0.9979 - Precision: 0.8999 - Recall: 0.8866 - Specificity: 0.9991 - F1: 0.8876 - Loss: 0.1254\n",
      "\n",
      "Batch 202/387 ━━━━━━━━━━━━━━━━━━━━ 18:13:36\n",
      "Accuracy: 0.9979 - Precision: 0.9004 - Recall: 0.8868 - Specificity: 0.9991 - F1: 0.8879 - Loss: 0.1250\n",
      "\n",
      "Batch 203/387 ━━━━━━━━━━━━━━━━━━━━ 18:14:57\n",
      "Accuracy: 0.9979 - Precision: 0.9004 - Recall: 0.8856 - Specificity: 0.9991 - F1: 0.8872 - Loss: 0.1258\n",
      "\n",
      "Batch 204/387 ━━━━━━━━━━━━━━━━━━━━ 18:16:29\n",
      "Accuracy: 0.9979 - Precision: 0.9005 - Recall: 0.8861 - Specificity: 0.9991 - F1: 0.8876 - Loss: 0.1255\n",
      "\n",
      "Batch 205/387 ━━━━━━━━━━━━━━━━━━━━ 18:18:00\n",
      "Accuracy: 0.9979 - Precision: 0.9006 - Recall: 0.8865 - Specificity: 0.9991 - F1: 0.8879 - Loss: 0.1252\n",
      "\n",
      "Batch 206/387 ━━━━━━━━━━━━━━━━━━━━ 18:19:28\n",
      "Accuracy: 0.9979 - Precision: 0.9001 - Recall: 0.8869 - Specificity: 0.9991 - F1: 0.8878 - Loss: 0.1253\n",
      "\n",
      "Batch 207/387 ━━━━━━━━━━━━━━━━━━━━ 18:21:06\n",
      "Accuracy: 0.9979 - Precision: 0.8999 - Recall: 0.8873 - Specificity: 0.9991 - F1: 0.8879 - Loss: 0.1252\n",
      "\n",
      "Batch 208/387 ━━━━━━━━━━━━━━━━━━━━ 18:22:37\n",
      "Accuracy: 0.9979 - Precision: 0.9000 - Recall: 0.8872 - Specificity: 0.9991 - F1: 0.8879 - Loss: 0.1252\n",
      "\n",
      "Batch 209/387 ━━━━━━━━━━━━━━━━━━━━ 18:24:10\n",
      "Accuracy: 0.9979 - Precision: 0.9003 - Recall: 0.8875 - Specificity: 0.9991 - F1: 0.8883 - Loss: 0.1248\n",
      "\n",
      "Batch 210/387 ━━━━━━━━━━━━━━━━━━━━ 18:25:41\n",
      "Accuracy: 0.9979 - Precision: 0.9004 - Recall: 0.8877 - Specificity: 0.9991 - F1: 0.8885 - Loss: 0.1246\n",
      "\n",
      "Batch 211/387 ━━━━━━━━━━━━━━━━━━━━ 18:27:23\n",
      "Accuracy: 0.9979 - Precision: 0.9004 - Recall: 0.8881 - Specificity: 0.9991 - F1: 0.8886 - Loss: 0.1244\n",
      "\n",
      "Batch 212/387 ━━━━━━━━━━━━━━━━━━━━ 18:28:50\n",
      "Accuracy: 0.9979 - Precision: 0.9001 - Recall: 0.8883 - Specificity: 0.9991 - F1: 0.8886 - Loss: 0.1244\n",
      "\n",
      "Batch 213/387 ━━━━━━━━━━━━━━━━━━━━ 18:30:16\n",
      "Accuracy: 0.9979 - Precision: 0.9003 - Recall: 0.8885 - Specificity: 0.9991 - F1: 0.8888 - Loss: 0.1242\n",
      "\n",
      "Batch 214/387 ━━━━━━━━━━━━━━━━━━━━ 18:31:36\n",
      "Accuracy: 0.9979 - Precision: 0.9004 - Recall: 0.8886 - Specificity: 0.9991 - F1: 0.8890 - Loss: 0.1241\n",
      "\n",
      "Batch 215/387 ━━━━━━━━━━━━━━━━━━━━ 18:32:57\n",
      "Accuracy: 0.9979 - Precision: 0.8991 - Recall: 0.8889 - Specificity: 0.9991 - F1: 0.8883 - Loss: 0.1247\n",
      "\n",
      "Batch 216/387 ━━━━━━━━━━━━━━━━━━━━ 18:34:25\n",
      "Accuracy: 0.9979 - Precision: 0.8992 - Recall: 0.8890 - Specificity: 0.9991 - F1: 0.8884 - Loss: 0.1246\n",
      "\n",
      "Batch 217/387 ━━━━━━━━━━━━━━━━━━━━ 18:36:05\n",
      "Accuracy: 0.9979 - Precision: 0.8989 - Recall: 0.8894 - Specificity: 0.9991 - F1: 0.8885 - Loss: 0.1246\n",
      "\n",
      "Batch 218/387 ━━━━━━━━━━━━━━━━━━━━ 18:37:37\n",
      "Accuracy: 0.9979 - Precision: 0.8993 - Recall: 0.8890 - Specificity: 0.9991 - F1: 0.8885 - Loss: 0.1247\n",
      "\n",
      "Batch 219/387 ━━━━━━━━━━━━━━━━━━━━ 18:39:09\n",
      "Accuracy: 0.9979 - Precision: 0.8994 - Recall: 0.8892 - Specificity: 0.9991 - F1: 0.8886 - Loss: 0.1245\n",
      "\n",
      "Batch 220/387 ━━━━━━━━━━━━━━━━━━━━ 18:40:42\n",
      "Accuracy: 0.9979 - Precision: 0.8997 - Recall: 0.8894 - Specificity: 0.9991 - F1: 0.8889 - Loss: 0.1242\n",
      "\n",
      "Batch 221/387 ━━━━━━━━━━━━━━━━━━━━ 18:42:16\n",
      "Accuracy: 0.9979 - Precision: 0.8993 - Recall: 0.8893 - Specificity: 0.9991 - F1: 0.8887 - Loss: 0.1244\n",
      "\n",
      "Batch 222/387 ━━━━━━━━━━━━━━━━━━━━ 18:43:44\n",
      "Accuracy: 0.9979 - Precision: 0.8981 - Recall: 0.8895 - Specificity: 0.9991 - F1: 0.8881 - Loss: 0.1250\n",
      "\n",
      "Batch 223/387 ━━━━━━━━━━━━━━━━━━━━ 18:45:13\n",
      "Accuracy: 0.9979 - Precision: 0.8964 - Recall: 0.8895 - Specificity: 0.9991 - F1: 0.8871 - Loss: 0.1261\n",
      "\n",
      "Batch 224/387 ━━━━━━━━━━━━━━━━━━━━ 18:46:54\n",
      "Accuracy: 0.9979 - Precision: 0.8963 - Recall: 0.8896 - Specificity: 0.9991 - F1: 0.8871 - Loss: 0.1261\n",
      "\n",
      "Batch 225/387 ━━━━━━━━━━━━━━━━━━━━ 18:48:34\n",
      "Accuracy: 0.9979 - Precision: 0.8967 - Recall: 0.8893 - Specificity: 0.9991 - F1: 0.8871 - Loss: 0.1261\n",
      "\n",
      "Batch 226/387 ━━━━━━━━━━━━━━━━━━━━ 18:50:08\n",
      "Accuracy: 0.9979 - Precision: 0.8971 - Recall: 0.8891 - Specificity: 0.9991 - F1: 0.8872 - Loss: 0.1260\n",
      "\n",
      "Batch 227/387 ━━━━━━━━━━━━━━━━━━━━ 18:51:37\n",
      "Accuracy: 0.9979 - Precision: 0.8974 - Recall: 0.8888 - Specificity: 0.9991 - F1: 0.8872 - Loss: 0.1259\n",
      "\n",
      "Batch 228/387 ━━━━━━━━━━━━━━━━━━━━ 18:52:59\n",
      "Accuracy: 0.9979 - Precision: 0.8977 - Recall: 0.8880 - Specificity: 0.9991 - F1: 0.8870 - Loss: 0.1262\n",
      "\n",
      "Batch 229/387 ━━━━━━━━━━━━━━━━━━━━ 18:54:16\n",
      "Accuracy: 0.9979 - Precision: 0.8980 - Recall: 0.8872 - Specificity: 0.9991 - F1: 0.8866 - Loss: 0.1266\n",
      "\n",
      "Batch 230/387 ━━━━━━━━━━━━━━━━━━━━ 18:55:45\n",
      "Accuracy: 0.9979 - Precision: 0.8984 - Recall: 0.8866 - Specificity: 0.9991 - F1: 0.8865 - Loss: 0.1267\n",
      "\n",
      "Batch 231/387 ━━━━━━━━━━━━━━━━━━━━ 18:57:20\n",
      "Accuracy: 0.9979 - Precision: 0.8986 - Recall: 0.8858 - Specificity: 0.9991 - F1: 0.8861 - Loss: 0.1271\n",
      "\n",
      "Batch 232/387 ━━━━━━━━━━━━━━━━━━━━ 18:58:41\n",
      "Accuracy: 0.9979 - Precision: 0.8981 - Recall: 0.8862 - Specificity: 0.9991 - F1: 0.8861 - Loss: 0.1271\n",
      "\n",
      "Batch 233/387 ━━━━━━━━━━━━━━━━━━━━ 19:00:11\n",
      "Accuracy: 0.9979 - Precision: 0.8982 - Recall: 0.8863 - Specificity: 0.9991 - F1: 0.8862 - Loss: 0.1270\n",
      "\n",
      "Batch 234/387 ━━━━━━━━━━━━━━━━━━━━ 19:01:40\n",
      "Accuracy: 0.9979 - Precision: 0.8981 - Recall: 0.8865 - Specificity: 0.9991 - F1: 0.8863 - Loss: 0.1270\n",
      "\n",
      "Batch 235/387 ━━━━━━━━━━━━━━━━━━━━ 19:03:03\n",
      "Accuracy: 0.9979 - Precision: 0.8979 - Recall: 0.8864 - Specificity: 0.9991 - F1: 0.8861 - Loss: 0.1272\n",
      "\n",
      "Batch 236/387 ━━━━━━━━━━━━━━━━━━━━ 19:04:25\n",
      "Accuracy: 0.9979 - Precision: 0.8981 - Recall: 0.8866 - Specificity: 0.9991 - F1: 0.8864 - Loss: 0.1269\n",
      "\n",
      "Batch 237/387 ━━━━━━━━━━━━━━━━━━━━ 19:05:54\n",
      "Accuracy: 0.9979 - Precision: 0.8983 - Recall: 0.8869 - Specificity: 0.9991 - F1: 0.8866 - Loss: 0.1266\n",
      "\n",
      "Batch 238/387 ━━━━━━━━━━━━━━━━━━━━ 19:07:14\n",
      "Accuracy: 0.9979 - Precision: 0.8984 - Recall: 0.8872 - Specificity: 0.9991 - F1: 0.8868 - Loss: 0.1263\n",
      "\n",
      "Batch 239/387 ━━━━━━━━━━━━━━━━━━━━ 19:08:44\n",
      "Accuracy: 0.9979 - Precision: 0.8985 - Recall: 0.8875 - Specificity: 0.9991 - F1: 0.8871 - Loss: 0.1261\n",
      "\n",
      "Batch 240/387 ━━━━━━━━━━━━━━━━━━━━ 19:10:19\n",
      "Accuracy: 0.9979 - Precision: 0.8980 - Recall: 0.8863 - Specificity: 0.9991 - F1: 0.8862 - Loss: 0.1270\n",
      "\n",
      "Batch 241/387 ━━━━━━━━━━━━━━━━━━━━ 19:12:01\n",
      "Accuracy: 0.9979 - Precision: 0.8972 - Recall: 0.8864 - Specificity: 0.9991 - F1: 0.8858 - Loss: 0.1274\n",
      "\n",
      "Batch 242/387 ━━━━━━━━━━━━━━━━━━━━ 19:13:36\n",
      "Accuracy: 0.9979 - Precision: 0.8971 - Recall: 0.8868 - Specificity: 0.9991 - F1: 0.8860 - Loss: 0.1272\n",
      "\n",
      "Batch 243/387 ━━━━━━━━━━━━━━━━━━━━ 19:15:08\n",
      "Accuracy: 0.9979 - Precision: 0.8973 - Recall: 0.8864 - Specificity: 0.9991 - F1: 0.8859 - Loss: 0.1274\n",
      "\n",
      "Batch 244/387 ━━━━━━━━━━━━━━━━━━━━ 19:16:39\n",
      "Accuracy: 0.9979 - Precision: 0.8971 - Recall: 0.8863 - Specificity: 0.9991 - F1: 0.8858 - Loss: 0.1275\n",
      "\n",
      "Batch 245/387 ━━━━━━━━━━━━━━━━━━━━ 19:18:06\n",
      "Accuracy: 0.9978 - Precision: 0.8965 - Recall: 0.8857 - Specificity: 0.9991 - F1: 0.8852 - Loss: 0.1282\n",
      "\n",
      "Batch 246/387 ━━━━━━━━━━━━━━━━━━━━ 19:19:43\n",
      "Accuracy: 0.9978 - Precision: 0.8962 - Recall: 0.8861 - Specificity: 0.9990 - F1: 0.8852 - Loss: 0.1281\n",
      "\n",
      "Batch 247/387 ━━━━━━━━━━━━━━━━━━━━ 19:21:13\n",
      "Accuracy: 0.9978 - Precision: 0.8960 - Recall: 0.8863 - Specificity: 0.9990 - F1: 0.8853 - Loss: 0.1281\n",
      "\n",
      "Batch 248/387 ━━━━━━━━━━━━━━━━━━━━ 19:22:30\n",
      "Accuracy: 0.9978 - Precision: 0.8962 - Recall: 0.8866 - Specificity: 0.9990 - F1: 0.8856 - Loss: 0.1278\n",
      "\n",
      "Batch 249/387 ━━━━━━━━━━━━━━━━━━━━ 19:23:59\n",
      "Accuracy: 0.9978 - Precision: 0.8965 - Recall: 0.8868 - Specificity: 0.9991 - F1: 0.8858 - Loss: 0.1275\n",
      "\n",
      "Batch 250/387 ━━━━━━━━━━━━━━━━━━━━ 19:25:35\n",
      "Accuracy: 0.9978 - Precision: 0.8962 - Recall: 0.8869 - Specificity: 0.9990 - F1: 0.8857 - Loss: 0.1276\n",
      "\n",
      "Batch 251/387 ━━━━━━━━━━━━━━━━━━━━ 19:27:06\n",
      "Accuracy: 0.9978 - Precision: 0.8953 - Recall: 0.8867 - Specificity: 0.9990 - F1: 0.8851 - Loss: 0.1282\n",
      "\n",
      "Batch 252/387 ━━━━━━━━━━━━━━━━━━━━ 19:28:33\n",
      "Accuracy: 0.9978 - Precision: 0.8953 - Recall: 0.8869 - Specificity: 0.9990 - F1: 0.8853 - Loss: 0.1280\n",
      "\n",
      "Batch 253/387 ━━━━━━━━━━━━━━━━━━━━ 19:30:12\n",
      "Accuracy: 0.9978 - Precision: 0.8949 - Recall: 0.8872 - Specificity: 0.9990 - F1: 0.8852 - Loss: 0.1281\n",
      "\n",
      "Batch 254/387 ━━━━━━━━━━━━━━━━━━━━ 19:31:42\n",
      "Accuracy: 0.9979 - Precision: 0.8951 - Recall: 0.8876 - Specificity: 0.9990 - F1: 0.8855 - Loss: 0.1277\n",
      "\n",
      "Batch 255/387 ━━━━━━━━━━━━━━━━━━━━ 19:33:16\n",
      "Accuracy: 0.9979 - Precision: 0.8950 - Recall: 0.8877 - Specificity: 0.9991 - F1: 0.8856 - Loss: 0.1277\n",
      "\n",
      "Batch 256/387 ━━━━━━━━━━━━━━━━━━━━ 19:34:51\n",
      "Accuracy: 0.9979 - Precision: 0.8952 - Recall: 0.8874 - Specificity: 0.9991 - F1: 0.8855 - Loss: 0.1278\n",
      "\n",
      "Batch 257/387 ━━━━━━━━━━━━━━━━━━━━ 19:36:25\n",
      "Accuracy: 0.9979 - Precision: 0.8951 - Recall: 0.8875 - Specificity: 0.9991 - F1: 0.8855 - Loss: 0.1277\n",
      "\n",
      "Batch 258/387 ━━━━━━━━━━━━━━━━━━━━ 19:37:59\n",
      "Accuracy: 0.9979 - Precision: 0.8955 - Recall: 0.8873 - Specificity: 0.9991 - F1: 0.8856 - Loss: 0.1276\n",
      "\n",
      "Batch 259/387 ━━━━━━━━━━━━━━━━━━━━ 19:39:36\n",
      "Accuracy: 0.9978 - Precision: 0.8959 - Recall: 0.8863 - Specificity: 0.9991 - F1: 0.8851 - Loss: 0.1283\n",
      "\n",
      "Batch 260/387 ━━━━━━━━━━━━━━━━━━━━ 19:41:06\n",
      "Accuracy: 0.9978 - Precision: 0.8958 - Recall: 0.8862 - Specificity: 0.9991 - F1: 0.8851 - Loss: 0.1283\n",
      "\n",
      "Batch 261/387 ━━━━━━━━━━━━━━━━━━━━ 19:42:27\n",
      "Accuracy: 0.9978 - Precision: 0.8954 - Recall: 0.8855 - Specificity: 0.9991 - F1: 0.8845 - Loss: 0.1289\n",
      "\n",
      "Batch 262/387 ━━━━━━━━━━━━━━━━━━━━ 19:43:58\n",
      "Accuracy: 0.9978 - Precision: 0.8957 - Recall: 0.8857 - Specificity: 0.9991 - F1: 0.8848 - Loss: 0.1286\n",
      "\n",
      "Batch 263/387 ━━━━━━━━━━━━━━━━━━━━ 19:45:42\n",
      "Accuracy: 0.9979 - Precision: 0.8959 - Recall: 0.8857 - Specificity: 0.9991 - F1: 0.8850 - Loss: 0.1284\n",
      "\n",
      "Batch 264/387 ━━━━━━━━━━━━━━━━━━━━ 19:47:17\n",
      "Accuracy: 0.9979 - Precision: 0.8958 - Recall: 0.8860 - Specificity: 0.9991 - F1: 0.8851 - Loss: 0.1283\n",
      "\n",
      "Batch 265/387 ━━━━━━━━━━━━━━━━━━━━ 19:48:51\n",
      "Accuracy: 0.9979 - Precision: 0.8952 - Recall: 0.8863 - Specificity: 0.9991 - F1: 0.8849 - Loss: 0.1285\n",
      "\n",
      "Batch 266/387 ━━━━━━━━━━━━━━━━━━━━ 19:50:26\n",
      "Accuracy: 0.9979 - Precision: 0.8953 - Recall: 0.8865 - Specificity: 0.9991 - F1: 0.8850 - Loss: 0.1283\n",
      "\n",
      "Batch 267/387 ━━━━━━━━━━━━━━━━━━━━ 19:52:06\n",
      "Accuracy: 0.9979 - Precision: 0.8944 - Recall: 0.8866 - Specificity: 0.9991 - F1: 0.8846 - Loss: 0.1287\n",
      "\n",
      "Batch 268/387 ━━━━━━━━━━━━━━━━━━━━ 19:53:31\n",
      "Accuracy: 0.9979 - Precision: 0.8948 - Recall: 0.8868 - Specificity: 0.9991 - F1: 0.8849 - Loss: 0.1285\n",
      "\n",
      "Batch 269/387 ━━━━━━━━━━━━━━━━━━━━ 19:55:02\n",
      "Accuracy: 0.9979 - Precision: 0.8951 - Recall: 0.8865 - Specificity: 0.9991 - F1: 0.8849 - Loss: 0.1284\n",
      "\n",
      "Batch 270/387 ━━━━━━━━━━━━━━━━━━━━ 19:56:36\n",
      "Accuracy: 0.9979 - Precision: 0.8953 - Recall: 0.8866 - Specificity: 0.9991 - F1: 0.8851 - Loss: 0.1283\n",
      "\n",
      "Batch 271/387 ━━━━━━━━━━━━━━━━━━━━ 19:58:04\n",
      "Accuracy: 0.9979 - Precision: 0.8953 - Recall: 0.8866 - Specificity: 0.9991 - F1: 0.8851 - Loss: 0.1283\n",
      "\n",
      "Batch 272/387 ━━━━━━━━━━━━━━━━━━━━ 19:59:33\n",
      "Accuracy: 0.9979 - Precision: 0.8954 - Recall: 0.8868 - Specificity: 0.9991 - F1: 0.8853 - Loss: 0.1281\n",
      "\n",
      "Batch 273/387 ━━━━━━━━━━━━━━━━━━━━ 20:01:09\n",
      "Accuracy: 0.9978 - Precision: 0.8955 - Recall: 0.8868 - Specificity: 0.9991 - F1: 0.8853 - Loss: 0.1281\n",
      "\n",
      "Batch 274/387 ━━━━━━━━━━━━━━━━━━━━ 20:02:40\n",
      "Accuracy: 0.9978 - Precision: 0.8955 - Recall: 0.8871 - Specificity: 0.9991 - F1: 0.8855 - Loss: 0.1279\n",
      "\n",
      "Batch 275/387 ━━━━━━━━━━━━━━━━━━━━ 20:04:09\n",
      "Accuracy: 0.9978 - Precision: 0.8959 - Recall: 0.8873 - Specificity: 0.9991 - F1: 0.8858 - Loss: 0.1276\n",
      "\n",
      "Batch 276/387 ━━━━━━━━━━━━━━━━━━━━ 20:05:45\n",
      "Accuracy: 0.9979 - Precision: 0.8959 - Recall: 0.8874 - Specificity: 0.9991 - F1: 0.8859 - Loss: 0.1274\n",
      "\n",
      "Batch 277/387 ━━━━━━━━━━━━━━━━━━━━ 20:07:21\n",
      "Accuracy: 0.9979 - Precision: 0.8953 - Recall: 0.8876 - Specificity: 0.9991 - F1: 0.8857 - Loss: 0.1277\n",
      "\n",
      "Batch 278/387 ━━━━━━━━━━━━━━━━━━━━ 20:08:55\n",
      "Accuracy: 0.9979 - Precision: 0.8956 - Recall: 0.8871 - Specificity: 0.9991 - F1: 0.8855 - Loss: 0.1278\n",
      "\n",
      "Batch 279/387 ━━━━━━━━━━━━━━━━━━━━ 20:10:37\n",
      "Accuracy: 0.9979 - Precision: 0.8957 - Recall: 0.8867 - Specificity: 0.9991 - F1: 0.8854 - Loss: 0.1280\n",
      "\n",
      "Batch 280/387 ━━━━━━━━━━━━━━━━━━━━ 20:12:06\n",
      "Accuracy: 0.9979 - Precision: 0.8958 - Recall: 0.8867 - Specificity: 0.9991 - F1: 0.8855 - Loss: 0.1278\n",
      "\n",
      "Batch 281/387 ━━━━━━━━━━━━━━━━━━━━ 20:13:54\n",
      "Accuracy: 0.9979 - Precision: 0.8957 - Recall: 0.8869 - Specificity: 0.9991 - F1: 0.8855 - Loss: 0.1278\n",
      "\n",
      "Batch 282/387 ━━━━━━━━━━━━━━━━━━━━ 20:15:24\n",
      "Accuracy: 0.9979 - Precision: 0.8957 - Recall: 0.8865 - Specificity: 0.9991 - F1: 0.8853 - Loss: 0.1280\n",
      "\n",
      "Batch 283/387 ━━━━━━━━━━━━━━━━━━━━ 20:17:03\n",
      "Accuracy: 0.9979 - Precision: 0.8941 - Recall: 0.8866 - Specificity: 0.9991 - F1: 0.8844 - Loss: 0.1290\n",
      "\n",
      "Batch 284/387 ━━━━━━━━━━━━━━━━━━━━ 20:18:35\n",
      "Accuracy: 0.9979 - Precision: 0.8942 - Recall: 0.8869 - Specificity: 0.9991 - F1: 0.8846 - Loss: 0.1288\n",
      "\n",
      "Batch 285/387 ━━━━━━━━━━━━━━━━━━━━ 20:20:11\n",
      "Accuracy: 0.9979 - Precision: 0.8945 - Recall: 0.8869 - Specificity: 0.9991 - F1: 0.8847 - Loss: 0.1286\n",
      "\n",
      "Batch 286/387 ━━━━━━━━━━━━━━━━━━━━ 20:21:41\n",
      "Accuracy: 0.9979 - Precision: 0.8948 - Recall: 0.8870 - Specificity: 0.9991 - F1: 0.8849 - Loss: 0.1284\n",
      "\n",
      "Batch 287/387 ━━━━━━━━━━━━━━━━━━━━ 20:23:11\n",
      "Accuracy: 0.9979 - Precision: 0.8951 - Recall: 0.8872 - Specificity: 0.9991 - F1: 0.8852 - Loss: 0.1281\n",
      "\n",
      "Batch 288/387 ━━━━━━━━━━━━━━━━━━━━ 20:24:41\n",
      "Accuracy: 0.9979 - Precision: 0.8952 - Recall: 0.8875 - Specificity: 0.9991 - F1: 0.8854 - Loss: 0.1279\n",
      "\n",
      "Batch 289/387 ━━━━━━━━━━━━━━━━━━━━ 20:26:12\n",
      "Accuracy: 0.9979 - Precision: 0.8951 - Recall: 0.8877 - Specificity: 0.9991 - F1: 0.8855 - Loss: 0.1278\n",
      "\n",
      "Batch 290/387 ━━━━━━━━━━━━━━━━━━━━ 20:27:51\n",
      "Accuracy: 0.9979 - Precision: 0.8954 - Recall: 0.8877 - Specificity: 0.9991 - F1: 0.8857 - Loss: 0.1275\n",
      "\n",
      "Batch 291/387 ━━━━━━━━━━━━━━━━━━━━ 20:29:31\n",
      "Accuracy: 0.9979 - Precision: 0.8957 - Recall: 0.8875 - Specificity: 0.9991 - F1: 0.8857 - Loss: 0.1276\n",
      "\n",
      "Batch 292/387 ━━━━━━━━━━━━━━━━━━━━ 20:31:10\n",
      "Accuracy: 0.9979 - Precision: 0.8960 - Recall: 0.8869 - Specificity: 0.9991 - F1: 0.8854 - Loss: 0.1279\n",
      "\n",
      "Batch 293/387 ━━━━━━━━━━━━━━━━━━━━ 20:32:46\n",
      "Accuracy: 0.9979 - Precision: 0.8962 - Recall: 0.8858 - Specificity: 0.9991 - F1: 0.8849 - Loss: 0.1284\n",
      "\n",
      "Batch 294/387 ━━━━━━━━━━━━━━━━━━━━ 20:34:18\n",
      "Accuracy: 0.9979 - Precision: 0.8963 - Recall: 0.8858 - Specificity: 0.9991 - F1: 0.8849 - Loss: 0.1284\n",
      "\n",
      "Batch 295/387 ━━━━━━━━━━━━━━━━━━━━ 20:35:52\n",
      "Accuracy: 0.9978 - Precision: 0.8965 - Recall: 0.8849 - Specificity: 0.9991 - F1: 0.8845 - Loss: 0.1289\n",
      "\n",
      "Batch 296/387 ━━━━━━━━━━━━━━━━━━━━ 20:37:25\n",
      "Accuracy: 0.9978 - Precision: 0.8967 - Recall: 0.8849 - Specificity: 0.9991 - F1: 0.8846 - Loss: 0.1287\n",
      "\n",
      "Batch 297/387 ━━━━━━━━━━━━━━━━━━━━ 20:39:03\n",
      "Accuracy: 0.9978 - Precision: 0.8970 - Recall: 0.8847 - Specificity: 0.9991 - F1: 0.8847 - Loss: 0.1287\n",
      "\n",
      "Batch 298/387 ━━━━━━━━━━━━━━━━━━━━ 20:40:31\n",
      "Accuracy: 0.9978 - Precision: 0.8972 - Recall: 0.8849 - Specificity: 0.9991 - F1: 0.8849 - Loss: 0.1285\n",
      "\n",
      "Batch 299/387 ━━━━━━━━━━━━━━━━━━━━ 20:42:07\n",
      "Accuracy: 0.9978 - Precision: 0.8975 - Recall: 0.8849 - Specificity: 0.9991 - F1: 0.8850 - Loss: 0.1284\n",
      "\n",
      "Batch 300/387 ━━━━━━━━━━━━━━━━━━━━ 20:43:44\n",
      "Accuracy: 0.9978 - Precision: 0.8973 - Recall: 0.8851 - Specificity: 0.9991 - F1: 0.8851 - Loss: 0.1283\n",
      "\n",
      "Batch 301/387 ━━━━━━━━━━━━━━━━━━━━ 20:45:32\n",
      "Accuracy: 0.9978 - Precision: 0.8975 - Recall: 0.8854 - Specificity: 0.9991 - F1: 0.8854 - Loss: 0.1280\n",
      "\n",
      "Batch 302/387 ━━━━━━━━━━━━━━━━━━━━ 20:46:59\n",
      "Accuracy: 0.9978 - Precision: 0.8975 - Recall: 0.8855 - Specificity: 0.9991 - F1: 0.8854 - Loss: 0.1280\n",
      "\n",
      "Batch 303/387 ━━━━━━━━━━━━━━━━━━━━ 20:48:29\n",
      "Accuracy: 0.9978 - Precision: 0.8978 - Recall: 0.8856 - Specificity: 0.9991 - F1: 0.8856 - Loss: 0.1277\n",
      "\n",
      "Batch 304/387 ━━━━━━━━━━━━━━━━━━━━ 20:50:04\n",
      "Accuracy: 0.9978 - Precision: 0.8979 - Recall: 0.8858 - Specificity: 0.9991 - F1: 0.8858 - Loss: 0.1276\n",
      "\n",
      "Batch 305/387 ━━━━━━━━━━━━━━━━━━━━ 20:51:39\n",
      "Accuracy: 0.9978 - Precision: 0.8980 - Recall: 0.8860 - Specificity: 0.9991 - F1: 0.8860 - Loss: 0.1274\n",
      "\n",
      "Batch 306/387 ━━━━━━━━━━━━━━━━━━━━ 20:53:15\n",
      "Accuracy: 0.9978 - Precision: 0.8979 - Recall: 0.8862 - Specificity: 0.9991 - F1: 0.8860 - Loss: 0.1274\n",
      "\n",
      "Batch 307/387 ━━━━━━━━━━━━━━━━━━━━ 20:54:37\n",
      "Accuracy: 0.9978 - Precision: 0.8979 - Recall: 0.8863 - Specificity: 0.9991 - F1: 0.8861 - Loss: 0.1273\n",
      "\n",
      "Batch 308/387 ━━━━━━━━━━━━━━━━━━━━ 20:56:05\n",
      "Accuracy: 0.9978 - Precision: 0.8980 - Recall: 0.8866 - Specificity: 0.9991 - F1: 0.8863 - Loss: 0.1271\n",
      "\n",
      "Batch 309/387 ━━━━━━━━━━━━━━━━━━━━ 20:57:29\n",
      "Accuracy: 0.9978 - Precision: 0.8976 - Recall: 0.8866 - Specificity: 0.9991 - F1: 0.8861 - Loss: 0.1273\n",
      "\n",
      "Batch 310/387 ━━━━━━━━━━━━━━━━━━━━ 20:58:58\n",
      "Accuracy: 0.9978 - Precision: 0.8976 - Recall: 0.8868 - Specificity: 0.9991 - F1: 0.8863 - Loss: 0.1272\n",
      "\n",
      "Batch 311/387 ━━━━━━━━━━━━━━━━━━━━ 21:00:30\n",
      "Accuracy: 0.9978 - Precision: 0.8972 - Recall: 0.8868 - Specificity: 0.9991 - F1: 0.8860 - Loss: 0.1274\n",
      "\n",
      "Batch 312/387 ━━━━━━━━━━━━━━━━━━━━ 21:02:06\n",
      "Accuracy: 0.9978 - Precision: 0.8973 - Recall: 0.8870 - Specificity: 0.9991 - F1: 0.8862 - Loss: 0.1273\n",
      "\n",
      "Batch 313/387 ━━━━━━━━━━━━━━━━━━━━ 21:03:39\n",
      "Accuracy: 0.9978 - Precision: 0.8972 - Recall: 0.8872 - Specificity: 0.9991 - F1: 0.8863 - Loss: 0.1272\n",
      "\n",
      "Batch 314/387 ━━━━━━━━━━━━━━━━━━━━ 21:05:07\n",
      "Accuracy: 0.9978 - Precision: 0.8973 - Recall: 0.8875 - Specificity: 0.9990 - F1: 0.8865 - Loss: 0.1270\n",
      "\n",
      "Batch 315/387 ━━━━━━━━━━━━━━━━━━━━ 21:06:48\n",
      "Accuracy: 0.9978 - Precision: 0.8975 - Recall: 0.8877 - Specificity: 0.9990 - F1: 0.8867 - Loss: 0.1267\n",
      "\n",
      "Batch 316/387 ━━━━━━━━━━━━━━━━━━━━ 21:08:20\n",
      "Accuracy: 0.9978 - Precision: 0.8976 - Recall: 0.8877 - Specificity: 0.9990 - F1: 0.8868 - Loss: 0.1267\n",
      "\n",
      "Batch 317/387 ━━━━━━━━━━━━━━━━━━━━ 21:09:46\n",
      "Accuracy: 0.9978 - Precision: 0.8979 - Recall: 0.8877 - Specificity: 0.9991 - F1: 0.8869 - Loss: 0.1266\n",
      "\n",
      "Batch 318/387 ━━━━━━━━━━━━━━━━━━━━ 21:11:26\n",
      "Accuracy: 0.9978 - Precision: 0.8980 - Recall: 0.8878 - Specificity: 0.9991 - F1: 0.8871 - Loss: 0.1263\n",
      "\n",
      "Batch 319/387 ━━━━━━━━━━━━━━━━━━━━ 21:13:01\n",
      "Accuracy: 0.9978 - Precision: 0.8977 - Recall: 0.8878 - Specificity: 0.9991 - F1: 0.8869 - Loss: 0.1265\n",
      "\n",
      "Batch 320/387 ━━━━━━━━━━━━━━━━━━━━ 21:14:35\n",
      "Accuracy: 0.9978 - Precision: 0.8975 - Recall: 0.8877 - Specificity: 0.9991 - F1: 0.8868 - Loss: 0.1267\n",
      "\n",
      "Batch 321/387 ━━━━━━━━━━━━━━━━━━━━ 21:16:08\n",
      "Accuracy: 0.9978 - Precision: 0.8975 - Recall: 0.8879 - Specificity: 0.9991 - F1: 0.8869 - Loss: 0.1266\n",
      "\n",
      "Batch 322/387 ━━━━━━━━━━━━━━━━━━━━ 21:17:32\n",
      "Accuracy: 0.9978 - Precision: 0.8975 - Recall: 0.8881 - Specificity: 0.9991 - F1: 0.8870 - Loss: 0.1264\n",
      "\n",
      "Batch 323/387 ━━━━━━━━━━━━━━━━━━━━ 21:19:10\n",
      "Accuracy: 0.9978 - Precision: 0.8970 - Recall: 0.8877 - Specificity: 0.9990 - F1: 0.8865 - Loss: 0.1269\n",
      "\n",
      "Batch 324/387 ━━━━━━━━━━━━━━━━━━━━ 21:20:44\n",
      "Accuracy: 0.9978 - Precision: 0.8968 - Recall: 0.8879 - Specificity: 0.9990 - F1: 0.8866 - Loss: 0.1269\n",
      "\n",
      "Batch 325/387 ━━━━━━━━━━━━━━━━━━━━ 21:22:22\n",
      "Accuracy: 0.9978 - Precision: 0.8967 - Recall: 0.8879 - Specificity: 0.9990 - F1: 0.8865 - Loss: 0.1270\n",
      "\n",
      "Batch 326/387 ━━━━━━━━━━━━━━━━━━━━ 21:23:51\n",
      "Accuracy: 0.9978 - Precision: 0.8956 - Recall: 0.8882 - Specificity: 0.9990 - F1: 0.8860 - Loss: 0.1276\n",
      "\n",
      "Batch 327/387 ━━━━━━━━━━━━━━━━━━━━ 21:25:23\n",
      "Accuracy: 0.9978 - Precision: 0.8959 - Recall: 0.8882 - Specificity: 0.9990 - F1: 0.8861 - Loss: 0.1274\n",
      "\n",
      "Batch 328/387 ━━━━━━━━━━━━━━━━━━━━ 21:26:47\n",
      "Accuracy: 0.9978 - Precision: 0.8962 - Recall: 0.8877 - Specificity: 0.9990 - F1: 0.8860 - Loss: 0.1276\n",
      "\n",
      "Batch 329/387 ━━━━━━━━━━━━━━━━━━━━ 21:28:19\n",
      "Accuracy: 0.9978 - Precision: 0.8963 - Recall: 0.8874 - Specificity: 0.9990 - F1: 0.8859 - Loss: 0.1276\n",
      "\n",
      "Batch 330/387 ━━━━━━━━━━━━━━━━━━━━ 21:29:59\n",
      "Accuracy: 0.9978 - Precision: 0.8966 - Recall: 0.8874 - Specificity: 0.9990 - F1: 0.8860 - Loss: 0.1275\n",
      "\n",
      "Batch 331/387 ━━━━━━━━━━━━━━━━━━━━ 21:31:35\n",
      "Accuracy: 0.9978 - Precision: 0.8969 - Recall: 0.8873 - Specificity: 0.9990 - F1: 0.8861 - Loss: 0.1274\n",
      "\n",
      "Batch 332/387 ━━━━━━━━━━━━━━━━━━━━ 21:33:10\n",
      "Accuracy: 0.9978 - Precision: 0.8970 - Recall: 0.8875 - Specificity: 0.9990 - F1: 0.8863 - Loss: 0.1272\n",
      "\n",
      "Batch 333/387 ━━━━━━━━━━━━━━━━━━━━ 21:34:32\n",
      "Accuracy: 0.9978 - Precision: 0.8972 - Recall: 0.8877 - Specificity: 0.9990 - F1: 0.8865 - Loss: 0.1270\n",
      "\n",
      "Batch 334/387 ━━━━━━━━━━━━━━━━━━━━ 21:36:11\n",
      "Accuracy: 0.9978 - Precision: 0.8970 - Recall: 0.8878 - Specificity: 0.9990 - F1: 0.8865 - Loss: 0.1270\n",
      "\n",
      "Batch 335/387 ━━━━━━━━━━━━━━━━━━━━ 21:37:37\n",
      "Accuracy: 0.9978 - Precision: 0.8969 - Recall: 0.8881 - Specificity: 0.9990 - F1: 0.8866 - Loss: 0.1269\n",
      "\n",
      "Batch 336/387 ━━━━━━━━━━━━━━━━━━━━ 21:39:15\n",
      "Accuracy: 0.9978 - Precision: 0.8966 - Recall: 0.8882 - Specificity: 0.9990 - F1: 0.8865 - Loss: 0.1271\n",
      "\n",
      "Batch 337/387 ━━━━━━━━━━━━━━━━━━━━ 21:40:54\n",
      "Accuracy: 0.9978 - Precision: 0.8965 - Recall: 0.8884 - Specificity: 0.9990 - F1: 0.8865 - Loss: 0.1270\n",
      "\n",
      "Batch 338/387 ━━━━━━━━━━━━━━━━━━━━ 21:42:28\n",
      "Accuracy: 0.9978 - Precision: 0.8961 - Recall: 0.8887 - Specificity: 0.9990 - F1: 0.8865 - Loss: 0.1270\n",
      "\n",
      "Batch 339/387 ━━━━━━━━━━━━━━━━━━━━ 21:43:48\n",
      "Accuracy: 0.9978 - Precision: 0.8963 - Recall: 0.8888 - Specificity: 0.9990 - F1: 0.8866 - Loss: 0.1269\n",
      "\n",
      "Batch 340/387 ━━━━━━━━━━━━━━━━━━━━ 21:45:26\n",
      "Accuracy: 0.9978 - Precision: 0.8964 - Recall: 0.8890 - Specificity: 0.9990 - F1: 0.8868 - Loss: 0.1267\n",
      "\n",
      "Batch 341/387 ━━━━━━━━━━━━━━━━━━━━ 21:47:03\n",
      "Accuracy: 0.9978 - Precision: 0.8964 - Recall: 0.8891 - Specificity: 0.9990 - F1: 0.8869 - Loss: 0.1266\n",
      "\n",
      "Batch 342/387 ━━━━━━━━━━━━━━━━━━━━ 21:48:43\n",
      "Accuracy: 0.9978 - Precision: 0.8966 - Recall: 0.8890 - Specificity: 0.9990 - F1: 0.8869 - Loss: 0.1265\n",
      "\n",
      "Batch 343/387 ━━━━━━━━━━━━━━━━━━━━ 21:50:06\n",
      "Accuracy: 0.9978 - Precision: 0.8965 - Recall: 0.8886 - Specificity: 0.9990 - F1: 0.8866 - Loss: 0.1268\n",
      "\n",
      "Batch 344/387 ━━━━━━━━━━━━━━━━━━━━ 21:51:32\n",
      "Accuracy: 0.9978 - Precision: 0.8965 - Recall: 0.8888 - Specificity: 0.9990 - F1: 0.8868 - Loss: 0.1267\n",
      "\n",
      "Batch 345/387 ━━━━━━━━━━━━━━━━━━━━ 21:53:06\n",
      "Accuracy: 0.9978 - Precision: 0.8964 - Recall: 0.8888 - Specificity: 0.9990 - F1: 0.8868 - Loss: 0.1267\n",
      "\n",
      "Batch 346/387 ━━━━━━━━━━━━━━━━━━━━ 21:54:44\n",
      "Accuracy: 0.9978 - Precision: 0.8967 - Recall: 0.8888 - Specificity: 0.9990 - F1: 0.8869 - Loss: 0.1265\n",
      "\n",
      "Batch 347/387 ━━━━━━━━━━━━━━━━━━━━ 21:56:17\n",
      "Accuracy: 0.9978 - Precision: 0.8965 - Recall: 0.8883 - Specificity: 0.9990 - F1: 0.8866 - Loss: 0.1269\n",
      "\n",
      "Batch 348/387 ━━━━━━━━━━━━━━━━━━━━ 21:57:51\n",
      "Accuracy: 0.9978 - Precision: 0.8965 - Recall: 0.8884 - Specificity: 0.9990 - F1: 0.8867 - Loss: 0.1268\n",
      "\n",
      "Batch 349/387 ━━━━━━━━━━━━━━━━━━━━ 21:59:18\n",
      "Accuracy: 0.9978 - Precision: 0.8966 - Recall: 0.8887 - Specificity: 0.9990 - F1: 0.8869 - Loss: 0.1266\n",
      "\n",
      "Batch 350/387 ━━━━━━━━━━━━━━━━━━━━ 22:00:57\n",
      "Accuracy: 0.9978 - Precision: 0.8968 - Recall: 0.8889 - Specificity: 0.9990 - F1: 0.8871 - Loss: 0.1264\n",
      "\n",
      "Batch 351/387 ━━━━━━━━━━━━━━━━━━━━ 22:02:37\n",
      "Accuracy: 0.9978 - Precision: 0.8963 - Recall: 0.8892 - Specificity: 0.9990 - F1: 0.8869 - Loss: 0.1265\n",
      "\n",
      "Batch 352/387 ━━━━━━━━━━━━━━━━━━━━ 22:04:14\n",
      "Accuracy: 0.9978 - Precision: 0.8963 - Recall: 0.8894 - Specificity: 0.9990 - F1: 0.8870 - Loss: 0.1264\n",
      "\n",
      "Batch 353/387 ━━━━━━━━━━━━━━━━━━━━ 22:05:52\n",
      "Accuracy: 0.9978 - Precision: 0.8964 - Recall: 0.8887 - Specificity: 0.9990 - F1: 0.8867 - Loss: 0.1268\n",
      "\n",
      "Batch 354/387 ━━━━━━━━━━━━━━━━━━━━ 22:07:22\n",
      "Accuracy: 0.9978 - Precision: 0.8965 - Recall: 0.8887 - Specificity: 0.9990 - F1: 0.8867 - Loss: 0.1267\n",
      "\n",
      "Batch 355/387 ━━━━━━━━━━━━━━━━━━━━ 22:08:50\n",
      "Accuracy: 0.9978 - Precision: 0.8965 - Recall: 0.8889 - Specificity: 0.9990 - F1: 0.8869 - Loss: 0.1266\n",
      "\n",
      "Batch 356/387 ━━━━━━━━━━━━━━━━━━━━ 22:10:23\n",
      "Accuracy: 0.9978 - Precision: 0.8968 - Recall: 0.8888 - Specificity: 0.9990 - F1: 0.8870 - Loss: 0.1265\n",
      "\n",
      "Batch 357/387 ━━━━━━━━━━━━━━━━━━━━ 22:11:49\n",
      "Accuracy: 0.9978 - Precision: 0.8965 - Recall: 0.8888 - Specificity: 0.9990 - F1: 0.8869 - Loss: 0.1266\n",
      "\n",
      "Batch 358/387 ━━━━━━━━━━━━━━━━━━━━ 22:13:30\n",
      "Accuracy: 0.9978 - Precision: 0.8966 - Recall: 0.8888 - Specificity: 0.9990 - F1: 0.8869 - Loss: 0.1266\n",
      "\n",
      "Batch 359/387 ━━━━━━━━━━━━━━━━━━━━ 22:15:10\n",
      "Accuracy: 0.9978 - Precision: 0.8966 - Recall: 0.8886 - Specificity: 0.9990 - F1: 0.8868 - Loss: 0.1267\n",
      "\n",
      "Batch 360/387 ━━━━━━━━━━━━━━━━━━━━ 22:16:39\n",
      "Accuracy: 0.9978 - Precision: 0.8968 - Recall: 0.8887 - Specificity: 0.9990 - F1: 0.8870 - Loss: 0.1265\n",
      "\n",
      "Batch 361/387 ━━━━━━━━━━━━━━━━━━━━ 22:18:07\n",
      "Accuracy: 0.9978 - Precision: 0.8964 - Recall: 0.8890 - Specificity: 0.9990 - F1: 0.8869 - Loss: 0.1266\n",
      "\n",
      "Batch 362/387 ━━━━━━━━━━━━━━━━━━━━ 22:19:34\n",
      "Accuracy: 0.9978 - Precision: 0.8966 - Recall: 0.8891 - Specificity: 0.9990 - F1: 0.8871 - Loss: 0.1264\n",
      "\n",
      "Batch 363/387 ━━━━━━━━━━━━━━━━━━━━ 22:21:11\n",
      "Accuracy: 0.9978 - Precision: 0.8963 - Recall: 0.8893 - Specificity: 0.9990 - F1: 0.8870 - Loss: 0.1265\n",
      "\n",
      "Batch 364/387 ━━━━━━━━━━━━━━━━━━━━ 22:22:58\n",
      "Accuracy: 0.9978 - Precision: 0.8965 - Recall: 0.8892 - Specificity: 0.9990 - F1: 0.8871 - Loss: 0.1264\n",
      "\n",
      "Batch 365/387 ━━━━━━━━━━━━━━━━━━━━ 22:24:15\n",
      "Accuracy: 0.9978 - Precision: 0.8959 - Recall: 0.8890 - Specificity: 0.9990 - F1: 0.8867 - Loss: 0.1268\n",
      "\n",
      "Batch 366/387 ━━━━━━━━━━━━━━━━━━━━ 22:25:49\n",
      "Accuracy: 0.9978 - Precision: 0.8957 - Recall: 0.8892 - Specificity: 0.9990 - F1: 0.8867 - Loss: 0.1268\n",
      "\n",
      "Batch 367/387 ━━━━━━━━━━━━━━━━━━━━ 22:27:15\n",
      "Accuracy: 0.9978 - Precision: 0.8960 - Recall: 0.8893 - Specificity: 0.9990 - F1: 0.8869 - Loss: 0.1266\n",
      "\n",
      "Batch 368/387 ━━━━━━━━━━━━━━━━━━━━ 22:28:37\n",
      "Accuracy: 0.9978 - Precision: 0.8961 - Recall: 0.8894 - Specificity: 0.9990 - F1: 0.8870 - Loss: 0.1264\n",
      "\n",
      "Batch 369/387 ━━━━━━━━━━━━━━━━━━━━ 22:30:01\n",
      "Accuracy: 0.9978 - Precision: 0.8956 - Recall: 0.8897 - Specificity: 0.9990 - F1: 0.8869 - Loss: 0.1266\n",
      "\n",
      "Batch 370/387 ━━━━━━━━━━━━━━━━━━━━ 22:31:25\n",
      "Accuracy: 0.9978 - Precision: 0.8957 - Recall: 0.8897 - Specificity: 0.9990 - F1: 0.8869 - Loss: 0.1265\n",
      "\n",
      "Batch 371/387 ━━━━━━━━━━━━━━━━━━━━ 22:33:01\n",
      "Accuracy: 0.9978 - Precision: 0.8954 - Recall: 0.8894 - Specificity: 0.9990 - F1: 0.8867 - Loss: 0.1268\n",
      "\n",
      "Batch 372/387 ━━━━━━━━━━━━━━━━━━━━ 22:34:35\n",
      "Accuracy: 0.9978 - Precision: 0.8954 - Recall: 0.8896 - Specificity: 0.9990 - F1: 0.8868 - Loss: 0.1267\n",
      "\n",
      "Batch 373/387 ━━━━━━━━━━━━━━━━━━━━ 22:36:00\n",
      "Accuracy: 0.9978 - Precision: 0.8950 - Recall: 0.8899 - Specificity: 0.9990 - F1: 0.8867 - Loss: 0.1267\n",
      "\n",
      "Batch 374/387 ━━━━━━━━━━━━━━━━━━━━ 22:37:54\n",
      "Accuracy: 0.9978 - Precision: 0.8949 - Recall: 0.8900 - Specificity: 0.9990 - F1: 0.8867 - Loss: 0.1267\n",
      "\n",
      "Batch 375/387 ━━━━━━━━━━━━━━━━━━━━ 22:39:47\n",
      "Accuracy: 0.9978 - Precision: 0.8951 - Recall: 0.8897 - Specificity: 0.9990 - F1: 0.8866 - Loss: 0.1268\n",
      "\n",
      "Batch 376/387 ━━━━━━━━━━━━━━━━━━━━ 22:41:23\n",
      "Accuracy: 0.9978 - Precision: 0.8953 - Recall: 0.8896 - Specificity: 0.9990 - F1: 0.8867 - Loss: 0.1267\n",
      "\n",
      "Batch 377/387 ━━━━━━━━━━━━━━━━━━━━ 22:43:04\n",
      "Accuracy: 0.9978 - Precision: 0.8952 - Recall: 0.8895 - Specificity: 0.9990 - F1: 0.8866 - Loss: 0.1268\n",
      "\n",
      "Batch 378/387 ━━━━━━━━━━━━━━━━━━━━ 22:44:34\n",
      "Accuracy: 0.9978 - Precision: 0.8954 - Recall: 0.8896 - Specificity: 0.9990 - F1: 0.8868 - Loss: 0.1266\n",
      "\n",
      "Batch 379/387 ━━━━━━━━━━━━━━━━━━━━ 22:46:04\n",
      "Accuracy: 0.9978 - Precision: 0.8957 - Recall: 0.8896 - Specificity: 0.9990 - F1: 0.8869 - Loss: 0.1265\n",
      "\n",
      "Batch 380/387 ━━━━━━━━━━━━━━━━━━━━ 22:47:31\n",
      "Accuracy: 0.9978 - Precision: 0.8951 - Recall: 0.8897 - Specificity: 0.9990 - F1: 0.8866 - Loss: 0.1268\n",
      "\n",
      "Batch 381/387 ━━━━━━━━━━━━━━━━━━━━ 22:49:14\n",
      "Accuracy: 0.9978 - Precision: 0.8953 - Recall: 0.8891 - Specificity: 0.9990 - F1: 0.8864 - Loss: 0.1271\n",
      "\n",
      "Batch 382/387 ━━━━━━━━━━━━━━━━━━━━ 22:50:36\n",
      "Accuracy: 0.9978 - Precision: 0.8954 - Recall: 0.8891 - Specificity: 0.9990 - F1: 0.8864 - Loss: 0.1270\n",
      "\n",
      "Batch 383/387 ━━━━━━━━━━━━━━━━━━━━ 22:52:13\n",
      "Accuracy: 0.9978 - Precision: 0.8956 - Recall: 0.8891 - Specificity: 0.9990 - F1: 0.8866 - Loss: 0.1269\n",
      "\n",
      "Batch 384/387 ━━━━━━━━━━━━━━━━━━━━ 22:53:46\n",
      "Accuracy: 0.9978 - Precision: 0.8957 - Recall: 0.8892 - Specificity: 0.9990 - F1: 0.8867 - Loss: 0.1268\n",
      "\n",
      "Batch 385/387 ━━━━━━━━━━━━━━━━━━━━ 22:55:36\n",
      "Accuracy: 0.9978 - Precision: 0.8958 - Recall: 0.8893 - Specificity: 0.9990 - F1: 0.8868 - Loss: 0.1266\n",
      "\n",
      "Batch 386/387 ━━━━━━━━━━━━━━━━━━━━ 22:57:04\n",
      "Accuracy: 0.9978 - Precision: 0.8958 - Recall: 0.8895 - Specificity: 0.9990 - F1: 0.8869 - Loss: 0.1265\n",
      "\n",
      "Batch 387/387 ━━━━━━━━━━━━━━━━━━━━ 22:58:30\n",
      "Accuracy: 0.9978 - Precision: 0.8960 - Recall: 0.8896 - Specificity: 0.9990 - F1: 0.8870 - Loss: 0.1264\n",
      "\n",
      "End of Epoch 13\n",
      "\n",
      "Epoch 14/50\n",
      "Batch 1/387 ━━━━━━━━━━━━━━━━━━━━ 23:20:20\n",
      "Accuracy: 0.9973 - Precision: 0.9567 - Recall: 0.8912 - Specificity: 0.9993 - F1: 0.9228 - Loss: 0.0904\n",
      "\n",
      "Batch 2/387 ━━━━━━━━━━━━━━━━━━━━ 23:22:01\n",
      "Accuracy: 0.9969 - Precision: 0.9419 - Recall: 0.8889 - Specificity: 0.9989 - F1: 0.9146 - Loss: 0.1024\n",
      "\n",
      "Batch 3/387 ━━━━━━━━━━━━━━━━━━━━ 23:23:27\n",
      "Accuracy: 0.9969 - Precision: 0.9282 - Recall: 0.9138 - Specificity: 0.9985 - F1: 0.9201 - Loss: 0.0957\n",
      "\n",
      "Batch 4/387 ━━━━━━━━━━━━━━━━━━━━ 23:24:56\n",
      "Accuracy: 0.9973 - Precision: 0.9350 - Recall: 0.9237 - Specificity: 0.9987 - F1: 0.9287 - Loss: 0.0850\n",
      "\n",
      "Batch 5/387 ━━━━━━━━━━━━━━━━━━━━ 23:26:13\n",
      "Accuracy: 0.9966 - Precision: 0.8997 - Recall: 0.8911 - Specificity: 0.9983 - F1: 0.8948 - Loss: 0.1227\n",
      "\n",
      "Batch 6/387 ━━━━━━━━━━━━━━━━━━━━ 23:27:49\n",
      "Accuracy: 0.9967 - Precision: 0.8863 - Recall: 0.9040 - Specificity: 0.9982 - F1: 0.8937 - Loss: 0.1237\n",
      "\n",
      "Batch 7/387 ━━━━━━━━━━━━━━━━━━━━ 23:29:11\n",
      "Accuracy: 0.9966 - Precision: 0.9007 - Recall: 0.8845 - Specificity: 0.9984 - F1: 0.8893 - Loss: 0.1293\n",
      "\n",
      "Batch 8/387 ━━━━━━━━━━━━━━━━━━━━ 23:30:38\n",
      "Accuracy: 0.9967 - Precision: 0.8700 - Recall: 0.8933 - Specificity: 0.9984 - F1: 0.8753 - Loss: 0.1430\n",
      "\n",
      "Batch 9/387 ━━━━━━━━━━━━━━━━━━━━ 23:31:58\n",
      "Accuracy: 0.9970 - Precision: 0.8556 - Recall: 0.8877 - Specificity: 0.9985 - F1: 0.8657 - Loss: 0.1517\n",
      "\n",
      "Batch 10/387 ━━━━━━━━━━━━━━━━━━━━ 23:33:29\n",
      "Accuracy: 0.9970 - Precision: 0.8613 - Recall: 0.8882 - Specificity: 0.9985 - F1: 0.8693 - Loss: 0.1476\n",
      "\n",
      "Batch 11/387 ━━━━━━━━━━━━━━━━━━━━ 23:35:07\n",
      "Accuracy: 0.9969 - Precision: 0.8712 - Recall: 0.8823 - Specificity: 0.9986 - F1: 0.8713 - Loss: 0.1464\n",
      "\n",
      "Batch 12/387 ━━━━━━━━━━━━━━━━━━━━ 23:36:34\n",
      "Accuracy: 0.9968 - Precision: 0.8787 - Recall: 0.8694 - Specificity: 0.9987 - F1: 0.8677 - Loss: 0.1503\n",
      "\n",
      "Batch 13/387 ━━━━━━━━━━━━━━━━━━━━ 23:38:15\n",
      "Accuracy: 0.9969 - Precision: 0.8814 - Recall: 0.8781 - Specificity: 0.9987 - F1: 0.8738 - Loss: 0.1435\n",
      "\n",
      "Batch 14/387 ━━━━━━━━━━━━━━━━━━━━ 23:39:46\n",
      "Accuracy: 0.9970 - Precision: 0.8849 - Recall: 0.8819 - Specificity: 0.9987 - F1: 0.8778 - Loss: 0.1391\n",
      "\n",
      "Batch 15/387 ━━━━━━━━━━━━━━━━━━━━ 23:41:14\n",
      "Accuracy: 0.9969 - Precision: 0.8891 - Recall: 0.8781 - Specificity: 0.9987 - F1: 0.8781 - Loss: 0.1397\n",
      "\n",
      "Batch 16/387 ━━━━━━━━━━━━━━━━━━━━ 23:42:31\n",
      "Accuracy: 0.9969 - Precision: 0.8697 - Recall: 0.8854 - Specificity: 0.9986 - F1: 0.8690 - Loss: 0.1488\n",
      "\n",
      "Batch 17/387 ━━━━━━━━━━━━━━━━━━━━ 23:44:04\n",
      "Accuracy: 0.9969 - Precision: 0.8739 - Recall: 0.8891 - Specificity: 0.9986 - F1: 0.8734 - Loss: 0.1441\n",
      "\n",
      "Batch 18/387 ━━━━━━━━━━━━━━━━━━━━ 23:45:37\n",
      "Accuracy: 0.9970 - Precision: 0.8717 - Recall: 0.8871 - Specificity: 0.9986 - F1: 0.8717 - Loss: 0.1454\n",
      "\n",
      "Batch 19/387 ━━━━━━━━━━━━━━━━━━━━ 23:47:14\n",
      "Accuracy: 0.9970 - Precision: 0.8728 - Recall: 0.8918 - Specificity: 0.9986 - F1: 0.8750 - Loss: 0.1420\n",
      "\n",
      "Batch 20/387 ━━━━━━━━━━━━━━━━━━━━ 23:48:42\n",
      "Accuracy: 0.9970 - Precision: 0.8722 - Recall: 0.8799 - Specificity: 0.9986 - F1: 0.8684 - Loss: 0.1487\n",
      "\n",
      "Batch 21/387 ━━━━━━━━━━━━━━━━━━━━ 23:50:23\n",
      "Accuracy: 0.9970 - Precision: 0.8670 - Recall: 0.8856 - Specificity: 0.9986 - F1: 0.8682 - Loss: 0.1485\n",
      "\n",
      "Batch 22/387 ━━━━━━━━━━━━━━━━━━━━ 23:51:46\n",
      "Accuracy: 0.9970 - Precision: 0.8700 - Recall: 0.8874 - Specificity: 0.9986 - F1: 0.8710 - Loss: 0.1456\n",
      "\n",
      "Batch 23/387 ━━━━━━━━━━━━━━━━━━━━ 23:53:10\n",
      "Accuracy: 0.9971 - Precision: 0.8667 - Recall: 0.8899 - Specificity: 0.9986 - F1: 0.8706 - Loss: 0.1457\n",
      "\n",
      "Batch 24/387 ━━━━━━━━━━━━━━━━━━━━ 23:54:31\n",
      "Accuracy: 0.9970 - Precision: 0.8708 - Recall: 0.8853 - Specificity: 0.9986 - F1: 0.8703 - Loss: 0.1466\n",
      "\n",
      "Batch 25/387 ━━━━━━━━━━━━━━━━━━━━ 23:56:00\n",
      "Accuracy: 0.9971 - Precision: 0.8711 - Recall: 0.8867 - Specificity: 0.9987 - F1: 0.8714 - Loss: 0.1451\n",
      "\n",
      "Batch 26/387 ━━━━━━━━━━━━━━━━━━━━ 23:57:33\n",
      "Accuracy: 0.9972 - Precision: 0.8751 - Recall: 0.8876 - Specificity: 0.9987 - F1: 0.8742 - Loss: 0.1420\n",
      "\n",
      "Batch 27/387 ━━━━━━━━━━━━━━━━━━━━ 23:58:52\n",
      "Accuracy: 0.9973 - Precision: 0.8748 - Recall: 0.8905 - Specificity: 0.9987 - F1: 0.8756 - Loss: 0.1402\n",
      "\n",
      "Batch 28/387 ━━━━━━━━━━━━━━━━━━━━ 00:00:35\n",
      "Accuracy: 0.9973 - Precision: 0.8755 - Recall: 0.8933 - Specificity: 0.9987 - F1: 0.8776 - Loss: 0.1382\n",
      "\n",
      "Batch 29/387 ━━━━━━━━━━━━━━━━━━━━ 00:02:02\n",
      "Accuracy: 0.9973 - Precision: 0.8792 - Recall: 0.8941 - Specificity: 0.9987 - F1: 0.8800 - Loss: 0.1354\n",
      "\n",
      "Batch 30/387 ━━━━━━━━━━━━━━━━━━━━ 00:03:22\n",
      "Accuracy: 0.9974 - Precision: 0.8810 - Recall: 0.8940 - Specificity: 0.9988 - F1: 0.8810 - Loss: 0.1345\n",
      "\n",
      "Batch 31/387 ━━━━━━━━━━━━━━━━━━━━ 00:04:51\n",
      "Accuracy: 0.9974 - Precision: 0.8833 - Recall: 0.8969 - Specificity: 0.9988 - F1: 0.8839 - Loss: 0.1314\n",
      "\n",
      "Batch 32/387 ━━━━━━━━━━━━━━━━━━━━ 00:06:24\n",
      "Accuracy: 0.9975 - Precision: 0.8867 - Recall: 0.8980 - Specificity: 0.9988 - F1: 0.8863 - Loss: 0.1287\n",
      "\n",
      "Batch 33/387 ━━━━━━━━━━━━━━━━━━━━ 00:07:50\n",
      "Accuracy: 0.9975 - Precision: 0.8895 - Recall: 0.8993 - Specificity: 0.9988 - F1: 0.8885 - Loss: 0.1262\n",
      "\n",
      "Batch 34/387 ━━━━━━━━━━━━━━━━━━━━ 00:09:09\n",
      "Accuracy: 0.9975 - Precision: 0.8926 - Recall: 0.8992 - Specificity: 0.9989 - F1: 0.8901 - Loss: 0.1245\n",
      "\n",
      "Batch 35/387 ━━━━━━━━━━━━━━━━━━━━ 00:10:30\n",
      "Accuracy: 0.9976 - Precision: 0.8949 - Recall: 0.8972 - Specificity: 0.9989 - F1: 0.8903 - Loss: 0.1241\n",
      "\n",
      "Batch 36/387 ━━━━━━━━━━━━━━━━━━━━ 00:12:02\n",
      "Accuracy: 0.9976 - Precision: 0.8974 - Recall: 0.8951 - Specificity: 0.9989 - F1: 0.8904 - Loss: 0.1238\n",
      "\n",
      "Batch 37/387 ━━━━━━━━━━━━━━━━━━━━ 00:13:26\n",
      "Accuracy: 0.9976 - Precision: 0.8995 - Recall: 0.8941 - Specificity: 0.9990 - F1: 0.8910 - Loss: 0.1231\n",
      "\n",
      "Batch 38/387 ━━━━━━━━━━━━━━━━━━━━ 00:14:59\n",
      "Accuracy: 0.9975 - Precision: 0.9016 - Recall: 0.8920 - Specificity: 0.9990 - F1: 0.8909 - Loss: 0.1234\n",
      "\n",
      "Batch 39/387 ━━━━━━━━━━━━━━━━━━━━ 00:16:27\n",
      "Accuracy: 0.9975 - Precision: 0.9037 - Recall: 0.8808 - Specificity: 0.9990 - F1: 0.8841 - Loss: 0.1307\n",
      "\n",
      "Batch 40/387 ━━━━━━━━━━━━━━━━━━━━ 00:17:49\n",
      "Accuracy: 0.9975 - Precision: 0.9006 - Recall: 0.8810 - Specificity: 0.9990 - F1: 0.8827 - Loss: 0.1320\n",
      "\n",
      "Batch 41/387 ━━━━━━━━━━━━━━━━━━━━ 00:19:06\n",
      "Accuracy: 0.9975 - Precision: 0.8992 - Recall: 0.8812 - Specificity: 0.9990 - F1: 0.8823 - Loss: 0.1324\n",
      "\n",
      "Batch 42/387 ━━━━━━━━━━━━━━━━━━━━ 00:20:36\n",
      "Accuracy: 0.9975 - Precision: 0.8961 - Recall: 0.8834 - Specificity: 0.9990 - F1: 0.8818 - Loss: 0.1329\n",
      "\n",
      "Batch 43/387 ━━━━━━━━━━━━━━━━━━━━ 00:22:07\n",
      "Accuracy: 0.9975 - Precision: 0.8921 - Recall: 0.8741 - Specificity: 0.9990 - F1: 0.8747 - Loss: 0.1402\n",
      "\n",
      "Batch 44/387 ━━━━━━━━━━━━━━━━━━━━ 00:23:40\n",
      "Accuracy: 0.9976 - Precision: 0.8928 - Recall: 0.8766 - Specificity: 0.9990 - F1: 0.8765 - Loss: 0.1383\n",
      "\n",
      "Batch 45/387 ━━━━━━━━━━━━━━━━━━━━ 00:25:12\n",
      "Accuracy: 0.9975 - Precision: 0.8916 - Recall: 0.8778 - Specificity: 0.9989 - F1: 0.8767 - Loss: 0.1384\n",
      "\n",
      "Batch 46/387 ━━━━━━━━━━━━━━━━━━━━ 00:26:41\n",
      "Accuracy: 0.9975 - Precision: 0.8854 - Recall: 0.8788 - Specificity: 0.9989 - F1: 0.8735 - Loss: 0.1415\n",
      "\n",
      "Batch 47/387 ━━━━━━━━━━━━━━━━━━━━ 00:28:05\n",
      "Accuracy: 0.9975 - Precision: 0.8837 - Recall: 0.8812 - Specificity: 0.9988 - F1: 0.8738 - Loss: 0.1413\n",
      "\n",
      "Batch 48/387 ━━━━━━━━━━━━━━━━━━━━ 00:29:39\n",
      "Accuracy: 0.9975 - Precision: 0.8836 - Recall: 0.8827 - Specificity: 0.9988 - F1: 0.8747 - Loss: 0.1405\n",
      "\n",
      "Batch 49/387 ━━━━━━━━━━━━━━━━━━━━ 00:31:05\n",
      "Accuracy: 0.9975 - Precision: 0.8843 - Recall: 0.8849 - Specificity: 0.9988 - F1: 0.8762 - Loss: 0.1387\n",
      "\n",
      "Batch 50/387 ━━━━━━━━━━━━━━━━━━━━ 00:32:36\n",
      "Accuracy: 0.9975 - Precision: 0.8780 - Recall: 0.8855 - Specificity: 0.9988 - F1: 0.8728 - Loss: 0.1424\n",
      "\n",
      "Batch 51/387 ━━━━━━━━━━━━━━━━━━━━ 00:34:00\n",
      "Accuracy: 0.9975 - Precision: 0.8799 - Recall: 0.8858 - Specificity: 0.9988 - F1: 0.8740 - Loss: 0.1411\n",
      "\n",
      "Batch 52/387 ━━━━━━━━━━━━━━━━━━━━ 00:35:27\n",
      "Accuracy: 0.9975 - Precision: 0.8802 - Recall: 0.8853 - Specificity: 0.9988 - F1: 0.8740 - Loss: 0.1410\n",
      "\n",
      "Batch 53/387 ━━━━━━━━━━━━━━━━━━━━ 00:37:00\n",
      "Accuracy: 0.9975 - Precision: 0.8810 - Recall: 0.8859 - Specificity: 0.9988 - F1: 0.8750 - Loss: 0.1400\n",
      "\n",
      "Batch 54/387 ━━━━━━━━━━━━━━━━━━━━ 00:38:36\n",
      "Accuracy: 0.9975 - Precision: 0.8817 - Recall: 0.8822 - Specificity: 0.9988 - F1: 0.8733 - Loss: 0.1417\n",
      "\n",
      "Batch 55/387 ━━━━━━━━━━━━━━━━━━━━ 00:40:02\n",
      "Accuracy: 0.9975 - Precision: 0.8832 - Recall: 0.8834 - Specificity: 0.9989 - F1: 0.8748 - Loss: 0.1400\n",
      "\n",
      "Batch 56/387 ━━━━━━━━━━━━━━━━━━━━ 00:41:39\n",
      "Accuracy: 0.9975 - Precision: 0.8827 - Recall: 0.8828 - Specificity: 0.9988 - F1: 0.8744 - Loss: 0.1405\n",
      "\n",
      "Batch 57/387 ━━━━━━━━━━━━━━━━━━━━ 00:43:06\n",
      "Accuracy: 0.9975 - Precision: 0.8795 - Recall: 0.8824 - Specificity: 0.9988 - F1: 0.8726 - Loss: 0.1423\n",
      "\n",
      "Batch 58/387 ━━━━━━━━━━━━━━━━━━━━ 00:44:34\n",
      "Accuracy: 0.9975 - Precision: 0.8812 - Recall: 0.8809 - Specificity: 0.9989 - F1: 0.8727 - Loss: 0.1421\n",
      "\n",
      "Batch 59/387 ━━━━━━━━━━━━━━━━━━━━ 00:45:56\n",
      "Accuracy: 0.9975 - Precision: 0.8821 - Recall: 0.8805 - Specificity: 0.9989 - F1: 0.8731 - Loss: 0.1417\n",
      "\n",
      "Batch 60/387 ━━━━━━━━━━━━━━━━━━━━ 00:47:26\n",
      "Accuracy: 0.9975 - Precision: 0.8835 - Recall: 0.8805 - Specificity: 0.9989 - F1: 0.8739 - Loss: 0.1410\n",
      "\n",
      "Batch 61/387 ━━━━━━━━━━━━━━━━━━━━ 00:48:57\n",
      "Accuracy: 0.9974 - Precision: 0.8831 - Recall: 0.8773 - Specificity: 0.9989 - F1: 0.8720 - Loss: 0.1434\n",
      "\n",
      "Batch 62/387 ━━━━━━━━━━━━━━━━━━━━ 00:50:30\n",
      "Accuracy: 0.9975 - Precision: 0.8830 - Recall: 0.8787 - Specificity: 0.9989 - F1: 0.8728 - Loss: 0.1425\n",
      "\n",
      "Batch 63/387 ━━━━━━━━━━━━━━━━━━━━ 00:52:06\n",
      "Accuracy: 0.9975 - Precision: 0.8842 - Recall: 0.8801 - Specificity: 0.9989 - F1: 0.8742 - Loss: 0.1410\n",
      "\n",
      "Batch 64/387 ━━━━━━━━━━━━━━━━━━━━ 00:53:32\n",
      "Accuracy: 0.9975 - Precision: 0.8850 - Recall: 0.8812 - Specificity: 0.9989 - F1: 0.8753 - Loss: 0.1400\n",
      "\n",
      "Batch 65/387 ━━━━━━━━━━━━━━━━━━━━ 00:55:01\n",
      "Accuracy: 0.9975 - Precision: 0.8822 - Recall: 0.8810 - Specificity: 0.9988 - F1: 0.8738 - Loss: 0.1417\n",
      "\n",
      "Batch 66/387 ━━━━━━━━━━━━━━━━━━━━ 00:56:35\n",
      "Accuracy: 0.9975 - Precision: 0.8787 - Recall: 0.8810 - Specificity: 0.9988 - F1: 0.8718 - Loss: 0.1437\n",
      "\n",
      "Batch 67/387 ━━━━━━━━━━━━━━━━━━━━ 00:58:08\n",
      "Accuracy: 0.9975 - Precision: 0.8795 - Recall: 0.8793 - Specificity: 0.9989 - F1: 0.8714 - Loss: 0.1441\n",
      "\n",
      "Batch 68/387 ━━━━━━━━━━━━━━━━━━━━ 00:59:30\n",
      "Accuracy: 0.9975 - Precision: 0.8803 - Recall: 0.8800 - Specificity: 0.9989 - F1: 0.8723 - Loss: 0.1431\n",
      "\n",
      "Batch 69/387 ━━━━━━━━━━━━━━━━━━━━ 01:01:04\n",
      "Accuracy: 0.9975 - Precision: 0.8779 - Recall: 0.8785 - Specificity: 0.9989 - F1: 0.8704 - Loss: 0.1450\n",
      "\n",
      "Batch 70/387 ━━━━━━━━━━━━━━━━━━━━ 01:02:28\n",
      "Accuracy: 0.9976 - Precision: 0.8760 - Recall: 0.8781 - Specificity: 0.9989 - F1: 0.8693 - Loss: 0.1460\n",
      "\n",
      "Batch 71/387 ━━━━━━━━━━━━━━━━━━━━ 01:03:58\n",
      "Accuracy: 0.9976 - Precision: 0.8775 - Recall: 0.8788 - Specificity: 0.9989 - F1: 0.8705 - Loss: 0.1448\n",
      "\n",
      "Batch 72/387 ━━━━━━━━━━━━━━━━━━━━ 01:05:29\n",
      "Accuracy: 0.9976 - Precision: 0.8784 - Recall: 0.8752 - Specificity: 0.9989 - F1: 0.8688 - Loss: 0.1463\n",
      "\n",
      "Batch 73/387 ━━━━━━━━━━━━━━━━━━━━ 01:07:00\n",
      "Accuracy: 0.9975 - Precision: 0.8798 - Recall: 0.8737 - Specificity: 0.9989 - F1: 0.8687 - Loss: 0.1467\n",
      "\n",
      "Batch 74/387 ━━━━━━━━━━━━━━━━━━━━ 01:08:26\n",
      "Accuracy: 0.9975 - Precision: 0.8798 - Recall: 0.8749 - Specificity: 0.9989 - F1: 0.8694 - Loss: 0.1459\n",
      "\n",
      "Batch 75/387 ━━━━━━━━━━━━━━━━━━━━ 01:09:51\n",
      "Accuracy: 0.9976 - Precision: 0.8803 - Recall: 0.8752 - Specificity: 0.9989 - F1: 0.8699 - Loss: 0.1453\n",
      "\n",
      "Batch 76/387 ━━━━━━━━━━━━━━━━━━━━ 01:11:32\n",
      "Accuracy: 0.9976 - Precision: 0.8801 - Recall: 0.8764 - Specificity: 0.9989 - F1: 0.8704 - Loss: 0.1446\n",
      "\n",
      "Batch 77/387 ━━━━━━━━━━━━━━━━━━━━ 01:12:57\n",
      "Accuracy: 0.9976 - Precision: 0.8812 - Recall: 0.8772 - Specificity: 0.9989 - F1: 0.8715 - Loss: 0.1436\n",
      "\n",
      "Batch 78/387 ━━━━━━━━━━━━━━━━━━━━ 01:14:33\n",
      "Accuracy: 0.9976 - Precision: 0.8816 - Recall: 0.8778 - Specificity: 0.9989 - F1: 0.8721 - Loss: 0.1429\n",
      "\n",
      "Batch 79/387 ━━━━━━━━━━━━━━━━━━━━ 01:15:57\n",
      "Accuracy: 0.9976 - Precision: 0.8825 - Recall: 0.8780 - Specificity: 0.9989 - F1: 0.8727 - Loss: 0.1423\n",
      "\n",
      "Batch 80/387 ━━━━━━━━━━━━━━━━━━━━ 01:17:25\n",
      "Accuracy: 0.9976 - Precision: 0.8837 - Recall: 0.8766 - Specificity: 0.9989 - F1: 0.8726 - Loss: 0.1424\n",
      "\n",
      "Batch 81/387 ━━━━━━━━━━━━━━━━━━━━ 01:18:59\n",
      "Accuracy: 0.9975 - Precision: 0.8850 - Recall: 0.8752 - Specificity: 0.9989 - F1: 0.8724 - Loss: 0.1429\n",
      "\n",
      "Batch 82/387 ━━━━━━━━━━━━━━━━━━━━ 01:20:38\n",
      "Accuracy: 0.9976 - Precision: 0.8844 - Recall: 0.8755 - Specificity: 0.9989 - F1: 0.8723 - Loss: 0.1430\n",
      "\n",
      "Batch 83/387 ━━━━━━━━━━━━━━━━━━━━ 01:22:01\n",
      "Accuracy: 0.9976 - Precision: 0.8844 - Recall: 0.8766 - Specificity: 0.9989 - F1: 0.8730 - Loss: 0.1422\n",
      "\n",
      "Batch 84/387 ━━━━━━━━━━━━━━━━━━━━ 01:23:30\n",
      "Accuracy: 0.9976 - Precision: 0.8843 - Recall: 0.8778 - Specificity: 0.9989 - F1: 0.8736 - Loss: 0.1415\n",
      "\n",
      "Batch 85/387 ━━━━━━━━━━━━━━━━━━━━ 01:24:51\n",
      "Accuracy: 0.9976 - Precision: 0.8847 - Recall: 0.8767 - Specificity: 0.9989 - F1: 0.8732 - Loss: 0.1418\n",
      "\n",
      "Batch 86/387 ━━━━━━━━━━━━━━━━━━━━ 01:26:22\n",
      "Accuracy: 0.9976 - Precision: 0.8835 - Recall: 0.8762 - Specificity: 0.9989 - F1: 0.8725 - Loss: 0.1426\n",
      "\n",
      "Batch 87/387 ━━━━━━━━━━━━━━━━━━━━ 01:27:51\n",
      "Accuracy: 0.9976 - Precision: 0.8831 - Recall: 0.8775 - Specificity: 0.9989 - F1: 0.8729 - Loss: 0.1420\n",
      "\n",
      "Batch 88/387 ━━━━━━━━━━━━━━━━━━━━ 01:29:22\n",
      "Accuracy: 0.9976 - Precision: 0.8818 - Recall: 0.8788 - Specificity: 0.9989 - F1: 0.8728 - Loss: 0.1421\n",
      "\n",
      "Batch 89/387 ━━━━━━━━━━━━━━━━━━━━ 01:30:55\n",
      "Accuracy: 0.9976 - Precision: 0.8828 - Recall: 0.8775 - Specificity: 0.9989 - F1: 0.8727 - Loss: 0.1423\n",
      "\n",
      "Batch 90/387 ━━━━━━━━━━━━━━━━━━━━ 01:32:23\n",
      "Accuracy: 0.9976 - Precision: 0.8818 - Recall: 0.8784 - Specificity: 0.9989 - F1: 0.8726 - Loss: 0.1424\n",
      "\n",
      "Batch 91/387 ━━━━━━━━━━━━━━━━━━━━ 01:33:44\n",
      "Accuracy: 0.9976 - Precision: 0.8828 - Recall: 0.8795 - Specificity: 0.9989 - F1: 0.8737 - Loss: 0.1411\n",
      "\n",
      "Batch 92/387 ━━━━━━━━━━━━━━━━━━━━ 01:35:02\n",
      "Accuracy: 0.9976 - Precision: 0.8834 - Recall: 0.8796 - Specificity: 0.9989 - F1: 0.8742 - Loss: 0.1408\n",
      "\n",
      "Batch 93/387 ━━━━━━━━━━━━━━━━━━━━ 01:36:36\n",
      "Accuracy: 0.9976 - Precision: 0.8820 - Recall: 0.8803 - Specificity: 0.9989 - F1: 0.8738 - Loss: 0.1410\n",
      "\n",
      "Batch 94/387 ━━━━━━━━━━━━━━━━━━━━ 01:38:03\n",
      "Accuracy: 0.9976 - Precision: 0.8814 - Recall: 0.8807 - Specificity: 0.9989 - F1: 0.8737 - Loss: 0.1412\n",
      "\n",
      "Batch 95/387 ━━━━━━━━━━━━━━━━━━━━ 01:39:40\n",
      "Accuracy: 0.9976 - Precision: 0.8797 - Recall: 0.8813 - Specificity: 0.9989 - F1: 0.8731 - Loss: 0.1417\n",
      "\n",
      "Batch 96/387 ━━━━━━━━━━━━━━━━━━━━ 01:41:17\n",
      "Accuracy: 0.9976 - Precision: 0.8790 - Recall: 0.8821 - Specificity: 0.9989 - F1: 0.8732 - Loss: 0.1416\n",
      "\n",
      "Batch 97/387 ━━━━━━━━━━━━━━━━━━━━ 01:42:53\n",
      "Accuracy: 0.9976 - Precision: 0.8758 - Recall: 0.8825 - Specificity: 0.9989 - F1: 0.8714 - Loss: 0.1433\n",
      "\n",
      "Batch 98/387 ━━━━━━━━━━━━━━━━━━━━ 01:44:13\n",
      "Accuracy: 0.9976 - Precision: 0.8767 - Recall: 0.8824 - Specificity: 0.9989 - F1: 0.8719 - Loss: 0.1427\n",
      "\n",
      "Batch 99/387 ━━━━━━━━━━━━━━━━━━━━ 01:45:45\n",
      "Accuracy: 0.9976 - Precision: 0.8779 - Recall: 0.8826 - Specificity: 0.9989 - F1: 0.8726 - Loss: 0.1420\n",
      "\n",
      "Batch 100/387 ━━━━━━━━━━━━━━━━━━━━ 01:47:21\n",
      "Accuracy: 0.9977 - Precision: 0.8786 - Recall: 0.8823 - Specificity: 0.9989 - F1: 0.8729 - Loss: 0.1417\n",
      "\n",
      "Batch 101/387 ━━━━━━━━━━━━━━━━━━━━ 01:48:46\n",
      "Accuracy: 0.9977 - Precision: 0.8788 - Recall: 0.8819 - Specificity: 0.9989 - F1: 0.8729 - Loss: 0.1417\n",
      "\n",
      "Batch 102/387 ━━━━━━━━━━━━━━━━━━━━ 08:51:32\n",
      "Accuracy: 0.9977 - Precision: 0.8800 - Recall: 0.8810 - Specificity: 0.9989 - F1: 0.8730 - Loss: 0.1415\n",
      "\n",
      "Batch 103/387 ━━━━━━━━━━━━━━━━━━━━ 08:53:00\n",
      "Accuracy: 0.9977 - Precision: 0.8809 - Recall: 0.8818 - Specificity: 0.9989 - F1: 0.8738 - Loss: 0.1406\n",
      "\n",
      "Batch 104/387 ━━━━━━━━━━━━━━━━━━━━ 08:54:26\n",
      "Accuracy: 0.9977 - Precision: 0.8819 - Recall: 0.8816 - Specificity: 0.9990 - F1: 0.8743 - Loss: 0.1401\n",
      "\n",
      "Batch 105/387 ━━━━━━━━━━━━━━━━━━━━ 08:55:53\n",
      "Accuracy: 0.9977 - Precision: 0.8830 - Recall: 0.8810 - Specificity: 0.9990 - F1: 0.8746 - Loss: 0.1398\n",
      "\n",
      "Batch 106/387 ━━━━━━━━━━━━━━━━━━━━ 08:57:43\n",
      "Accuracy: 0.9977 - Precision: 0.8840 - Recall: 0.8790 - Specificity: 0.9990 - F1: 0.8738 - Loss: 0.1407\n",
      "\n",
      "Batch 107/387 ━━━━━━━━━━━━━━━━━━━━ 08:59:07\n",
      "Accuracy: 0.9977 - Precision: 0.8850 - Recall: 0.8784 - Specificity: 0.9990 - F1: 0.8740 - Loss: 0.1406\n",
      "\n",
      "Batch 108/387 ━━━━━━━━━━━━━━━━━━━━ 09:00:26\n",
      "Accuracy: 0.9976 - Precision: 0.8860 - Recall: 0.8766 - Specificity: 0.9990 - F1: 0.8734 - Loss: 0.1412\n",
      "\n",
      "Batch 109/387 ━━━━━━━━━━━━━━━━━━━━ 09:01:43\n",
      "Accuracy: 0.9977 - Precision: 0.8862 - Recall: 0.8772 - Specificity: 0.9990 - F1: 0.8739 - Loss: 0.1407\n",
      "\n",
      "Batch 110/387 ━━━━━━━━━━━━━━━━━━━━ 09:03:21\n",
      "Accuracy: 0.9977 - Precision: 0.8868 - Recall: 0.8777 - Specificity: 0.9990 - F1: 0.8745 - Loss: 0.1400\n",
      "\n",
      "Batch 111/387 ━━━━━━━━━━━━━━━━━━━━ 09:04:44\n",
      "Accuracy: 0.9977 - Precision: 0.8872 - Recall: 0.8784 - Specificity: 0.9990 - F1: 0.8752 - Loss: 0.1393\n",
      "\n",
      "Batch 112/387 ━━━━━━━━━━━━━━━━━━━━ 09:06:13\n",
      "Accuracy: 0.9977 - Precision: 0.8877 - Recall: 0.8789 - Specificity: 0.9990 - F1: 0.8757 - Loss: 0.1387\n",
      "\n",
      "Batch 113/387 ━━━━━━━━━━━━━━━━━━━━ 09:07:38\n",
      "Accuracy: 0.9977 - Precision: 0.8880 - Recall: 0.8796 - Specificity: 0.9990 - F1: 0.8763 - Loss: 0.1381\n",
      "\n",
      "Batch 114/387 ━━━━━━━━━━━━━━━━━━━━ 09:09:09\n",
      "Accuracy: 0.9977 - Precision: 0.8878 - Recall: 0.8796 - Specificity: 0.9990 - F1: 0.8763 - Loss: 0.1381\n",
      "\n",
      "Batch 115/387 ━━━━━━━━━━━━━━━━━━━━ 09:10:35\n",
      "Accuracy: 0.9977 - Precision: 0.8865 - Recall: 0.8805 - Specificity: 0.9990 - F1: 0.8760 - Loss: 0.1384\n",
      "\n",
      "Batch 116/387 ━━━━━━━━━━━━━━━━━━━━ 09:11:53\n",
      "Accuracy: 0.9977 - Precision: 0.8851 - Recall: 0.8812 - Specificity: 0.9989 - F1: 0.8756 - Loss: 0.1390\n",
      "\n",
      "Batch 117/387 ━━━━━━━━━━━━━━━━━━━━ 09:13:26\n",
      "Accuracy: 0.9977 - Precision: 0.8854 - Recall: 0.8820 - Specificity: 0.9989 - F1: 0.8761 - Loss: 0.1384\n",
      "\n",
      "Batch 118/387 ━━━━━━━━━━━━━━━━━━━━ 09:14:51\n",
      "Accuracy: 0.9977 - Precision: 0.8852 - Recall: 0.8819 - Specificity: 0.9990 - F1: 0.8761 - Loss: 0.1384\n",
      "\n",
      "Batch 119/387 ━━━━━━━━━━━━━━━━━━━━ 09:16:15\n",
      "Accuracy: 0.9977 - Precision: 0.8850 - Recall: 0.8825 - Specificity: 0.9989 - F1: 0.8763 - Loss: 0.1382\n",
      "\n",
      "Batch 120/387 ━━━━━━━━━━━━━━━━━━━━ 09:17:41\n",
      "Accuracy: 0.9977 - Precision: 0.8857 - Recall: 0.8830 - Specificity: 0.9989 - F1: 0.8769 - Loss: 0.1375\n",
      "\n",
      "Batch 121/387 ━━━━━━━━━━━━━━━━━━━━ 09:19:10\n",
      "Accuracy: 0.9977 - Precision: 0.8851 - Recall: 0.8835 - Specificity: 0.9989 - F1: 0.8769 - Loss: 0.1376\n",
      "\n",
      "Batch 122/387 ━━━━━━━━━━━━━━━━━━━━ 09:20:35\n",
      "Accuracy: 0.9977 - Precision: 0.8855 - Recall: 0.8843 - Specificity: 0.9989 - F1: 0.8776 - Loss: 0.1369\n",
      "\n",
      "Batch 123/387 ━━━━━━━━━━━━━━━━━━━━ 09:22:04\n",
      "Accuracy: 0.9977 - Precision: 0.8860 - Recall: 0.8846 - Specificity: 0.9989 - F1: 0.8781 - Loss: 0.1364\n",
      "\n",
      "Batch 124/387 ━━━━━━━━━━━━━━━━━━━━ 09:23:33\n",
      "Accuracy: 0.9977 - Precision: 0.8866 - Recall: 0.8847 - Specificity: 0.9989 - F1: 0.8785 - Loss: 0.1360\n",
      "\n",
      "Batch 125/387 ━━━━━━━━━━━━━━━━━━━━ 09:24:59\n",
      "Accuracy: 0.9977 - Precision: 0.8851 - Recall: 0.8843 - Specificity: 0.9989 - F1: 0.8775 - Loss: 0.1369\n",
      "\n",
      "Batch 126/387 ━━━━━━━━━━━━━━━━━━━━ 09:26:33\n",
      "Accuracy: 0.9977 - Precision: 0.8859 - Recall: 0.8844 - Specificity: 0.9989 - F1: 0.8780 - Loss: 0.1363\n",
      "\n",
      "Batch 127/387 ━━━━━━━━━━━━━━━━━━━━ 09:28:27\n",
      "Accuracy: 0.9977 - Precision: 0.8865 - Recall: 0.8844 - Specificity: 0.9989 - F1: 0.8783 - Loss: 0.1361\n",
      "\n",
      "Batch 128/387 ━━━━━━━━━━━━━━━━━━━━ 09:29:56\n",
      "Accuracy: 0.9977 - Precision: 0.8864 - Recall: 0.8841 - Specificity: 0.9989 - F1: 0.8782 - Loss: 0.1361\n",
      "\n",
      "Batch 129/387 ━━━━━━━━━━━━━━━━━━━━ 09:31:16\n",
      "Accuracy: 0.9977 - Precision: 0.8872 - Recall: 0.8834 - Specificity: 0.9990 - F1: 0.8782 - Loss: 0.1361\n",
      "\n",
      "Batch 130/387 ━━━━━━━━━━━━━━━━━━━━ 09:32:46\n",
      "Accuracy: 0.9977 - Precision: 0.8880 - Recall: 0.8833 - Specificity: 0.9990 - F1: 0.8786 - Loss: 0.1358\n",
      "\n",
      "Batch 131/387 ━━━━━━━━━━━━━━━━━━━━ 09:34:13\n",
      "Accuracy: 0.9977 - Precision: 0.8887 - Recall: 0.8824 - Specificity: 0.9990 - F1: 0.8784 - Loss: 0.1359\n",
      "\n",
      "Batch 132/387 ━━━━━━━━━━━━━━━━━━━━ 09:35:48\n",
      "Accuracy: 0.9977 - Precision: 0.8889 - Recall: 0.8827 - Specificity: 0.9990 - F1: 0.8788 - Loss: 0.1355\n",
      "\n",
      "Batch 133/387 ━━━━━━━━━━━━━━━━━━━━ 09:37:05\n",
      "Accuracy: 0.9977 - Precision: 0.8894 - Recall: 0.8829 - Specificity: 0.9990 - F1: 0.8792 - Loss: 0.1351\n",
      "\n",
      "Batch 134/387 ━━━━━━━━━━━━━━━━━━━━ 09:38:26\n",
      "Accuracy: 0.9977 - Precision: 0.8901 - Recall: 0.8831 - Specificity: 0.9990 - F1: 0.8796 - Loss: 0.1346\n",
      "\n",
      "Batch 135/387 ━━━━━━━━━━━━━━━━━━━━ 09:39:59\n",
      "Accuracy: 0.9977 - Precision: 0.8906 - Recall: 0.8834 - Specificity: 0.9990 - F1: 0.8801 - Loss: 0.1341\n",
      "\n",
      "Batch 136/387 ━━━━━━━━━━━━━━━━━━━━ 09:41:37\n",
      "Accuracy: 0.9977 - Precision: 0.8911 - Recall: 0.8839 - Specificity: 0.9990 - F1: 0.8806 - Loss: 0.1335\n",
      "\n",
      "Batch 137/387 ━━━━━━━━━━━━━━━━━━━━ 09:43:05\n",
      "Accuracy: 0.9977 - Precision: 0.8904 - Recall: 0.8846 - Specificity: 0.9990 - F1: 0.8806 - Loss: 0.1335\n",
      "\n",
      "Batch 138/387 ━━━━━━━━━━━━━━━━━━━━ 09:44:47\n",
      "Accuracy: 0.9977 - Precision: 0.8897 - Recall: 0.8830 - Specificity: 0.9990 - F1: 0.8795 - Loss: 0.1347\n",
      "\n",
      "Batch 139/387 ━━━━━━━━━━━━━━━━━━━━ 09:46:22\n",
      "Accuracy: 0.9977 - Precision: 0.8902 - Recall: 0.8832 - Specificity: 0.9990 - F1: 0.8799 - Loss: 0.1343\n",
      "\n",
      "Batch 140/387 ━━━━━━━━━━━━━━━━━━━━ 09:47:57\n",
      "Accuracy: 0.9977 - Precision: 0.8906 - Recall: 0.8838 - Specificity: 0.9990 - F1: 0.8804 - Loss: 0.1337\n",
      "\n",
      "Batch 141/387 ━━━━━━━━━━━━━━━━━━━━ 09:49:28\n",
      "Accuracy: 0.9977 - Precision: 0.8909 - Recall: 0.8842 - Specificity: 0.9990 - F1: 0.8809 - Loss: 0.1332\n",
      "\n",
      "Batch 142/387 ━━━━━━━━━━━━━━━━━━━━ 09:50:58\n",
      "Accuracy: 0.9977 - Precision: 0.8883 - Recall: 0.8850 - Specificity: 0.9989 - F1: 0.8794 - Loss: 0.1349\n",
      "\n",
      "Batch 143/387 ━━━━━━━━━━━━━━━━━━━━ 09:52:23\n",
      "Accuracy: 0.9977 - Precision: 0.8882 - Recall: 0.8858 - Specificity: 0.9989 - F1: 0.8798 - Loss: 0.1345\n",
      "\n",
      "Batch 144/387 ━━━━━━━━━━━━━━━━━━━━ 09:53:52\n",
      "Accuracy: 0.9977 - Precision: 0.8887 - Recall: 0.8862 - Specificity: 0.9989 - F1: 0.8803 - Loss: 0.1340\n",
      "\n",
      "Batch 145/387 ━━━━━━━━━━━━━━━━━━━━ 09:55:12\n",
      "Accuracy: 0.9977 - Precision: 0.8890 - Recall: 0.8865 - Specificity: 0.9989 - F1: 0.8807 - Loss: 0.1336\n",
      "\n",
      "Batch 146/387 ━━━━━━━━━━━━━━━━━━━━ 09:56:35\n",
      "Accuracy: 0.9977 - Precision: 0.8895 - Recall: 0.8857 - Specificity: 0.9989 - F1: 0.8805 - Loss: 0.1337\n",
      "\n",
      "Batch 147/387 ━━━━━━━━━━━━━━━━━━━━ 09:57:59\n",
      "Accuracy: 0.9977 - Precision: 0.8900 - Recall: 0.8860 - Specificity: 0.9989 - F1: 0.8809 - Loss: 0.1333\n",
      "\n",
      "Batch 148/387 ━━━━━━━━━━━━━━━━━━━━ 09:59:33\n",
      "Accuracy: 0.9977 - Precision: 0.8903 - Recall: 0.8855 - Specificity: 0.9990 - F1: 0.8808 - Loss: 0.1334\n",
      "\n",
      "Batch 149/387 ━━━━━━━━━━━━━━━━━━━━ 10:01:09\n",
      "Accuracy: 0.9977 - Precision: 0.8901 - Recall: 0.8856 - Specificity: 0.9990 - F1: 0.8808 - Loss: 0.1334\n",
      "\n",
      "Batch 150/387 ━━━━━━━━━━━━━━━━━━━━ 10:02:28\n",
      "Accuracy: 0.9977 - Precision: 0.8901 - Recall: 0.8859 - Specificity: 0.9990 - F1: 0.8810 - Loss: 0.1331\n",
      "\n",
      "Batch 151/387 ━━━━━━━━━━━━━━━━━━━━ 10:03:58\n",
      "Accuracy: 0.9977 - Precision: 0.8901 - Recall: 0.8865 - Specificity: 0.9990 - F1: 0.8813 - Loss: 0.1327\n",
      "\n",
      "Batch 152/387 ━━━━━━━━━━━━━━━━━━━━ 10:05:28\n",
      "Accuracy: 0.9977 - Precision: 0.8895 - Recall: 0.8868 - Specificity: 0.9990 - F1: 0.8812 - Loss: 0.1328\n",
      "\n",
      "Batch 153/387 ━━━━━━━━━━━━━━━━━━━━ 10:06:54\n",
      "Accuracy: 0.9977 - Precision: 0.8901 - Recall: 0.8862 - Specificity: 0.9990 - F1: 0.8812 - Loss: 0.1329\n",
      "\n",
      "Batch 154/387 ━━━━━━━━━━━━━━━━━━━━ 10:08:16\n",
      "Accuracy: 0.9977 - Precision: 0.8908 - Recall: 0.8864 - Specificity: 0.9990 - F1: 0.8817 - Loss: 0.1324\n",
      "\n",
      "Batch 155/387 ━━━━━━━━━━━━━━━━━━━━ 10:09:37\n",
      "Accuracy: 0.9977 - Precision: 0.8913 - Recall: 0.8859 - Specificity: 0.9990 - F1: 0.8817 - Loss: 0.1323\n",
      "\n",
      "Batch 156/387 ━━━━━━━━━━━━━━━━━━━━ 10:10:59\n",
      "Accuracy: 0.9978 - Precision: 0.8913 - Recall: 0.8863 - Specificity: 0.9990 - F1: 0.8819 - Loss: 0.1321\n",
      "\n",
      "Batch 157/387 ━━━━━━━━━━━━━━━━━━━━ 10:12:24\n",
      "Accuracy: 0.9978 - Precision: 0.8911 - Recall: 0.8866 - Specificity: 0.9990 - F1: 0.8821 - Loss: 0.1319\n",
      "\n",
      "Batch 158/387 ━━━━━━━━━━━━━━━━━━━━ 10:13:48\n",
      "Accuracy: 0.9977 - Precision: 0.8913 - Recall: 0.8870 - Specificity: 0.9990 - F1: 0.8823 - Loss: 0.1316\n",
      "\n",
      "Batch 159/387 ━━━━━━━━━━━━━━━━━━━━ 10:15:22\n",
      "Accuracy: 0.9978 - Precision: 0.8917 - Recall: 0.8867 - Specificity: 0.9990 - F1: 0.8824 - Loss: 0.1315\n",
      "\n",
      "Batch 160/387 ━━━━━━━━━━━━━━━━━━━━ 10:16:57\n",
      "Accuracy: 0.9978 - Precision: 0.8920 - Recall: 0.8863 - Specificity: 0.9990 - F1: 0.8823 - Loss: 0.1316\n",
      "\n",
      "Batch 161/387 ━━━━━━━━━━━━━━━━━━━━ 10:18:15\n",
      "Accuracy: 0.9978 - Precision: 0.8913 - Recall: 0.8867 - Specificity: 0.9990 - F1: 0.8822 - Loss: 0.1317\n",
      "\n",
      "Batch 162/387 ━━━━━━━━━━━━━━━━━━━━ 10:19:38\n",
      "Accuracy: 0.9977 - Precision: 0.8905 - Recall: 0.8869 - Specificity: 0.9989 - F1: 0.8819 - Loss: 0.1321\n",
      "\n",
      "Batch 163/387 ━━━━━━━━━━━━━━━━━━━━ 10:21:21\n",
      "Accuracy: 0.9977 - Precision: 0.8909 - Recall: 0.8872 - Specificity: 0.9990 - F1: 0.8823 - Loss: 0.1316\n",
      "\n",
      "Batch 164/387 ━━━━━━━━━━━━━━━━━━━━ 10:22:51\n",
      "Accuracy: 0.9978 - Precision: 0.8906 - Recall: 0.8877 - Specificity: 0.9989 - F1: 0.8824 - Loss: 0.1315\n",
      "\n",
      "Batch 165/387 ━━━━━━━━━━━━━━━━━━━━ 10:24:17\n",
      "Accuracy: 0.9978 - Precision: 0.8906 - Recall: 0.8881 - Specificity: 0.9989 - F1: 0.8826 - Loss: 0.1313\n",
      "\n",
      "Batch 166/387 ━━━━━━━━━━━━━━━━━━━━ 10:25:48\n",
      "Accuracy: 0.9978 - Precision: 0.8910 - Recall: 0.8876 - Specificity: 0.9990 - F1: 0.8826 - Loss: 0.1313\n",
      "\n",
      "Batch 167/387 ━━━━━━━━━━━━━━━━━━━━ 10:27:23\n",
      "Accuracy: 0.9978 - Precision: 0.8898 - Recall: 0.8881 - Specificity: 0.9990 - F1: 0.8822 - Loss: 0.1316\n",
      "\n",
      "Batch 168/387 ━━━━━━━━━━━━━━━━━━━━ 10:28:44\n",
      "Accuracy: 0.9978 - Precision: 0.8887 - Recall: 0.8877 - Specificity: 0.9990 - F1: 0.8814 - Loss: 0.1324\n",
      "\n",
      "Batch 169/387 ━━━━━━━━━━━━━━━━━━━━ 10:30:12\n",
      "Accuracy: 0.9978 - Precision: 0.8875 - Recall: 0.8876 - Specificity: 0.9989 - F1: 0.8807 - Loss: 0.1332\n",
      "\n",
      "Batch 170/387 ━━━━━━━━━━━━━━━━━━━━ 10:31:48\n",
      "Accuracy: 0.9978 - Precision: 0.8879 - Recall: 0.8878 - Specificity: 0.9989 - F1: 0.8811 - Loss: 0.1328\n",
      "\n",
      "Batch 171/387 ━━━━━━━━━━━━━━━━━━━━ 10:33:18\n",
      "Accuracy: 0.9977 - Precision: 0.8884 - Recall: 0.8873 - Specificity: 0.9989 - F1: 0.8811 - Loss: 0.1329\n",
      "\n",
      "Batch 172/387 ━━━━━━━━━━━━━━━━━━━━ 10:34:36\n",
      "Accuracy: 0.9978 - Precision: 0.8889 - Recall: 0.8876 - Specificity: 0.9989 - F1: 0.8815 - Loss: 0.1324\n",
      "\n",
      "Batch 173/387 ━━━━━━━━━━━━━━━━━━━━ 10:36:10\n",
      "Accuracy: 0.9978 - Precision: 0.8894 - Recall: 0.8877 - Specificity: 0.9989 - F1: 0.8818 - Loss: 0.1321\n",
      "\n",
      "Batch 174/387 ━━━━━━━━━━━━━━━━━━━━ 10:37:41\n",
      "Accuracy: 0.9978 - Precision: 0.8899 - Recall: 0.8880 - Specificity: 0.9990 - F1: 0.8822 - Loss: 0.1316\n",
      "\n",
      "Batch 175/387 ━━━━━━━━━━━━━━━━━━━━ 10:39:13\n",
      "Accuracy: 0.9978 - Precision: 0.8902 - Recall: 0.8885 - Specificity: 0.9990 - F1: 0.8827 - Loss: 0.1311\n",
      "\n",
      "Batch 176/387 ━━━━━━━━━━━━━━━━━━━━ 10:40:31\n",
      "Accuracy: 0.9978 - Precision: 0.8907 - Recall: 0.8886 - Specificity: 0.9990 - F1: 0.8830 - Loss: 0.1307\n",
      "\n",
      "Batch 177/387 ━━━━━━━━━━━━━━━━━━━━ 10:42:05\n",
      "Accuracy: 0.9978 - Precision: 0.8911 - Recall: 0.8881 - Specificity: 0.9990 - F1: 0.8830 - Loss: 0.1308\n",
      "\n",
      "Batch 178/387 ━━━━━━━━━━━━━━━━━━━━ 10:43:36\n",
      "Accuracy: 0.9978 - Precision: 0.8916 - Recall: 0.8866 - Specificity: 0.9990 - F1: 0.8823 - Loss: 0.1314\n",
      "\n",
      "Batch 179/387 ━━━━━━━━━━━━━━━━━━━━ 10:44:50\n",
      "Accuracy: 0.9978 - Precision: 0.8921 - Recall: 0.8866 - Specificity: 0.9990 - F1: 0.8826 - Loss: 0.1312\n",
      "\n",
      "Batch 180/387 ━━━━━━━━━━━━━━━━━━━━ 10:46:21\n",
      "Accuracy: 0.9978 - Precision: 0.8923 - Recall: 0.8858 - Specificity: 0.9990 - F1: 0.8823 - Loss: 0.1315\n",
      "\n",
      "Batch 181/387 ━━━━━━━━━━━━━━━━━━━━ 10:47:56\n",
      "Accuracy: 0.9978 - Precision: 0.8925 - Recall: 0.8860 - Specificity: 0.9990 - F1: 0.8825 - Loss: 0.1313\n",
      "\n",
      "Batch 182/387 ━━━━━━━━━━━━━━━━━━━━ 10:49:18\n",
      "Accuracy: 0.9978 - Precision: 0.8925 - Recall: 0.8863 - Specificity: 0.9990 - F1: 0.8827 - Loss: 0.1310\n",
      "\n",
      "Batch 183/387 ━━━━━━━━━━━━━━━━━━━━ 10:50:51\n",
      "Accuracy: 0.9978 - Precision: 0.8930 - Recall: 0.8865 - Specificity: 0.9990 - F1: 0.8830 - Loss: 0.1306\n",
      "\n",
      "Batch 184/387 ━━━━━━━━━━━━━━━━━━━━ 10:52:15\n",
      "Accuracy: 0.9978 - Precision: 0.8934 - Recall: 0.8860 - Specificity: 0.9990 - F1: 0.8830 - Loss: 0.1306\n",
      "\n",
      "Batch 185/387 ━━━━━━━━━━━━━━━━━━━━ 10:53:46\n",
      "Accuracy: 0.9978 - Precision: 0.8934 - Recall: 0.8859 - Specificity: 0.9990 - F1: 0.8830 - Loss: 0.1307\n",
      "\n",
      "Batch 186/387 ━━━━━━━━━━━━━━━━━━━━ 10:55:07\n",
      "Accuracy: 0.9978 - Precision: 0.8934 - Recall: 0.8863 - Specificity: 0.9990 - F1: 0.8833 - Loss: 0.1304\n",
      "\n",
      "Batch 187/387 ━━━━━━━━━━━━━━━━━━━━ 10:56:34\n",
      "Accuracy: 0.9978 - Precision: 0.8926 - Recall: 0.8864 - Specificity: 0.9990 - F1: 0.8829 - Loss: 0.1307\n",
      "\n",
      "Batch 188/387 ━━━━━━━━━━━━━━━━━━━━ 10:58:04\n",
      "Accuracy: 0.9978 - Precision: 0.8931 - Recall: 0.8866 - Specificity: 0.9990 - F1: 0.8832 - Loss: 0.1304\n",
      "\n",
      "Batch 189/387 ━━━━━━━━━━━━━━━━━━━━ 10:59:37\n",
      "Accuracy: 0.9978 - Precision: 0.8925 - Recall: 0.8871 - Specificity: 0.9990 - F1: 0.8832 - Loss: 0.1305\n",
      "\n",
      "Batch 190/387 ━━━━━━━━━━━━━━━━━━━━ 11:01:05\n",
      "Accuracy: 0.9978 - Precision: 0.8915 - Recall: 0.8876 - Specificity: 0.9990 - F1: 0.8828 - Loss: 0.1308\n",
      "\n",
      "Batch 191/387 ━━━━━━━━━━━━━━━━━━━━ 11:02:40\n",
      "Accuracy: 0.9978 - Precision: 0.8915 - Recall: 0.8859 - Specificity: 0.9990 - F1: 0.8818 - Loss: 0.1319\n",
      "\n",
      "Batch 192/387 ━━━━━━━━━━━━━━━━━━━━ 11:04:17\n",
      "Accuracy: 0.9978 - Precision: 0.8917 - Recall: 0.8862 - Specificity: 0.9990 - F1: 0.8821 - Loss: 0.1315\n",
      "\n",
      "Batch 193/387 ━━━━━━━━━━━━━━━━━━━━ 11:05:58\n",
      "Accuracy: 0.9978 - Precision: 0.8916 - Recall: 0.8866 - Specificity: 0.9990 - F1: 0.8823 - Loss: 0.1313\n",
      "\n",
      "Batch 194/387 ━━━━━━━━━━━━━━━━━━━━ 11:07:27\n",
      "Accuracy: 0.9978 - Precision: 0.8921 - Recall: 0.8867 - Specificity: 0.9990 - F1: 0.8826 - Loss: 0.1310\n",
      "\n",
      "Batch 195/387 ━━━━━━━━━━━━━━━━━━━━ 11:09:05\n",
      "Accuracy: 0.9978 - Precision: 0.8913 - Recall: 0.8871 - Specificity: 0.9990 - F1: 0.8824 - Loss: 0.1312\n",
      "\n",
      "Batch 196/387 ━━━━━━━━━━━━━━━━━━━━ 11:10:40\n",
      "Accuracy: 0.9978 - Precision: 0.8916 - Recall: 0.8875 - Specificity: 0.9990 - F1: 0.8827 - Loss: 0.1308\n",
      "\n",
      "Batch 197/387 ━━━━━━━━━━━━━━━━━━━━ 11:12:17\n",
      "Accuracy: 0.9978 - Precision: 0.8909 - Recall: 0.8880 - Specificity: 0.9990 - F1: 0.8826 - Loss: 0.1310\n",
      "\n",
      "Batch 198/387 ━━━━━━━━━━━━━━━━━━━━ 11:13:49\n",
      "Accuracy: 0.9978 - Precision: 0.8911 - Recall: 0.8882 - Specificity: 0.9990 - F1: 0.8829 - Loss: 0.1307\n",
      "\n",
      "Batch 199/387 ━━━━━━━━━━━━━━━━━━━━ 11:15:12\n",
      "Accuracy: 0.9978 - Precision: 0.8912 - Recall: 0.8885 - Specificity: 0.9990 - F1: 0.8831 - Loss: 0.1305\n",
      "\n",
      "Batch 200/387 ━━━━━━━━━━━━━━━━━━━━ 11:16:31\n",
      "Accuracy: 0.9978 - Precision: 0.8916 - Recall: 0.8888 - Specificity: 0.9990 - F1: 0.8834 - Loss: 0.1301\n",
      "\n",
      "Batch 201/387 ━━━━━━━━━━━━━━━━━━━━ 11:18:06\n",
      "Accuracy: 0.9978 - Precision: 0.8920 - Recall: 0.8886 - Specificity: 0.9990 - F1: 0.8835 - Loss: 0.1300\n",
      "\n",
      "Batch 202/387 ━━━━━━━━━━━━━━━━━━━━ 11:19:40\n",
      "Accuracy: 0.9978 - Precision: 0.8922 - Recall: 0.8888 - Specificity: 0.9990 - F1: 0.8838 - Loss: 0.1297\n",
      "\n",
      "Batch 203/387 ━━━━━━━━━━━━━━━━━━━━ 11:21:05\n",
      "Accuracy: 0.9978 - Precision: 0.8924 - Recall: 0.8890 - Specificity: 0.9990 - F1: 0.8840 - Loss: 0.1295\n",
      "\n",
      "Batch 204/387 ━━━━━━━━━━━━━━━━━━━━ 11:22:28\n",
      "Accuracy: 0.9978 - Precision: 0.8928 - Recall: 0.8887 - Specificity: 0.9990 - F1: 0.8841 - Loss: 0.1295\n",
      "\n",
      "Batch 205/387 ━━━━━━━━━━━━━━━━━━━━ 11:24:00\n",
      "Accuracy: 0.9978 - Precision: 0.8929 - Recall: 0.8890 - Specificity: 0.9990 - F1: 0.8843 - Loss: 0.1293\n",
      "\n",
      "Batch 206/387 ━━━━━━━━━━━━━━━━━━━━ 11:25:37\n",
      "Accuracy: 0.9978 - Precision: 0.8920 - Recall: 0.8895 - Specificity: 0.9990 - F1: 0.8841 - Loss: 0.1295\n",
      "\n",
      "Batch 207/387 ━━━━━━━━━━━━━━━━━━━━ 11:26:59\n",
      "Accuracy: 0.9978 - Precision: 0.8920 - Recall: 0.8898 - Specificity: 0.9990 - F1: 0.8842 - Loss: 0.1293\n",
      "\n",
      "Batch 208/387 ━━━━━━━━━━━━━━━━━━━━ 11:28:22\n",
      "Accuracy: 0.9978 - Precision: 0.8923 - Recall: 0.8901 - Specificity: 0.9990 - F1: 0.8846 - Loss: 0.1289\n",
      "\n",
      "Batch 209/387 ━━━━━━━━━━━━━━━━━━━━ 11:29:56\n",
      "Accuracy: 0.9978 - Precision: 0.8921 - Recall: 0.8900 - Specificity: 0.9990 - F1: 0.8844 - Loss: 0.1291\n",
      "\n",
      "Batch 210/387 ━━━━━━━━━━━━━━━━━━━━ 11:31:27\n",
      "Accuracy: 0.9978 - Precision: 0.8923 - Recall: 0.8895 - Specificity: 0.9990 - F1: 0.8843 - Loss: 0.1293\n",
      "\n",
      "Batch 211/387 ━━━━━━━━━━━━━━━━━━━━ 11:33:09\n",
      "Accuracy: 0.9978 - Precision: 0.8928 - Recall: 0.8893 - Specificity: 0.9990 - F1: 0.8844 - Loss: 0.1292\n",
      "\n",
      "Batch 212/387 ━━━━━━━━━━━━━━━━━━━━ 11:34:38\n",
      "Accuracy: 0.9978 - Precision: 0.8925 - Recall: 0.8895 - Specificity: 0.9990 - F1: 0.8844 - Loss: 0.1292\n",
      "\n",
      "Batch 213/387 ━━━━━━━━━━━━━━━━━━━━ 11:36:29\n",
      "Accuracy: 0.9978 - Precision: 0.8926 - Recall: 0.8896 - Specificity: 0.9990 - F1: 0.8845 - Loss: 0.1291\n",
      "\n",
      "Batch 214/387 ━━━━━━━━━━━━━━━━━━━━ 11:37:53\n",
      "Accuracy: 0.9978 - Precision: 0.8929 - Recall: 0.8899 - Specificity: 0.9990 - F1: 0.8849 - Loss: 0.1287\n",
      "\n",
      "Batch 215/387 ━━━━━━━━━━━━━━━━━━━━ 11:39:26\n",
      "Accuracy: 0.9978 - Precision: 0.8933 - Recall: 0.8901 - Specificity: 0.9990 - F1: 0.8852 - Loss: 0.1284\n",
      "\n",
      "Batch 216/387 ━━━━━━━━━━━━━━━━━━━━ 11:40:56\n",
      "Accuracy: 0.9978 - Precision: 0.8934 - Recall: 0.8904 - Specificity: 0.9990 - F1: 0.8855 - Loss: 0.1281\n",
      "\n",
      "Batch 217/387 ━━━━━━━━━━━━━━━━━━━━ 11:42:16\n",
      "Accuracy: 0.9978 - Precision: 0.8938 - Recall: 0.8900 - Specificity: 0.9990 - F1: 0.8854 - Loss: 0.1281\n",
      "\n",
      "Batch 218/387 ━━━━━━━━━━━━━━━━━━━━ 11:43:50\n",
      "Accuracy: 0.9978 - Precision: 0.8943 - Recall: 0.8902 - Specificity: 0.9990 - F1: 0.8858 - Loss: 0.1278\n",
      "\n",
      "Batch 219/387 ━━━━━━━━━━━━━━━━━━━━ 11:45:16\n",
      "Accuracy: 0.9978 - Precision: 0.8938 - Recall: 0.8897 - Specificity: 0.9990 - F1: 0.8853 - Loss: 0.1283\n",
      "\n",
      "Batch 220/387 ━━━━━━━━━━━━━━━━━━━━ 11:46:50\n",
      "Accuracy: 0.9978 - Precision: 0.8941 - Recall: 0.8901 - Specificity: 0.9990 - F1: 0.8857 - Loss: 0.1279\n",
      "\n",
      "Batch 221/387 ━━━━━━━━━━━━━━━━━━━━ 11:48:32\n",
      "Accuracy: 0.9978 - Precision: 0.8939 - Recall: 0.8905 - Specificity: 0.9990 - F1: 0.8858 - Loss: 0.1277\n",
      "\n",
      "Batch 222/387 ━━━━━━━━━━━━━━━━━━━━ 11:50:00\n",
      "Accuracy: 0.9978 - Precision: 0.8942 - Recall: 0.8908 - Specificity: 0.9990 - F1: 0.8862 - Loss: 0.1274\n",
      "\n",
      "Batch 223/387 ━━━━━━━━━━━━━━━━━━━━ 11:51:23\n",
      "Accuracy: 0.9978 - Precision: 0.8945 - Recall: 0.8908 - Specificity: 0.9990 - F1: 0.8863 - Loss: 0.1272\n",
      "\n",
      "Batch 224/387 ━━━━━━━━━━━━━━━━━━━━ 11:52:54\n",
      "Accuracy: 0.9978 - Precision: 0.8938 - Recall: 0.8911 - Specificity: 0.9990 - F1: 0.8861 - Loss: 0.1274\n",
      "\n",
      "Batch 225/387 ━━━━━━━━━━━━━━━━━━━━ 11:54:19\n",
      "Accuracy: 0.9978 - Precision: 0.8940 - Recall: 0.8915 - Specificity: 0.9990 - F1: 0.8864 - Loss: 0.1271\n",
      "\n",
      "Batch 226/387 ━━━━━━━━━━━━━━━━━━━━ 11:55:59\n",
      "Accuracy: 0.9978 - Precision: 0.8940 - Recall: 0.8915 - Specificity: 0.9990 - F1: 0.8864 - Loss: 0.1271\n",
      "\n",
      "Batch 227/387 ━━━━━━━━━━━━━━━━━━━━ 11:57:33\n",
      "Accuracy: 0.9978 - Precision: 0.8944 - Recall: 0.8914 - Specificity: 0.9990 - F1: 0.8866 - Loss: 0.1269\n",
      "\n",
      "Batch 228/387 ━━━━━━━━━━━━━━━━━━━━ 11:59:07\n",
      "Accuracy: 0.9978 - Precision: 0.8946 - Recall: 0.8916 - Specificity: 0.9990 - F1: 0.8868 - Loss: 0.1267\n",
      "\n",
      "Batch 229/387 ━━━━━━━━━━━━━━━━━━━━ 12:00:48\n",
      "Accuracy: 0.9978 - Precision: 0.8937 - Recall: 0.8920 - Specificity: 0.9990 - F1: 0.8865 - Loss: 0.1270\n",
      "\n",
      "Batch 230/387 ━━━━━━━━━━━━━━━━━━━━ 12:02:30\n",
      "Accuracy: 0.9978 - Precision: 0.8936 - Recall: 0.8923 - Specificity: 0.9990 - F1: 0.8866 - Loss: 0.1269\n",
      "\n",
      "Batch 231/387 ━━━━━━━━━━━━━━━━━━━━ 12:04:18\n",
      "Accuracy: 0.9978 - Precision: 0.8937 - Recall: 0.8916 - Specificity: 0.9990 - F1: 0.8863 - Loss: 0.1271\n",
      "\n",
      "Batch 232/387 ━━━━━━━━━━━━━━━━━━━━ 12:05:48\n",
      "Accuracy: 0.9978 - Precision: 0.8940 - Recall: 0.8916 - Specificity: 0.9990 - F1: 0.8864 - Loss: 0.1270\n",
      "\n",
      "Batch 233/387 ━━━━━━━━━━━━━━━━━━━━ 12:07:14\n",
      "Accuracy: 0.9978 - Precision: 0.8942 - Recall: 0.8915 - Specificity: 0.9990 - F1: 0.8865 - Loss: 0.1269\n",
      "\n",
      "Batch 234/387 ━━━━━━━━━━━━━━━━━━━━ 12:08:58\n",
      "Accuracy: 0.9978 - Precision: 0.8945 - Recall: 0.8916 - Specificity: 0.9990 - F1: 0.8868 - Loss: 0.1266\n",
      "\n",
      "Batch 235/387 ━━━━━━━━━━━━━━━━━━━━ 12:10:49\n",
      "Accuracy: 0.9978 - Precision: 0.8947 - Recall: 0.8918 - Specificity: 0.9990 - F1: 0.8869 - Loss: 0.1264\n",
      "\n",
      "Batch 236/387 ━━━━━━━━━━━━━━━━━━━━ 12:12:22\n",
      "Accuracy: 0.9978 - Precision: 0.8950 - Recall: 0.8908 - Specificity: 0.9990 - F1: 0.8865 - Loss: 0.1269\n",
      "\n",
      "Batch 237/387 ━━━━━━━━━━━━━━━━━━━━ 12:13:47\n",
      "Accuracy: 0.9978 - Precision: 0.8953 - Recall: 0.8903 - Specificity: 0.9990 - F1: 0.8864 - Loss: 0.1271\n",
      "\n",
      "Batch 238/387 ━━━━━━━━━━━━━━━━━━━━ 12:15:14\n",
      "Accuracy: 0.9978 - Precision: 0.8951 - Recall: 0.8907 - Specificity: 0.9990 - F1: 0.8865 - Loss: 0.1270\n",
      "\n",
      "Batch 239/387 ━━━━━━━━━━━━━━━━━━━━ 12:16:44\n",
      "Accuracy: 0.9978 - Precision: 0.8951 - Recall: 0.8911 - Specificity: 0.9990 - F1: 0.8867 - Loss: 0.1267\n",
      "\n",
      "Batch 240/387 ━━━━━━━━━━━━━━━━━━━━ 12:18:15\n",
      "Accuracy: 0.9978 - Precision: 0.8955 - Recall: 0.8913 - Specificity: 0.9990 - F1: 0.8870 - Loss: 0.1264\n",
      "\n",
      "Batch 241/387 ━━━━━━━━━━━━━━━━━━━━ 12:19:36\n",
      "Accuracy: 0.9978 - Precision: 0.8952 - Recall: 0.8916 - Specificity: 0.9990 - F1: 0.8871 - Loss: 0.1263\n",
      "\n",
      "Batch 242/387 ━━━━━━━━━━━━━━━━━━━━ 12:21:09\n",
      "Accuracy: 0.9978 - Precision: 0.8948 - Recall: 0.8916 - Specificity: 0.9990 - F1: 0.8869 - Loss: 0.1265\n",
      "\n",
      "Batch 243/387 ━━━━━━━━━━━━━━━━━━━━ 12:22:48\n",
      "Accuracy: 0.9978 - Precision: 0.8948 - Recall: 0.8920 - Specificity: 0.9990 - F1: 0.8871 - Loss: 0.1263\n",
      "\n",
      "Batch 244/387 ━━━━━━━━━━━━━━━━━━━━ 12:24:22\n",
      "Accuracy: 0.9978 - Precision: 0.8949 - Recall: 0.8923 - Specificity: 0.9990 - F1: 0.8873 - Loss: 0.1260\n",
      "\n",
      "Batch 245/387 ━━━━━━━━━━━━━━━━━━━━ 12:26:00\n",
      "Accuracy: 0.9978 - Precision: 0.8947 - Recall: 0.8927 - Specificity: 0.9990 - F1: 0.8874 - Loss: 0.1259\n",
      "\n",
      "Batch 246/387 ━━━━━━━━━━━━━━━━━━━━ 12:27:35\n",
      "Accuracy: 0.9978 - Precision: 0.8949 - Recall: 0.8928 - Specificity: 0.9990 - F1: 0.8876 - Loss: 0.1257\n",
      "\n",
      "Batch 247/387 ━━━━━━━━━━━━━━━━━━━━ 12:29:03\n",
      "Accuracy: 0.9978 - Precision: 0.8951 - Recall: 0.8929 - Specificity: 0.9990 - F1: 0.8878 - Loss: 0.1256\n",
      "\n",
      "Batch 248/387 ━━━━━━━━━━━━━━━━━━━━ 12:30:35\n",
      "Accuracy: 0.9978 - Precision: 0.8955 - Recall: 0.8930 - Specificity: 0.9990 - F1: 0.8880 - Loss: 0.1253\n",
      "\n",
      "Batch 249/387 ━━━━━━━━━━━━━━━━━━━━ 12:32:13\n",
      "Accuracy: 0.9978 - Precision: 0.8953 - Recall: 0.8933 - Specificity: 0.9990 - F1: 0.8881 - Loss: 0.1252\n",
      "\n",
      "Batch 250/387 ━━━━━━━━━━━━━━━━━━━━ 12:33:47\n",
      "Accuracy: 0.9978 - Precision: 0.8957 - Recall: 0.8931 - Specificity: 0.9990 - F1: 0.8882 - Loss: 0.1252\n",
      "\n",
      "Batch 251/387 ━━━━━━━━━━━━━━━━━━━━ 12:35:23\n",
      "Accuracy: 0.9978 - Precision: 0.8959 - Recall: 0.8931 - Specificity: 0.9990 - F1: 0.8883 - Loss: 0.1250\n",
      "\n",
      "Batch 252/387 ━━━━━━━━━━━━━━━━━━━━ 12:36:55\n",
      "Accuracy: 0.9978 - Precision: 0.8959 - Recall: 0.8929 - Specificity: 0.9990 - F1: 0.8883 - Loss: 0.1251\n",
      "\n",
      "Batch 253/387 ━━━━━━━━━━━━━━━━━━━━ 12:38:37\n",
      "Accuracy: 0.9978 - Precision: 0.8957 - Recall: 0.8933 - Specificity: 0.9990 - F1: 0.8883 - Loss: 0.1250\n",
      "\n",
      "Batch 254/387 ━━━━━━━━━━━━━━━━━━━━ 12:40:13\n",
      "Accuracy: 0.9978 - Precision: 0.8960 - Recall: 0.8929 - Specificity: 0.9990 - F1: 0.8883 - Loss: 0.1250\n",
      "\n",
      "Batch 255/387 ━━━━━━━━━━━━━━━━━━━━ 12:41:54\n",
      "Accuracy: 0.9978 - Precision: 0.8953 - Recall: 0.8932 - Specificity: 0.9990 - F1: 0.8880 - Loss: 0.1253\n",
      "\n",
      "Batch 256/387 ━━━━━━━━━━━━━━━━━━━━ 12:43:30\n",
      "Accuracy: 0.9978 - Precision: 0.8955 - Recall: 0.8934 - Specificity: 0.9990 - F1: 0.8882 - Loss: 0.1251\n",
      "\n",
      "Batch 257/387 ━━━━━━━━━━━━━━━━━━━━ 12:45:11\n",
      "Accuracy: 0.9978 - Precision: 0.8957 - Recall: 0.8926 - Specificity: 0.9990 - F1: 0.8879 - Loss: 0.1254\n",
      "\n",
      "Batch 258/387 ━━━━━━━━━━━━━━━━━━━━ 12:46:53\n",
      "Accuracy: 0.9979 - Precision: 0.8953 - Recall: 0.8927 - Specificity: 0.9990 - F1: 0.8878 - Loss: 0.1255\n",
      "\n",
      "Batch 259/387 ━━━━━━━━━━━━━━━━━━━━ 12:48:27\n",
      "Accuracy: 0.9979 - Precision: 0.8956 - Recall: 0.8929 - Specificity: 0.9990 - F1: 0.8880 - Loss: 0.1252\n",
      "\n",
      "Batch 260/387 ━━━━━━━━━━━━━━━━━━━━ 12:50:01\n",
      "Accuracy: 0.9979 - Precision: 0.8958 - Recall: 0.8928 - Specificity: 0.9990 - F1: 0.8881 - Loss: 0.1251\n",
      "\n",
      "Batch 261/387 ━━━━━━━━━━━━━━━━━━━━ 12:51:34\n",
      "Accuracy: 0.9979 - Precision: 0.8961 - Recall: 0.8929 - Specificity: 0.9990 - F1: 0.8884 - Loss: 0.1249\n",
      "\n",
      "Batch 262/387 ━━━━━━━━━━━━━━━━━━━━ 12:53:12\n",
      "Accuracy: 0.9979 - Precision: 0.8960 - Recall: 0.8931 - Specificity: 0.9990 - F1: 0.8884 - Loss: 0.1248\n",
      "\n",
      "Batch 263/387 ━━━━━━━━━━━━━━━━━━━━ 12:54:49\n",
      "Accuracy: 0.9979 - Precision: 0.8959 - Recall: 0.8932 - Specificity: 0.9990 - F1: 0.8884 - Loss: 0.1248\n",
      "\n",
      "Batch 264/387 ━━━━━━━━━━━━━━━━━━━━ 12:56:31\n",
      "Accuracy: 0.9979 - Precision: 0.8962 - Recall: 0.8932 - Specificity: 0.9990 - F1: 0.8886 - Loss: 0.1246\n",
      "\n",
      "Batch 265/387 ━━━━━━━━━━━━━━━━━━━━ 12:57:58\n",
      "Accuracy: 0.9979 - Precision: 0.8966 - Recall: 0.8927 - Specificity: 0.9990 - F1: 0.8885 - Loss: 0.1248\n",
      "\n",
      "Batch 266/387 ━━━━━━━━━━━━━━━━━━━━ 12:59:40\n",
      "Accuracy: 0.9979 - Precision: 0.8969 - Recall: 0.8927 - Specificity: 0.9990 - F1: 0.8887 - Loss: 0.1246\n",
      "\n",
      "Batch 267/387 ━━━━━━━━━━━━━━━━━━━━ 13:01:06\n",
      "Accuracy: 0.9979 - Precision: 0.8968 - Recall: 0.8928 - Specificity: 0.9990 - F1: 0.8887 - Loss: 0.1246\n",
      "\n",
      "Batch 268/387 ━━━━━━━━━━━━━━━━━━━━ 13:02:34\n",
      "Accuracy: 0.9979 - Precision: 0.8969 - Recall: 0.8930 - Specificity: 0.9990 - F1: 0.8888 - Loss: 0.1244\n",
      "\n",
      "Batch 269/387 ━━━━━━━━━━━━━━━━━━━━ 13:04:00\n",
      "Accuracy: 0.9979 - Precision: 0.8967 - Recall: 0.8932 - Specificity: 0.9990 - F1: 0.8889 - Loss: 0.1244\n",
      "\n",
      "Batch 270/387 ━━━━━━━━━━━━━━━━━━━━ 13:05:49\n",
      "Accuracy: 0.9979 - Precision: 0.8969 - Recall: 0.8934 - Specificity: 0.9990 - F1: 0.8891 - Loss: 0.1241\n",
      "\n",
      "Batch 271/387 ━━━━━━━━━━━━━━━━━━━━ 13:07:21\n",
      "Accuracy: 0.9979 - Precision: 0.8970 - Recall: 0.8936 - Specificity: 0.9990 - F1: 0.8893 - Loss: 0.1239\n",
      "\n",
      "Batch 272/387 ━━━━━━━━━━━━━━━━━━━━ 13:08:48\n",
      "Accuracy: 0.9979 - Precision: 0.8967 - Recall: 0.8938 - Specificity: 0.9990 - F1: 0.8892 - Loss: 0.1240\n",
      "\n",
      "Batch 273/387 ━━━━━━━━━━━━━━━━━━━━ 13:10:17\n",
      "Accuracy: 0.9979 - Precision: 0.8970 - Recall: 0.8938 - Specificity: 0.9990 - F1: 0.8894 - Loss: 0.1238\n",
      "\n",
      "Batch 274/387 ━━━━━━━━━━━━━━━━━━━━ 13:11:52\n",
      "Accuracy: 0.9979 - Precision: 0.8972 - Recall: 0.8937 - Specificity: 0.9990 - F1: 0.8894 - Loss: 0.1238\n",
      "\n",
      "Batch 275/387 ━━━━━━━━━━━━━━━━━━━━ 13:13:19\n",
      "Accuracy: 0.9979 - Precision: 0.8975 - Recall: 0.8936 - Specificity: 0.9990 - F1: 0.8895 - Loss: 0.1237\n",
      "\n",
      "Batch 276/387 ━━━━━━━━━━━━━━━━━━━━ 13:14:50\n",
      "Accuracy: 0.9979 - Precision: 0.8976 - Recall: 0.8937 - Specificity: 0.9990 - F1: 0.8897 - Loss: 0.1235\n",
      "\n",
      "Batch 277/387 ━━━━━━━━━━━━━━━━━━━━ 13:16:20\n",
      "Accuracy: 0.9979 - Precision: 0.8977 - Recall: 0.8940 - Specificity: 0.9990 - F1: 0.8899 - Loss: 0.1233\n",
      "\n",
      "Batch 278/387 ━━━━━━━━━━━━━━━━━━━━ 13:17:58\n",
      "Accuracy: 0.9979 - Precision: 0.8971 - Recall: 0.8941 - Specificity: 0.9990 - F1: 0.8896 - Loss: 0.1235\n",
      "\n",
      "Batch 279/387 ━━━━━━━━━━━━━━━━━━━━ 13:19:36\n",
      "Accuracy: 0.9979 - Precision: 0.8972 - Recall: 0.8943 - Specificity: 0.9990 - F1: 0.8898 - Loss: 0.1234\n",
      "\n",
      "Batch 280/387 ━━━━━━━━━━━━━━━━━━━━ 13:21:16\n",
      "Accuracy: 0.9979 - Precision: 0.8969 - Recall: 0.8938 - Specificity: 0.9990 - F1: 0.8894 - Loss: 0.1238\n",
      "\n",
      "Batch 281/387 ━━━━━━━━━━━━━━━━━━━━ 13:22:56\n",
      "Accuracy: 0.9979 - Precision: 0.8965 - Recall: 0.8942 - Specificity: 0.9990 - F1: 0.8894 - Loss: 0.1238\n",
      "\n",
      "Batch 282/387 ━━━━━━━━━━━━━━━━━━━━ 13:24:28\n",
      "Accuracy: 0.9979 - Precision: 0.8967 - Recall: 0.8932 - Specificity: 0.9990 - F1: 0.8889 - Loss: 0.1243\n",
      "\n",
      "Batch 283/387 ━━━━━━━━━━━━━━━━━━━━ 13:26:00\n",
      "Accuracy: 0.9979 - Precision: 0.8969 - Recall: 0.8934 - Specificity: 0.9990 - F1: 0.8891 - Loss: 0.1241\n",
      "\n",
      "Batch 284/387 ━━━━━━━━━━━━━━━━━━━━ 13:27:29\n",
      "Accuracy: 0.9979 - Precision: 0.8970 - Recall: 0.8934 - Specificity: 0.9990 - F1: 0.8892 - Loss: 0.1240\n",
      "\n",
      "Batch 285/387 ━━━━━━━━━━━━━━━━━━━━ 13:28:52\n",
      "Accuracy: 0.9979 - Precision: 0.8971 - Recall: 0.8936 - Specificity: 0.9990 - F1: 0.8893 - Loss: 0.1239\n",
      "\n",
      "Batch 286/387 ━━━━━━━━━━━━━━━━━━━━ 13:30:34\n",
      "Accuracy: 0.9979 - Precision: 0.8972 - Recall: 0.8931 - Specificity: 0.9990 - F1: 0.8891 - Loss: 0.1240\n",
      "\n",
      "Batch 287/387 ━━━━━━━━━━━━━━━━━━━━ 13:32:24\n",
      "Accuracy: 0.9979 - Precision: 0.8973 - Recall: 0.8932 - Specificity: 0.9990 - F1: 0.8892 - Loss: 0.1239\n",
      "\n",
      "Batch 288/387 ━━━━━━━━━━━━━━━━━━━━ 13:33:57\n",
      "Accuracy: 0.9979 - Precision: 0.8973 - Recall: 0.8935 - Specificity: 0.9990 - F1: 0.8894 - Loss: 0.1238\n",
      "\n",
      "Batch 289/387 ━━━━━━━━━━━━━━━━━━━━ 13:35:31\n",
      "Accuracy: 0.9979 - Precision: 0.8974 - Recall: 0.8930 - Specificity: 0.9990 - F1: 0.8892 - Loss: 0.1240\n",
      "\n",
      "Batch 290/387 ━━━━━━━━━━━━━━━━━━━━ 13:36:51\n",
      "Accuracy: 0.9979 - Precision: 0.8969 - Recall: 0.8930 - Specificity: 0.9990 - F1: 0.8890 - Loss: 0.1242\n",
      "\n",
      "Batch 291/387 ━━━━━━━━━━━━━━━━━━━━ 13:38:27\n",
      "Accuracy: 0.9979 - Precision: 0.8967 - Recall: 0.8931 - Specificity: 0.9990 - F1: 0.8889 - Loss: 0.1244\n",
      "\n",
      "Batch 292/387 ━━━━━━━━━━━━━━━━━━━━ 13:39:53\n",
      "Accuracy: 0.9979 - Precision: 0.8968 - Recall: 0.8930 - Specificity: 0.9990 - F1: 0.8889 - Loss: 0.1243\n",
      "\n",
      "Batch 293/387 ━━━━━━━━━━━━━━━━━━━━ 13:41:25\n",
      "Accuracy: 0.9979 - Precision: 0.8965 - Recall: 0.8932 - Specificity: 0.9990 - F1: 0.8888 - Loss: 0.1244\n",
      "\n",
      "Batch 294/387 ━━━━━━━━━━━━━━━━━━━━ 13:42:54\n",
      "Accuracy: 0.9979 - Precision: 0.8967 - Recall: 0.8933 - Specificity: 0.9990 - F1: 0.8891 - Loss: 0.1242\n",
      "\n",
      "Batch 295/387 ━━━━━━━━━━━━━━━━━━━━ 13:44:17\n",
      "Accuracy: 0.9978 - Precision: 0.8965 - Recall: 0.8933 - Specificity: 0.9990 - F1: 0.8890 - Loss: 0.1243\n",
      "\n",
      "Batch 296/387 ━━━━━━━━━━━━━━━━━━━━ 13:45:36\n",
      "Accuracy: 0.9978 - Precision: 0.8968 - Recall: 0.8932 - Specificity: 0.9990 - F1: 0.8891 - Loss: 0.1242\n",
      "\n",
      "Batch 297/387 ━━━━━━━━━━━━━━━━━━━━ 13:46:58\n",
      "Accuracy: 0.9978 - Precision: 0.8964 - Recall: 0.8934 - Specificity: 0.9990 - F1: 0.8890 - Loss: 0.1243\n",
      "\n",
      "Batch 298/387 ━━━━━━━━━━━━━━━━━━━━ 13:48:25\n",
      "Accuracy: 0.9978 - Precision: 0.8966 - Recall: 0.8936 - Specificity: 0.9990 - F1: 0.8892 - Loss: 0.1241\n",
      "\n",
      "Batch 299/387 ━━━━━━━━━━━━━━━━━━━━ 13:50:02\n",
      "Accuracy: 0.9978 - Precision: 0.8967 - Recall: 0.8927 - Specificity: 0.9990 - F1: 0.8887 - Loss: 0.1246\n",
      "\n",
      "Batch 300/387 ━━━━━━━━━━━━━━━━━━━━ 13:51:41\n",
      "Accuracy: 0.9978 - Precision: 0.8966 - Recall: 0.8928 - Specificity: 0.9990 - F1: 0.8888 - Loss: 0.1245\n",
      "\n",
      "Batch 301/387 ━━━━━━━━━━━━━━━━━━━━ 13:53:06\n",
      "Accuracy: 0.9978 - Precision: 0.8969 - Recall: 0.8929 - Specificity: 0.9990 - F1: 0.8890 - Loss: 0.1243\n",
      "\n",
      "Batch 302/387 ━━━━━━━━━━━━━━━━━━━━ 13:54:28\n",
      "Accuracy: 0.9978 - Precision: 0.8968 - Recall: 0.8931 - Specificity: 0.9990 - F1: 0.8890 - Loss: 0.1242\n",
      "\n",
      "Batch 303/387 ━━━━━━━━━━━━━━━━━━━━ 13:56:01\n",
      "Accuracy: 0.9978 - Precision: 0.8961 - Recall: 0.8933 - Specificity: 0.9990 - F1: 0.8887 - Loss: 0.1246\n",
      "\n",
      "Batch 304/387 ━━━━━━━━━━━━━━━━━━━━ 13:57:34\n",
      "Accuracy: 0.9978 - Precision: 0.8957 - Recall: 0.8934 - Specificity: 0.9990 - F1: 0.8886 - Loss: 0.1247\n",
      "\n",
      "Batch 305/387 ━━━━━━━━━━━━━━━━━━━━ 13:59:06\n",
      "Accuracy: 0.9978 - Precision: 0.8960 - Recall: 0.8935 - Specificity: 0.9990 - F1: 0.8887 - Loss: 0.1245\n",
      "\n",
      "Batch 306/387 ━━━━━━━━━━━━━━━━━━━━ 14:00:28\n",
      "Accuracy: 0.9978 - Precision: 0.8960 - Recall: 0.8934 - Specificity: 0.9990 - F1: 0.8887 - Loss: 0.1245\n",
      "\n",
      "Batch 307/387 ━━━━━━━━━━━━━━━━━━━━ 14:01:55\n",
      "Accuracy: 0.9978 - Precision: 0.8954 - Recall: 0.8935 - Specificity: 0.9990 - F1: 0.8884 - Loss: 0.1248\n",
      "\n",
      "Batch 308/387 ━━━━━━━━━━━━━━━━━━━━ 14:03:40\n",
      "Accuracy: 0.9978 - Precision: 0.8954 - Recall: 0.8933 - Specificity: 0.9990 - F1: 0.8884 - Loss: 0.1249\n",
      "\n",
      "Batch 309/387 ━━━━━━━━━━━━━━━━━━━━ 14:05:07\n",
      "Accuracy: 0.9978 - Precision: 0.8954 - Recall: 0.8931 - Specificity: 0.9990 - F1: 0.8883 - Loss: 0.1250\n",
      "\n",
      "Batch 310/387 ━━━━━━━━━━━━━━━━━━━━ 14:06:29\n",
      "Accuracy: 0.9978 - Precision: 0.8955 - Recall: 0.8933 - Specificity: 0.9990 - F1: 0.8885 - Loss: 0.1247\n",
      "\n",
      "Batch 311/387 ━━━━━━━━━━━━━━━━━━━━ 14:08:04\n",
      "Accuracy: 0.9978 - Precision: 0.8957 - Recall: 0.8935 - Specificity: 0.9990 - F1: 0.8886 - Loss: 0.1246\n",
      "\n",
      "Batch 312/387 ━━━━━━━━━━━━━━━━━━━━ 14:09:33\n",
      "Accuracy: 0.9978 - Precision: 0.8957 - Recall: 0.8937 - Specificity: 0.9990 - F1: 0.8888 - Loss: 0.1244\n",
      "\n",
      "Batch 313/387 ━━━━━━━━━━━━━━━━━━━━ 14:10:56\n",
      "Accuracy: 0.9978 - Precision: 0.8959 - Recall: 0.8938 - Specificity: 0.9990 - F1: 0.8890 - Loss: 0.1242\n",
      "\n",
      "Batch 314/387 ━━━━━━━━━━━━━━━━━━━━ 14:12:24\n",
      "Accuracy: 0.9978 - Precision: 0.8960 - Recall: 0.8934 - Specificity: 0.9990 - F1: 0.8888 - Loss: 0.1244\n",
      "\n",
      "Batch 315/387 ━━━━━━━━━━━━━━━━━━━━ 14:13:50\n",
      "Accuracy: 0.9978 - Precision: 0.8960 - Recall: 0.8937 - Specificity: 0.9990 - F1: 0.8889 - Loss: 0.1243\n",
      "\n",
      "Batch 316/387 ━━━━━━━━━━━━━━━━━━━━ 14:15:32\n",
      "Accuracy: 0.9978 - Precision: 0.8955 - Recall: 0.8932 - Specificity: 0.9990 - F1: 0.8885 - Loss: 0.1248\n",
      "\n",
      "Batch 317/387 ━━━━━━━━━━━━━━━━━━━━ 14:17:07\n",
      "Accuracy: 0.9978 - Precision: 0.8956 - Recall: 0.8934 - Specificity: 0.9990 - F1: 0.8887 - Loss: 0.1246\n",
      "\n",
      "Batch 318/387 ━━━━━━━━━━━━━━━━━━━━ 14:18:41\n",
      "Accuracy: 0.9978 - Precision: 0.8958 - Recall: 0.8936 - Specificity: 0.9990 - F1: 0.8889 - Loss: 0.1244\n",
      "\n",
      "Batch 319/387 ━━━━━━━━━━━━━━━━━━━━ 14:20:06\n",
      "Accuracy: 0.9978 - Precision: 0.8959 - Recall: 0.8935 - Specificity: 0.9990 - F1: 0.8889 - Loss: 0.1243\n",
      "\n",
      "Batch 320/387 ━━━━━━━━━━━━━━━━━━━━ 14:22:14\n",
      "Accuracy: 0.9978 - Precision: 0.8961 - Recall: 0.8935 - Specificity: 0.9990 - F1: 0.8890 - Loss: 0.1242\n",
      "\n",
      "Batch 321/387 ━━━━━━━━━━━━━━━━━━━━ 14:23:41\n",
      "Accuracy: 0.9978 - Precision: 0.8962 - Recall: 0.8934 - Specificity: 0.9990 - F1: 0.8890 - Loss: 0.1242\n",
      "\n",
      "Batch 322/387 ━━━━━━━━━━━━━━━━━━━━ 14:25:26\n",
      "Accuracy: 0.9978 - Precision: 0.8957 - Recall: 0.8931 - Specificity: 0.9990 - F1: 0.8886 - Loss: 0.1246\n",
      "\n",
      "Batch 323/387 ━━━━━━━━━━━━━━━━━━━━ 14:27:02\n",
      "Accuracy: 0.9978 - Precision: 0.8958 - Recall: 0.8930 - Specificity: 0.9990 - F1: 0.8887 - Loss: 0.1246\n",
      "\n",
      "Batch 324/387 ━━━━━━━━━━━━━━━━━━━━ 14:28:33\n",
      "Accuracy: 0.9978 - Precision: 0.8960 - Recall: 0.8929 - Specificity: 0.9990 - F1: 0.8887 - Loss: 0.1246\n",
      "\n",
      "Batch 325/387 ━━━━━━━━━━━━━━━━━━━━ 14:30:05\n",
      "Accuracy: 0.9978 - Precision: 0.8961 - Recall: 0.8929 - Specificity: 0.9990 - F1: 0.8887 - Loss: 0.1245\n",
      "\n",
      "Batch 326/387 ━━━━━━━━━━━━━━━━━━━━ 14:31:29\n",
      "Accuracy: 0.9978 - Precision: 0.8957 - Recall: 0.8926 - Specificity: 0.9990 - F1: 0.8884 - Loss: 0.1249\n",
      "\n",
      "Batch 327/387 ━━━━━━━━━━━━━━━━━━━━ 14:33:01\n",
      "Accuracy: 0.9978 - Precision: 0.8959 - Recall: 0.8926 - Specificity: 0.9990 - F1: 0.8885 - Loss: 0.1247\n",
      "\n",
      "Batch 328/387 ━━━━━━━━━━━━━━━━━━━━ 14:34:21\n",
      "Accuracy: 0.9978 - Precision: 0.8956 - Recall: 0.8926 - Specificity: 0.9990 - F1: 0.8884 - Loss: 0.1248\n",
      "\n",
      "Batch 329/387 ━━━━━━━━━━━━━━━━━━━━ 14:35:45\n",
      "Accuracy: 0.9978 - Precision: 0.8955 - Recall: 0.8929 - Specificity: 0.9990 - F1: 0.8885 - Loss: 0.1248\n",
      "\n",
      "Batch 330/387 ━━━━━━━━━━━━━━━━━━━━ 14:37:12\n",
      "Accuracy: 0.9978 - Precision: 0.8956 - Recall: 0.8931 - Specificity: 0.9990 - F1: 0.8887 - Loss: 0.1246\n",
      "\n",
      "Batch 331/387 ━━━━━━━━━━━━━━━━━━━━ 14:38:41\n",
      "Accuracy: 0.9978 - Precision: 0.8957 - Recall: 0.8934 - Specificity: 0.9990 - F1: 0.8889 - Loss: 0.1243\n",
      "\n",
      "Batch 332/387 ━━━━━━━━━━━━━━━━━━━━ 14:40:17\n",
      "Accuracy: 0.9978 - Precision: 0.8959 - Recall: 0.8935 - Specificity: 0.9990 - F1: 0.8891 - Loss: 0.1241\n",
      "\n",
      "Batch 333/387 ━━━━━━━━━━━━━━━━━━━━ 14:41:53\n",
      "Accuracy: 0.9978 - Precision: 0.8958 - Recall: 0.8936 - Specificity: 0.9990 - F1: 0.8891 - Loss: 0.1241\n",
      "\n",
      "Batch 334/387 ━━━━━━━━━━━━━━━━━━━━ 14:43:21\n",
      "Accuracy: 0.9978 - Precision: 0.8951 - Recall: 0.8937 - Specificity: 0.9990 - F1: 0.8887 - Loss: 0.1245\n",
      "\n",
      "Batch 335/387 ━━━━━━━━━━━━━━━━━━━━ 14:44:45\n",
      "Accuracy: 0.9978 - Precision: 0.8951 - Recall: 0.8939 - Specificity: 0.9990 - F1: 0.8888 - Loss: 0.1244\n",
      "\n",
      "Batch 336/387 ━━━━━━━━━━━━━━━━━━━━ 14:46:26\n",
      "Accuracy: 0.9978 - Precision: 0.8952 - Recall: 0.8940 - Specificity: 0.9990 - F1: 0.8890 - Loss: 0.1243\n",
      "\n",
      "Batch 337/387 ━━━━━━━━━━━━━━━━━━━━ 14:47:59\n",
      "Accuracy: 0.9978 - Precision: 0.8953 - Recall: 0.8938 - Specificity: 0.9990 - F1: 0.8889 - Loss: 0.1243\n",
      "\n",
      "Batch 338/387 ━━━━━━━━━━━━━━━━━━━━ 14:49:31\n",
      "Accuracy: 0.9978 - Precision: 0.8953 - Recall: 0.8938 - Specificity: 0.9990 - F1: 0.8889 - Loss: 0.1243\n",
      "\n",
      "Batch 339/387 ━━━━━━━━━━━━━━━━━━━━ 14:51:09\n",
      "Accuracy: 0.9978 - Precision: 0.8950 - Recall: 0.8938 - Specificity: 0.9990 - F1: 0.8888 - Loss: 0.1245\n",
      "\n",
      "Batch 340/387 ━━━━━━━━━━━━━━━━━━━━ 14:52:40\n",
      "Accuracy: 0.9978 - Precision: 0.8951 - Recall: 0.8938 - Specificity: 0.9990 - F1: 0.8889 - Loss: 0.1244\n",
      "\n",
      "Batch 341/387 ━━━━━━━━━━━━━━━━━━━━ 14:54:11\n",
      "Accuracy: 0.9978 - Precision: 0.8954 - Recall: 0.8936 - Specificity: 0.9990 - F1: 0.8889 - Loss: 0.1244\n",
      "\n",
      "Batch 342/387 ━━━━━━━━━━━━━━━━━━━━ 14:55:42\n",
      "Accuracy: 0.9978 - Precision: 0.8954 - Recall: 0.8937 - Specificity: 0.9990 - F1: 0.8889 - Loss: 0.1244\n",
      "\n",
      "Batch 343/387 ━━━━━━━━━━━━━━━━━━━━ 14:57:22\n",
      "Accuracy: 0.9978 - Precision: 0.8950 - Recall: 0.8937 - Specificity: 0.9990 - F1: 0.8887 - Loss: 0.1246\n",
      "\n",
      "Batch 344/387 ━━━━━━━━━━━━━━━━━━━━ 14:58:55\n",
      "Accuracy: 0.9978 - Precision: 0.8951 - Recall: 0.8936 - Specificity: 0.9990 - F1: 0.8888 - Loss: 0.1246\n",
      "\n",
      "Batch 345/387 ━━━━━━━━━━━━━━━━━━━━ 15:00:14\n",
      "Accuracy: 0.9978 - Precision: 0.8952 - Recall: 0.8936 - Specificity: 0.9990 - F1: 0.8888 - Loss: 0.1245\n",
      "\n",
      "Batch 346/387 ━━━━━━━━━━━━━━━━━━━━ 15:01:42\n",
      "Accuracy: 0.9978 - Precision: 0.8954 - Recall: 0.8935 - Specificity: 0.9990 - F1: 0.8889 - Loss: 0.1244\n",
      "\n",
      "Batch 347/387 ━━━━━━━━━━━━━━━━━━━━ 15:03:13\n",
      "Accuracy: 0.9978 - Precision: 0.8957 - Recall: 0.8934 - Specificity: 0.9990 - F1: 0.8890 - Loss: 0.1243\n",
      "\n",
      "Batch 348/387 ━━━━━━━━━━━━━━━━━━━━ 15:04:46\n",
      "Accuracy: 0.9978 - Precision: 0.8960 - Recall: 0.8933 - Specificity: 0.9990 - F1: 0.8891 - Loss: 0.1242\n",
      "\n",
      "Batch 349/387 ━━━━━━━━━━━━━━━━━━━━ 15:06:19\n",
      "Accuracy: 0.9978 - Precision: 0.8963 - Recall: 0.8932 - Specificity: 0.9990 - F1: 0.8892 - Loss: 0.1241\n",
      "\n",
      "Batch 350/387 ━━━━━━━━━━━━━━━━━━━━ 15:07:44\n",
      "Accuracy: 0.9978 - Precision: 0.8965 - Recall: 0.8925 - Specificity: 0.9990 - F1: 0.8888 - Loss: 0.1245\n",
      "\n",
      "Batch 351/387 ━━━━━━━━━━━━━━━━━━━━ 15:09:21\n",
      "Accuracy: 0.9978 - Precision: 0.8967 - Recall: 0.8924 - Specificity: 0.9990 - F1: 0.8889 - Loss: 0.1245\n",
      "\n",
      "Batch 352/387 ━━━━━━━━━━━━━━━━━━━━ 15:10:59\n",
      "Accuracy: 0.9978 - Precision: 0.8961 - Recall: 0.8920 - Specificity: 0.9990 - F1: 0.8884 - Loss: 0.1249\n",
      "\n",
      "Batch 353/387 ━━━━━━━━━━━━━━━━━━━━ 15:12:30\n",
      "Accuracy: 0.9978 - Precision: 0.8964 - Recall: 0.8917 - Specificity: 0.9990 - F1: 0.8884 - Loss: 0.1249\n",
      "\n",
      "Batch 354/387 ━━━━━━━━━━━━━━━━━━━━ 15:14:10\n",
      "Accuracy: 0.9978 - Precision: 0.8964 - Recall: 0.8918 - Specificity: 0.9990 - F1: 0.8885 - Loss: 0.1248\n",
      "\n",
      "Batch 355/387 ━━━━━━━━━━━━━━━━━━━━ 15:15:41\n",
      "Accuracy: 0.9978 - Precision: 0.8966 - Recall: 0.8920 - Specificity: 0.9990 - F1: 0.8887 - Loss: 0.1247\n",
      "\n",
      "Batch 356/387 ━━━━━━━━━━━━━━━━━━━━ 15:17:17\n",
      "Accuracy: 0.9978 - Precision: 0.8966 - Recall: 0.8922 - Specificity: 0.9990 - F1: 0.8888 - Loss: 0.1245\n",
      "\n",
      "Batch 357/387 ━━━━━━━━━━━━━━━━━━━━ 15:18:59\n",
      "Accuracy: 0.9978 - Precision: 0.8968 - Recall: 0.8923 - Specificity: 0.9990 - F1: 0.8890 - Loss: 0.1243\n",
      "\n",
      "Batch 358/387 ━━━━━━━━━━━━━━━━━━━━ 15:20:38\n",
      "Accuracy: 0.9978 - Precision: 0.8965 - Recall: 0.8926 - Specificity: 0.9990 - F1: 0.8889 - Loss: 0.1244\n",
      "\n",
      "Batch 359/387 ━━━━━━━━━━━━━━━━━━━━ 15:22:13\n",
      "Accuracy: 0.9978 - Precision: 0.8965 - Recall: 0.8928 - Specificity: 0.9990 - F1: 0.8890 - Loss: 0.1242\n",
      "\n",
      "Batch 360/387 ━━━━━━━━━━━━━━━━━━━━ 15:23:41\n",
      "Accuracy: 0.9978 - Precision: 0.8967 - Recall: 0.8930 - Specificity: 0.9990 - F1: 0.8892 - Loss: 0.1240\n",
      "\n",
      "Batch 361/387 ━━━━━━━━━━━━━━━━━━━━ 15:24:58\n",
      "Accuracy: 0.9978 - Precision: 0.8967 - Recall: 0.8930 - Specificity: 0.9990 - F1: 0.8893 - Loss: 0.1240\n",
      "\n",
      "Batch 362/387 ━━━━━━━━━━━━━━━━━━━━ 15:26:41\n",
      "Accuracy: 0.9978 - Precision: 0.8968 - Recall: 0.8930 - Specificity: 0.9990 - F1: 0.8893 - Loss: 0.1239\n",
      "\n",
      "Batch 363/387 ━━━━━━━━━━━━━━━━━━━━ 15:28:20\n",
      "Accuracy: 0.9978 - Precision: 0.8968 - Recall: 0.8932 - Specificity: 0.9990 - F1: 0.8895 - Loss: 0.1238\n",
      "\n",
      "Batch 364/387 ━━━━━━━━━━━━━━━━━━━━ 15:29:51\n",
      "Accuracy: 0.9978 - Precision: 0.8969 - Recall: 0.8934 - Specificity: 0.9990 - F1: 0.8896 - Loss: 0.1236\n",
      "\n",
      "Batch 365/387 ━━━━━━━━━━━━━━━━━━━━ 15:31:15\n",
      "Accuracy: 0.9978 - Precision: 0.8969 - Recall: 0.8936 - Specificity: 0.9990 - F1: 0.8897 - Loss: 0.1235\n",
      "\n",
      "Batch 366/387 ━━━━━━━━━━━━━━━━━━━━ 15:32:58\n",
      "Accuracy: 0.9978 - Precision: 0.8965 - Recall: 0.8938 - Specificity: 0.9990 - F1: 0.8896 - Loss: 0.1236\n",
      "\n",
      "Batch 367/387 ━━━━━━━━━━━━━━━━━━━━ 15:34:28\n",
      "Accuracy: 0.9979 - Precision: 0.8962 - Recall: 0.8940 - Specificity: 0.9990 - F1: 0.8895 - Loss: 0.1237\n",
      "\n",
      "Batch 368/387 ━━━━━━━━━━━━━━━━━━━━ 15:35:50\n",
      "Accuracy: 0.9978 - Precision: 0.8964 - Recall: 0.8938 - Specificity: 0.9990 - F1: 0.8895 - Loss: 0.1237\n",
      "\n",
      "Batch 369/387 ━━━━━━━━━━━━━━━━━━━━ 15:37:26\n",
      "Accuracy: 0.9978 - Precision: 0.8959 - Recall: 0.8940 - Specificity: 0.9990 - F1: 0.8894 - Loss: 0.1239\n",
      "\n",
      "Batch 370/387 ━━━━━━━━━━━━━━━━━━━━ 15:38:56\n",
      "Accuracy: 0.9978 - Precision: 0.8960 - Recall: 0.8937 - Specificity: 0.9990 - F1: 0.8893 - Loss: 0.1240\n",
      "\n",
      "Batch 371/387 ━━━━━━━━━━━━━━━━━━━━ 15:40:37\n",
      "Accuracy: 0.9978 - Precision: 0.8961 - Recall: 0.8933 - Specificity: 0.9990 - F1: 0.8891 - Loss: 0.1241\n",
      "\n",
      "Batch 372/387 ━━━━━━━━━━━━━━━━━━━━ 15:42:20\n",
      "Accuracy: 0.9978 - Precision: 0.8962 - Recall: 0.8933 - Specificity: 0.9990 - F1: 0.8892 - Loss: 0.1241\n",
      "\n",
      "Batch 373/387 ━━━━━━━━━━━━━━━━━━━━ 15:44:05\n",
      "Accuracy: 0.9978 - Precision: 0.8963 - Recall: 0.8934 - Specificity: 0.9990 - F1: 0.8893 - Loss: 0.1240\n",
      "\n",
      "Batch 374/387 ━━━━━━━━━━━━━━━━━━━━ 15:45:48\n",
      "Accuracy: 0.9978 - Precision: 0.8958 - Recall: 0.8934 - Specificity: 0.9990 - F1: 0.8890 - Loss: 0.1242\n",
      "\n",
      "Batch 375/387 ━━━━━━━━━━━━━━━━━━━━ 15:47:27\n",
      "Accuracy: 0.9978 - Precision: 0.8960 - Recall: 0.8936 - Specificity: 0.9990 - F1: 0.8892 - Loss: 0.1241\n",
      "\n",
      "Batch 376/387 ━━━━━━━━━━━━━━━━━━━━ 15:49:03\n",
      "Accuracy: 0.9978 - Precision: 0.8962 - Recall: 0.8936 - Specificity: 0.9990 - F1: 0.8893 - Loss: 0.1239\n",
      "\n",
      "Batch 377/387 ━━━━━━━━━━━━━━━━━━━━ 15:50:31\n",
      "Accuracy: 0.9978 - Precision: 0.8963 - Recall: 0.8935 - Specificity: 0.9990 - F1: 0.8893 - Loss: 0.1239\n",
      "\n",
      "Batch 378/387 ━━━━━━━━━━━━━━━━━━━━ 15:51:57\n",
      "Accuracy: 0.9978 - Precision: 0.8965 - Recall: 0.8932 - Specificity: 0.9990 - F1: 0.8892 - Loss: 0.1240\n",
      "\n",
      "Batch 379/387 ━━━━━━━━━━━━━━━━━━━━ 15:53:26\n",
      "Accuracy: 0.9978 - Precision: 0.8962 - Recall: 0.8934 - Specificity: 0.9990 - F1: 0.8892 - Loss: 0.1240\n",
      "\n",
      "Batch 380/387 ━━━━━━━━━━━━━━━━━━━━ 15:54:49\n",
      "Accuracy: 0.9978 - Precision: 0.8963 - Recall: 0.8933 - Specificity: 0.9990 - F1: 0.8892 - Loss: 0.1240\n",
      "\n",
      "Batch 381/387 ━━━━━━━━━━━━━━━━━━━━ 15:56:18\n",
      "Accuracy: 0.9978 - Precision: 0.8962 - Recall: 0.8935 - Specificity: 0.9990 - F1: 0.8893 - Loss: 0.1240\n",
      "\n",
      "Batch 382/387 ━━━━━━━━━━━━━━━━━━━━ 15:57:48\n",
      "Accuracy: 0.9978 - Precision: 0.8964 - Recall: 0.8930 - Specificity: 0.9990 - F1: 0.8891 - Loss: 0.1242\n",
      "\n",
      "Batch 383/387 ━━━━━━━━━━━━━━━━━━━━ 15:59:22\n",
      "Accuracy: 0.9978 - Precision: 0.8965 - Recall: 0.8932 - Specificity: 0.9990 - F1: 0.8892 - Loss: 0.1241\n",
      "\n",
      "Batch 384/387 ━━━━━━━━━━━━━━━━━━━━ 16:01:01\n",
      "Accuracy: 0.9978 - Precision: 0.8964 - Recall: 0.8930 - Specificity: 0.9990 - F1: 0.8891 - Loss: 0.1242\n",
      "\n",
      "Batch 385/387 ━━━━━━━━━━━━━━━━━━━━ 16:02:31\n",
      "Accuracy: 0.9978 - Precision: 0.8957 - Recall: 0.8931 - Specificity: 0.9990 - F1: 0.8888 - Loss: 0.1245\n",
      "\n",
      "Batch 386/387 ━━━━━━━━━━━━━━━━━━━━ 16:04:00\n",
      "Accuracy: 0.9978 - Precision: 0.8958 - Recall: 0.8932 - Specificity: 0.9990 - F1: 0.8889 - Loss: 0.1244\n",
      "\n",
      "Batch 387/387 ━━━━━━━━━━━━━━━━━━━━ 16:05:34\n",
      "Accuracy: 0.9978 - Precision: 0.8959 - Recall: 0.8934 - Specificity: 0.9990 - F1: 0.8890 - Loss: 0.1242\n",
      "\n",
      "End of Epoch 14\n",
      "\n",
      "Epoch 15/50\n",
      "Batch 1/387 ━━━━━━━━━━━━━━━━━━━━ 16:28:00\n",
      "Accuracy: 0.9969 - Precision: 0.7122 - Recall: 0.9775 - Specificity: 0.9970 - F1: 0.8240 - Loss: 0.1899\n",
      "\n",
      "Batch 2/387 ━━━━━━━━━━━━━━━━━━━━ 16:29:33\n",
      "Accuracy: 0.9976 - Precision: 0.8415 - Recall: 0.9652 - Specificity: 0.9982 - F1: 0.8929 - Loss: 0.1183\n",
      "\n",
      "Batch 3/387 ━━━━━━━━━━━━━━━━━━━━ 16:31:18\n",
      "Accuracy: 0.9979 - Precision: 0.8546 - Recall: 0.9424 - Specificity: 0.9985 - F1: 0.8915 - Loss: 0.1192\n",
      "\n",
      "Batch 4/387 ━━━━━━━━━━━━━━━━━━━━ 16:32:59\n",
      "Accuracy: 0.9982 - Precision: 0.8582 - Recall: 0.9447 - Specificity: 0.9987 - F1: 0.8957 - Loss: 0.1138\n",
      "\n",
      "Batch 5/387 ━━━━━━━━━━━━━━━━━━━━ 16:34:43\n",
      "Accuracy: 0.9978 - Precision: 0.8682 - Recall: 0.8762 - Specificity: 0.9989 - F1: 0.8614 - Loss: 0.1526\n",
      "\n",
      "Batch 6/387 ━━━━━━━━━━━━━━━━━━━━ 16:36:07\n",
      "Accuracy: 0.9978 - Precision: 0.8458 - Recall: 0.8717 - Specificity: 0.9989 - F1: 0.8491 - Loss: 0.1642\n",
      "\n",
      "Batch 7/387 ━━━━━━━━━━━━━━━━━━━━ 16:37:42\n",
      "Accuracy: 0.9980 - Precision: 0.8580 - Recall: 0.8873 - Specificity: 0.9989 - F1: 0.8643 - Loss: 0.1480\n",
      "\n",
      "Batch 8/387 ━━━━━━━━━━━━━━━━━━━━ 16:39:23\n",
      "Accuracy: 0.9978 - Precision: 0.8575 - Recall: 0.8860 - Specificity: 0.9988 - F1: 0.8644 - Loss: 0.1488\n",
      "\n",
      "Batch 9/387 ━━━━━━━━━━━━━━━━━━━━ 16:40:55\n",
      "Accuracy: 0.9979 - Precision: 0.8710 - Recall: 0.8812 - Specificity: 0.9989 - F1: 0.8690 - Loss: 0.1436\n",
      "\n",
      "Batch 10/387 ━━━━━━━━━━━━━━━━━━━━ 16:42:24\n",
      "Accuracy: 0.9981 - Precision: 0.8755 - Recall: 0.8892 - Specificity: 0.9990 - F1: 0.8759 - Loss: 0.1359\n",
      "\n",
      "Batch 11/387 ━━━━━━━━━━━━━━━━━━━━ 16:43:51\n",
      "Accuracy: 0.9978 - Precision: 0.8866 - Recall: 0.8774 - Specificity: 0.9991 - F1: 0.8747 - Loss: 0.1388\n",
      "\n",
      "Batch 12/387 ━━━━━━━━━━━━━━━━━━━━ 16:45:15\n",
      "Accuracy: 0.9979 - Precision: 0.8871 - Recall: 0.8837 - Specificity: 0.9991 - F1: 0.8786 - Loss: 0.1345\n",
      "\n",
      "Batch 13/387 ━━━━━━━━━━━━━━━━━━━━ 16:46:40\n",
      "Accuracy: 0.9978 - Precision: 0.8854 - Recall: 0.8812 - Specificity: 0.9990 - F1: 0.8770 - Loss: 0.1365\n",
      "\n",
      "Batch 14/387 ━━━━━━━━━━━━━━━━━━━━ 16:48:05\n",
      "Accuracy: 0.9977 - Precision: 0.8923 - Recall: 0.8825 - Specificity: 0.9991 - F1: 0.8814 - Loss: 0.1328\n",
      "\n",
      "Batch 15/387 ━━━━━━━━━━━━━━━━━━━━ 16:49:44\n",
      "Accuracy: 0.9977 - Precision: 0.8823 - Recall: 0.8893 - Specificity: 0.9990 - F1: 0.8791 - Loss: 0.1347\n",
      "\n",
      "Batch 16/387 ━━━━━━━━━━━━━━━━━━━━ 16:51:55\n",
      "Accuracy: 0.9978 - Precision: 0.8862 - Recall: 0.8947 - Specificity: 0.9991 - F1: 0.8841 - Loss: 0.1292\n",
      "\n",
      "Batch 17/387 ━━━━━━━━━━━━━━━━━━━━ 16:53:39\n",
      "Accuracy: 0.9977 - Precision: 0.8881 - Recall: 0.8927 - Specificity: 0.9990 - F1: 0.8844 - Loss: 0.1294\n",
      "\n",
      "Batch 18/387 ━━━━━━━━━━━━━━━━━━━━ 16:55:22\n",
      "Accuracy: 0.9978 - Precision: 0.8830 - Recall: 0.8970 - Specificity: 0.9990 - F1: 0.8839 - Loss: 0.1297\n",
      "\n",
      "Batch 19/387 ━━━━━━━━━━━━━━━━━━━━ 16:57:05\n",
      "Accuracy: 0.9977 - Precision: 0.8875 - Recall: 0.8987 - Specificity: 0.9990 - F1: 0.8873 - Loss: 0.1263\n",
      "\n",
      "Batch 20/387 ━━━━━━━━━━━━━━━━━━━━ 16:58:51\n",
      "Accuracy: 0.9978 - Precision: 0.8905 - Recall: 0.8964 - Specificity: 0.9991 - F1: 0.8878 - Loss: 0.1256\n",
      "\n",
      "Batch 21/387 ━━━━━━━━━━━━━━━━━━━━ 17:00:33\n",
      "Accuracy: 0.9979 - Precision: 0.8945 - Recall: 0.8978 - Specificity: 0.9991 - F1: 0.8907 - Loss: 0.1224\n",
      "\n",
      "Batch 22/387 ━━━━━━━━━━━━━━━━━━━━ 17:01:54\n",
      "Accuracy: 0.9979 - Precision: 0.8962 - Recall: 0.9009 - Specificity: 0.9991 - F1: 0.8934 - Loss: 0.1195\n",
      "\n",
      "Batch 23/387 ━━━━━━━━━━━━━━━━━━━━ 17:03:25\n",
      "Accuracy: 0.9979 - Precision: 0.8994 - Recall: 0.9031 - Specificity: 0.9991 - F1: 0.8963 - Loss: 0.1164\n",
      "\n",
      "Batch 24/387 ━━━━━━━━━━━━━━━━━━━━ 17:04:46\n",
      "Accuracy: 0.9979 - Precision: 0.8934 - Recall: 0.9064 - Specificity: 0.9991 - F1: 0.8946 - Loss: 0.1180\n",
      "\n",
      "Batch 25/387 ━━━━━━━━━━━━━━━━━━━━ 17:06:26\n",
      "Accuracy: 0.9979 - Precision: 0.8975 - Recall: 0.9067 - Specificity: 0.9991 - F1: 0.8969 - Loss: 0.1156\n",
      "\n",
      "Batch 26/387 ━━━━━━━━━━━━━━━━━━━━ 17:08:06\n",
      "Accuracy: 0.9980 - Precision: 0.9010 - Recall: 0.9055 - Specificity: 0.9991 - F1: 0.8981 - Loss: 0.1142\n",
      "\n",
      "Batch 27/387 ━━━━━━━━━━━━━━━━━━━━ 17:09:36\n",
      "Accuracy: 0.9979 - Precision: 0.9029 - Recall: 0.9045 - Specificity: 0.9991 - F1: 0.8987 - Loss: 0.1137\n",
      "\n",
      "Batch 28/387 ━━━━━━━━━━━━━━━━━━━━ 17:11:06\n",
      "Accuracy: 0.9980 - Precision: 0.9043 - Recall: 0.9034 - Specificity: 0.9992 - F1: 0.8990 - Loss: 0.1133\n",
      "\n",
      "Batch 29/387 ━━━━━━━━━━━━━━━━━━━━ 17:12:28\n",
      "Accuracy: 0.9979 - Precision: 0.9048 - Recall: 0.9029 - Specificity: 0.9991 - F1: 0.8991 - Loss: 0.1135\n",
      "\n",
      "Batch 30/387 ━━━━━━━━━━━━━━━━━━━━ 17:14:01\n",
      "Accuracy: 0.9979 - Precision: 0.9028 - Recall: 0.9050 - Specificity: 0.9991 - F1: 0.8992 - Loss: 0.1132\n",
      "\n",
      "Batch 31/387 ━━━━━━━━━━━━━━━━━━━━ 17:15:34\n",
      "Accuracy: 0.9980 - Precision: 0.8995 - Recall: 0.9052 - Specificity: 0.9991 - F1: 0.8977 - Loss: 0.1144\n",
      "\n",
      "Batch 32/387 ━━━━━━━━━━━━━━━━━━━━ 17:17:08\n",
      "Accuracy: 0.9980 - Precision: 0.9014 - Recall: 0.9062 - Specificity: 0.9991 - F1: 0.8993 - Loss: 0.1127\n",
      "\n",
      "Batch 33/387 ━━━━━━━━━━━━━━━━━━━━ 17:18:47\n",
      "Accuracy: 0.9980 - Precision: 0.9031 - Recall: 0.9054 - Specificity: 0.9992 - F1: 0.8998 - Loss: 0.1122\n",
      "\n",
      "Batch 34/387 ━━━━━━━━━━━━━━━━━━━━ 17:20:18\n",
      "Accuracy: 0.9980 - Precision: 0.9048 - Recall: 0.9068 - Specificity: 0.9992 - F1: 0.9015 - Loss: 0.1104\n",
      "\n",
      "Batch 35/387 ━━━━━━━━━━━━━━━━━━━━ 17:21:44\n",
      "Accuracy: 0.9979 - Precision: 0.9065 - Recall: 0.8999 - Specificity: 0.9992 - F1: 0.8982 - Loss: 0.1140\n",
      "\n",
      "Batch 36/387 ━━━━━━━━━━━━━━━━━━━━ 17:23:17\n",
      "Accuracy: 0.9979 - Precision: 0.9070 - Recall: 0.9019 - Specificity: 0.9992 - F1: 0.8996 - Loss: 0.1125\n",
      "\n",
      "Batch 37/387 ━━━━━━━━━━━━━━━━━━━━ 17:24:51\n",
      "Accuracy: 0.9980 - Precision: 0.9075 - Recall: 0.8987 - Specificity: 0.9992 - F1: 0.8983 - Loss: 0.1138\n",
      "\n",
      "Batch 38/387 ━━━━━━━━━━━━━━━━━━━━ 17:26:20\n",
      "Accuracy: 0.9980 - Precision: 0.9075 - Recall: 0.8991 - Specificity: 0.9992 - F1: 0.8986 - Loss: 0.1135\n",
      "\n",
      "Batch 39/387 ━━━━━━━━━━━━━━━━━━━━ 17:27:55\n",
      "Accuracy: 0.9980 - Precision: 0.9087 - Recall: 0.9011 - Specificity: 0.9992 - F1: 0.9003 - Loss: 0.1116\n",
      "\n",
      "Batch 40/387 ━━━━━━━━━━━━━━━━━━━━ 17:29:23\n",
      "Accuracy: 0.9980 - Precision: 0.9084 - Recall: 0.9029 - Specificity: 0.9991 - F1: 0.9011 - Loss: 0.1109\n",
      "\n",
      "Batch 41/387 ━━━━━━━━━━━━━━━━━━━━ 17:31:09\n",
      "Accuracy: 0.9979 - Precision: 0.9057 - Recall: 0.9048 - Specificity: 0.9991 - F1: 0.9006 - Loss: 0.1116\n",
      "\n",
      "Batch 42/387 ━━━━━━━━━━━━━━━━━━━━ 17:32:53\n",
      "Accuracy: 0.9979 - Precision: 0.9057 - Recall: 0.9066 - Specificity: 0.9991 - F1: 0.9015 - Loss: 0.1105\n",
      "\n",
      "Batch 43/387 ━━━━━━━━━━━━━━━━━━━━ 17:34:18\n",
      "Accuracy: 0.9980 - Precision: 0.9008 - Recall: 0.9085 - Specificity: 0.9991 - F1: 0.8996 - Loss: 0.1125\n",
      "\n",
      "Batch 44/387 ━━━━━━━━━━━━━━━━━━━━ 17:35:56\n",
      "Accuracy: 0.9979 - Precision: 0.8996 - Recall: 0.9079 - Specificity: 0.9991 - F1: 0.8988 - Loss: 0.1134\n",
      "\n",
      "Batch 45/387 ━━━━━━━━━━━━━━━━━━━━ 17:37:24\n",
      "Accuracy: 0.9979 - Precision: 0.9000 - Recall: 0.9078 - Specificity: 0.9990 - F1: 0.8990 - Loss: 0.1133\n",
      "\n",
      "Batch 46/387 ━━━━━━━━━━━━━━━━━━━━ 17:39:00\n",
      "Accuracy: 0.9979 - Precision: 0.9002 - Recall: 0.9087 - Specificity: 0.9990 - F1: 0.8997 - Loss: 0.1126\n",
      "\n",
      "Batch 47/387 ━━━━━━━━━━━━━━━━━━━━ 17:40:47\n",
      "Accuracy: 0.9979 - Precision: 0.9017 - Recall: 0.9076 - Specificity: 0.9991 - F1: 0.8999 - Loss: 0.1124\n",
      "\n",
      "Batch 48/387 ━━━━━━━━━━━━━━━━━━━━ 17:42:18\n",
      "Accuracy: 0.9979 - Precision: 0.9007 - Recall: 0.9087 - Specificity: 0.9990 - F1: 0.9000 - Loss: 0.1122\n",
      "\n",
      "Batch 49/387 ━━━━━━━━━━━━━━━━━━━━ 17:43:55\n",
      "Accuracy: 0.9979 - Precision: 0.9024 - Recall: 0.9060 - Specificity: 0.9991 - F1: 0.8993 - Loss: 0.1128\n",
      "\n",
      "Batch 50/387 ━━━━━━━━━━━━━━━━━━━━ 17:45:29\n",
      "Accuracy: 0.9980 - Precision: 0.9036 - Recall: 0.9056 - Specificity: 0.9991 - F1: 0.8998 - Loss: 0.1122\n",
      "\n",
      "Batch 51/387 ━━━━━━━━━━━━━━━━━━━━ 17:47:01\n",
      "Accuracy: 0.9980 - Precision: 0.9051 - Recall: 0.9059 - Specificity: 0.9991 - F1: 0.9008 - Loss: 0.1112\n",
      "\n",
      "Batch 52/387 ━━━━━━━━━━━━━━━━━━━━ 17:48:25\n",
      "Accuracy: 0.9979 - Precision: 0.9058 - Recall: 0.9053 - Specificity: 0.9991 - F1: 0.9009 - Loss: 0.1112\n",
      "\n",
      "Batch 53/387 ━━━━━━━━━━━━━━━━━━━━ 17:49:46\n",
      "Accuracy: 0.9979 - Precision: 0.9067 - Recall: 0.9056 - Specificity: 0.9991 - F1: 0.9016 - Loss: 0.1106\n",
      "\n",
      "Batch 54/387 ━━━━━━━━━━━━━━━━━━━━ 17:51:19\n",
      "Accuracy: 0.9979 - Precision: 0.9056 - Recall: 0.9066 - Specificity: 0.9991 - F1: 0.9015 - Loss: 0.1107\n",
      "\n",
      "Batch 55/387 ━━━━━━━━━━━━━━━━━━━━ 17:52:41\n",
      "Accuracy: 0.9979 - Precision: 0.9065 - Recall: 0.9071 - Specificity: 0.9991 - F1: 0.9023 - Loss: 0.1099\n",
      "\n",
      "Batch 56/387 ━━━━━━━━━━━━━━━━━━━━ 17:54:08\n",
      "Accuracy: 0.9979 - Precision: 0.9041 - Recall: 0.9026 - Specificity: 0.9991 - F1: 0.8989 - Loss: 0.1136\n",
      "\n",
      "Batch 57/387 ━━━━━━━━━━━━━━━━━━━━ 17:55:37\n",
      "Accuracy: 0.9979 - Precision: 0.9032 - Recall: 0.9024 - Specificity: 0.9991 - F1: 0.8984 - Loss: 0.1139\n",
      "\n",
      "Batch 58/387 ━━━━━━━━━━━━━━━━━━━━ 17:57:11\n",
      "Accuracy: 0.9979 - Precision: 0.9032 - Recall: 0.9039 - Specificity: 0.9991 - F1: 0.8992 - Loss: 0.1130\n",
      "\n",
      "Batch 59/387 ━━━━━━━━━━━━━━━━━━━━ 17:58:23\n",
      "Accuracy: 0.9979 - Precision: 0.9045 - Recall: 0.9037 - Specificity: 0.9991 - F1: 0.8998 - Loss: 0.1126\n",
      "\n",
      "Batch 60/387 ━━━━━━━━━━━━━━━━━━━━ 18:00:08\n",
      "Accuracy: 0.9979 - Precision: 0.9046 - Recall: 0.9040 - Specificity: 0.9991 - F1: 0.9001 - Loss: 0.1121\n",
      "\n",
      "Batch 61/387 ━━━━━━━━━━━━━━━━━━━━ 18:01:27\n",
      "Accuracy: 0.9980 - Precision: 0.9047 - Recall: 0.9025 - Specificity: 0.9991 - F1: 0.8994 - Loss: 0.1127\n",
      "\n",
      "Batch 62/387 ━━━━━━━━━━━━━━━━━━━━ 18:02:57\n",
      "Accuracy: 0.9980 - Precision: 0.9056 - Recall: 0.9028 - Specificity: 0.9991 - F1: 0.9000 - Loss: 0.1120\n",
      "\n",
      "Batch 63/387 ━━━━━━━━━━━━━━━━━━━━ 18:04:24\n",
      "Accuracy: 0.9980 - Precision: 0.9068 - Recall: 0.8960 - Specificity: 0.9991 - F1: 0.8959 - Loss: 0.1164\n",
      "\n",
      "Batch 64/387 ━━━━━━━━━━━━━━━━━━━━ 18:05:47\n",
      "Accuracy: 0.9979 - Precision: 0.9061 - Recall: 0.8973 - Specificity: 0.9991 - F1: 0.8962 - Loss: 0.1161\n",
      "\n",
      "Batch 65/387 ━━━━━━━━━━━━━━━━━━━━ 18:07:10\n",
      "Accuracy: 0.9979 - Precision: 0.9064 - Recall: 0.8978 - Specificity: 0.9991 - F1: 0.8967 - Loss: 0.1156\n",
      "\n",
      "Batch 66/387 ━━━━━━━━━━━━━━━━━━━━ 18:08:41\n",
      "Accuracy: 0.9979 - Precision: 0.9074 - Recall: 0.8953 - Specificity: 0.9991 - F1: 0.8958 - Loss: 0.1166\n",
      "\n",
      "Batch 67/387 ━━━━━━━━━━━━━━━━━━━━ 18:10:07\n",
      "Accuracy: 0.9979 - Precision: 0.9073 - Recall: 0.8964 - Specificity: 0.9991 - F1: 0.8963 - Loss: 0.1160\n",
      "\n",
      "Batch 68/387 ━━━━━━━━━━━━━━━━━━━━ 18:11:30\n",
      "Accuracy: 0.9980 - Precision: 0.9062 - Recall: 0.8965 - Specificity: 0.9991 - F1: 0.8959 - Loss: 0.1164\n",
      "\n",
      "Batch 69/387 ━━━━━━━━━━━━━━━━━━━━ 18:13:08\n",
      "Accuracy: 0.9980 - Precision: 0.9050 - Recall: 0.8977 - Specificity: 0.9991 - F1: 0.8959 - Loss: 0.1163\n",
      "\n",
      "Batch 70/387 ━━━━━━━━━━━━━━━━━━━━ 18:14:35\n",
      "Accuracy: 0.9980 - Precision: 0.9049 - Recall: 0.8986 - Specificity: 0.9991 - F1: 0.8964 - Loss: 0.1159\n",
      "\n",
      "Batch 71/387 ━━━━━━━━━━━━━━━━━━━━ 18:15:55\n",
      "Accuracy: 0.9980 - Precision: 0.9046 - Recall: 0.8993 - Specificity: 0.9991 - F1: 0.8966 - Loss: 0.1156\n",
      "\n",
      "Batch 72/387 ━━━━━━━━━━━━━━━━━━━━ 18:17:27\n",
      "Accuracy: 0.9979 - Precision: 0.9044 - Recall: 0.9003 - Specificity: 0.9990 - F1: 0.8971 - Loss: 0.1152\n",
      "\n",
      "Batch 73/387 ━━━━━━━━━━━━━━━━━━━━ 18:18:55\n",
      "Accuracy: 0.9979 - Precision: 0.9057 - Recall: 0.8991 - Specificity: 0.9991 - F1: 0.8971 - Loss: 0.1152\n",
      "\n",
      "Batch 74/387 ━━━━━━━━━━━━━━━━━━━━ 18:20:18\n",
      "Accuracy: 0.9979 - Precision: 0.9062 - Recall: 0.8958 - Specificity: 0.9991 - F1: 0.8954 - Loss: 0.1170\n",
      "\n",
      "Batch 75/387 ━━━━━━━━━━━━━━━━━━━━ 18:21:44\n",
      "Accuracy: 0.9979 - Precision: 0.9065 - Recall: 0.8930 - Specificity: 0.9991 - F1: 0.8940 - Loss: 0.1185\n",
      "\n",
      "Batch 76/387 ━━━━━━━━━━━━━━━━━━━━ 18:23:06\n",
      "Accuracy: 0.9979 - Precision: 0.9065 - Recall: 0.8931 - Specificity: 0.9991 - F1: 0.8941 - Loss: 0.1186\n",
      "\n",
      "Batch 77/387 ━━━━━━━━━━━━━━━━━━━━ 18:24:30\n",
      "Accuracy: 0.9979 - Precision: 0.9057 - Recall: 0.8933 - Specificity: 0.9991 - F1: 0.8939 - Loss: 0.1188\n",
      "\n",
      "Batch 78/387 ━━━━━━━━━━━━━━━━━━━━ 18:25:54\n",
      "Accuracy: 0.9978 - Precision: 0.9063 - Recall: 0.8910 - Specificity: 0.9991 - F1: 0.8929 - Loss: 0.1201\n",
      "\n",
      "Batch 79/387 ━━━━━━━━━━━━━━━━━━━━ 18:27:34\n",
      "Accuracy: 0.9978 - Precision: 0.9051 - Recall: 0.8915 - Specificity: 0.9991 - F1: 0.8926 - Loss: 0.1203\n",
      "\n",
      "Batch 80/387 ━━━━━━━━━━━━━━━━━━━━ 18:28:59\n",
      "Accuracy: 0.9978 - Precision: 0.9048 - Recall: 0.8922 - Specificity: 0.9990 - F1: 0.8928 - Loss: 0.1201\n",
      "\n",
      "Batch 81/387 ━━━━━━━━━━━━━━━━━━━━ 18:30:22\n",
      "Accuracy: 0.9979 - Precision: 0.9044 - Recall: 0.8930 - Specificity: 0.9991 - F1: 0.8930 - Loss: 0.1198\n",
      "\n",
      "Batch 82/387 ━━━━━━━━━━━━━━━━━━━━ 18:32:06\n",
      "Accuracy: 0.9979 - Precision: 0.9028 - Recall: 0.8938 - Specificity: 0.9991 - F1: 0.8926 - Loss: 0.1202\n",
      "\n",
      "Batch 83/387 ━━━━━━━━━━━━━━━━━━━━ 18:33:29\n",
      "Accuracy: 0.9979 - Precision: 0.9033 - Recall: 0.8929 - Specificity: 0.9991 - F1: 0.8924 - Loss: 0.1203\n",
      "\n",
      "Batch 84/387 ━━━━━━━━━━━━━━━━━━━━ 18:34:58\n",
      "Accuracy: 0.9979 - Precision: 0.9040 - Recall: 0.8936 - Specificity: 0.9991 - F1: 0.8931 - Loss: 0.1195\n",
      "\n",
      "Batch 85/387 ━━━━━━━━━━━━━━━━━━━━ 18:36:27\n",
      "Accuracy: 0.9979 - Precision: 0.9046 - Recall: 0.8937 - Specificity: 0.9991 - F1: 0.8936 - Loss: 0.1191\n",
      "\n",
      "Batch 86/387 ━━━━━━━━━━━━━━━━━━━━ 18:37:48\n",
      "Accuracy: 0.9979 - Precision: 0.9054 - Recall: 0.8941 - Specificity: 0.9991 - F1: 0.8943 - Loss: 0.1184\n",
      "\n",
      "Batch 87/387 ━━━━━━━━━━━━━━━━━━━━ 18:39:15\n",
      "Accuracy: 0.9979 - Precision: 0.9058 - Recall: 0.8945 - Specificity: 0.9991 - F1: 0.8947 - Loss: 0.1179\n",
      "\n",
      "Batch 88/387 ━━━━━━━━━━━━━━━━━━━━ 18:40:34\n",
      "Accuracy: 0.9979 - Precision: 0.9062 - Recall: 0.8944 - Specificity: 0.9991 - F1: 0.8949 - Loss: 0.1177\n",
      "\n",
      "Batch 89/387 ━━━━━━━━━━━━━━━━━━━━ 18:42:07\n",
      "Accuracy: 0.9979 - Precision: 0.9071 - Recall: 0.8936 - Specificity: 0.9991 - F1: 0.8949 - Loss: 0.1177\n",
      "\n",
      "Batch 90/387 ━━━━━━━━━━━━━━━━━━━━ 18:43:43\n",
      "Accuracy: 0.9979 - Precision: 0.9073 - Recall: 0.8936 - Specificity: 0.9991 - F1: 0.8951 - Loss: 0.1175\n",
      "\n",
      "Batch 91/387 ━━━━━━━━━━━━━━━━━━━━ 18:45:13\n",
      "Accuracy: 0.9979 - Precision: 0.9074 - Recall: 0.8941 - Specificity: 0.9991 - F1: 0.8955 - Loss: 0.1171\n",
      "\n",
      "Batch 92/387 ━━━━━━━━━━━━━━━━━━━━ 18:46:46\n",
      "Accuracy: 0.9979 - Precision: 0.9078 - Recall: 0.8935 - Specificity: 0.9991 - F1: 0.8954 - Loss: 0.1173\n",
      "\n",
      "Batch 93/387 ━━━━━━━━━━━━━━━━━━━━ 18:48:15\n",
      "Accuracy: 0.9979 - Precision: 0.9085 - Recall: 0.8937 - Specificity: 0.9991 - F1: 0.8958 - Loss: 0.1167\n",
      "\n",
      "Batch 94/387 ━━━━━━━━━━━━━━━━━━━━ 18:49:32\n",
      "Accuracy: 0.9979 - Precision: 0.9091 - Recall: 0.8930 - Specificity: 0.9991 - F1: 0.8958 - Loss: 0.1169\n",
      "\n",
      "Batch 95/387 ━━━━━━━━━━━━━━━━━━━━ 18:50:56\n",
      "Accuracy: 0.9979 - Precision: 0.9079 - Recall: 0.8937 - Specificity: 0.9991 - F1: 0.8956 - Loss: 0.1172\n",
      "\n",
      "Batch 96/387 ━━━━━━━━━━━━━━━━━━━━ 18:52:34\n",
      "Accuracy: 0.9979 - Precision: 0.9075 - Recall: 0.8947 - Specificity: 0.9991 - F1: 0.8958 - Loss: 0.1169\n",
      "\n",
      "Batch 97/387 ━━━━━━━━━━━━━━━━━━━━ 18:54:00\n",
      "Accuracy: 0.9979 - Precision: 0.9078 - Recall: 0.8954 - Specificity: 0.9991 - F1: 0.8964 - Loss: 0.1162\n",
      "\n",
      "Batch 98/387 ━━━━━━━━━━━━━━━━━━━━ 18:55:26\n",
      "Accuracy: 0.9979 - Precision: 0.9081 - Recall: 0.8960 - Specificity: 0.9991 - F1: 0.8969 - Loss: 0.1158\n",
      "\n",
      "Batch 99/387 ━━━━━━━━━━━━━━━━━━━━ 18:56:43\n",
      "Accuracy: 0.9979 - Precision: 0.9045 - Recall: 0.8969 - Specificity: 0.9991 - F1: 0.8950 - Loss: 0.1176\n",
      "\n",
      "Batch 100/387 ━━━━━━━━━━━━━━━━━━━━ 18:58:03\n",
      "Accuracy: 0.9979 - Precision: 0.9050 - Recall: 0.8976 - Specificity: 0.9991 - F1: 0.8957 - Loss: 0.1169\n",
      "\n",
      "Batch 101/387 ━━━━━━━━━━━━━━━━━━━━ 18:59:32\n",
      "Accuracy: 0.9979 - Precision: 0.9050 - Recall: 0.8969 - Specificity: 0.9991 - F1: 0.8953 - Loss: 0.1172\n",
      "\n",
      "Batch 102/387 ━━━━━━━━━━━━━━━━━━━━ 19:01:06\n",
      "Accuracy: 0.9979 - Precision: 0.9055 - Recall: 0.8964 - Specificity: 0.9991 - F1: 0.8954 - Loss: 0.1171\n",
      "\n",
      "Batch 103/387 ━━━━━━━━━━━━━━━━━━━━ 19:02:24\n",
      "Accuracy: 0.9980 - Precision: 0.9052 - Recall: 0.8969 - Specificity: 0.9991 - F1: 0.8956 - Loss: 0.1169\n",
      "\n",
      "Batch 104/387 ━━━━━━━━━━━━━━━━━━━━ 19:03:48\n",
      "Accuracy: 0.9980 - Precision: 0.9059 - Recall: 0.8960 - Specificity: 0.9991 - F1: 0.8954 - Loss: 0.1170\n",
      "\n",
      "Batch 105/387 ━━━━━━━━━━━━━━━━━━━━ 19:05:08\n",
      "Accuracy: 0.9980 - Precision: 0.9062 - Recall: 0.8959 - Specificity: 0.9991 - F1: 0.8956 - Loss: 0.1168\n",
      "\n",
      "Batch 106/387 ━━━━━━━━━━━━━━━━━━━━ 19:06:40\n",
      "Accuracy: 0.9980 - Precision: 0.9067 - Recall: 0.8963 - Specificity: 0.9991 - F1: 0.8961 - Loss: 0.1162\n",
      "\n",
      "Batch 107/387 ━━━━━━━━━━━━━━━━━━━━ 19:08:19\n",
      "Accuracy: 0.9980 - Precision: 0.9064 - Recall: 0.8969 - Specificity: 0.9991 - F1: 0.8962 - Loss: 0.1161\n",
      "\n",
      "Batch 108/387 ━━━━━━━━━━━━━━━━━━━━ 19:09:44\n",
      "Accuracy: 0.9980 - Precision: 0.9053 - Recall: 0.8969 - Specificity: 0.9991 - F1: 0.8957 - Loss: 0.1166\n",
      "\n",
      "Batch 109/387 ━━━━━━━━━━━━━━━━━━━━ 19:11:11\n",
      "Accuracy: 0.9980 - Precision: 0.9053 - Recall: 0.8947 - Specificity: 0.9991 - F1: 0.8944 - Loss: 0.1180\n",
      "\n",
      "Batch 110/387 ━━━━━━━━━━━━━━━━━━━━ 19:12:31\n",
      "Accuracy: 0.9980 - Precision: 0.9048 - Recall: 0.8951 - Specificity: 0.9991 - F1: 0.8944 - Loss: 0.1179\n",
      "\n",
      "Batch 111/387 ━━━━━━━━━━━━━━━━━━━━ 19:13:48\n",
      "Accuracy: 0.9980 - Precision: 0.9044 - Recall: 0.8957 - Specificity: 0.9991 - F1: 0.8946 - Loss: 0.1178\n",
      "\n",
      "Batch 112/387 ━━━━━━━━━━━━━━━━━━━━ 19:15:16\n",
      "Accuracy: 0.9980 - Precision: 0.9044 - Recall: 0.8960 - Specificity: 0.9991 - F1: 0.8948 - Loss: 0.1176\n",
      "\n",
      "Batch 113/387 ━━━━━━━━━━━━━━━━━━━━ 19:16:44\n",
      "Accuracy: 0.9980 - Precision: 0.9050 - Recall: 0.8955 - Specificity: 0.9991 - F1: 0.8948 - Loss: 0.1175\n",
      "\n",
      "Batch 114/387 ━━━━━━━━━━━━━━━━━━━━ 19:18:05\n",
      "Accuracy: 0.9980 - Precision: 0.9055 - Recall: 0.8959 - Specificity: 0.9991 - F1: 0.8953 - Loss: 0.1170\n",
      "\n",
      "Batch 115/387 ━━━━━━━━━━━━━━━━━━━━ 19:19:29\n",
      "Accuracy: 0.9980 - Precision: 0.9062 - Recall: 0.8951 - Specificity: 0.9991 - F1: 0.8952 - Loss: 0.1172\n",
      "\n",
      "Batch 116/387 ━━━━━━━━━━━━━━━━━━━━ 19:20:50\n",
      "Accuracy: 0.9980 - Precision: 0.9069 - Recall: 0.8939 - Specificity: 0.9991 - F1: 0.8949 - Loss: 0.1175\n",
      "\n",
      "Batch 117/387 ━━━━━━━━━━━━━━━━━━━━ 19:22:10\n",
      "Accuracy: 0.9980 - Precision: 0.9073 - Recall: 0.8934 - Specificity: 0.9991 - F1: 0.8949 - Loss: 0.1176\n",
      "\n",
      "Batch 118/387 ━━━━━━━━━━━━━━━━━━━━ 19:23:43\n",
      "Accuracy: 0.9979 - Precision: 0.9079 - Recall: 0.8923 - Specificity: 0.9991 - F1: 0.8946 - Loss: 0.1180\n",
      "\n",
      "Batch 119/387 ━━━━━━━━━━━━━━━━━━━━ 19:25:04\n",
      "Accuracy: 0.9979 - Precision: 0.9077 - Recall: 0.8912 - Specificity: 0.9991 - F1: 0.8939 - Loss: 0.1186\n",
      "\n",
      "Batch 120/387 ━━━━━━━━━━━━━━━━━━━━ 19:26:29\n",
      "Accuracy: 0.9979 - Precision: 0.9076 - Recall: 0.8914 - Specificity: 0.9991 - F1: 0.8940 - Loss: 0.1186\n",
      "\n",
      "Batch 121/387 ━━━━━━━━━━━━━━━━━━━━ 19:27:59\n",
      "Accuracy: 0.9979 - Precision: 0.9041 - Recall: 0.8916 - Specificity: 0.9991 - F1: 0.8919 - Loss: 0.1209\n",
      "\n",
      "Batch 122/387 ━━━━━━━━━━━━━━━━━━━━ 19:29:16\n",
      "Accuracy: 0.9979 - Precision: 0.9042 - Recall: 0.8921 - Specificity: 0.9991 - F1: 0.8922 - Loss: 0.1204\n",
      "\n",
      "Batch 123/387 ━━━━━━━━━━━━━━━━━━━━ 19:30:43\n",
      "Accuracy: 0.9979 - Precision: 0.9041 - Recall: 0.8921 - Specificity: 0.9991 - F1: 0.8922 - Loss: 0.1205\n",
      "\n",
      "Batch 124/387 ━━━━━━━━━━━━━━━━━━━━ 19:32:18\n",
      "Accuracy: 0.9979 - Precision: 0.9027 - Recall: 0.8923 - Specificity: 0.9991 - F1: 0.8916 - Loss: 0.1212\n",
      "\n",
      "Batch 125/387 ━━━━━━━━━━━━━━━━━━━━ 19:33:52\n",
      "Accuracy: 0.9979 - Precision: 0.9025 - Recall: 0.8928 - Specificity: 0.9991 - F1: 0.8918 - Loss: 0.1209\n",
      "\n",
      "Batch 126/387 ━━━━━━━━━━━━━━━━━━━━ 19:35:25\n",
      "Accuracy: 0.9979 - Precision: 0.9031 - Recall: 0.8934 - Specificity: 0.9991 - F1: 0.8924 - Loss: 0.1203\n",
      "\n",
      "Batch 127/387 ━━━━━━━━━━━━━━━━━━━━ 19:36:53\n",
      "Accuracy: 0.9979 - Precision: 0.9018 - Recall: 0.8941 - Specificity: 0.9991 - F1: 0.8921 - Loss: 0.1207\n",
      "\n",
      "Batch 128/387 ━━━━━━━━━━━━━━━━━━━━ 19:38:10\n",
      "Accuracy: 0.9979 - Precision: 0.9018 - Recall: 0.8938 - Specificity: 0.9991 - F1: 0.8919 - Loss: 0.1209\n",
      "\n",
      "Batch 129/387 ━━━━━━━━━━━━━━━━━━━━ 19:39:30\n",
      "Accuracy: 0.9979 - Precision: 0.9018 - Recall: 0.8941 - Specificity: 0.9991 - F1: 0.8921 - Loss: 0.1207\n",
      "\n",
      "Batch 130/387 ━━━━━━━━━━━━━━━━━━━━ 19:41:05\n",
      "Accuracy: 0.9979 - Precision: 0.9023 - Recall: 0.8944 - Specificity: 0.9991 - F1: 0.8926 - Loss: 0.1203\n",
      "\n",
      "Batch 131/387 ━━━━━━━━━━━━━━━━━━━━ 19:42:25\n",
      "Accuracy: 0.9979 - Precision: 0.9028 - Recall: 0.8938 - Specificity: 0.9991 - F1: 0.8925 - Loss: 0.1204\n",
      "\n",
      "Batch 132/387 ━━━━━━━━━━━━━━━━━━━━ 19:43:49\n",
      "Accuracy: 0.9979 - Precision: 0.9033 - Recall: 0.8933 - Specificity: 0.9991 - F1: 0.8925 - Loss: 0.1204\n",
      "\n",
      "Batch 133/387 ━━━━━━━━━━━━━━━━━━━━ 19:45:36\n",
      "Accuracy: 0.9979 - Precision: 0.9024 - Recall: 0.8936 - Specificity: 0.9990 - F1: 0.8922 - Loss: 0.1208\n",
      "\n",
      "Batch 134/387 ━━━━━━━━━━━━━━━━━━━━ 19:47:03\n",
      "Accuracy: 0.9978 - Precision: 0.9025 - Recall: 0.8933 - Specificity: 0.9990 - F1: 0.8921 - Loss: 0.1209\n",
      "\n",
      "Batch 135/387 ━━━━━━━━━━━━━━━━━━━━ 19:48:31\n",
      "Accuracy: 0.9979 - Precision: 0.9030 - Recall: 0.8937 - Specificity: 0.9990 - F1: 0.8926 - Loss: 0.1204\n",
      "\n",
      "Batch 136/387 ━━━━━━━━━━━━━━━━━━━━ 19:49:56\n",
      "Accuracy: 0.9979 - Precision: 0.9034 - Recall: 0.8939 - Specificity: 0.9990 - F1: 0.8930 - Loss: 0.1200\n",
      "\n",
      "Batch 137/387 ━━━━━━━━━━━━━━━━━━━━ 19:51:23\n",
      "Accuracy: 0.9979 - Precision: 0.9039 - Recall: 0.8941 - Specificity: 0.9991 - F1: 0.8933 - Loss: 0.1196\n",
      "\n",
      "Batch 138/387 ━━━━━━━━━━━━━━━━━━━━ 19:52:48\n",
      "Accuracy: 0.9978 - Precision: 0.9045 - Recall: 0.8929 - Specificity: 0.9991 - F1: 0.8929 - Loss: 0.1202\n",
      "\n",
      "Batch 139/387 ━━━━━━━━━━━━━━━━━━━━ 19:54:21\n",
      "Accuracy: 0.9978 - Precision: 0.9045 - Recall: 0.8932 - Specificity: 0.9991 - F1: 0.8931 - Loss: 0.1200\n",
      "\n",
      "Batch 140/387 ━━━━━━━━━━━━━━━━━━━━ 19:55:47\n",
      "Accuracy: 0.9978 - Precision: 0.9041 - Recall: 0.8937 - Specificity: 0.9991 - F1: 0.8932 - Loss: 0.1199\n",
      "\n",
      "Batch 141/387 ━━━━━━━━━━━━━━━━━━━━ 19:57:16\n",
      "Accuracy: 0.9978 - Precision: 0.9013 - Recall: 0.8944 - Specificity: 0.9990 - F1: 0.8916 - Loss: 0.1217\n",
      "\n",
      "Batch 142/387 ━━━━━━━━━━━━━━━━━━━━ 19:58:40\n",
      "Accuracy: 0.9978 - Precision: 0.9009 - Recall: 0.8949 - Specificity: 0.9990 - F1: 0.8917 - Loss: 0.1215\n",
      "\n",
      "Batch 143/387 ━━━━━━━━━━━━━━━━━━━━ 20:00:00\n",
      "Accuracy: 0.9978 - Precision: 0.9014 - Recall: 0.8926 - Specificity: 0.9990 - F1: 0.8904 - Loss: 0.1229\n",
      "\n",
      "Batch 144/387 ━━━━━━━━━━━━━━━━━━━━ 20:01:30\n",
      "Accuracy: 0.9978 - Precision: 0.9011 - Recall: 0.8932 - Specificity: 0.9990 - F1: 0.8906 - Loss: 0.1227\n",
      "\n",
      "Batch 145/387 ━━━━━━━━━━━━━━━━━━━━ 20:02:50\n",
      "Accuracy: 0.9978 - Precision: 0.9012 - Recall: 0.8937 - Specificity: 0.9990 - F1: 0.8909 - Loss: 0.1224\n",
      "\n",
      "Batch 146/387 ━━━━━━━━━━━━━━━━━━━━ 20:04:09\n",
      "Accuracy: 0.9978 - Precision: 0.9017 - Recall: 0.8940 - Specificity: 0.9990 - F1: 0.8914 - Loss: 0.1219\n",
      "\n",
      "Batch 147/387 ━━━━━━━━━━━━━━━━━━━━ 20:05:35\n",
      "Accuracy: 0.9978 - Precision: 0.9017 - Recall: 0.8940 - Specificity: 0.9990 - F1: 0.8914 - Loss: 0.1218\n",
      "\n",
      "Batch 148/387 ━━━━━━━━━━━━━━━━━━━━ 20:07:02\n",
      "Accuracy: 0.9978 - Precision: 0.9017 - Recall: 0.8944 - Specificity: 0.9990 - F1: 0.8917 - Loss: 0.1215\n",
      "\n",
      "Batch 149/387 ━━━━━━━━━━━━━━━━━━━━ 20:08:28\n",
      "Accuracy: 0.9978 - Precision: 0.9021 - Recall: 0.8947 - Specificity: 0.9990 - F1: 0.8920 - Loss: 0.1211\n",
      "\n",
      "Batch 150/387 ━━━━━━━━━━━━━━━━━━━━ 20:09:54\n",
      "Accuracy: 0.9978 - Precision: 0.9024 - Recall: 0.8951 - Specificity: 0.9990 - F1: 0.8925 - Loss: 0.1207\n",
      "\n",
      "Batch 151/387 ━━━━━━━━━━━━━━━━━━━━ 20:11:14\n",
      "Accuracy: 0.9978 - Precision: 0.9025 - Recall: 0.8956 - Specificity: 0.9990 - F1: 0.8928 - Loss: 0.1203\n",
      "\n",
      "Batch 152/387 ━━━━━━━━━━━━━━━━━━━━ 20:12:38\n",
      "Accuracy: 0.9978 - Precision: 0.9029 - Recall: 0.8956 - Specificity: 0.9990 - F1: 0.8931 - Loss: 0.1200\n",
      "\n",
      "Batch 153/387 ━━━━━━━━━━━━━━━━━━━━ 20:14:02\n",
      "Accuracy: 0.9978 - Precision: 0.9019 - Recall: 0.8958 - Specificity: 0.9990 - F1: 0.8926 - Loss: 0.1205\n",
      "\n",
      "Batch 154/387 ━━━━━━━━━━━━━━━━━━━━ 20:15:27\n",
      "Accuracy: 0.9978 - Precision: 0.9009 - Recall: 0.8955 - Specificity: 0.9990 - F1: 0.8920 - Loss: 0.1212\n",
      "\n",
      "Batch 155/387 ━━━━━━━━━━━━━━━━━━━━ 20:16:42\n",
      "Accuracy: 0.9978 - Precision: 0.9013 - Recall: 0.8957 - Specificity: 0.9990 - F1: 0.8923 - Loss: 0.1208\n",
      "\n",
      "Batch 156/387 ━━━━━━━━━━━━━━━━━━━━ 20:18:18\n",
      "Accuracy: 0.9978 - Precision: 0.9014 - Recall: 0.8949 - Specificity: 0.9990 - F1: 0.8920 - Loss: 0.1212\n",
      "\n",
      "Batch 157/387 ━━━━━━━━━━━━━━━━━━━━ 20:19:50\n",
      "Accuracy: 0.9978 - Precision: 0.9019 - Recall: 0.8951 - Specificity: 0.9990 - F1: 0.8923 - Loss: 0.1208\n",
      "\n",
      "Batch 158/387 ━━━━━━━━━━━━━━━━━━━━ 20:21:14\n",
      "Accuracy: 0.9978 - Precision: 0.9020 - Recall: 0.8954 - Specificity: 0.9990 - F1: 0.8926 - Loss: 0.1205\n",
      "\n",
      "Batch 159/387 ━━━━━━━━━━━━━━━━━━━━ 20:22:39\n",
      "Accuracy: 0.9978 - Precision: 0.9023 - Recall: 0.8956 - Specificity: 0.9990 - F1: 0.8929 - Loss: 0.1202\n",
      "\n",
      "Batch 160/387 ━━━━━━━━━━━━━━━━━━━━ 20:24:15\n",
      "Accuracy: 0.9978 - Precision: 0.9024 - Recall: 0.8960 - Specificity: 0.9990 - F1: 0.8932 - Loss: 0.1199\n",
      "\n",
      "Batch 161/387 ━━━━━━━━━━━━━━━━━━━━ 20:25:44\n",
      "Accuracy: 0.9978 - Precision: 0.9027 - Recall: 0.8962 - Specificity: 0.9990 - F1: 0.8934 - Loss: 0.1196\n",
      "\n",
      "Batch 162/387 ━━━━━━━━━━━━━━━━━━━━ 20:27:11\n",
      "Accuracy: 0.9979 - Precision: 0.9029 - Recall: 0.8962 - Specificity: 0.9990 - F1: 0.8936 - Loss: 0.1194\n",
      "\n",
      "Batch 163/387 ━━━━━━━━━━━━━━━━━━━━ 20:28:37\n",
      "Accuracy: 0.9979 - Precision: 0.9032 - Recall: 0.8959 - Specificity: 0.9990 - F1: 0.8936 - Loss: 0.1194\n",
      "\n",
      "Batch 164/387 ━━━━━━━━━━━━━━━━━━━━ 20:30:15\n",
      "Accuracy: 0.9979 - Precision: 0.9033 - Recall: 0.8954 - Specificity: 0.9990 - F1: 0.8934 - Loss: 0.1195\n",
      "\n",
      "Batch 165/387 ━━━━━━━━━━━━━━━━━━━━ 20:31:46\n",
      "Accuracy: 0.9979 - Precision: 0.9036 - Recall: 0.8958 - Specificity: 0.9990 - F1: 0.8938 - Loss: 0.1191\n",
      "\n",
      "Batch 166/387 ━━━━━━━━━━━━━━━━━━━━ 20:33:14\n",
      "Accuracy: 0.9979 - Precision: 0.9035 - Recall: 0.8960 - Specificity: 0.9990 - F1: 0.8939 - Loss: 0.1190\n",
      "\n",
      "Batch 167/387 ━━━━━━━━━━━━━━━━━━━━ 20:34:46\n",
      "Accuracy: 0.9979 - Precision: 0.9027 - Recall: 0.8960 - Specificity: 0.9990 - F1: 0.8935 - Loss: 0.1195\n",
      "\n",
      "Batch 168/387 ━━━━━━━━━━━━━━━━━━━━ 20:36:09\n",
      "Accuracy: 0.9979 - Precision: 0.9029 - Recall: 0.8964 - Specificity: 0.9990 - F1: 0.8938 - Loss: 0.1191\n",
      "\n",
      "Batch 169/387 ━━━━━━━━━━━━━━━━━━━━ 20:37:33\n",
      "Accuracy: 0.9979 - Precision: 0.9032 - Recall: 0.8968 - Specificity: 0.9990 - F1: 0.8942 - Loss: 0.1187\n",
      "\n",
      "Batch 170/387 ━━━━━━━━━━━━━━━━━━━━ 20:39:13\n",
      "Accuracy: 0.9979 - Precision: 0.9034 - Recall: 0.8971 - Specificity: 0.9990 - F1: 0.8945 - Loss: 0.1184\n",
      "\n",
      "Batch 171/387 ━━━━━━━━━━━━━━━━━━━━ 20:40:37\n",
      "Accuracy: 0.9979 - Precision: 0.9037 - Recall: 0.8973 - Specificity: 0.9990 - F1: 0.8948 - Loss: 0.1180\n",
      "\n",
      "Batch 172/387 ━━━━━━━━━━━━━━━━━━━━ 20:42:03\n",
      "Accuracy: 0.9979 - Precision: 0.9028 - Recall: 0.8964 - Specificity: 0.9990 - F1: 0.8939 - Loss: 0.1189\n",
      "\n",
      "Batch 173/387 ━━━━━━━━━━━━━━━━━━━━ 20:43:47\n",
      "Accuracy: 0.9979 - Precision: 0.9033 - Recall: 0.8966 - Specificity: 0.9990 - F1: 0.8942 - Loss: 0.1185\n",
      "\n",
      "Batch 174/387 ━━━━━━━━━━━━━━━━━━━━ 20:45:33\n",
      "Accuracy: 0.9979 - Precision: 0.9033 - Recall: 0.8970 - Specificity: 0.9990 - F1: 0.8945 - Loss: 0.1182\n",
      "\n",
      "Batch 175/387 ━━━━━━━━━━━━━━━━━━━━ 20:47:12\n",
      "Accuracy: 0.9979 - Precision: 0.9033 - Recall: 0.8973 - Specificity: 0.9990 - F1: 0.8947 - Loss: 0.1181\n",
      "\n",
      "Batch 176/387 ━━━━━━━━━━━━━━━━━━━━ 20:48:36\n",
      "Accuracy: 0.9979 - Precision: 0.9034 - Recall: 0.8972 - Specificity: 0.9990 - F1: 0.8947 - Loss: 0.1180\n",
      "\n",
      "Batch 177/387 ━━━━━━━━━━━━━━━━━━━━ 20:50:08\n",
      "Accuracy: 0.9979 - Precision: 0.9024 - Recall: 0.8974 - Specificity: 0.9990 - F1: 0.8943 - Loss: 0.1185\n",
      "\n",
      "Batch 178/387 ━━━━━━━━━━━━━━━━━━━━ 20:51:37\n",
      "Accuracy: 0.9979 - Precision: 0.9028 - Recall: 0.8966 - Specificity: 0.9990 - F1: 0.8940 - Loss: 0.1187\n",
      "\n",
      "Batch 179/387 ━━━━━━━━━━━━━━━━━━━━ 20:53:14\n",
      "Accuracy: 0.9979 - Precision: 0.9032 - Recall: 0.8963 - Specificity: 0.9990 - F1: 0.8940 - Loss: 0.1188\n",
      "\n",
      "Batch 180/387 ━━━━━━━━━━━━━━━━━━━━ 20:54:37\n",
      "Accuracy: 0.9979 - Precision: 0.9034 - Recall: 0.8963 - Specificity: 0.9990 - F1: 0.8942 - Loss: 0.1186\n",
      "\n",
      "Batch 181/387 ━━━━━━━━━━━━━━━━━━━━ 20:56:05\n",
      "Accuracy: 0.9979 - Precision: 0.9037 - Recall: 0.8966 - Specificity: 0.9990 - F1: 0.8945 - Loss: 0.1183\n",
      "\n",
      "Batch 182/387 ━━━━━━━━━━━━━━━━━━━━ 20:57:32\n",
      "Accuracy: 0.9979 - Precision: 0.9028 - Recall: 0.8957 - Specificity: 0.9990 - F1: 0.8937 - Loss: 0.1193\n",
      "\n",
      "Batch 183/387 ━━━━━━━━━━━━━━━━━━━━ 20:58:52\n",
      "Accuracy: 0.9979 - Precision: 0.9027 - Recall: 0.8959 - Specificity: 0.9990 - F1: 0.8937 - Loss: 0.1192\n",
      "\n",
      "Batch 184/387 ━━━━━━━━━━━━━━━━━━━━ 21:00:22\n",
      "Accuracy: 0.9979 - Precision: 0.9019 - Recall: 0.8961 - Specificity: 0.9990 - F1: 0.8934 - Loss: 0.1195\n",
      "\n",
      "Batch 185/387 ━━━━━━━━━━━━━━━━━━━━ 21:01:50\n",
      "Accuracy: 0.9979 - Precision: 0.9014 - Recall: 0.8963 - Specificity: 0.9990 - F1: 0.8933 - Loss: 0.1197\n",
      "\n",
      "Batch 186/387 ━━━━━━━━━━━━━━━━━━━━ 21:03:22\n",
      "Accuracy: 0.9979 - Precision: 0.9015 - Recall: 0.8969 - Specificity: 0.9990 - F1: 0.8936 - Loss: 0.1193\n",
      "\n",
      "Batch 187/387 ━━━━━━━━━━━━━━━━━━━━ 21:04:44\n",
      "Accuracy: 0.9979 - Precision: 0.9018 - Recall: 0.8972 - Specificity: 0.9990 - F1: 0.8940 - Loss: 0.1189\n",
      "\n",
      "Batch 188/387 ━━━━━━━━━━━━━━━━━━━━ 21:06:05\n",
      "Accuracy: 0.9979 - Precision: 0.9019 - Recall: 0.8974 - Specificity: 0.9990 - F1: 0.8942 - Loss: 0.1187\n",
      "\n",
      "Batch 189/387 ━━━━━━━━━━━━━━━━━━━━ 21:07:29\n",
      "Accuracy: 0.9979 - Precision: 0.9017 - Recall: 0.8977 - Specificity: 0.9990 - F1: 0.8942 - Loss: 0.1187\n",
      "\n",
      "Batch 190/387 ━━━━━━━━━━━━━━━━━━━━ 21:08:55\n",
      "Accuracy: 0.9979 - Precision: 0.9017 - Recall: 0.8977 - Specificity: 0.9990 - F1: 0.8943 - Loss: 0.1186\n",
      "\n",
      "Batch 191/387 ━━━━━━━━━━━━━━━━━━━━ 21:10:20\n",
      "Accuracy: 0.9979 - Precision: 0.9013 - Recall: 0.8980 - Specificity: 0.9990 - F1: 0.8942 - Loss: 0.1186\n",
      "\n",
      "Batch 192/387 ━━━━━━━━━━━━━━━━━━━━ 21:11:33\n",
      "Accuracy: 0.9979 - Precision: 0.9000 - Recall: 0.8975 - Specificity: 0.9990 - F1: 0.8933 - Loss: 0.1196\n",
      "\n",
      "Batch 193/387 ━━━━━━━━━━━━━━━━━━━━ 21:13:04\n",
      "Accuracy: 0.9979 - Precision: 0.9003 - Recall: 0.8969 - Specificity: 0.9990 - F1: 0.8931 - Loss: 0.1197\n",
      "\n",
      "Batch 194/387 ━━━━━━━━━━━━━━━━━━━━ 21:14:37\n",
      "Accuracy: 0.9979 - Precision: 0.9000 - Recall: 0.8973 - Specificity: 0.9990 - F1: 0.8932 - Loss: 0.1197\n",
      "\n",
      "Batch 195/387 ━━━━━━━━━━━━━━━━━━━━ 21:16:10\n",
      "Accuracy: 0.9979 - Precision: 0.9000 - Recall: 0.8975 - Specificity: 0.9990 - F1: 0.8933 - Loss: 0.1195\n",
      "\n",
      "Batch 196/387 ━━━━━━━━━━━━━━━━━━━━ 21:17:44\n",
      "Accuracy: 0.9979 - Precision: 0.9004 - Recall: 0.8976 - Specificity: 0.9990 - F1: 0.8936 - Loss: 0.1192\n",
      "\n",
      "Batch 197/387 ━━━━━━━━━━━━━━━━━━━━ 21:19:09\n",
      "Accuracy: 0.9979 - Precision: 0.9009 - Recall: 0.8979 - Specificity: 0.9990 - F1: 0.8940 - Loss: 0.1188\n",
      "\n",
      "Batch 198/387 ━━━━━━━━━━━━━━━━━━━━ 21:20:32\n",
      "Accuracy: 0.9979 - Precision: 0.9008 - Recall: 0.8979 - Specificity: 0.9990 - F1: 0.8940 - Loss: 0.1188\n",
      "\n",
      "Batch 199/387 ━━━━━━━━━━━━━━━━━━━━ 21:22:04\n",
      "Accuracy: 0.9979 - Precision: 0.9005 - Recall: 0.8972 - Specificity: 0.9990 - F1: 0.8935 - Loss: 0.1193\n",
      "\n",
      "Batch 200/387 ━━━━━━━━━━━━━━━━━━━━ 21:23:18\n",
      "Accuracy: 0.9979 - Precision: 0.9003 - Recall: 0.8971 - Specificity: 0.9990 - F1: 0.8934 - Loss: 0.1194\n",
      "\n",
      "Batch 201/387 ━━━━━━━━━━━━━━━━━━━━ 21:24:42\n",
      "Accuracy: 0.9979 - Precision: 0.9006 - Recall: 0.8973 - Specificity: 0.9990 - F1: 0.8937 - Loss: 0.1191\n",
      "\n",
      "Batch 202/387 ━━━━━━━━━━━━━━━━━━━━ 21:26:15\n",
      "Accuracy: 0.9979 - Precision: 0.9009 - Recall: 0.8975 - Specificity: 0.9990 - F1: 0.8939 - Loss: 0.1188\n",
      "\n",
      "Batch 203/387 ━━━━━━━━━━━━━━━━━━━━ 21:27:34\n",
      "Accuracy: 0.9979 - Precision: 0.9013 - Recall: 0.8976 - Specificity: 0.9990 - F1: 0.8942 - Loss: 0.1185\n",
      "\n",
      "Batch 204/387 ━━━━━━━━━━━━━━━━━━━━ 21:29:03\n",
      "Accuracy: 0.9979 - Precision: 0.9015 - Recall: 0.8978 - Specificity: 0.9990 - F1: 0.8944 - Loss: 0.1183\n",
      "\n",
      "Batch 205/387 ━━━━━━━━━━━━━━━━━━━━ 21:30:28\n",
      "Accuracy: 0.9979 - Precision: 0.9010 - Recall: 0.8982 - Specificity: 0.9990 - F1: 0.8944 - Loss: 0.1183\n",
      "\n",
      "Batch 206/387 ━━━━━━━━━━━━━━━━━━━━ 21:31:57\n",
      "Accuracy: 0.9979 - Precision: 0.9015 - Recall: 0.8984 - Specificity: 0.9990 - F1: 0.8947 - Loss: 0.1179\n",
      "\n",
      "Batch 207/387 ━━━━━━━━━━━━━━━━━━━━ 21:33:19\n",
      "Accuracy: 0.9979 - Precision: 0.9015 - Recall: 0.8976 - Specificity: 0.9990 - F1: 0.8943 - Loss: 0.1183\n",
      "\n",
      "Batch 208/387 ━━━━━━━━━━━━━━━━━━━━ 21:34:43\n",
      "Accuracy: 0.9979 - Precision: 0.9017 - Recall: 0.8978 - Specificity: 0.9990 - F1: 0.8945 - Loss: 0.1181\n",
      "\n",
      "Batch 209/387 ━━━━━━━━━━━━━━━━━━━━ 21:36:09\n",
      "Accuracy: 0.9979 - Precision: 0.9015 - Recall: 0.8978 - Specificity: 0.9990 - F1: 0.8945 - Loss: 0.1181\n",
      "\n",
      "Batch 210/387 ━━━━━━━━━━━━━━━━━━━━ 21:37:38\n",
      "Accuracy: 0.9979 - Precision: 0.9015 - Recall: 0.8979 - Specificity: 0.9990 - F1: 0.8946 - Loss: 0.1181\n",
      "\n",
      "Batch 211/387 ━━━━━━━━━━━━━━━━━━━━ 21:38:59\n",
      "Accuracy: 0.9979 - Precision: 0.9018 - Recall: 0.8982 - Specificity: 0.9990 - F1: 0.8949 - Loss: 0.1178\n",
      "\n",
      "Batch 212/387 ━━━━━━━━━━━━━━━━━━━━ 21:40:41\n",
      "Accuracy: 0.9979 - Precision: 0.9016 - Recall: 0.8984 - Specificity: 0.9990 - F1: 0.8949 - Loss: 0.1177\n",
      "\n",
      "Batch 213/387 ━━━━━━━━━━━━━━━━━━━━ 21:42:12\n",
      "Accuracy: 0.9979 - Precision: 0.9017 - Recall: 0.8985 - Specificity: 0.9990 - F1: 0.8950 - Loss: 0.1176\n",
      "\n",
      "Batch 214/387 ━━━━━━━━━━━━━━━━━━━━ 21:43:39\n",
      "Accuracy: 0.9979 - Precision: 0.9015 - Recall: 0.8988 - Specificity: 0.9990 - F1: 0.8951 - Loss: 0.1175\n",
      "\n",
      "Batch 215/387 ━━━━━━━━━━━━━━━━━━━━ 21:45:03\n",
      "Accuracy: 0.9979 - Precision: 0.9010 - Recall: 0.8973 - Specificity: 0.9990 - F1: 0.8940 - Loss: 0.1186\n",
      "\n",
      "Batch 216/387 ━━━━━━━━━━━━━━━━━━━━ 21:46:30\n",
      "Accuracy: 0.9979 - Precision: 0.9014 - Recall: 0.8975 - Specificity: 0.9990 - F1: 0.8943 - Loss: 0.1183\n",
      "\n",
      "Batch 217/387 ━━━━━━━━━━━━━━━━━━━━ 21:47:48\n",
      "Accuracy: 0.9979 - Precision: 0.9016 - Recall: 0.8977 - Specificity: 0.9990 - F1: 0.8946 - Loss: 0.1180\n",
      "\n",
      "Batch 218/387 ━━━━━━━━━━━━━━━━━━━━ 21:49:17\n",
      "Accuracy: 0.9979 - Precision: 0.9007 - Recall: 0.8975 - Specificity: 0.9990 - F1: 0.8940 - Loss: 0.1186\n",
      "\n",
      "Batch 219/387 ━━━━━━━━━━━━━━━━━━━━ 21:50:48\n",
      "Accuracy: 0.9979 - Precision: 0.9005 - Recall: 0.8977 - Specificity: 0.9990 - F1: 0.8940 - Loss: 0.1186\n",
      "\n",
      "Batch 220/387 ━━━━━━━━━━━━━━━━━━━━ 21:52:21\n",
      "Accuracy: 0.9979 - Precision: 0.9007 - Recall: 0.8979 - Specificity: 0.9990 - F1: 0.8942 - Loss: 0.1184\n",
      "\n",
      "Batch 221/387 ━━━━━━━━━━━━━━━━━━━━ 21:53:39\n",
      "Accuracy: 0.9979 - Precision: 0.9006 - Recall: 0.8981 - Specificity: 0.9990 - F1: 0.8943 - Loss: 0.1183\n",
      "\n",
      "Batch 222/387 ━━━━━━━━━━━━━━━━━━━━ 21:55:19\n",
      "Accuracy: 0.9979 - Precision: 0.9009 - Recall: 0.8983 - Specificity: 0.9990 - F1: 0.8946 - Loss: 0.1180\n",
      "\n",
      "Batch 223/387 ━━━━━━━━━━━━━━━━━━━━ 21:56:49\n",
      "Accuracy: 0.9979 - Precision: 0.9013 - Recall: 0.8981 - Specificity: 0.9990 - F1: 0.8947 - Loss: 0.1179\n",
      "\n",
      "Batch 224/387 ━━━━━━━━━━━━━━━━━━━━ 21:58:23\n",
      "Accuracy: 0.9979 - Precision: 0.9016 - Recall: 0.8981 - Specificity: 0.9990 - F1: 0.8948 - Loss: 0.1177\n",
      "\n",
      "Batch 225/387 ━━━━━━━━━━━━━━━━━━━━ 21:59:44\n",
      "Accuracy: 0.9979 - Precision: 0.9020 - Recall: 0.8983 - Specificity: 0.9990 - F1: 0.8951 - Loss: 0.1174\n",
      "\n",
      "Batch 226/387 ━━━━━━━━━━━━━━━━━━━━ 22:01:13\n",
      "Accuracy: 0.9979 - Precision: 0.9023 - Recall: 0.8986 - Specificity: 0.9990 - F1: 0.8955 - Loss: 0.1170\n",
      "\n",
      "Batch 227/387 ━━━━━━━━━━━━━━━━━━━━ 22:02:37\n",
      "Accuracy: 0.9979 - Precision: 0.9027 - Recall: 0.8982 - Specificity: 0.9990 - F1: 0.8954 - Loss: 0.1172\n",
      "\n",
      "Batch 228/387 ━━━━━━━━━━━━━━━━━━━━ 22:04:09\n",
      "Accuracy: 0.9979 - Precision: 0.9020 - Recall: 0.8983 - Specificity: 0.9990 - F1: 0.8951 - Loss: 0.1175\n",
      "\n",
      "Batch 229/387 ━━━━━━━━━━━━━━━━━━━━ 22:05:40\n",
      "Accuracy: 0.9979 - Precision: 0.9021 - Recall: 0.8985 - Specificity: 0.9990 - F1: 0.8953 - Loss: 0.1173\n",
      "\n",
      "Batch 230/387 ━━━━━━━━━━━━━━━━━━━━ 22:07:04\n",
      "Accuracy: 0.9979 - Precision: 0.9024 - Recall: 0.8987 - Specificity: 0.9990 - F1: 0.8956 - Loss: 0.1170\n",
      "\n",
      "Batch 231/387 ━━━━━━━━━━━━━━━━━━━━ 22:08:35\n",
      "Accuracy: 0.9979 - Precision: 0.9026 - Recall: 0.8990 - Specificity: 0.9990 - F1: 0.8958 - Loss: 0.1167\n",
      "\n",
      "Batch 232/387 ━━━━━━━━━━━━━━━━━━━━ 22:10:09\n",
      "Accuracy: 0.9979 - Precision: 0.9014 - Recall: 0.8994 - Specificity: 0.9990 - F1: 0.8953 - Loss: 0.1173\n",
      "\n",
      "Batch 233/387 ━━━━━━━━━━━━━━━━━━━━ 22:11:42\n",
      "Accuracy: 0.9979 - Precision: 0.9014 - Recall: 0.8996 - Specificity: 0.9990 - F1: 0.8954 - Loss: 0.1171\n",
      "\n",
      "Batch 234/387 ━━━━━━━━━━━━━━━━━━━━ 22:13:07\n",
      "Accuracy: 0.9979 - Precision: 0.9018 - Recall: 0.8993 - Specificity: 0.9990 - F1: 0.8955 - Loss: 0.1171\n",
      "\n",
      "Batch 235/387 ━━━━━━━━━━━━━━━━━━━━ 22:14:25\n",
      "Accuracy: 0.9979 - Precision: 0.9021 - Recall: 0.8994 - Specificity: 0.9990 - F1: 0.8957 - Loss: 0.1169\n",
      "\n",
      "Batch 236/387 ━━━━━━━━━━━━━━━━━━━━ 22:15:52\n",
      "Accuracy: 0.9979 - Precision: 0.9025 - Recall: 0.8993 - Specificity: 0.9990 - F1: 0.8958 - Loss: 0.1167\n",
      "\n",
      "Batch 237/387 ━━━━━━━━━━━━━━━━━━━━ 22:17:12\n",
      "Accuracy: 0.9979 - Precision: 0.9028 - Recall: 0.8994 - Specificity: 0.9990 - F1: 0.8960 - Loss: 0.1165\n",
      "\n",
      "Batch 238/387 ━━━━━━━━━━━━━━━━━━━━ 22:18:37\n",
      "Accuracy: 0.9979 - Precision: 0.9031 - Recall: 0.8990 - Specificity: 0.9990 - F1: 0.8960 - Loss: 0.1165\n",
      "\n",
      "Batch 239/387 ━━━━━━━━━━━━━━━━━━━━ 22:20:25\n",
      "Accuracy: 0.9979 - Precision: 0.9025 - Recall: 0.8991 - Specificity: 0.9990 - F1: 0.8957 - Loss: 0.1168\n",
      "\n",
      "Batch 240/387 ━━━━━━━━━━━━━━━━━━━━ 22:21:41\n",
      "Accuracy: 0.9979 - Precision: 0.9028 - Recall: 0.8993 - Specificity: 0.9990 - F1: 0.8960 - Loss: 0.1165\n",
      "\n",
      "Batch 241/387 ━━━━━━━━━━━━━━━━━━━━ 22:23:01\n",
      "Accuracy: 0.9979 - Precision: 0.9025 - Recall: 0.8995 - Specificity: 0.9990 - F1: 0.8960 - Loss: 0.1165\n",
      "\n",
      "Batch 242/387 ━━━━━━━━━━━━━━━━━━━━ 22:24:29\n",
      "Accuracy: 0.9979 - Precision: 0.9028 - Recall: 0.8992 - Specificity: 0.9990 - F1: 0.8960 - Loss: 0.1166\n",
      "\n",
      "Batch 243/387 ━━━━━━━━━━━━━━━━━━━━ 22:26:05\n",
      "Accuracy: 0.9979 - Precision: 0.9028 - Recall: 0.8988 - Specificity: 0.9990 - F1: 0.8958 - Loss: 0.1168\n",
      "\n",
      "Batch 244/387 ━━━━━━━━━━━━━━━━━━━━ 22:27:29\n",
      "Accuracy: 0.9979 - Precision: 0.9028 - Recall: 0.8985 - Specificity: 0.9990 - F1: 0.8957 - Loss: 0.1168\n",
      "\n",
      "Batch 245/387 ━━━━━━━━━━━━━━━━━━━━ 22:28:52\n",
      "Accuracy: 0.9979 - Precision: 0.9030 - Recall: 0.8984 - Specificity: 0.9990 - F1: 0.8957 - Loss: 0.1168\n",
      "\n",
      "Batch 246/387 ━━━━━━━━━━━━━━━━━━━━ 22:30:13\n",
      "Accuracy: 0.9979 - Precision: 0.9032 - Recall: 0.8985 - Specificity: 0.9990 - F1: 0.8959 - Loss: 0.1166\n",
      "\n",
      "Batch 247/387 ━━━━━━━━━━━━━━━━━━━━ 22:31:45\n",
      "Accuracy: 0.9979 - Precision: 0.9024 - Recall: 0.8983 - Specificity: 0.9990 - F1: 0.8953 - Loss: 0.1171\n",
      "\n",
      "Batch 248/387 ━━━━━━━━━━━━━━━━━━━━ 22:33:02\n",
      "Accuracy: 0.9979 - Precision: 0.9027 - Recall: 0.8984 - Specificity: 0.9990 - F1: 0.8956 - Loss: 0.1168\n",
      "\n",
      "Batch 249/387 ━━━━━━━━━━━━━━━━━━━━ 22:34:26\n",
      "Accuracy: 0.9979 - Precision: 0.9030 - Recall: 0.8976 - Specificity: 0.9991 - F1: 0.8952 - Loss: 0.1172\n",
      "\n",
      "Batch 250/387 ━━━━━━━━━━━━━━━━━━━━ 22:35:44\n",
      "Accuracy: 0.9980 - Precision: 0.9031 - Recall: 0.8974 - Specificity: 0.9991 - F1: 0.8952 - Loss: 0.1172\n",
      "\n",
      "Batch 251/387 ━━━━━━━━━━━━━━━━━━━━ 22:37:27\n",
      "Accuracy: 0.9980 - Precision: 0.9032 - Recall: 0.8975 - Specificity: 0.9991 - F1: 0.8954 - Loss: 0.1171\n",
      "\n",
      "Batch 252/387 ━━━━━━━━━━━━━━━━━━━━ 22:39:15\n",
      "Accuracy: 0.9980 - Precision: 0.9021 - Recall: 0.8977 - Specificity: 0.9991 - F1: 0.8947 - Loss: 0.1177\n",
      "\n",
      "Batch 253/387 ━━━━━━━━━━━━━━━━━━━━ 22:40:50\n",
      "Accuracy: 0.9980 - Precision: 0.9018 - Recall: 0.8980 - Specificity: 0.9991 - F1: 0.8947 - Loss: 0.1177\n",
      "\n",
      "Batch 254/387 ━━━━━━━━━━━━━━━━━━━━ 22:42:18\n",
      "Accuracy: 0.9980 - Precision: 0.9015 - Recall: 0.8981 - Specificity: 0.9991 - F1: 0.8947 - Loss: 0.1177\n",
      "\n",
      "Batch 255/387 ━━━━━━━━━━━━━━━━━━━━ 22:43:37\n",
      "Accuracy: 0.9980 - Precision: 0.9013 - Recall: 0.8985 - Specificity: 0.9990 - F1: 0.8947 - Loss: 0.1177\n",
      "\n",
      "Batch 256/387 ━━━━━━━━━━━━━━━━━━━━ 22:45:08\n",
      "Accuracy: 0.9980 - Precision: 0.9009 - Recall: 0.8988 - Specificity: 0.9990 - F1: 0.8947 - Loss: 0.1177\n",
      "\n",
      "Batch 257/387 ━━━━━━━━━━━━━━━━━━━━ 22:46:32\n",
      "Accuracy: 0.9980 - Precision: 0.9011 - Recall: 0.8990 - Specificity: 0.9990 - F1: 0.8949 - Loss: 0.1175\n",
      "\n",
      "Batch 258/387 ━━━━━━━━━━━━━━━━━━━━ 22:48:05\n",
      "Accuracy: 0.9980 - Precision: 0.9012 - Recall: 0.8993 - Specificity: 0.9990 - F1: 0.8951 - Loss: 0.1173\n",
      "\n",
      "Batch 259/387 ━━━━━━━━━━━━━━━━━━━━ 22:49:33\n",
      "Accuracy: 0.9980 - Precision: 0.9010 - Recall: 0.8995 - Specificity: 0.9990 - F1: 0.8951 - Loss: 0.1173\n",
      "\n",
      "Batch 260/387 ━━━━━━━━━━━━━━━━━━━━ 22:51:19\n",
      "Accuracy: 0.9980 - Precision: 0.9013 - Recall: 0.8996 - Specificity: 0.9991 - F1: 0.8954 - Loss: 0.1170\n",
      "\n",
      "Batch 261/387 ━━━━━━━━━━━━━━━━━━━━ 22:53:00\n",
      "Accuracy: 0.9980 - Precision: 0.9015 - Recall: 0.8998 - Specificity: 0.9991 - F1: 0.8956 - Loss: 0.1168\n",
      "\n",
      "Batch 262/387 ━━━━━━━━━━━━━━━━━━━━ 22:54:28\n",
      "Accuracy: 0.9980 - Precision: 0.9018 - Recall: 0.8994 - Specificity: 0.9991 - F1: 0.8955 - Loss: 0.1169\n",
      "\n",
      "Batch 263/387 ━━━━━━━━━━━━━━━━━━━━ 22:56:05\n",
      "Accuracy: 0.9980 - Precision: 0.9019 - Recall: 0.8991 - Specificity: 0.9991 - F1: 0.8954 - Loss: 0.1169\n",
      "\n",
      "Batch 264/387 ━━━━━━━━━━━━━━━━━━━━ 22:57:41\n",
      "Accuracy: 0.9980 - Precision: 0.9014 - Recall: 0.8989 - Specificity: 0.9991 - F1: 0.8951 - Loss: 0.1172\n",
      "\n",
      "Batch 265/387 ━━━━━━━━━━━━━━━━━━━━ 22:59:05\n",
      "Accuracy: 0.9980 - Precision: 0.9018 - Recall: 0.8988 - Specificity: 0.9991 - F1: 0.8952 - Loss: 0.1172\n",
      "\n",
      "Batch 266/387 ━━━━━━━━━━━━━━━━━━━━ 23:00:44\n",
      "Accuracy: 0.9980 - Precision: 0.9021 - Recall: 0.8988 - Specificity: 0.9991 - F1: 0.8954 - Loss: 0.1170\n",
      "\n",
      "Batch 267/387 ━━━━━━━━━━━━━━━━━━━━ 23:02:25\n",
      "Accuracy: 0.9980 - Precision: 0.9013 - Recall: 0.8988 - Specificity: 0.9991 - F1: 0.8950 - Loss: 0.1174\n",
      "\n",
      "Batch 268/387 ━━━━━━━━━━━━━━━━━━━━ 23:03:56\n",
      "Accuracy: 0.9980 - Precision: 0.9015 - Recall: 0.8990 - Specificity: 0.9991 - F1: 0.8952 - Loss: 0.1171\n",
      "\n",
      "Batch 269/387 ━━━━━━━━━━━━━━━━━━━━ 23:05:33\n",
      "Accuracy: 0.9980 - Precision: 0.9018 - Recall: 0.8990 - Specificity: 0.9991 - F1: 0.8953 - Loss: 0.1170\n",
      "\n",
      "Batch 270/387 ━━━━━━━━━━━━━━━━━━━━ 23:07:06\n",
      "Accuracy: 0.9980 - Precision: 0.9012 - Recall: 0.8991 - Specificity: 0.9991 - F1: 0.8950 - Loss: 0.1173\n",
      "\n",
      "Batch 271/387 ━━━━━━━━━━━━━━━━━━━━ 23:08:32\n",
      "Accuracy: 0.9980 - Precision: 0.9013 - Recall: 0.8993 - Specificity: 0.9991 - F1: 0.8952 - Loss: 0.1171\n",
      "\n",
      "Batch 272/387 ━━━━━━━━━━━━━━━━━━━━ 23:09:57\n",
      "Accuracy: 0.9980 - Precision: 0.9014 - Recall: 0.8994 - Specificity: 0.9991 - F1: 0.8953 - Loss: 0.1170\n",
      "\n",
      "Batch 273/387 ━━━━━━━━━━━━━━━━━━━━ 23:11:29\n",
      "Accuracy: 0.9980 - Precision: 0.9013 - Recall: 0.8995 - Specificity: 0.9991 - F1: 0.8954 - Loss: 0.1170\n",
      "\n",
      "Batch 274/387 ━━━━━━━━━━━━━━━━━━━━ 23:12:56\n",
      "Accuracy: 0.9980 - Precision: 0.9015 - Recall: 0.8989 - Specificity: 0.9991 - F1: 0.8951 - Loss: 0.1172\n",
      "\n",
      "Batch 275/387 ━━━━━━━━━━━━━━━━━━━━ 23:14:27\n",
      "Accuracy: 0.9980 - Precision: 0.9011 - Recall: 0.8979 - Specificity: 0.9991 - F1: 0.8944 - Loss: 0.1180\n",
      "\n",
      "Batch 276/387 ━━━━━━━━━━━━━━━━━━━━ 23:15:57\n",
      "Accuracy: 0.9980 - Precision: 0.9012 - Recall: 0.8981 - Specificity: 0.9991 - F1: 0.8946 - Loss: 0.1179\n",
      "\n",
      "Batch 277/387 ━━━━━━━━━━━━━━━━━━━━ 23:17:27\n",
      "Accuracy: 0.9980 - Precision: 0.9015 - Recall: 0.8966 - Specificity: 0.9991 - F1: 0.8937 - Loss: 0.1188\n",
      "\n",
      "Batch 278/387 ━━━━━━━━━━━━━━━━━━━━ 23:18:52\n",
      "Accuracy: 0.9979 - Precision: 0.9016 - Recall: 0.8969 - Specificity: 0.9991 - F1: 0.8939 - Loss: 0.1186\n",
      "\n",
      "Batch 279/387 ━━━━━━━━━━━━━━━━━━━━ 23:20:24\n",
      "Accuracy: 0.9979 - Precision: 0.9017 - Recall: 0.8969 - Specificity: 0.9991 - F1: 0.8940 - Loss: 0.1185\n",
      "\n",
      "Batch 280/387 ━━━━━━━━━━━━━━━━━━━━ 23:21:42\n",
      "Accuracy: 0.9979 - Precision: 0.9018 - Recall: 0.8969 - Specificity: 0.9991 - F1: 0.8940 - Loss: 0.1185\n",
      "\n",
      "Batch 281/387 ━━━━━━━━━━━━━━━━━━━━ 23:23:15\n",
      "Accuracy: 0.9979 - Precision: 0.9018 - Recall: 0.8967 - Specificity: 0.9991 - F1: 0.8940 - Loss: 0.1185\n",
      "\n",
      "Batch 282/387 ━━━━━━━━━━━━━━━━━━━━ 23:24:47\n",
      "Accuracy: 0.9980 - Precision: 0.9020 - Recall: 0.8969 - Specificity: 0.9991 - F1: 0.8942 - Loss: 0.1183\n",
      "\n",
      "Batch 283/387 ━━━━━━━━━━━━━━━━━━━━ 23:26:17\n",
      "Accuracy: 0.9980 - Precision: 0.9018 - Recall: 0.8973 - Specificity: 0.9991 - F1: 0.8943 - Loss: 0.1182\n",
      "\n",
      "Batch 284/387 ━━━━━━━━━━━━━━━━━━━━ 23:27:47\n",
      "Accuracy: 0.9980 - Precision: 0.9011 - Recall: 0.8974 - Specificity: 0.9991 - F1: 0.8940 - Loss: 0.1185\n",
      "\n",
      "Batch 285/387 ━━━━━━━━━━━━━━━━━━━━ 23:29:24\n",
      "Accuracy: 0.9979 - Precision: 0.9012 - Recall: 0.8975 - Specificity: 0.9991 - F1: 0.8941 - Loss: 0.1185\n",
      "\n",
      "Batch 286/387 ━━━━━━━━━━━━━━━━━━━━ 23:31:16\n",
      "Accuracy: 0.9979 - Precision: 0.9010 - Recall: 0.8977 - Specificity: 0.9990 - F1: 0.8941 - Loss: 0.1185\n",
      "\n",
      "Batch 287/387 ━━━━━━━━━━━━━━━━━━━━ 23:32:52\n",
      "Accuracy: 0.9979 - Precision: 0.9005 - Recall: 0.8981 - Specificity: 0.9990 - F1: 0.8940 - Loss: 0.1186\n",
      "\n",
      "Batch 288/387 ━━━━━━━━━━━━━━━━━━━━ 23:34:23\n",
      "Accuracy: 0.9979 - Precision: 0.9003 - Recall: 0.8983 - Specificity: 0.9990 - F1: 0.8940 - Loss: 0.1186\n",
      "\n",
      "Batch 289/387 ━━━━━━━━━━━━━━━━━━━━ 23:35:56\n",
      "Accuracy: 0.9979 - Precision: 0.9003 - Recall: 0.8985 - Specificity: 0.9990 - F1: 0.8941 - Loss: 0.1184\n",
      "\n",
      "Batch 290/387 ━━━━━━━━━━━━━━━━━━━━ 23:37:35\n",
      "Accuracy: 0.9979 - Precision: 0.9004 - Recall: 0.8987 - Specificity: 0.9990 - F1: 0.8943 - Loss: 0.1182\n",
      "\n",
      "Batch 291/387 ━━━━━━━━━━━━━━━━━━━━ 23:39:29\n",
      "Accuracy: 0.9979 - Precision: 0.9005 - Recall: 0.8990 - Specificity: 0.9990 - F1: 0.8944 - Loss: 0.1181\n",
      "\n",
      "Batch 292/387 ━━━━━━━━━━━━━━━━━━━━ 23:41:02\n",
      "Accuracy: 0.9979 - Precision: 0.8998 - Recall: 0.8988 - Specificity: 0.9990 - F1: 0.8940 - Loss: 0.1185\n",
      "\n",
      "Batch 293/387 ━━━━━━━━━━━━━━━━━━━━ 23:42:31\n",
      "Accuracy: 0.9979 - Precision: 0.8997 - Recall: 0.8990 - Specificity: 0.9990 - F1: 0.8941 - Loss: 0.1185\n",
      "\n",
      "Batch 294/387 ━━━━━━━━━━━━━━━━━━━━ 23:44:17\n",
      "Accuracy: 0.9979 - Precision: 0.8987 - Recall: 0.8991 - Specificity: 0.9990 - F1: 0.8935 - Loss: 0.1190\n",
      "\n",
      "Batch 295/387 ━━━━━━━━━━━━━━━━━━━━ 23:45:55\n",
      "Accuracy: 0.9979 - Precision: 0.8989 - Recall: 0.8994 - Specificity: 0.9990 - F1: 0.8938 - Loss: 0.1188\n",
      "\n",
      "Batch 296/387 ━━━━━━━━━━━━━━━━━━━━ 23:47:23\n",
      "Accuracy: 0.9979 - Precision: 0.8992 - Recall: 0.8990 - Specificity: 0.9990 - F1: 0.8937 - Loss: 0.1189\n",
      "\n",
      "Batch 297/387 ━━━━━━━━━━━━━━━━━━━━ 23:48:56\n",
      "Accuracy: 0.9979 - Precision: 0.8992 - Recall: 0.8991 - Specificity: 0.9990 - F1: 0.8938 - Loss: 0.1188\n",
      "\n",
      "Batch 298/387 ━━━━━━━━━━━━━━━━━━━━ 23:50:19\n",
      "Accuracy: 0.9979 - Precision: 0.8995 - Recall: 0.8989 - Specificity: 0.9990 - F1: 0.8938 - Loss: 0.1189\n",
      "\n",
      "Batch 299/387 ━━━━━━━━━━━━━━━━━━━━ 23:51:50\n",
      "Accuracy: 0.9979 - Precision: 0.8991 - Recall: 0.8991 - Specificity: 0.9990 - F1: 0.8937 - Loss: 0.1190\n",
      "\n",
      "Batch 300/387 ━━━━━━━━━━━━━━━━━━━━ 23:53:12\n",
      "Accuracy: 0.9979 - Precision: 0.8994 - Recall: 0.8990 - Specificity: 0.9990 - F1: 0.8938 - Loss: 0.1188\n",
      "\n",
      "Batch 301/387 ━━━━━━━━━━━━━━━━━━━━ 23:54:36\n",
      "Accuracy: 0.9979 - Precision: 0.8997 - Recall: 0.8988 - Specificity: 0.9990 - F1: 0.8939 - Loss: 0.1188\n",
      "\n",
      "Batch 302/387 ━━━━━━━━━━━━━━━━━━━━ 23:56:21\n",
      "Accuracy: 0.9979 - Precision: 0.8994 - Recall: 0.8977 - Specificity: 0.9990 - F1: 0.8932 - Loss: 0.1195\n",
      "\n",
      "Batch 303/387 ━━━━━━━━━━━━━━━━━━━━ 23:57:53\n",
      "Accuracy: 0.9979 - Precision: 0.8995 - Recall: 0.8970 - Specificity: 0.9990 - F1: 0.8928 - Loss: 0.1198\n",
      "\n",
      "Batch 304/387 ━━━━━━━━━━━━━━━━━━━━ 23:59:30\n",
      "Accuracy: 0.9979 - Precision: 0.8994 - Recall: 0.8967 - Specificity: 0.9990 - F1: 0.8926 - Loss: 0.1200\n",
      "\n",
      "Batch 305/387 ━━━━━━━━━━━━━━━━━━━━ 00:00:59\n",
      "Accuracy: 0.9979 - Precision: 0.8996 - Recall: 0.8970 - Specificity: 0.9990 - F1: 0.8929 - Loss: 0.1197\n",
      "\n",
      "Batch 306/387 ━━━━━━━━━━━━━━━━━━━━ 00:02:30\n",
      "Accuracy: 0.9979 - Precision: 0.8993 - Recall: 0.8965 - Specificity: 0.9990 - F1: 0.8925 - Loss: 0.1201\n",
      "\n",
      "Batch 307/387 ━━━━━━━━━━━━━━━━━━━━ 00:03:51\n",
      "Accuracy: 0.9979 - Precision: 0.8996 - Recall: 0.8962 - Specificity: 0.9990 - F1: 0.8925 - Loss: 0.1201\n",
      "\n",
      "Batch 308/387 ━━━━━━━━━━━━━━━━━━━━ 00:05:37\n",
      "Accuracy: 0.9979 - Precision: 0.8998 - Recall: 0.8963 - Specificity: 0.9990 - F1: 0.8927 - Loss: 0.1200\n",
      "\n",
      "Batch 309/387 ━━━━━━━━━━━━━━━━━━━━ 00:07:07\n",
      "Accuracy: 0.9979 - Precision: 0.8999 - Recall: 0.8963 - Specificity: 0.9990 - F1: 0.8927 - Loss: 0.1200\n",
      "\n",
      "Batch 310/387 ━━━━━━━━━━━━━━━━━━━━ 00:08:37\n",
      "Accuracy: 0.9979 - Precision: 0.8999 - Recall: 0.8962 - Specificity: 0.9990 - F1: 0.8927 - Loss: 0.1200\n",
      "\n",
      "Batch 311/387 ━━━━━━━━━━━━━━━━━━━━ 00:10:09\n",
      "Accuracy: 0.9979 - Precision: 0.8996 - Recall: 0.8963 - Specificity: 0.9990 - F1: 0.8926 - Loss: 0.1200\n",
      "\n",
      "Batch 312/387 ━━━━━━━━━━━━━━━━━━━━ 00:11:33\n",
      "Accuracy: 0.9979 - Precision: 0.8998 - Recall: 0.8965 - Specificity: 0.9990 - F1: 0.8928 - Loss: 0.1198\n",
      "\n",
      "Batch 313/387 ━━━━━━━━━━━━━━━━━━━━ 00:12:51\n",
      "Accuracy: 0.9979 - Precision: 0.8998 - Recall: 0.8965 - Specificity: 0.9990 - F1: 0.8928 - Loss: 0.1198\n",
      "\n",
      "Batch 314/387 ━━━━━━━━━━━━━━━━━━━━ 00:14:21\n",
      "Accuracy: 0.9979 - Precision: 0.8993 - Recall: 0.8968 - Specificity: 0.9990 - F1: 0.8927 - Loss: 0.1199\n",
      "\n",
      "Batch 315/387 ━━━━━━━━━━━━━━━━━━━━ 00:16:01\n",
      "Accuracy: 0.9979 - Precision: 0.8995 - Recall: 0.8968 - Specificity: 0.9990 - F1: 0.8928 - Loss: 0.1198\n",
      "\n",
      "Batch 316/387 ━━━━━━━━━━━━━━━━━━━━ 00:17:39\n",
      "Accuracy: 0.9979 - Precision: 0.8992 - Recall: 0.8971 - Specificity: 0.9990 - F1: 0.8928 - Loss: 0.1198\n",
      "\n",
      "Batch 317/387 ━━━━━━━━━━━━━━━━━━━━ 00:19:01\n",
      "Accuracy: 0.9979 - Precision: 0.8994 - Recall: 0.8971 - Specificity: 0.9990 - F1: 0.8929 - Loss: 0.1197\n",
      "\n",
      "Batch 318/387 ━━━━━━━━━━━━━━━━━━━━ 00:20:48\n",
      "Accuracy: 0.9979 - Precision: 0.8994 - Recall: 0.8973 - Specificity: 0.9990 - F1: 0.8930 - Loss: 0.1196\n",
      "\n",
      "Batch 319/387 ━━━━━━━━━━━━━━━━━━━━ 00:22:27\n",
      "Accuracy: 0.9979 - Precision: 0.8993 - Recall: 0.8972 - Specificity: 0.9990 - F1: 0.8929 - Loss: 0.1197\n",
      "\n",
      "Batch 320/387 ━━━━━━━━━━━━━━━━━━━━ 00:23:56\n",
      "Accuracy: 0.9979 - Precision: 0.8990 - Recall: 0.8973 - Specificity: 0.9990 - F1: 0.8928 - Loss: 0.1198\n",
      "\n",
      "Batch 321/387 ━━━━━━━━━━━━━━━━━━━━ 00:25:34\n",
      "Accuracy: 0.9979 - Precision: 0.8985 - Recall: 0.8975 - Specificity: 0.9990 - F1: 0.8927 - Loss: 0.1199\n",
      "\n",
      "Batch 322/387 ━━━━━━━━━━━━━━━━━━━━ 00:26:56\n",
      "Accuracy: 0.9979 - Precision: 0.8987 - Recall: 0.8976 - Specificity: 0.9990 - F1: 0.8928 - Loss: 0.1198\n",
      "\n",
      "Batch 323/387 ━━━━━━━━━━━━━━━━━━━━ 00:28:21\n",
      "Accuracy: 0.9979 - Precision: 0.8983 - Recall: 0.8978 - Specificity: 0.9990 - F1: 0.8927 - Loss: 0.1199\n",
      "\n",
      "Batch 324/387 ━━━━━━━━━━━━━━━━━━━━ 00:29:45\n",
      "Accuracy: 0.9979 - Precision: 0.8984 - Recall: 0.8980 - Specificity: 0.9990 - F1: 0.8929 - Loss: 0.1197\n",
      "\n",
      "Batch 325/387 ━━━━━━━━━━━━━━━━━━━━ 00:31:17\n",
      "Accuracy: 0.9979 - Precision: 0.8987 - Recall: 0.8978 - Specificity: 0.9990 - F1: 0.8929 - Loss: 0.1197\n",
      "\n",
      "Batch 326/387 ━━━━━━━━━━━━━━━━━━━━ 00:32:44\n",
      "Accuracy: 0.9979 - Precision: 0.8988 - Recall: 0.8977 - Specificity: 0.9990 - F1: 0.8929 - Loss: 0.1196\n",
      "\n",
      "Batch 327/387 ━━━━━━━━━━━━━━━━━━━━ 00:34:04\n",
      "Accuracy: 0.9979 - Precision: 0.8990 - Recall: 0.8978 - Specificity: 0.9990 - F1: 0.8932 - Loss: 0.1194\n",
      "\n",
      "Batch 328/387 ━━━━━━━━━━━━━━━━━━━━ 00:35:26\n",
      "Accuracy: 0.9979 - Precision: 0.8990 - Recall: 0.8973 - Specificity: 0.9990 - F1: 0.8929 - Loss: 0.1197\n",
      "\n",
      "Batch 329/387 ━━━━━━━━━━━━━━━━━━━━ 00:36:54\n",
      "Accuracy: 0.9979 - Precision: 0.8988 - Recall: 0.8974 - Specificity: 0.9990 - F1: 0.8928 - Loss: 0.1198\n",
      "\n",
      "Batch 330/387 ━━━━━━━━━━━━━━━━━━━━ 00:38:30\n",
      "Accuracy: 0.9979 - Precision: 0.8991 - Recall: 0.8973 - Specificity: 0.9990 - F1: 0.8929 - Loss: 0.1197\n",
      "\n",
      "Batch 331/387 ━━━━━━━━━━━━━━━━━━━━ 00:39:54\n",
      "Accuracy: 0.9979 - Precision: 0.8991 - Recall: 0.8974 - Specificity: 0.9990 - F1: 0.8930 - Loss: 0.1196\n",
      "\n",
      "Batch 332/387 ━━━━━━━━━━━━━━━━━━━━ 00:41:15\n",
      "Accuracy: 0.9979 - Precision: 0.8993 - Recall: 0.8972 - Specificity: 0.9990 - F1: 0.8930 - Loss: 0.1196\n",
      "\n",
      "Batch 333/387 ━━━━━━━━━━━━━━━━━━━━ 00:42:58\n",
      "Accuracy: 0.9979 - Precision: 0.8996 - Recall: 0.8967 - Specificity: 0.9990 - F1: 0.8928 - Loss: 0.1199\n",
      "\n",
      "Batch 334/387 ━━━━━━━━━━━━━━━━━━━━ 00:44:30\n",
      "Accuracy: 0.9979 - Precision: 0.8994 - Recall: 0.8967 - Specificity: 0.9990 - F1: 0.8927 - Loss: 0.1199\n",
      "\n",
      "Batch 335/387 ━━━━━━━━━━━━━━━━━━━━ 00:46:05\n",
      "Accuracy: 0.9979 - Precision: 0.8994 - Recall: 0.8969 - Specificity: 0.9990 - F1: 0.8928 - Loss: 0.1199\n",
      "\n",
      "Batch 336/387 ━━━━━━━━━━━━━━━━━━━━ 00:47:41\n",
      "Accuracy: 0.9979 - Precision: 0.8986 - Recall: 0.8967 - Specificity: 0.9990 - F1: 0.8924 - Loss: 0.1204\n",
      "\n",
      "Batch 337/387 ━━━━━━━━━━━━━━━━━━━━ 00:49:05\n",
      "Accuracy: 0.9979 - Precision: 0.8988 - Recall: 0.8963 - Specificity: 0.9990 - F1: 0.8922 - Loss: 0.1205\n",
      "\n",
      "Batch 338/387 ━━━━━━━━━━━━━━━━━━━━ 00:50:41\n",
      "Accuracy: 0.9979 - Precision: 0.8987 - Recall: 0.8965 - Specificity: 0.9990 - F1: 0.8923 - Loss: 0.1204\n",
      "\n",
      "Batch 339/387 ━━━━━━━━━━━━━━━━━━━━ 00:52:09\n",
      "Accuracy: 0.9979 - Precision: 0.8988 - Recall: 0.8967 - Specificity: 0.9990 - F1: 0.8924 - Loss: 0.1203\n",
      "\n",
      "Batch 340/387 ━━━━━━━━━━━━━━━━━━━━ 00:53:38\n",
      "Accuracy: 0.9979 - Precision: 0.8988 - Recall: 0.8969 - Specificity: 0.9990 - F1: 0.8925 - Loss: 0.1202\n",
      "\n",
      "Batch 341/387 ━━━━━━━━━━━━━━━━━━━━ 00:54:55\n",
      "Accuracy: 0.9979 - Precision: 0.8989 - Recall: 0.8968 - Specificity: 0.9990 - F1: 0.8925 - Loss: 0.1202\n",
      "\n",
      "Batch 342/387 ━━━━━━━━━━━━━━━━━━━━ 00:56:19\n",
      "Accuracy: 0.9979 - Precision: 0.8985 - Recall: 0.8967 - Specificity: 0.9990 - F1: 0.8923 - Loss: 0.1204\n",
      "\n",
      "Batch 343/387 ━━━━━━━━━━━━━━━━━━━━ 00:57:37\n",
      "Accuracy: 0.9979 - Precision: 0.8980 - Recall: 0.8965 - Specificity: 0.9990 - F1: 0.8920 - Loss: 0.1207\n",
      "\n",
      "Batch 344/387 ━━━━━━━━━━━━━━━━━━━━ 00:59:07\n",
      "Accuracy: 0.9979 - Precision: 0.8979 - Recall: 0.8960 - Specificity: 0.9990 - F1: 0.8916 - Loss: 0.1211\n",
      "\n",
      "Batch 345/387 ━━━━━━━━━━━━━━━━━━━━ 01:00:50\n",
      "Accuracy: 0.9979 - Precision: 0.8978 - Recall: 0.8961 - Specificity: 0.9990 - F1: 0.8916 - Loss: 0.1212\n",
      "\n",
      "Batch 346/387 ━━━━━━━━━━━━━━━━━━━━ 01:02:20\n",
      "Accuracy: 0.9979 - Precision: 0.8979 - Recall: 0.8962 - Specificity: 0.9990 - F1: 0.8918 - Loss: 0.1210\n",
      "\n",
      "Batch 347/387 ━━━━━━━━━━━━━━━━━━━━ 01:03:51\n",
      "Accuracy: 0.9979 - Precision: 0.8980 - Recall: 0.8961 - Specificity: 0.9990 - F1: 0.8918 - Loss: 0.1210\n",
      "\n",
      "Batch 348/387 ━━━━━━━━━━━━━━━━━━━━ 01:05:15\n",
      "Accuracy: 0.9979 - Precision: 0.8977 - Recall: 0.8963 - Specificity: 0.9990 - F1: 0.8917 - Loss: 0.1211\n",
      "\n",
      "Batch 349/387 ━━━━━━━━━━━━━━━━━━━━ 01:06:50\n",
      "Accuracy: 0.9979 - Precision: 0.8979 - Recall: 0.8963 - Specificity: 0.9990 - F1: 0.8918 - Loss: 0.1210\n",
      "\n",
      "Batch 350/387 ━━━━━━━━━━━━━━━━━━━━ 01:08:15\n",
      "Accuracy: 0.9979 - Precision: 0.8980 - Recall: 0.8964 - Specificity: 0.9990 - F1: 0.8919 - Loss: 0.1209\n",
      "\n",
      "Batch 351/387 ━━━━━━━━━━━━━━━━━━━━ 01:09:38\n",
      "Accuracy: 0.9979 - Precision: 0.8981 - Recall: 0.8963 - Specificity: 0.9990 - F1: 0.8920 - Loss: 0.1208\n",
      "\n",
      "Batch 352/387 ━━━━━━━━━━━━━━━━━━━━ 01:11:15\n",
      "Accuracy: 0.9979 - Precision: 0.8982 - Recall: 0.8966 - Specificity: 0.9990 - F1: 0.8921 - Loss: 0.1207\n",
      "\n",
      "Batch 353/387 ━━━━━━━━━━━━━━━━━━━━ 01:12:38\n",
      "Accuracy: 0.9979 - Precision: 0.8984 - Recall: 0.8968 - Specificity: 0.9990 - F1: 0.8923 - Loss: 0.1204\n",
      "\n",
      "Batch 354/387 ━━━━━━━━━━━━━━━━━━━━ 01:14:03\n",
      "Accuracy: 0.9979 - Precision: 0.8983 - Recall: 0.8964 - Specificity: 0.9990 - F1: 0.8921 - Loss: 0.1206\n",
      "\n",
      "Batch 355/387 ━━━━━━━━━━━━━━━━━━━━ 01:15:28\n",
      "Accuracy: 0.9979 - Precision: 0.8984 - Recall: 0.8965 - Specificity: 0.9990 - F1: 0.8923 - Loss: 0.1205\n",
      "\n",
      "Batch 356/387 ━━━━━━━━━━━━━━━━━━━━ 01:16:59\n",
      "Accuracy: 0.9979 - Precision: 0.8983 - Recall: 0.8967 - Specificity: 0.9990 - F1: 0.8923 - Loss: 0.1205\n",
      "\n",
      "Batch 357/387 ━━━━━━━━━━━━━━━━━━━━ 01:18:20\n",
      "Accuracy: 0.9979 - Precision: 0.8981 - Recall: 0.8969 - Specificity: 0.9990 - F1: 0.8923 - Loss: 0.1204\n",
      "\n",
      "Batch 358/387 ━━━━━━━━━━━━━━━━━━━━ 01:20:06\n",
      "Accuracy: 0.9979 - Precision: 0.8982 - Recall: 0.8970 - Specificity: 0.9990 - F1: 0.8924 - Loss: 0.1203\n",
      "\n",
      "Batch 359/387 ━━━━━━━━━━━━━━━━━━━━ 01:21:44\n",
      "Accuracy: 0.9979 - Precision: 0.8982 - Recall: 0.8964 - Specificity: 0.9990 - F1: 0.8921 - Loss: 0.1206\n",
      "\n",
      "Batch 360/387 ━━━━━━━━━━━━━━━━━━━━ 01:23:12\n",
      "Accuracy: 0.9979 - Precision: 0.8984 - Recall: 0.8965 - Specificity: 0.9990 - F1: 0.8923 - Loss: 0.1205\n",
      "\n",
      "Batch 361/387 ━━━━━━━━━━━━━━━━━━━━ 01:24:48\n",
      "Accuracy: 0.9979 - Precision: 0.8983 - Recall: 0.8965 - Specificity: 0.9990 - F1: 0.8923 - Loss: 0.1205\n",
      "\n",
      "Batch 362/387 ━━━━━━━━━━━━━━━━━━━━ 01:26:17\n",
      "Accuracy: 0.9979 - Precision: 0.8985 - Recall: 0.8964 - Specificity: 0.9990 - F1: 0.8923 - Loss: 0.1204\n",
      "\n",
      "Batch 363/387 ━━━━━━━━━━━━━━━━━━━━ 01:27:56\n",
      "Accuracy: 0.9979 - Precision: 0.8980 - Recall: 0.8964 - Specificity: 0.9990 - F1: 0.8920 - Loss: 0.1207\n",
      "\n",
      "Batch 364/387 ━━━━━━━━━━━━━━━━━━━━ 01:29:46\n",
      "Accuracy: 0.9979 - Precision: 0.8979 - Recall: 0.8966 - Specificity: 0.9990 - F1: 0.8921 - Loss: 0.1206\n",
      "\n",
      "Batch 365/387 ━━━━━━━━━━━━━━━━━━━━ 01:31:19\n",
      "Accuracy: 0.9979 - Precision: 0.8982 - Recall: 0.8965 - Specificity: 0.9990 - F1: 0.8922 - Loss: 0.1205\n",
      "\n",
      "Batch 366/387 ━━━━━━━━━━━━━━━━━━━━ 01:33:05\n",
      "Accuracy: 0.9979 - Precision: 0.8984 - Recall: 0.8962 - Specificity: 0.9990 - F1: 0.8921 - Loss: 0.1206\n",
      "\n",
      "Batch 367/387 ━━━━━━━━━━━━━━━━━━━━ 01:34:35\n",
      "Accuracy: 0.9979 - Precision: 0.8984 - Recall: 0.8962 - Specificity: 0.9990 - F1: 0.8921 - Loss: 0.1206\n",
      "\n",
      "Batch 368/387 ━━━━━━━━━━━━━━━━━━━━ 01:36:00\n",
      "Accuracy: 0.9979 - Precision: 0.8983 - Recall: 0.8955 - Specificity: 0.9990 - F1: 0.8917 - Loss: 0.1210\n",
      "\n",
      "Batch 369/387 ━━━━━━━━━━━━━━━━━━━━ 01:37:32\n",
      "Accuracy: 0.9979 - Precision: 0.8985 - Recall: 0.8955 - Specificity: 0.9990 - F1: 0.8918 - Loss: 0.1209\n",
      "\n",
      "Batch 370/387 ━━━━━━━━━━━━━━━━━━━━ 01:39:03\n",
      "Accuracy: 0.9979 - Precision: 0.8986 - Recall: 0.8957 - Specificity: 0.9990 - F1: 0.8920 - Loss: 0.1207\n",
      "\n",
      "Batch 371/387 ━━━━━━━━━━━━━━━━━━━━ 01:40:38\n",
      "Accuracy: 0.9979 - Precision: 0.8986 - Recall: 0.8959 - Specificity: 0.9990 - F1: 0.8921 - Loss: 0.1206\n",
      "\n",
      "Batch 372/387 ━━━━━━━━━━━━━━━━━━━━ 01:42:17\n",
      "Accuracy: 0.9979 - Precision: 0.8988 - Recall: 0.8961 - Specificity: 0.9990 - F1: 0.8923 - Loss: 0.1204\n",
      "\n",
      "Batch 373/387 ━━━━━━━━━━━━━━━━━━━━ 01:43:50\n",
      "Accuracy: 0.9979 - Precision: 0.8989 - Recall: 0.8961 - Specificity: 0.9990 - F1: 0.8924 - Loss: 0.1202\n",
      "\n",
      "Batch 374/387 ━━━━━━━━━━━━━━━━━━━━ 01:45:19\n",
      "Accuracy: 0.9979 - Precision: 0.8987 - Recall: 0.8962 - Specificity: 0.9990 - F1: 0.8924 - Loss: 0.1203\n",
      "\n",
      "Batch 375/387 ━━━━━━━━━━━━━━━━━━━━ 01:46:45\n",
      "Accuracy: 0.9979 - Precision: 0.8989 - Recall: 0.8964 - Specificity: 0.9990 - F1: 0.8925 - Loss: 0.1201\n",
      "\n",
      "Batch 376/387 ━━━━━━━━━━━━━━━━━━━━ 01:48:09\n",
      "Accuracy: 0.9979 - Precision: 0.8990 - Recall: 0.8965 - Specificity: 0.9990 - F1: 0.8927 - Loss: 0.1200\n",
      "\n",
      "Batch 377/387 ━━━━━━━━━━━━━━━━━━━━ 01:49:39\n",
      "Accuracy: 0.9979 - Precision: 0.8990 - Recall: 0.8967 - Specificity: 0.9990 - F1: 0.8928 - Loss: 0.1198\n",
      "\n",
      "Batch 378/387 ━━━━━━━━━━━━━━━━━━━━ 01:51:05\n",
      "Accuracy: 0.9979 - Precision: 0.8988 - Recall: 0.8964 - Specificity: 0.9990 - F1: 0.8925 - Loss: 0.1201\n",
      "\n",
      "Batch 379/387 ━━━━━━━━━━━━━━━━━━━━ 01:52:35\n",
      "Accuracy: 0.9979 - Precision: 0.8985 - Recall: 0.8965 - Specificity: 0.9990 - F1: 0.8924 - Loss: 0.1202\n",
      "\n",
      "Batch 380/387 ━━━━━━━━━━━━━━━━━━━━ 01:53:59\n",
      "Accuracy: 0.9979 - Precision: 0.8982 - Recall: 0.8966 - Specificity: 0.9990 - F1: 0.8923 - Loss: 0.1203\n",
      "\n",
      "Batch 381/387 ━━━━━━━━━━━━━━━━━━━━ 01:55:46\n",
      "Accuracy: 0.9979 - Precision: 0.8982 - Recall: 0.8967 - Specificity: 0.9990 - F1: 0.8924 - Loss: 0.1202\n",
      "\n",
      "Batch 382/387 ━━━━━━━━━━━━━━━━━━━━ 01:57:13\n",
      "Accuracy: 0.9979 - Precision: 0.8983 - Recall: 0.8964 - Specificity: 0.9990 - F1: 0.8922 - Loss: 0.1204\n",
      "\n",
      "Batch 383/387 ━━━━━━━━━━━━━━━━━━━━ 01:59:03\n",
      "Accuracy: 0.9979 - Precision: 0.8983 - Recall: 0.8960 - Specificity: 0.9990 - F1: 0.8921 - Loss: 0.1205\n",
      "\n",
      "Batch 384/387 ━━━━━━━━━━━━━━━━━━━━ 02:00:45\n",
      "Accuracy: 0.9979 - Precision: 0.8985 - Recall: 0.8960 - Specificity: 0.9990 - F1: 0.8922 - Loss: 0.1204\n",
      "\n",
      "Batch 385/387 ━━━━━━━━━━━━━━━━━━━━ 02:02:01\n",
      "Accuracy: 0.9979 - Precision: 0.8983 - Recall: 0.8955 - Specificity: 0.9990 - F1: 0.8918 - Loss: 0.1209\n",
      "\n",
      "Batch 386/387 ━━━━━━━━━━━━━━━━━━━━ 02:03:36\n",
      "Accuracy: 0.9979 - Precision: 0.8985 - Recall: 0.8955 - Specificity: 0.9990 - F1: 0.8919 - Loss: 0.1207\n",
      "\n",
      "Batch 387/387 ━━━━━━━━━━━━━━━━━━━━ 02:05:11\n",
      "Accuracy: 0.9979 - Precision: 0.8987 - Recall: 0.8956 - Specificity: 0.9990 - F1: 0.8921 - Loss: 0.1206\n",
      "\n",
      "End of Epoch 15\n",
      "\n",
      "Epoch 16/50\n",
      "Batch 1/387 ━━━━━━━━━━━━━━━━━━━━ 02:26:55\n",
      "Accuracy: 0.9963 - Precision: 0.7282 - Recall: 0.7129 - Specificity: 0.9982 - F1: 0.7205 - Loss: 0.3067\n",
      "\n",
      "Batch 2/387 ━━━━━━━━━━━━━━━━━━━━ 02:28:34\n",
      "Accuracy: 0.9975 - Precision: 0.8454 - Recall: 0.8323 - Specificity: 0.9988 - F1: 0.8388 - Loss: 0.1783\n",
      "\n",
      "Batch 3/387 ━━━━━━━━━━━━━━━━━━━━ 02:30:05\n",
      "Accuracy: 0.9976 - Precision: 0.8835 - Recall: 0.8624 - Specificity: 0.9990 - F1: 0.8728 - Loss: 0.1427\n",
      "\n",
      "Batch 4/387 ━━━━━━━━━━━━━━━━━━━━ 02:31:26\n",
      "Accuracy: 0.9972 - Precision: 0.9055 - Recall: 0.8552 - Specificity: 0.9991 - F1: 0.8789 - Loss: 0.1390\n",
      "\n",
      "Batch 5/387 ━━━━━━━━━━━━━━━━━━━━ 02:32:49\n",
      "Accuracy: 0.9972 - Precision: 0.8782 - Recall: 0.8689 - Specificity: 0.9988 - F1: 0.8710 - Loss: 0.1467\n",
      "\n",
      "Batch 6/387 ━━━━━━━━━━━━━━━━━━━━ 02:34:17\n",
      "Accuracy: 0.9973 - Precision: 0.8598 - Recall: 0.8833 - Specificity: 0.9987 - F1: 0.8677 - Loss: 0.1489\n",
      "\n",
      "Batch 7/387 ━━━━━━━━━━━━━━━━━━━━ 02:35:42\n",
      "Accuracy: 0.9975 - Precision: 0.8745 - Recall: 0.8916 - Specificity: 0.9988 - F1: 0.8798 - Loss: 0.1354\n",
      "\n",
      "Batch 8/387 ━━━━━━━━━━━━━━━━━━━━ 02:37:06\n",
      "Accuracy: 0.9975 - Precision: 0.8752 - Recall: 0.8922 - Specificity: 0.9988 - F1: 0.8808 - Loss: 0.1343\n",
      "\n",
      "Batch 9/387 ━━━━━━━━━━━━━━━━━━━━ 02:38:27\n",
      "Accuracy: 0.9977 - Precision: 0.8847 - Recall: 0.9011 - Specificity: 0.9989 - F1: 0.8903 - Loss: 0.1236\n",
      "\n",
      "Batch 10/387 ━━━━━━━━━━━━━━━━━━━━ 02:39:58\n",
      "Accuracy: 0.9977 - Precision: 0.8865 - Recall: 0.9099 - Specificity: 0.9988 - F1: 0.8957 - Loss: 0.1177\n",
      "\n",
      "Batch 11/387 ━━━━━━━━━━━━━━━━━━━━ 02:41:15\n",
      "Accuracy: 0.9978 - Precision: 0.8864 - Recall: 0.9179 - Specificity: 0.9988 - F1: 0.8995 - Loss: 0.1133\n",
      "\n",
      "Batch 12/387 ━━━━━━━━━━━━━━━━━━━━ 02:42:43\n",
      "Accuracy: 0.9978 - Precision: 0.8944 - Recall: 0.9158 - Specificity: 0.9989 - F1: 0.9025 - Loss: 0.1103\n",
      "\n",
      "Batch 13/387 ━━━━━━━━━━━━━━━━━━━━ 02:44:07\n",
      "Accuracy: 0.9978 - Precision: 0.8997 - Recall: 0.9152 - Specificity: 0.9989 - F1: 0.9050 - Loss: 0.1077\n",
      "\n",
      "Batch 14/387 ━━━━━━━━━━━━━━━━━━━━ 02:45:25\n",
      "Accuracy: 0.9977 - Precision: 0.9004 - Recall: 0.9156 - Specificity: 0.9989 - F1: 0.9057 - Loss: 0.1072\n",
      "\n",
      "Batch 15/387 ━━━━━━━━━━━━━━━━━━━━ 02:46:55\n",
      "Accuracy: 0.9977 - Precision: 0.9046 - Recall: 0.9170 - Specificity: 0.9989 - F1: 0.9087 - Loss: 0.1042\n",
      "\n",
      "Batch 16/387 ━━━━━━━━━━━━━━━━━━━━ 02:48:26\n",
      "Accuracy: 0.9977 - Precision: 0.9075 - Recall: 0.9149 - Specificity: 0.9989 - F1: 0.9091 - Loss: 0.1042\n",
      "\n",
      "Batch 17/387 ━━━━━━━━━━━━━━━━━━━━ 02:49:53\n",
      "Accuracy: 0.9976 - Precision: 0.9039 - Recall: 0.9181 - Specificity: 0.9988 - F1: 0.9088 - Loss: 0.1048\n",
      "\n",
      "Batch 18/387 ━━━━━━━━━━━━━━━━━━━━ 02:51:21\n",
      "Accuracy: 0.9977 - Precision: 0.9043 - Recall: 0.9150 - Specificity: 0.9988 - F1: 0.9076 - Loss: 0.1058\n",
      "\n",
      "Batch 19/387 ━━━━━━━━━━━━━━━━━━━━ 02:52:53\n",
      "Accuracy: 0.9977 - Precision: 0.9073 - Recall: 0.9157 - Specificity: 0.9989 - F1: 0.9095 - Loss: 0.1036\n",
      "\n",
      "Batch 20/387 ━━━━━━━━━━━━━━━━━━━━ 02:54:25\n",
      "Accuracy: 0.9977 - Precision: 0.8937 - Recall: 0.9175 - Specificity: 0.9988 - F1: 0.9021 - Loss: 0.1110\n",
      "\n",
      "Batch 21/387 ━━━━━━━━━━━━━━━━━━━━ 02:56:04\n",
      "Accuracy: 0.9975 - Precision: 0.8924 - Recall: 0.9096 - Specificity: 0.9988 - F1: 0.8975 - Loss: 0.1168\n",
      "\n",
      "Batch 22/387 ━━━━━━━━━━━━━━━━━━━━ 02:57:26\n",
      "Accuracy: 0.9975 - Precision: 0.8965 - Recall: 0.9102 - Specificity: 0.9988 - F1: 0.9000 - Loss: 0.1142\n",
      "\n",
      "Batch 23/387 ━━━━━━━━━━━━━━━━━━━━ 02:58:54\n",
      "Accuracy: 0.9976 - Precision: 0.8975 - Recall: 0.9124 - Specificity: 0.9988 - F1: 0.9017 - Loss: 0.1123\n",
      "\n",
      "Batch 24/387 ━━━━━━━━━━━━━━━━━━━━ 03:00:31\n",
      "Accuracy: 0.9976 - Precision: 0.8998 - Recall: 0.9096 - Specificity: 0.9988 - F1: 0.9015 - Loss: 0.1124\n",
      "\n",
      "Batch 25/387 ━━━━━━━━━━━━━━━━━━━━ 03:02:02\n",
      "Accuracy: 0.9977 - Precision: 0.9025 - Recall: 0.9105 - Specificity: 0.9989 - F1: 0.9033 - Loss: 0.1102\n",
      "\n",
      "Batch 26/387 ━━━━━━━━━━━━━━━━━━━━ 03:03:28\n",
      "Accuracy: 0.9977 - Precision: 0.9052 - Recall: 0.9116 - Specificity: 0.9989 - F1: 0.9053 - Loss: 0.1081\n",
      "\n",
      "Batch 27/387 ━━━━━━━━━━━━━━━━━━━━ 03:04:50\n",
      "Accuracy: 0.9977 - Precision: 0.9069 - Recall: 0.9114 - Specificity: 0.9989 - F1: 0.9062 - Loss: 0.1071\n",
      "\n",
      "Batch 28/387 ━━━━━━━━━━━━━━━━━━━━ 03:06:20\n",
      "Accuracy: 0.9977 - Precision: 0.9048 - Recall: 0.9112 - Specificity: 0.9989 - F1: 0.9051 - Loss: 0.1081\n",
      "\n",
      "Batch 29/387 ━━━━━━━━━━━━━━━━━━━━ 03:07:47\n",
      "Accuracy: 0.9978 - Precision: 0.9036 - Recall: 0.9128 - Specificity: 0.9989 - F1: 0.9054 - Loss: 0.1077\n",
      "\n",
      "Batch 30/387 ━━━━━━━━━━━━━━━━━━━━ 03:09:09\n",
      "Accuracy: 0.9978 - Precision: 0.9061 - Recall: 0.9127 - Specificity: 0.9989 - F1: 0.9066 - Loss: 0.1064\n",
      "\n",
      "Batch 31/387 ━━━━━━━━━━━━━━━━━━━━ 03:10:40\n",
      "Accuracy: 0.9977 - Precision: 0.9077 - Recall: 0.9122 - Specificity: 0.9989 - F1: 0.9072 - Loss: 0.1059\n",
      "\n",
      "Batch 32/387 ━━━━━━━━━━━━━━━━━━━━ 03:12:18\n",
      "Accuracy: 0.9977 - Precision: 0.9033 - Recall: 0.9101 - Specificity: 0.9989 - F1: 0.9040 - Loss: 0.1093\n",
      "\n",
      "Batch 33/387 ━━━━━━━━━━━━━━━━━━━━ 03:13:38\n",
      "Accuracy: 0.9977 - Precision: 0.9036 - Recall: 0.9106 - Specificity: 0.9989 - F1: 0.9045 - Loss: 0.1091\n",
      "\n",
      "Batch 34/387 ━━━━━━━━━━━━━━━━━━━━ 03:15:06\n",
      "Accuracy: 0.9977 - Precision: 0.8979 - Recall: 0.9083 - Specificity: 0.9989 - F1: 0.9004 - Loss: 0.1131\n",
      "\n",
      "Batch 35/387 ━━━━━━━━━━━━━━━━━━━━ 03:16:28\n",
      "Accuracy: 0.9977 - Precision: 0.8917 - Recall: 0.9096 - Specificity: 0.9989 - F1: 0.8974 - Loss: 0.1162\n",
      "\n",
      "Batch 36/387 ━━━━━━━━━━━━━━━━━━━━ 03:17:53\n",
      "Accuracy: 0.9978 - Precision: 0.8906 - Recall: 0.9114 - Specificity: 0.9989 - F1: 0.8977 - Loss: 0.1156\n",
      "\n",
      "Batch 37/387 ━━━━━━━━━━━━━━━━━━━━ 03:19:29\n",
      "Accuracy: 0.9978 - Precision: 0.8918 - Recall: 0.9117 - Specificity: 0.9989 - F1: 0.8985 - Loss: 0.1145\n",
      "\n",
      "Batch 38/387 ━━━━━━━━━━━━━━━━━━━━ 03:20:54\n",
      "Accuracy: 0.9979 - Precision: 0.8935 - Recall: 0.9118 - Specificity: 0.9990 - F1: 0.8995 - Loss: 0.1134\n",
      "\n",
      "Batch 39/387 ━━━━━━━━━━━━━━━━━━━━ 08:24:44\n",
      "Accuracy: 0.9979 - Precision: 0.8920 - Recall: 0.9129 - Specificity: 0.9989 - F1: 0.8993 - Loss: 0.1137\n",
      "\n",
      "Batch 40/387 ━━━━━━━━━━━━━━━━━━━━ 08:26:27\n",
      "Accuracy: 0.9979 - Precision: 0.8907 - Recall: 0.9129 - Specificity: 0.9989 - F1: 0.8987 - Loss: 0.1141\n",
      "\n",
      "Batch 41/387 ━━━━━━━━━━━━━━━━━━━━ 08:27:59\n",
      "Accuracy: 0.9979 - Precision: 0.8922 - Recall: 0.9133 - Specificity: 0.9989 - F1: 0.8997 - Loss: 0.1130\n",
      "\n",
      "Batch 42/387 ━━━━━━━━━━━━━━━━━━━━ 08:29:26\n",
      "Accuracy: 0.9979 - Precision: 0.8940 - Recall: 0.9107 - Specificity: 0.9990 - F1: 0.8992 - Loss: 0.1136\n",
      "\n",
      "Batch 43/387 ━━━━━━━━━━━━━━━━━━━━ 08:30:58\n",
      "Accuracy: 0.9979 - Precision: 0.8962 - Recall: 0.9108 - Specificity: 0.9990 - F1: 0.9004 - Loss: 0.1122\n",
      "\n",
      "Batch 44/387 ━━━━━━━━━━━━━━━━━━━━ 08:32:37\n",
      "Accuracy: 0.9979 - Precision: 0.8984 - Recall: 0.9078 - Specificity: 0.9990 - F1: 0.8998 - Loss: 0.1127\n",
      "\n",
      "Batch 45/387 ━━━━━━━━━━━━━━━━━━━━ 08:34:09\n",
      "Accuracy: 0.9979 - Precision: 0.8994 - Recall: 0.9034 - Specificity: 0.9990 - F1: 0.8978 - Loss: 0.1150\n",
      "\n",
      "Batch 46/387 ━━━━━━━━━━━━━━━━━━━━ 08:35:41\n",
      "Accuracy: 0.9979 - Precision: 0.9005 - Recall: 0.9048 - Specificity: 0.9990 - F1: 0.8991 - Loss: 0.1135\n",
      "\n",
      "Batch 47/387 ━━━━━━━━━━━━━━━━━━━━ 08:37:13\n",
      "Accuracy: 0.9979 - Precision: 0.8980 - Recall: 0.9059 - Specificity: 0.9990 - F1: 0.8983 - Loss: 0.1144\n",
      "\n",
      "Batch 48/387 ━━━━━━━━━━━━━━━━━━━━ 08:38:42\n",
      "Accuracy: 0.9979 - Precision: 0.8931 - Recall: 0.9023 - Specificity: 0.9990 - F1: 0.8941 - Loss: 0.1186\n",
      "\n",
      "Batch 49/387 ━━━━━━━━━━━━━━━━━━━━ 08:40:04\n",
      "Accuracy: 0.9979 - Precision: 0.8937 - Recall: 0.9030 - Specificity: 0.9990 - F1: 0.8948 - Loss: 0.1178\n",
      "\n",
      "Batch 50/387 ━━━━━━━━━━━━━━━━━━━━ 08:41:34\n",
      "Accuracy: 0.9979 - Precision: 0.8938 - Recall: 0.9001 - Specificity: 0.9990 - F1: 0.8934 - Loss: 0.1194\n",
      "\n",
      "Batch 51/387 ━━━━━━━━━━━━━━━━━━━━ 08:43:07\n",
      "Accuracy: 0.9979 - Precision: 0.8955 - Recall: 0.8965 - Specificity: 0.9990 - F1: 0.8921 - Loss: 0.1208\n",
      "\n",
      "Batch 52/387 ━━━━━━━━━━━━━━━━━━━━ 08:44:44\n",
      "Accuracy: 0.9979 - Precision: 0.8970 - Recall: 0.8962 - Specificity: 0.9990 - F1: 0.8927 - Loss: 0.1200\n",
      "\n",
      "Batch 53/387 ━━━━━━━━━━━━━━━━━━━━ 08:46:02\n",
      "Accuracy: 0.9979 - Precision: 0.8985 - Recall: 0.8886 - Specificity: 0.9991 - F1: 0.8882 - Loss: 0.1247\n",
      "\n",
      "Batch 54/387 ━━━━━━━━━━━━━━━━━━━━ 08:47:29\n",
      "Accuracy: 0.9979 - Precision: 0.8960 - Recall: 0.8907 - Specificity: 0.9991 - F1: 0.8878 - Loss: 0.1251\n",
      "\n",
      "Batch 55/387 ━━━━━━━━━━━━━━━━━━━━ 08:49:02\n",
      "Accuracy: 0.9979 - Precision: 0.8968 - Recall: 0.8903 - Specificity: 0.9991 - F1: 0.8881 - Loss: 0.1248\n",
      "\n",
      "Batch 56/387 ━━━━━━━━━━━━━━━━━━━━ 08:50:33\n",
      "Accuracy: 0.9979 - Precision: 0.8967 - Recall: 0.8900 - Specificity: 0.9991 - F1: 0.8880 - Loss: 0.1248\n",
      "\n",
      "Batch 57/387 ━━━━━━━━━━━━━━━━━━━━ 08:52:07\n",
      "Accuracy: 0.9979 - Precision: 0.8930 - Recall: 0.8903 - Specificity: 0.9991 - F1: 0.8862 - Loss: 0.1266\n",
      "\n",
      "Batch 58/387 ━━━━━━━━━━━━━━━━━━━━ 08:53:27\n",
      "Accuracy: 0.9979 - Precision: 0.8922 - Recall: 0.8909 - Specificity: 0.9990 - F1: 0.8861 - Loss: 0.1269\n",
      "\n",
      "Batch 59/387 ━━━━━━━━━━━━━━━━━━━━ 08:54:45\n",
      "Accuracy: 0.9978 - Precision: 0.8910 - Recall: 0.8885 - Specificity: 0.9990 - F1: 0.8844 - Loss: 0.1289\n",
      "\n",
      "Batch 60/387 ━━━━━━━━━━━━━━━━━━━━ 08:56:06\n",
      "Accuracy: 0.9978 - Precision: 0.8893 - Recall: 0.8895 - Specificity: 0.9990 - F1: 0.8840 - Loss: 0.1294\n",
      "\n",
      "Batch 61/387 ━━━━━━━━━━━━━━━━━━━━ 08:57:37\n",
      "Accuracy: 0.9978 - Precision: 0.8900 - Recall: 0.8889 - Specificity: 0.9990 - F1: 0.8841 - Loss: 0.1293\n",
      "\n",
      "Batch 62/387 ━━━━━━━━━━━━━━━━━━━━ 08:59:06\n",
      "Accuracy: 0.9979 - Precision: 0.8903 - Recall: 0.8902 - Specificity: 0.9990 - F1: 0.8850 - Loss: 0.1282\n",
      "\n",
      "Batch 63/387 ━━━━━━━━━━━━━━━━━━━━ 09:00:38\n",
      "Accuracy: 0.9979 - Precision: 0.8920 - Recall: 0.8901 - Specificity: 0.9990 - F1: 0.8858 - Loss: 0.1274\n",
      "\n",
      "Batch 64/387 ━━━━━━━━━━━━━━━━━━━━ 09:02:01\n",
      "Accuracy: 0.9979 - Precision: 0.8934 - Recall: 0.8909 - Specificity: 0.9990 - F1: 0.8870 - Loss: 0.1261\n",
      "\n",
      "Batch 65/387 ━━━━━━━━━━━━━━━━━━━━ 09:03:40\n",
      "Accuracy: 0.9979 - Precision: 0.8940 - Recall: 0.8911 - Specificity: 0.9990 - F1: 0.8874 - Loss: 0.1257\n",
      "\n",
      "Batch 66/387 ━━━━━━━━━━━━━━━━━━━━ 09:04:59\n",
      "Accuracy: 0.9979 - Precision: 0.8952 - Recall: 0.8923 - Specificity: 0.9990 - F1: 0.8887 - Loss: 0.1243\n",
      "\n",
      "Batch 67/387 ━━━━━━━━━━━━━━━━━━━━ 09:06:21\n",
      "Accuracy: 0.9979 - Precision: 0.8941 - Recall: 0.8933 - Specificity: 0.9990 - F1: 0.8887 - Loss: 0.1243\n",
      "\n",
      "Batch 68/387 ━━━━━━━━━━━━━━━━━━━━ 09:07:51\n",
      "Accuracy: 0.9979 - Precision: 0.8936 - Recall: 0.8929 - Specificity: 0.9990 - F1: 0.8883 - Loss: 0.1246\n",
      "\n",
      "Batch 69/387 ━━━━━━━━━━━━━━━━━━━━ 09:09:25\n",
      "Accuracy: 0.9979 - Precision: 0.8937 - Recall: 0.8937 - Specificity: 0.9990 - F1: 0.8888 - Loss: 0.1241\n",
      "\n",
      "Batch 70/387 ━━━━━━━━━━━━━━━━━━━━ 09:11:00\n",
      "Accuracy: 0.9979 - Precision: 0.8942 - Recall: 0.8933 - Specificity: 0.9990 - F1: 0.8890 - Loss: 0.1241\n",
      "\n",
      "Batch 71/387 ━━━━━━━━━━━━━━━━━━━━ 09:12:24\n",
      "Accuracy: 0.9979 - Precision: 0.8955 - Recall: 0.8922 - Specificity: 0.9990 - F1: 0.8890 - Loss: 0.1240\n",
      "\n",
      "Batch 72/387 ━━━━━━━━━━━━━━━━━━━━ 09:13:52\n",
      "Accuracy: 0.9979 - Precision: 0.8950 - Recall: 0.8930 - Specificity: 0.9990 - F1: 0.8892 - Loss: 0.1237\n",
      "\n",
      "Batch 73/387 ━━━━━━━━━━━━━━━━━━━━ 09:15:14\n",
      "Accuracy: 0.9979 - Precision: 0.8959 - Recall: 0.8938 - Specificity: 0.9990 - F1: 0.8901 - Loss: 0.1227\n",
      "\n",
      "Batch 74/387 ━━━━━━━━━━━━━━━━━━━━ 09:16:49\n",
      "Accuracy: 0.9979 - Precision: 0.8966 - Recall: 0.8940 - Specificity: 0.9990 - F1: 0.8906 - Loss: 0.1222\n",
      "\n",
      "Batch 75/387 ━━━━━━━━━━━━━━━━━━━━ 09:18:41\n",
      "Accuracy: 0.9979 - Precision: 0.8971 - Recall: 0.8918 - Specificity: 0.9990 - F1: 0.8896 - Loss: 0.1233\n",
      "\n",
      "Batch 76/387 ━━━━━━━━━━━━━━━━━━━━ 09:20:13\n",
      "Accuracy: 0.9979 - Precision: 0.8963 - Recall: 0.8917 - Specificity: 0.9990 - F1: 0.8892 - Loss: 0.1237\n",
      "\n",
      "Batch 77/387 ━━━━━━━━━━━━━━━━━━━━ 09:21:37\n",
      "Accuracy: 0.9979 - Precision: 0.8970 - Recall: 0.8917 - Specificity: 0.9990 - F1: 0.8896 - Loss: 0.1233\n",
      "\n",
      "Batch 78/387 ━━━━━━━━━━━━━━━━━━━━ 09:22:59\n",
      "Accuracy: 0.9979 - Precision: 0.8974 - Recall: 0.8922 - Specificity: 0.9991 - F1: 0.8902 - Loss: 0.1227\n",
      "\n",
      "Batch 79/387 ━━━━━━━━━━━━━━━━━━━━ 09:24:35\n",
      "Accuracy: 0.9979 - Precision: 0.8982 - Recall: 0.8931 - Specificity: 0.9991 - F1: 0.8910 - Loss: 0.1218\n",
      "\n",
      "Batch 80/387 ━━━━━━━━━━━━━━━━━━━━ 09:25:55\n",
      "Accuracy: 0.9979 - Precision: 0.8986 - Recall: 0.8922 - Specificity: 0.9991 - F1: 0.8908 - Loss: 0.1220\n",
      "\n",
      "Batch 81/387 ━━━━━━━━━━━━━━━━━━━━ 09:27:13\n",
      "Accuracy: 0.9979 - Precision: 0.8991 - Recall: 0.8921 - Specificity: 0.9991 - F1: 0.8910 - Loss: 0.1217\n",
      "\n",
      "Batch 82/387 ━━━━━━━━━━━━━━━━━━━━ 09:28:29\n",
      "Accuracy: 0.9979 - Precision: 0.8990 - Recall: 0.8930 - Specificity: 0.9991 - F1: 0.8915 - Loss: 0.1212\n",
      "\n",
      "Batch 83/387 ━━━━━━━━━━━━━━━━━━━━ 09:29:57\n",
      "Accuracy: 0.9979 - Precision: 0.8998 - Recall: 0.8938 - Specificity: 0.9991 - F1: 0.8924 - Loss: 0.1203\n",
      "\n",
      "Batch 84/387 ━━━━━━━━━━━━━━━━━━━━ 09:31:13\n",
      "Accuracy: 0.9979 - Precision: 0.9003 - Recall: 0.8943 - Specificity: 0.9991 - F1: 0.8929 - Loss: 0.1197\n",
      "\n",
      "Batch 85/387 ━━━━━━━━━━━━━━━━━━━━ 09:32:37\n",
      "Accuracy: 0.9980 - Precision: 0.9013 - Recall: 0.8949 - Specificity: 0.9991 - F1: 0.8937 - Loss: 0.1188\n",
      "\n",
      "Batch 86/387 ━━━━━━━━━━━━━━━━━━━━ 09:34:01\n",
      "Accuracy: 0.9979 - Precision: 0.9022 - Recall: 0.8940 - Specificity: 0.9991 - F1: 0.8937 - Loss: 0.1189\n",
      "\n",
      "Batch 87/387 ━━━━━━━━━━━━━━━━━━━━ 09:35:27\n",
      "Accuracy: 0.9979 - Precision: 0.8990 - Recall: 0.8952 - Specificity: 0.9991 - F1: 0.8923 - Loss: 0.1203\n",
      "\n",
      "Batch 88/387 ━━━━━━━━━━━━━━━━━━━━ 09:37:01\n",
      "Accuracy: 0.9979 - Precision: 0.8990 - Recall: 0.8959 - Specificity: 0.9991 - F1: 0.8927 - Loss: 0.1199\n",
      "\n",
      "Batch 89/387 ━━━━━━━━━━━━━━━━━━━━ 09:38:34\n",
      "Accuracy: 0.9980 - Precision: 0.8975 - Recall: 0.8968 - Specificity: 0.9991 - F1: 0.8923 - Loss: 0.1202\n",
      "\n",
      "Batch 90/387 ━━━━━━━━━━━━━━━━━━━━ 09:39:58\n",
      "Accuracy: 0.9980 - Precision: 0.8985 - Recall: 0.8962 - Specificity: 0.9991 - F1: 0.8925 - Loss: 0.1201\n",
      "\n",
      "Batch 91/387 ━━━━━━━━━━━━━━━━━━━━ 09:41:28\n",
      "Accuracy: 0.9980 - Precision: 0.8993 - Recall: 0.8967 - Specificity: 0.9991 - F1: 0.8932 - Loss: 0.1193\n",
      "\n",
      "Batch 92/387 ━━━━━━━━━━━━━━━━━━━━ 09:43:04\n",
      "Accuracy: 0.9980 - Precision: 0.8983 - Recall: 0.8966 - Specificity: 0.9991 - F1: 0.8927 - Loss: 0.1199\n",
      "\n",
      "Batch 93/387 ━━━━━━━━━━━━━━━━━━━━ 09:44:35\n",
      "Accuracy: 0.9980 - Precision: 0.8975 - Recall: 0.8972 - Specificity: 0.9991 - F1: 0.8926 - Loss: 0.1199\n",
      "\n",
      "Batch 94/387 ━━━━━━━━━━━━━━━━━━━━ 09:45:57\n",
      "Accuracy: 0.9980 - Precision: 0.8968 - Recall: 0.8974 - Specificity: 0.9991 - F1: 0.8923 - Loss: 0.1202\n",
      "\n",
      "Batch 95/387 ━━━━━━━━━━━━━━━━━━━━ 09:47:13\n",
      "Accuracy: 0.9980 - Precision: 0.8964 - Recall: 0.8977 - Specificity: 0.9991 - F1: 0.8923 - Loss: 0.1202\n",
      "\n",
      "Batch 96/387 ━━━━━━━━━━━━━━━━━━━━ 09:48:40\n",
      "Accuracy: 0.9980 - Precision: 0.8965 - Recall: 0.8966 - Specificity: 0.9991 - F1: 0.8919 - Loss: 0.1206\n",
      "\n",
      "Batch 97/387 ━━━━━━━━━━━━━━━━━━━━ 09:50:10\n",
      "Accuracy: 0.9980 - Precision: 0.8969 - Recall: 0.8950 - Specificity: 0.9991 - F1: 0.8912 - Loss: 0.1212\n",
      "\n",
      "Batch 98/387 ━━━━━━━━━━━━━━━━━━━━ 09:51:24\n",
      "Accuracy: 0.9980 - Precision: 0.8968 - Recall: 0.8949 - Specificity: 0.9991 - F1: 0.8911 - Loss: 0.1212\n",
      "\n",
      "Batch 99/387 ━━━━━━━━━━━━━━━━━━━━ 09:52:56\n",
      "Accuracy: 0.9980 - Precision: 0.8975 - Recall: 0.8933 - Specificity: 0.9991 - F1: 0.8906 - Loss: 0.1217\n",
      "\n",
      "Batch 100/387 ━━━━━━━━━━━━━━━━━━━━ 09:54:25\n",
      "Accuracy: 0.9980 - Precision: 0.8979 - Recall: 0.8927 - Specificity: 0.9991 - F1: 0.8905 - Loss: 0.1219\n",
      "\n",
      "Batch 101/387 ━━━━━━━━━━━━━━━━━━━━ 09:55:43\n",
      "Accuracy: 0.9980 - Precision: 0.8978 - Recall: 0.8913 - Specificity: 0.9991 - F1: 0.8897 - Loss: 0.1227\n",
      "\n",
      "Batch 102/387 ━━━━━━━━━━━━━━━━━━━━ 09:57:16\n",
      "Accuracy: 0.9980 - Precision: 0.8982 - Recall: 0.8917 - Specificity: 0.9991 - F1: 0.8902 - Loss: 0.1222\n",
      "\n",
      "Batch 103/387 ━━━━━━━━━━━━━━━━━━━━ 09:58:50\n",
      "Accuracy: 0.9980 - Precision: 0.8987 - Recall: 0.8918 - Specificity: 0.9991 - F1: 0.8905 - Loss: 0.1218\n",
      "\n",
      "Batch 104/387 ━━━━━━━━━━━━━━━━━━━━ 10:00:19\n",
      "Accuracy: 0.9980 - Precision: 0.8994 - Recall: 0.8919 - Specificity: 0.9991 - F1: 0.8909 - Loss: 0.1213\n",
      "\n",
      "Batch 105/387 ━━━━━━━━━━━━━━━━━━━━ 10:01:58\n",
      "Accuracy: 0.9980 - Precision: 0.8992 - Recall: 0.8924 - Specificity: 0.9991 - F1: 0.8911 - Loss: 0.1211\n",
      "\n",
      "Batch 106/387 ━━━━━━━━━━━━━━━━━━━━ 10:03:20\n",
      "Accuracy: 0.9980 - Precision: 0.8987 - Recall: 0.8921 - Specificity: 0.9991 - F1: 0.8908 - Loss: 0.1215\n",
      "\n",
      "Batch 107/387 ━━━━━━━━━━━━━━━━━━━━ 10:04:44\n",
      "Accuracy: 0.9980 - Precision: 0.8988 - Recall: 0.8930 - Specificity: 0.9991 - F1: 0.8913 - Loss: 0.1209\n",
      "\n",
      "Batch 108/387 ━━━━━━━━━━━━━━━━━━━━ 10:06:20\n",
      "Accuracy: 0.9980 - Precision: 0.8994 - Recall: 0.8935 - Specificity: 0.9991 - F1: 0.8919 - Loss: 0.1203\n",
      "\n",
      "Batch 109/387 ━━━━━━━━━━━━━━━━━━━━ 10:07:46\n",
      "Accuracy: 0.9980 - Precision: 0.8992 - Recall: 0.8944 - Specificity: 0.9991 - F1: 0.8922 - Loss: 0.1200\n",
      "\n",
      "Batch 110/387 ━━━━━━━━━━━━━━━━━━━━ 10:09:15\n",
      "Accuracy: 0.9980 - Precision: 0.8993 - Recall: 0.8951 - Specificity: 0.9991 - F1: 0.8927 - Loss: 0.1195\n",
      "\n",
      "Batch 111/387 ━━━━━━━━━━━━━━━━━━━━ 10:10:48\n",
      "Accuracy: 0.9980 - Precision: 0.8996 - Recall: 0.8956 - Specificity: 0.9991 - F1: 0.8931 - Loss: 0.1191\n",
      "\n",
      "Batch 112/387 ━━━━━━━━━━━━━━━━━━━━ 10:12:05\n",
      "Accuracy: 0.9980 - Precision: 0.8980 - Recall: 0.8956 - Specificity: 0.9991 - F1: 0.8923 - Loss: 0.1199\n",
      "\n",
      "Batch 113/387 ━━━━━━━━━━━━━━━━━━━━ 10:13:30\n",
      "Accuracy: 0.9980 - Precision: 0.8984 - Recall: 0.8960 - Specificity: 0.9991 - F1: 0.8927 - Loss: 0.1194\n",
      "\n",
      "Batch 114/387 ━━━━━━━━━━━━━━━━━━━━ 10:14:53\n",
      "Accuracy: 0.9980 - Precision: 0.8978 - Recall: 0.8959 - Specificity: 0.9991 - F1: 0.8924 - Loss: 0.1197\n",
      "\n",
      "Batch 115/387 ━━━━━━━━━━━━━━━━━━━━ 10:16:21\n",
      "Accuracy: 0.9980 - Precision: 0.8978 - Recall: 0.8962 - Specificity: 0.9991 - F1: 0.8926 - Loss: 0.1195\n",
      "\n",
      "Batch 116/387 ━━━━━━━━━━━━━━━━━━━━ 10:17:51\n",
      "Accuracy: 0.9980 - Precision: 0.8971 - Recall: 0.8953 - Specificity: 0.9991 - F1: 0.8918 - Loss: 0.1204\n",
      "\n",
      "Batch 117/387 ━━━━━━━━━━━━━━━━━━━━ 10:19:23\n",
      "Accuracy: 0.9980 - Precision: 0.8977 - Recall: 0.8957 - Specificity: 0.9991 - F1: 0.8923 - Loss: 0.1197\n",
      "\n",
      "Batch 118/387 ━━━━━━━━━━━━━━━━━━━━ 10:20:40\n",
      "Accuracy: 0.9980 - Precision: 0.8984 - Recall: 0.8960 - Specificity: 0.9991 - F1: 0.8929 - Loss: 0.1192\n",
      "\n",
      "Batch 119/387 ━━━━━━━━━━━━━━━━━━━━ 10:22:00\n",
      "Accuracy: 0.9980 - Precision: 0.8988 - Recall: 0.8961 - Specificity: 0.9991 - F1: 0.8931 - Loss: 0.1189\n",
      "\n",
      "Batch 120/387 ━━━━━━━━━━━━━━━━━━━━ 10:23:29\n",
      "Accuracy: 0.9980 - Precision: 0.8969 - Recall: 0.8962 - Specificity: 0.9991 - F1: 0.8922 - Loss: 0.1198\n",
      "\n",
      "Batch 121/387 ━━━━━━━━━━━━━━━━━━━━ 10:25:00\n",
      "Accuracy: 0.9980 - Precision: 0.8950 - Recall: 0.8966 - Specificity: 0.9991 - F1: 0.8913 - Loss: 0.1208\n",
      "\n",
      "Batch 122/387 ━━━━━━━━━━━━━━━━━━━━ 10:26:34\n",
      "Accuracy: 0.9980 - Precision: 0.8950 - Recall: 0.8965 - Specificity: 0.9991 - F1: 0.8912 - Loss: 0.1208\n",
      "\n",
      "Batch 123/387 ━━━━━━━━━━━━━━━━━━━━ 10:28:09\n",
      "Accuracy: 0.9980 - Precision: 0.8934 - Recall: 0.8954 - Specificity: 0.9991 - F1: 0.8899 - Loss: 0.1222\n",
      "\n",
      "Batch 124/387 ━━━━━━━━━━━━━━━━━━━━ 10:29:51\n",
      "Accuracy: 0.9980 - Precision: 0.8940 - Recall: 0.8957 - Specificity: 0.9991 - F1: 0.8904 - Loss: 0.1216\n",
      "\n",
      "Batch 125/387 ━━━━━━━━━━━━━━━━━━━━ 10:31:14\n",
      "Accuracy: 0.9980 - Precision: 0.8948 - Recall: 0.8940 - Specificity: 0.9991 - F1: 0.8898 - Loss: 0.1223\n",
      "\n",
      "Batch 126/387 ━━━━━━━━━━━━━━━━━━━━ 10:32:47\n",
      "Accuracy: 0.9980 - Precision: 0.8955 - Recall: 0.8926 - Specificity: 0.9991 - F1: 0.8893 - Loss: 0.1229\n",
      "\n",
      "Batch 127/387 ━━━━━━━━━━━━━━━━━━━━ 10:34:20\n",
      "Accuracy: 0.9980 - Precision: 0.8962 - Recall: 0.8926 - Specificity: 0.9991 - F1: 0.8896 - Loss: 0.1225\n",
      "\n",
      "Batch 128/387 ━━━━━━━━━━━━━━━━━━━━ 10:35:46\n",
      "Accuracy: 0.9980 - Precision: 0.8968 - Recall: 0.8931 - Specificity: 0.9991 - F1: 0.8902 - Loss: 0.1219\n",
      "\n",
      "Batch 129/387 ━━━━━━━━━━━━━━━━━━━━ 10:37:18\n",
      "Accuracy: 0.9980 - Precision: 0.8966 - Recall: 0.8914 - Specificity: 0.9991 - F1: 0.8892 - Loss: 0.1228\n",
      "\n",
      "Batch 130/387 ━━━━━━━━━━━━━━━━━━━━ 10:38:40\n",
      "Accuracy: 0.9980 - Precision: 0.8968 - Recall: 0.8920 - Specificity: 0.9991 - F1: 0.8897 - Loss: 0.1224\n",
      "\n",
      "Batch 131/387 ━━━━━━━━━━━━━━━━━━━━ 10:40:09\n",
      "Accuracy: 0.9980 - Precision: 0.8971 - Recall: 0.8922 - Specificity: 0.9991 - F1: 0.8900 - Loss: 0.1220\n",
      "\n",
      "Batch 132/387 ━━━━━━━━━━━━━━━━━━━━ 10:41:40\n",
      "Accuracy: 0.9980 - Precision: 0.8973 - Recall: 0.8924 - Specificity: 0.9991 - F1: 0.8901 - Loss: 0.1219\n",
      "\n",
      "Batch 133/387 ━━━━━━━━━━━━━━━━━━━━ 10:43:24\n",
      "Accuracy: 0.9980 - Precision: 0.8978 - Recall: 0.8927 - Specificity: 0.9991 - F1: 0.8906 - Loss: 0.1214\n",
      "\n",
      "Batch 134/387 ━━━━━━━━━━━━━━━━━━━━ 10:44:59\n",
      "Accuracy: 0.9980 - Precision: 0.8970 - Recall: 0.8930 - Specificity: 0.9991 - F1: 0.8903 - Loss: 0.1218\n",
      "\n",
      "Batch 135/387 ━━━━━━━━━━━━━━━━━━━━ 10:46:44\n",
      "Accuracy: 0.9980 - Precision: 0.8975 - Recall: 0.8923 - Specificity: 0.9991 - F1: 0.8902 - Loss: 0.1219\n",
      "\n",
      "Batch 136/387 ━━━━━━━━━━━━━━━━━━━━ 10:48:18\n",
      "Accuracy: 0.9980 - Precision: 0.8975 - Recall: 0.8926 - Specificity: 0.9991 - F1: 0.8905 - Loss: 0.1217\n",
      "\n",
      "Batch 137/387 ━━━━━━━━━━━━━━━━━━━━ 10:49:47\n",
      "Accuracy: 0.9980 - Precision: 0.8981 - Recall: 0.8928 - Specificity: 0.9991 - F1: 0.8908 - Loss: 0.1213\n",
      "\n",
      "Batch 138/387 ━━━━━━━━━━━━━━━━━━━━ 10:51:21\n",
      "Accuracy: 0.9980 - Precision: 0.8985 - Recall: 0.8929 - Specificity: 0.9991 - F1: 0.8911 - Loss: 0.1209\n",
      "\n",
      "Batch 139/387 ━━━━━━━━━━━━━━━━━━━━ 10:52:43\n",
      "Accuracy: 0.9980 - Precision: 0.8981 - Recall: 0.8933 - Specificity: 0.9991 - F1: 0.8912 - Loss: 0.1209\n",
      "\n",
      "Batch 140/387 ━━━━━━━━━━━━━━━━━━━━ 10:54:14\n",
      "Accuracy: 0.9980 - Precision: 0.8984 - Recall: 0.8939 - Specificity: 0.9991 - F1: 0.8916 - Loss: 0.1205\n",
      "\n",
      "Batch 141/387 ━━━━━━━━━━━━━━━━━━━━ 10:55:39\n",
      "Accuracy: 0.9980 - Precision: 0.8979 - Recall: 0.8936 - Specificity: 0.9991 - F1: 0.8913 - Loss: 0.1209\n",
      "\n",
      "Batch 142/387 ━━━━━━━━━━━━━━━━━━━━ 10:57:00\n",
      "Accuracy: 0.9980 - Precision: 0.8968 - Recall: 0.8937 - Specificity: 0.9991 - F1: 0.8907 - Loss: 0.1215\n",
      "\n",
      "Batch 143/387 ━━━━━━━━━━━━━━━━━━━━ 10:58:24\n",
      "Accuracy: 0.9980 - Precision: 0.8967 - Recall: 0.8935 - Specificity: 0.9991 - F1: 0.8906 - Loss: 0.1216\n",
      "\n",
      "Batch 144/387 ━━━━━━━━━━━━━━━━━━━━ 10:59:52\n",
      "Accuracy: 0.9980 - Precision: 0.8950 - Recall: 0.8939 - Specificity: 0.9991 - F1: 0.8898 - Loss: 0.1224\n",
      "\n",
      "Batch 145/387 ━━━━━━━━━━━━━━━━━━━━ 11:01:19\n",
      "Accuracy: 0.9980 - Precision: 0.8938 - Recall: 0.8940 - Specificity: 0.9991 - F1: 0.8892 - Loss: 0.1230\n",
      "\n",
      "Batch 146/387 ━━━━━━━━━━━━━━━━━━━━ 11:02:40\n",
      "Accuracy: 0.9980 - Precision: 0.8932 - Recall: 0.8946 - Specificity: 0.9991 - F1: 0.8892 - Loss: 0.1230\n",
      "\n",
      "Batch 147/387 ━━━━━━━━━━━━━━━━━━━━ 11:04:10\n",
      "Accuracy: 0.9980 - Precision: 0.8938 - Recall: 0.8943 - Specificity: 0.9991 - F1: 0.8893 - Loss: 0.1228\n",
      "\n",
      "Batch 148/387 ━━━━━━━━━━━━━━━━━━━━ 11:05:39\n",
      "Accuracy: 0.9980 - Precision: 0.8940 - Recall: 0.8933 - Specificity: 0.9991 - F1: 0.8889 - Loss: 0.1232\n",
      "\n",
      "Batch 149/387 ━━━━━━━━━━━━━━━━━━━━ 11:07:09\n",
      "Accuracy: 0.9980 - Precision: 0.8941 - Recall: 0.8931 - Specificity: 0.9991 - F1: 0.8888 - Loss: 0.1234\n",
      "\n",
      "Batch 150/387 ━━━━━━━━━━━━━━━━━━━━ 11:08:32\n",
      "Accuracy: 0.9980 - Precision: 0.8940 - Recall: 0.8935 - Specificity: 0.9991 - F1: 0.8890 - Loss: 0.1232\n",
      "\n",
      "Batch 151/387 ━━━━━━━━━━━━━━━━━━━━ 11:10:13\n",
      "Accuracy: 0.9980 - Precision: 0.8939 - Recall: 0.8939 - Specificity: 0.9991 - F1: 0.8892 - Loss: 0.1230\n",
      "\n",
      "Batch 152/387 ━━━━━━━━━━━━━━━━━━━━ 11:11:50\n",
      "Accuracy: 0.9980 - Precision: 0.8940 - Recall: 0.8943 - Specificity: 0.9991 - F1: 0.8894 - Loss: 0.1227\n",
      "\n",
      "Batch 153/387 ━━━━━━━━━━━━━━━━━━━━ 11:13:10\n",
      "Accuracy: 0.9980 - Precision: 0.8942 - Recall: 0.8943 - Specificity: 0.9991 - F1: 0.8896 - Loss: 0.1227\n",
      "\n",
      "Batch 154/387 ━━━━━━━━━━━━━━━━━━━━ 11:14:31\n",
      "Accuracy: 0.9980 - Precision: 0.8940 - Recall: 0.8937 - Specificity: 0.9991 - F1: 0.8892 - Loss: 0.1231\n",
      "\n",
      "Batch 155/387 ━━━━━━━━━━━━━━━━━━━━ 11:16:02\n",
      "Accuracy: 0.9980 - Precision: 0.8946 - Recall: 0.8938 - Specificity: 0.9991 - F1: 0.8896 - Loss: 0.1227\n",
      "\n",
      "Batch 156/387 ━━━━━━━━━━━━━━━━━━━━ 11:17:17\n",
      "Accuracy: 0.9980 - Precision: 0.8952 - Recall: 0.8924 - Specificity: 0.9991 - F1: 0.8890 - Loss: 0.1232\n",
      "\n",
      "Batch 157/387 ━━━━━━━━━━━━━━━━━━━━ 11:18:45\n",
      "Accuracy: 0.9980 - Precision: 0.8958 - Recall: 0.8915 - Specificity: 0.9991 - F1: 0.8888 - Loss: 0.1236\n",
      "\n",
      "Batch 158/387 ━━━━━━━━━━━━━━━━━━━━ 11:20:05\n",
      "Accuracy: 0.9980 - Precision: 0.8962 - Recall: 0.8915 - Specificity: 0.9991 - F1: 0.8890 - Loss: 0.1233\n",
      "\n",
      "Batch 159/387 ━━━━━━━━━━━━━━━━━━━━ 11:21:33\n",
      "Accuracy: 0.9980 - Precision: 0.8957 - Recall: 0.8919 - Specificity: 0.9991 - F1: 0.8889 - Loss: 0.1234\n",
      "\n",
      "Batch 160/387 ━━━━━━━━━━━━━━━━━━━━ 11:22:57\n",
      "Accuracy: 0.9980 - Precision: 0.8960 - Recall: 0.8915 - Specificity: 0.9991 - F1: 0.8889 - Loss: 0.1234\n",
      "\n",
      "Batch 161/387 ━━━━━━━━━━━━━━━━━━━━ 12:02:45\n",
      "Accuracy: 0.9980 - Precision: 0.8964 - Recall: 0.8918 - Specificity: 0.9991 - F1: 0.8893 - Loss: 0.1230\n",
      "\n",
      "Batch 162/387 ━━━━━━━━━━━━━━━━━━━━ 12:04:14\n",
      "Accuracy: 0.9980 - Precision: 0.8958 - Recall: 0.8913 - Specificity: 0.9991 - F1: 0.8888 - Loss: 0.1235\n",
      "\n",
      "Batch 163/387 ━━━━━━━━━━━━━━━━━━━━ 12:05:51\n",
      "Accuracy: 0.9980 - Precision: 0.8961 - Recall: 0.8917 - Specificity: 0.9991 - F1: 0.8892 - Loss: 0.1231\n",
      "\n",
      "Batch 164/387 ━━━━━━━━━━━━━━━━━━━━ 12:07:19\n",
      "Accuracy: 0.9980 - Precision: 0.8964 - Recall: 0.8919 - Specificity: 0.9991 - F1: 0.8894 - Loss: 0.1229\n",
      "\n",
      "Batch 165/387 ━━━━━━━━━━━━━━━━━━━━ 12:08:50\n",
      "Accuracy: 0.9980 - Precision: 0.8967 - Recall: 0.8920 - Specificity: 0.9991 - F1: 0.8896 - Loss: 0.1227\n",
      "\n",
      "Batch 166/387 ━━━━━━━━━━━━━━━━━━━━ 12:10:17\n",
      "Accuracy: 0.9980 - Precision: 0.8968 - Recall: 0.8919 - Specificity: 0.9991 - F1: 0.8897 - Loss: 0.1227\n",
      "\n",
      "Batch 167/387 ━━━━━━━━━━━━━━━━━━━━ 12:11:36\n",
      "Accuracy: 0.9980 - Precision: 0.8967 - Recall: 0.8924 - Specificity: 0.9991 - F1: 0.8899 - Loss: 0.1225\n",
      "\n",
      "Batch 168/387 ━━━━━━━━━━━━━━━━━━━━ 12:12:54\n",
      "Accuracy: 0.9980 - Precision: 0.8957 - Recall: 0.8930 - Specificity: 0.9991 - F1: 0.8896 - Loss: 0.1227\n",
      "\n",
      "Batch 169/387 ━━━━━━━━━━━━━━━━━━━━ 12:14:23\n",
      "Accuracy: 0.9980 - Precision: 0.8958 - Recall: 0.8934 - Specificity: 0.9991 - F1: 0.8899 - Loss: 0.1225\n",
      "\n",
      "Batch 170/387 ━━━━━━━━━━━━━━━━━━━━ 12:15:53\n",
      "Accuracy: 0.9980 - Precision: 0.8958 - Recall: 0.8932 - Specificity: 0.9991 - F1: 0.8898 - Loss: 0.1225\n",
      "\n",
      "Batch 171/387 ━━━━━━━━━━━━━━━━━━━━ 12:17:17\n",
      "Accuracy: 0.9980 - Precision: 0.8964 - Recall: 0.8929 - Specificity: 0.9991 - F1: 0.8900 - Loss: 0.1224\n",
      "\n",
      "Batch 172/387 ━━━━━━━━━━━━━━━━━━━━ 12:18:52\n",
      "Accuracy: 0.9980 - Precision: 0.8967 - Recall: 0.8933 - Specificity: 0.9991 - F1: 0.8903 - Loss: 0.1220\n",
      "\n",
      "Batch 173/387 ━━━━━━━━━━━━━━━━━━━━ 12:20:20\n",
      "Accuracy: 0.9980 - Precision: 0.8968 - Recall: 0.8938 - Specificity: 0.9991 - F1: 0.8907 - Loss: 0.1216\n",
      "\n",
      "Batch 174/387 ━━━━━━━━━━━━━━━━━━━━ 12:21:46\n",
      "Accuracy: 0.9980 - Precision: 0.8971 - Recall: 0.8940 - Specificity: 0.9991 - F1: 0.8910 - Loss: 0.1214\n",
      "\n",
      "Batch 175/387 ━━━━━━━━━━━━━━━━━━━━ 12:23:16\n",
      "Accuracy: 0.9980 - Precision: 0.8975 - Recall: 0.8938 - Specificity: 0.9991 - F1: 0.8910 - Loss: 0.1213\n",
      "\n",
      "Batch 176/387 ━━━━━━━━━━━━━━━━━━━━ 12:24:46\n",
      "Accuracy: 0.9980 - Precision: 0.8974 - Recall: 0.8937 - Specificity: 0.9991 - F1: 0.8909 - Loss: 0.1215\n",
      "\n",
      "Batch 177/387 ━━━━━━━━━━━━━━━━━━━━ 12:26:02\n",
      "Accuracy: 0.9980 - Precision: 0.8969 - Recall: 0.8942 - Specificity: 0.9991 - F1: 0.8910 - Loss: 0.1214\n",
      "\n",
      "Batch 178/387 ━━━━━━━━━━━━━━━━━━━━ 12:27:24\n",
      "Accuracy: 0.9980 - Precision: 0.8970 - Recall: 0.8946 - Specificity: 0.9991 - F1: 0.8912 - Loss: 0.1212\n",
      "\n",
      "Batch 179/387 ━━━━━━━━━━━━━━━━━━━━ 12:28:50\n",
      "Accuracy: 0.9980 - Precision: 0.8973 - Recall: 0.8946 - Specificity: 0.9991 - F1: 0.8914 - Loss: 0.1210\n",
      "\n",
      "Batch 180/387 ━━━━━━━━━━━━━━━━━━━━ 12:30:11\n",
      "Accuracy: 0.9979 - Precision: 0.8970 - Recall: 0.8950 - Specificity: 0.9990 - F1: 0.8914 - Loss: 0.1210\n",
      "\n",
      "Batch 181/387 ━━━━━━━━━━━━━━━━━━━━ 12:31:37\n",
      "Accuracy: 0.9979 - Precision: 0.8974 - Recall: 0.8952 - Specificity: 0.9990 - F1: 0.8917 - Loss: 0.1207\n",
      "\n",
      "Batch 182/387 ━━━━━━━━━━━━━━━━━━━━ 12:33:03\n",
      "Accuracy: 0.9979 - Precision: 0.8975 - Recall: 0.8953 - Specificity: 0.9990 - F1: 0.8919 - Loss: 0.1206\n",
      "\n",
      "Batch 183/387 ━━━━━━━━━━━━━━━━━━━━ 12:34:29\n",
      "Accuracy: 0.9979 - Precision: 0.8975 - Recall: 0.8948 - Specificity: 0.9990 - F1: 0.8916 - Loss: 0.1209\n",
      "\n",
      "Batch 184/387 ━━━━━━━━━━━━━━━━━━━━ 12:36:01\n",
      "Accuracy: 0.9979 - Precision: 0.8978 - Recall: 0.8947 - Specificity: 0.9990 - F1: 0.8917 - Loss: 0.1208\n",
      "\n",
      "Batch 185/387 ━━━━━━━━━━━━━━━━━━━━ 12:37:21\n",
      "Accuracy: 0.9979 - Precision: 0.8980 - Recall: 0.8950 - Specificity: 0.9990 - F1: 0.8921 - Loss: 0.1204\n",
      "\n",
      "Batch 186/387 ━━━━━━━━━━━━━━━━━━━━ 12:38:37\n",
      "Accuracy: 0.9979 - Precision: 0.8982 - Recall: 0.8955 - Specificity: 0.9990 - F1: 0.8924 - Loss: 0.1201\n",
      "\n",
      "Batch 187/387 ━━━━━━━━━━━━━━━━━━━━ 12:40:09\n",
      "Accuracy: 0.9979 - Precision: 0.8987 - Recall: 0.8957 - Specificity: 0.9991 - F1: 0.8928 - Loss: 0.1197\n",
      "\n",
      "Batch 188/387 ━━━━━━━━━━━━━━━━━━━━ 12:41:39\n",
      "Accuracy: 0.9980 - Precision: 0.8987 - Recall: 0.8958 - Specificity: 0.9991 - F1: 0.8928 - Loss: 0.1196\n",
      "\n",
      "Batch 189/387 ━━━━━━━━━━━━━━━━━━━━ 12:43:04\n",
      "Accuracy: 0.9980 - Precision: 0.8991 - Recall: 0.8962 - Specificity: 0.9991 - F1: 0.8933 - Loss: 0.1191\n",
      "\n",
      "Batch 190/387 ━━━━━━━━━━━━━━━━━━━━ 12:44:35\n",
      "Accuracy: 0.9980 - Precision: 0.8993 - Recall: 0.8966 - Specificity: 0.9991 - F1: 0.8936 - Loss: 0.1188\n",
      "\n",
      "Batch 191/387 ━━━━━━━━━━━━━━━━━━━━ 12:46:04\n",
      "Accuracy: 0.9980 - Precision: 0.8996 - Recall: 0.8970 - Specificity: 0.9991 - F1: 0.8939 - Loss: 0.1184\n",
      "\n",
      "Batch 192/387 ━━━━━━━━━━━━━━━━━━━━ 12:47:31\n",
      "Accuracy: 0.9980 - Precision: 0.8992 - Recall: 0.8971 - Specificity: 0.9991 - F1: 0.8938 - Loss: 0.1185\n",
      "\n",
      "Batch 193/387 ━━━━━━━━━━━━━━━━━━━━ 12:48:58\n",
      "Accuracy: 0.9980 - Precision: 0.8987 - Recall: 0.8975 - Specificity: 0.9990 - F1: 0.8937 - Loss: 0.1186\n",
      "\n",
      "Batch 194/387 ━━━━━━━━━━━━━━━━━━━━ 12:50:30\n",
      "Accuracy: 0.9980 - Precision: 0.8987 - Recall: 0.8978 - Specificity: 0.9990 - F1: 0.8939 - Loss: 0.1184\n",
      "\n",
      "Batch 195/387 ━━━━━━━━━━━━━━━━━━━━ 12:51:50\n",
      "Accuracy: 0.9980 - Precision: 0.8975 - Recall: 0.8977 - Specificity: 0.9990 - F1: 0.8932 - Loss: 0.1190\n",
      "\n",
      "Batch 196/387 ━━━━━━━━━━━━━━━━━━━━ 12:53:22\n",
      "Accuracy: 0.9980 - Precision: 0.8980 - Recall: 0.8978 - Specificity: 0.9991 - F1: 0.8935 - Loss: 0.1187\n",
      "\n",
      "Batch 197/387 ━━━━━━━━━━━━━━━━━━━━ 12:54:47\n",
      "Accuracy: 0.9980 - Precision: 0.8985 - Recall: 0.8972 - Specificity: 0.9991 - F1: 0.8934 - Loss: 0.1188\n",
      "\n",
      "Batch 198/387 ━━━━━━━━━━━━━━━━━━━━ 12:56:17\n",
      "Accuracy: 0.9980 - Precision: 0.8984 - Recall: 0.8974 - Specificity: 0.9991 - F1: 0.8935 - Loss: 0.1187\n",
      "\n",
      "Batch 199/387 ━━━━━━━━━━━━━━━━━━━━ 12:57:50\n",
      "Accuracy: 0.9980 - Precision: 0.8988 - Recall: 0.8965 - Specificity: 0.9991 - F1: 0.8932 - Loss: 0.1190\n",
      "\n",
      "Batch 200/387 ━━━━━━━━━━━━━━━━━━━━ 12:59:21\n",
      "Accuracy: 0.9980 - Precision: 0.8991 - Recall: 0.8960 - Specificity: 0.9991 - F1: 0.8931 - Loss: 0.1191\n",
      "\n",
      "Batch 201/387 ━━━━━━━━━━━━━━━━━━━━ 13:00:56\n",
      "Accuracy: 0.9980 - Precision: 0.8994 - Recall: 0.8957 - Specificity: 0.9991 - F1: 0.8931 - Loss: 0.1191\n",
      "\n",
      "Batch 202/387 ━━━━━━━━━━━━━━━━━━━━ 13:02:19\n",
      "Accuracy: 0.9980 - Precision: 0.8991 - Recall: 0.8960 - Specificity: 0.9991 - F1: 0.8931 - Loss: 0.1192\n",
      "\n",
      "Batch 203/387 ━━━━━━━━━━━━━━━━━━━━ 13:04:06\n",
      "Accuracy: 0.9980 - Precision: 0.8985 - Recall: 0.8963 - Specificity: 0.9991 - F1: 0.8929 - Loss: 0.1193\n",
      "\n",
      "Batch 204/387 ━━━━━━━━━━━━━━━━━━━━ 13:05:33\n",
      "Accuracy: 0.9980 - Precision: 0.8989 - Recall: 0.8958 - Specificity: 0.9991 - F1: 0.8928 - Loss: 0.1194\n",
      "\n",
      "Batch 205/387 ━━━━━━━━━━━━━━━━━━━━ 13:06:56\n",
      "Accuracy: 0.9980 - Precision: 0.8989 - Recall: 0.8960 - Specificity: 0.9991 - F1: 0.8930 - Loss: 0.1192\n",
      "\n",
      "Batch 206/387 ━━━━━━━━━━━━━━━━━━━━ 13:08:36\n",
      "Accuracy: 0.9980 - Precision: 0.8979 - Recall: 0.8964 - Specificity: 0.9991 - F1: 0.8925 - Loss: 0.1197\n",
      "\n",
      "Batch 207/387 ━━━━━━━━━━━━━━━━━━━━ 13:10:10\n",
      "Accuracy: 0.9980 - Precision: 0.8981 - Recall: 0.8965 - Specificity: 0.9991 - F1: 0.8928 - Loss: 0.1194\n",
      "\n",
      "Batch 208/387 ━━━━━━━━━━━━━━━━━━━━ 13:11:32\n",
      "Accuracy: 0.9980 - Precision: 0.8984 - Recall: 0.8967 - Specificity: 0.9991 - F1: 0.8930 - Loss: 0.1192\n",
      "\n",
      "Batch 209/387 ━━━━━━━━━━━━━━━━━━━━ 13:13:07\n",
      "Accuracy: 0.9980 - Precision: 0.8985 - Recall: 0.8969 - Specificity: 0.9991 - F1: 0.8932 - Loss: 0.1190\n",
      "\n",
      "Batch 210/387 ━━━━━━━━━━━━━━━━━━━━ 13:14:27\n",
      "Accuracy: 0.9980 - Precision: 0.8989 - Recall: 0.8963 - Specificity: 0.9991 - F1: 0.8930 - Loss: 0.1192\n",
      "\n",
      "Batch 211/387 ━━━━━━━━━━━━━━━━━━━━ 13:15:59\n",
      "Accuracy: 0.9980 - Precision: 0.8989 - Recall: 0.8966 - Specificity: 0.9991 - F1: 0.8932 - Loss: 0.1190\n",
      "\n",
      "Batch 212/387 ━━━━━━━━━━━━━━━━━━━━ 13:17:37\n",
      "Accuracy: 0.9980 - Precision: 0.8990 - Recall: 0.8965 - Specificity: 0.9991 - F1: 0.8933 - Loss: 0.1189\n",
      "\n",
      "Batch 213/387 ━━━━━━━━━━━━━━━━━━━━ 13:19:16\n",
      "Accuracy: 0.9980 - Precision: 0.8990 - Recall: 0.8965 - Specificity: 0.9991 - F1: 0.8932 - Loss: 0.1189\n",
      "\n",
      "Batch 214/387 ━━━━━━━━━━━━━━━━━━━━ 13:20:43\n",
      "Accuracy: 0.9980 - Precision: 0.8991 - Recall: 0.8967 - Specificity: 0.9991 - F1: 0.8934 - Loss: 0.1188\n",
      "\n",
      "Batch 215/387 ━━━━━━━━━━━━━━━━━━━━ 13:22:03\n",
      "Accuracy: 0.9980 - Precision: 0.8994 - Recall: 0.8966 - Specificity: 0.9991 - F1: 0.8936 - Loss: 0.1186\n",
      "\n",
      "Batch 216/387 ━━━━━━━━━━━━━━━━━━━━ 13:23:24\n",
      "Accuracy: 0.9980 - Precision: 0.8999 - Recall: 0.8966 - Specificity: 0.9991 - F1: 0.8938 - Loss: 0.1184\n",
      "\n",
      "Batch 217/387 ━━━━━━━━━━━━━━━━━━━━ 13:24:43\n",
      "Accuracy: 0.9980 - Precision: 0.8991 - Recall: 0.8970 - Specificity: 0.9991 - F1: 0.8935 - Loss: 0.1186\n",
      "\n",
      "Batch 218/387 ━━━━━━━━━━━━━━━━━━━━ 13:26:01\n",
      "Accuracy: 0.9980 - Precision: 0.8989 - Recall: 0.8973 - Specificity: 0.9991 - F1: 0.8936 - Loss: 0.1185\n",
      "\n",
      "Batch 219/387 ━━━━━━━━━━━━━━━━━━━━ 13:27:23\n",
      "Accuracy: 0.9980 - Precision: 0.8990 - Recall: 0.8976 - Specificity: 0.9991 - F1: 0.8938 - Loss: 0.1183\n",
      "\n",
      "Batch 220/387 ━━━━━━━━━━━━━━━━━━━━ 13:28:44\n",
      "Accuracy: 0.9980 - Precision: 0.8990 - Recall: 0.8978 - Specificity: 0.9991 - F1: 0.8939 - Loss: 0.1182\n",
      "\n",
      "Batch 221/387 ━━━━━━━━━━━━━━━━━━━━ 13:30:14\n",
      "Accuracy: 0.9980 - Precision: 0.8986 - Recall: 0.8971 - Specificity: 0.9991 - F1: 0.8934 - Loss: 0.1188\n",
      "\n",
      "Batch 222/387 ━━━━━━━━━━━━━━━━━━━━ 13:31:45\n",
      "Accuracy: 0.9980 - Precision: 0.8987 - Recall: 0.8973 - Specificity: 0.9991 - F1: 0.8935 - Loss: 0.1186\n",
      "\n",
      "Batch 223/387 ━━━━━━━━━━━━━━━━━━━━ 13:33:22\n",
      "Accuracy: 0.9980 - Precision: 0.8988 - Recall: 0.8972 - Specificity: 0.9991 - F1: 0.8936 - Loss: 0.1186\n",
      "\n",
      "Batch 224/387 ━━━━━━━━━━━━━━━━━━━━ 13:34:40\n",
      "Accuracy: 0.9980 - Precision: 0.8989 - Recall: 0.8976 - Specificity: 0.9991 - F1: 0.8938 - Loss: 0.1183\n",
      "\n",
      "Batch 225/387 ━━━━━━━━━━━━━━━━━━━━ 13:36:01\n",
      "Accuracy: 0.9980 - Precision: 0.8991 - Recall: 0.8970 - Specificity: 0.9991 - F1: 0.8936 - Loss: 0.1185\n",
      "\n",
      "Batch 226/387 ━━━━━━━━━━━━━━━━━━━━ 13:37:39\n",
      "Accuracy: 0.9980 - Precision: 0.8994 - Recall: 0.8965 - Specificity: 0.9991 - F1: 0.8935 - Loss: 0.1186\n",
      "\n",
      "Batch 227/387 ━━━━━━━━━━━━━━━━━━━━ 13:39:13\n",
      "Accuracy: 0.9980 - Precision: 0.8993 - Recall: 0.8969 - Specificity: 0.9991 - F1: 0.8937 - Loss: 0.1184\n",
      "\n",
      "Batch 228/387 ━━━━━━━━━━━━━━━━━━━━ 13:40:46\n",
      "Accuracy: 0.9980 - Precision: 0.8990 - Recall: 0.8973 - Specificity: 0.9991 - F1: 0.8937 - Loss: 0.1184\n",
      "\n",
      "Batch 229/387 ━━━━━━━━━━━━━━━━━━━━ 13:42:09\n",
      "Accuracy: 0.9980 - Precision: 0.8987 - Recall: 0.8972 - Specificity: 0.9991 - F1: 0.8935 - Loss: 0.1186\n",
      "\n",
      "Batch 230/387 ━━━━━━━━━━━━━━━━━━━━ 13:43:43\n",
      "Accuracy: 0.9980 - Precision: 0.8989 - Recall: 0.8970 - Specificity: 0.9991 - F1: 0.8935 - Loss: 0.1185\n",
      "\n",
      "Batch 231/387 ━━━━━━━━━━━━━━━━━━━━ 13:45:11\n",
      "Accuracy: 0.9980 - Precision: 0.8989 - Recall: 0.8974 - Specificity: 0.9991 - F1: 0.8937 - Loss: 0.1183\n",
      "\n",
      "Batch 232/387 ━━━━━━━━━━━━━━━━━━━━ 13:46:34\n",
      "Accuracy: 0.9980 - Precision: 0.8992 - Recall: 0.8975 - Specificity: 0.9991 - F1: 0.8940 - Loss: 0.1180\n",
      "\n",
      "Batch 233/387 ━━━━━━━━━━━━━━━━━━━━ 13:47:59\n",
      "Accuracy: 0.9980 - Precision: 0.8995 - Recall: 0.8976 - Specificity: 0.9991 - F1: 0.8942 - Loss: 0.1179\n",
      "\n",
      "Batch 234/387 ━━━━━━━━━━━━━━━━━━━━ 13:49:21\n",
      "Accuracy: 0.9980 - Precision: 0.8997 - Recall: 0.8976 - Specificity: 0.9991 - F1: 0.8943 - Loss: 0.1177\n",
      "\n",
      "Batch 235/387 ━━━━━━━━━━━━━━━━━━━━ 13:50:52\n",
      "Accuracy: 0.9980 - Precision: 0.9000 - Recall: 0.8977 - Specificity: 0.9991 - F1: 0.8945 - Loss: 0.1175\n",
      "\n",
      "Batch 236/387 ━━━━━━━━━━━━━━━━━━━━ 13:52:14\n",
      "Accuracy: 0.9980 - Precision: 0.8999 - Recall: 0.8981 - Specificity: 0.9991 - F1: 0.8946 - Loss: 0.1174\n",
      "\n",
      "Batch 237/387 ━━━━━━━━━━━━━━━━━━━━ 13:53:54\n",
      "Accuracy: 0.9980 - Precision: 0.8989 - Recall: 0.8977 - Specificity: 0.9991 - F1: 0.8939 - Loss: 0.1181\n",
      "\n",
      "Batch 238/387 ━━━━━━━━━━━━━━━━━━━━ 13:55:26\n",
      "Accuracy: 0.9980 - Precision: 0.8987 - Recall: 0.8958 - Specificity: 0.9991 - F1: 0.8926 - Loss: 0.1194\n",
      "\n",
      "Batch 239/387 ━━━━━━━━━━━━━━━━━━━━ 13:56:53\n",
      "Accuracy: 0.9980 - Precision: 0.8989 - Recall: 0.8961 - Specificity: 0.9991 - F1: 0.8929 - Loss: 0.1191\n",
      "\n",
      "Batch 240/387 ━━━━━━━━━━━━━━━━━━━━ 13:58:23\n",
      "Accuracy: 0.9980 - Precision: 0.8991 - Recall: 0.8957 - Specificity: 0.9991 - F1: 0.8928 - Loss: 0.1192\n",
      "\n",
      "Batch 241/387 ━━━━━━━━━━━━━━━━━━━━ 13:59:48\n",
      "Accuracy: 0.9980 - Precision: 0.8992 - Recall: 0.8960 - Specificity: 0.9991 - F1: 0.8930 - Loss: 0.1190\n",
      "\n",
      "Batch 242/387 ━━━━━━━━━━━━━━━━━━━━ 14:01:09\n",
      "Accuracy: 0.9980 - Precision: 0.8993 - Recall: 0.8961 - Specificity: 0.9991 - F1: 0.8931 - Loss: 0.1189\n",
      "\n",
      "Batch 243/387 ━━━━━━━━━━━━━━━━━━━━ 14:02:30\n",
      "Accuracy: 0.9980 - Precision: 0.8993 - Recall: 0.8963 - Specificity: 0.9991 - F1: 0.8933 - Loss: 0.1187\n",
      "\n",
      "Batch 244/387 ━━━━━━━━━━━━━━━━━━━━ 14:03:56\n",
      "Accuracy: 0.9980 - Precision: 0.8986 - Recall: 0.8963 - Specificity: 0.9991 - F1: 0.8929 - Loss: 0.1191\n",
      "\n",
      "Batch 245/387 ━━━━━━━━━━━━━━━━━━━━ 14:05:12\n",
      "Accuracy: 0.9980 - Precision: 0.8976 - Recall: 0.8954 - Specificity: 0.9991 - F1: 0.8919 - Loss: 0.1201\n",
      "\n",
      "Batch 246/387 ━━━━━━━━━━━━━━━━━━━━ 14:06:44\n",
      "Accuracy: 0.9980 - Precision: 0.8979 - Recall: 0.8956 - Specificity: 0.9991 - F1: 0.8922 - Loss: 0.1198\n",
      "\n",
      "Batch 247/387 ━━━━━━━━━━━━━━━━━━━━ 14:08:17\n",
      "Accuracy: 0.9980 - Precision: 0.8982 - Recall: 0.8955 - Specificity: 0.9991 - F1: 0.8923 - Loss: 0.1197\n",
      "\n",
      "Batch 248/387 ━━━━━━━━━━━━━━━━━━━━ 14:09:29\n",
      "Accuracy: 0.9980 - Precision: 0.8986 - Recall: 0.8956 - Specificity: 0.9991 - F1: 0.8925 - Loss: 0.1194\n",
      "\n",
      "Batch 249/387 ━━━━━━━━━━━━━━━━━━━━ 14:11:02\n",
      "Accuracy: 0.9980 - Precision: 0.8989 - Recall: 0.8947 - Specificity: 0.9991 - F1: 0.8922 - Loss: 0.1199\n",
      "\n",
      "Batch 250/387 ━━━━━━━━━━━━━━━━━━━━ 14:12:31\n",
      "Accuracy: 0.9980 - Precision: 0.8987 - Recall: 0.8950 - Specificity: 0.9991 - F1: 0.8922 - Loss: 0.1199\n",
      "\n",
      "Batch 251/387 ━━━━━━━━━━━━━━━━━━━━ 14:14:05\n",
      "Accuracy: 0.9980 - Precision: 0.8990 - Recall: 0.8951 - Specificity: 0.9991 - F1: 0.8925 - Loss: 0.1196\n",
      "\n",
      "Batch 252/387 ━━━━━━━━━━━━━━━━━━━━ 14:15:29\n",
      "Accuracy: 0.9980 - Precision: 0.8990 - Recall: 0.8945 - Specificity: 0.9991 - F1: 0.8921 - Loss: 0.1200\n",
      "\n",
      "Batch 253/387 ━━━━━━━━━━━━━━━━━━━━ 14:16:56\n",
      "Accuracy: 0.9980 - Precision: 0.8992 - Recall: 0.8941 - Specificity: 0.9991 - F1: 0.8920 - Loss: 0.1202\n",
      "\n",
      "Batch 254/387 ━━━━━━━━━━━━━━━━━━━━ 14:18:11\n",
      "Accuracy: 0.9980 - Precision: 0.8994 - Recall: 0.8936 - Specificity: 0.9991 - F1: 0.8919 - Loss: 0.1204\n",
      "\n",
      "Batch 255/387 ━━━━━━━━━━━━━━━━━━━━ 14:19:39\n",
      "Accuracy: 0.9980 - Precision: 0.8997 - Recall: 0.8938 - Specificity: 0.9991 - F1: 0.8921 - Loss: 0.1201\n",
      "\n",
      "Batch 256/387 ━━━━━━━━━━━━━━━━━━━━ 14:21:17\n",
      "Accuracy: 0.9980 - Precision: 0.8997 - Recall: 0.8935 - Specificity: 0.9991 - F1: 0.8920 - Loss: 0.1202\n",
      "\n",
      "Batch 257/387 ━━━━━━━━━━━━━━━━━━━━ 14:22:48\n",
      "Accuracy: 0.9980 - Precision: 0.8990 - Recall: 0.8934 - Specificity: 0.9991 - F1: 0.8916 - Loss: 0.1207\n",
      "\n",
      "Batch 258/387 ━━━━━━━━━━━━━━━━━━━━ 14:24:15\n",
      "Accuracy: 0.9980 - Precision: 0.8989 - Recall: 0.8935 - Specificity: 0.9991 - F1: 0.8916 - Loss: 0.1206\n",
      "\n",
      "Batch 259/387 ━━━━━━━━━━━━━━━━━━━━ 14:25:41\n",
      "Accuracy: 0.9980 - Precision: 0.8990 - Recall: 0.8936 - Specificity: 0.9991 - F1: 0.8917 - Loss: 0.1206\n",
      "\n",
      "Batch 260/387 ━━━━━━━━━━━━━━━━━━━━ 14:27:05\n",
      "Accuracy: 0.9980 - Precision: 0.8990 - Recall: 0.8937 - Specificity: 0.9991 - F1: 0.8918 - Loss: 0.1205\n",
      "\n",
      "Batch 261/387 ━━━━━━━━━━━━━━━━━━━━ 14:28:37\n",
      "Accuracy: 0.9980 - Precision: 0.8993 - Recall: 0.8932 - Specificity: 0.9991 - F1: 0.8917 - Loss: 0.1206\n",
      "\n",
      "Batch 262/387 ━━━━━━━━━━━━━━━━━━━━ 14:30:12\n",
      "Accuracy: 0.9980 - Precision: 0.8992 - Recall: 0.8935 - Specificity: 0.9991 - F1: 0.8918 - Loss: 0.1205\n",
      "\n",
      "Batch 263/387 ━━━━━━━━━━━━━━━━━━━━ 14:31:47\n",
      "Accuracy: 0.9980 - Precision: 0.8991 - Recall: 0.8937 - Specificity: 0.9991 - F1: 0.8918 - Loss: 0.1205\n",
      "\n",
      "Batch 264/387 ━━━━━━━━━━━━━━━━━━━━ 14:33:06\n",
      "Accuracy: 0.9979 - Precision: 0.8992 - Recall: 0.8940 - Specificity: 0.9991 - F1: 0.8920 - Loss: 0.1203\n",
      "\n",
      "Batch 265/387 ━━━━━━━━━━━━━━━━━━━━ 14:34:24\n",
      "Accuracy: 0.9980 - Precision: 0.8979 - Recall: 0.8941 - Specificity: 0.9991 - F1: 0.8913 - Loss: 0.1211\n",
      "\n",
      "Batch 266/387 ━━━━━━━━━━━━━━━━━━━━ 14:35:58\n",
      "Accuracy: 0.9980 - Precision: 0.8971 - Recall: 0.8945 - Specificity: 0.9991 - F1: 0.8909 - Loss: 0.1215\n",
      "\n",
      "Batch 267/387 ━━━━━━━━━━━━━━━━━━━━ 14:37:31\n",
      "Accuracy: 0.9980 - Precision: 0.8964 - Recall: 0.8948 - Specificity: 0.9991 - F1: 0.8907 - Loss: 0.1217\n",
      "\n",
      "Batch 268/387 ━━━━━━━━━━━━━━━━━━━━ 14:39:00\n",
      "Accuracy: 0.9980 - Precision: 0.8966 - Recall: 0.8950 - Specificity: 0.9991 - F1: 0.8909 - Loss: 0.1214\n",
      "\n",
      "Batch 269/387 ━━━━━━━━━━━━━━━━━━━━ 14:40:21\n",
      "Accuracy: 0.9980 - Precision: 0.8969 - Recall: 0.8949 - Specificity: 0.9991 - F1: 0.8910 - Loss: 0.1214\n",
      "\n",
      "Batch 270/387 ━━━━━━━━━━━━━━━━━━━━ 14:41:54\n",
      "Accuracy: 0.9979 - Precision: 0.8972 - Recall: 0.8944 - Specificity: 0.9991 - F1: 0.8909 - Loss: 0.1215\n",
      "\n",
      "Batch 271/387 ━━━━━━━━━━━━━━━━━━━━ 14:43:22\n",
      "Accuracy: 0.9979 - Precision: 0.8975 - Recall: 0.8942 - Specificity: 0.9991 - F1: 0.8909 - Loss: 0.1215\n",
      "\n",
      "Batch 272/387 ━━━━━━━━━━━━━━━━━━━━ 14:44:57\n",
      "Accuracy: 0.9979 - Precision: 0.8978 - Recall: 0.8943 - Specificity: 0.9991 - F1: 0.8912 - Loss: 0.1213\n",
      "\n",
      "Batch 273/387 ━━━━━━━━━━━━━━━━━━━━ 14:46:37\n",
      "Accuracy: 0.9979 - Precision: 0.8981 - Recall: 0.8935 - Specificity: 0.9991 - F1: 0.8908 - Loss: 0.1217\n",
      "\n",
      "Batch 274/387 ━━━━━━━━━━━━━━━━━━━━ 14:48:02\n",
      "Accuracy: 0.9979 - Precision: 0.8981 - Recall: 0.8937 - Specificity: 0.9991 - F1: 0.8910 - Loss: 0.1216\n",
      "\n",
      "Batch 275/387 ━━━━━━━━━━━━━━━━━━━━ 14:49:27\n",
      "Accuracy: 0.9979 - Precision: 0.8984 - Recall: 0.8939 - Specificity: 0.9991 - F1: 0.8912 - Loss: 0.1213\n",
      "\n",
      "Batch 276/387 ━━━━━━━━━━━━━━━━━━━━ 14:50:54\n",
      "Accuracy: 0.9979 - Precision: 0.8986 - Recall: 0.8940 - Specificity: 0.9991 - F1: 0.8914 - Loss: 0.1211\n",
      "\n",
      "Batch 277/387 ━━━━━━━━━━━━━━━━━━━━ 14:52:51\n",
      "Accuracy: 0.9979 - Precision: 0.8984 - Recall: 0.8942 - Specificity: 0.9991 - F1: 0.8914 - Loss: 0.1211\n",
      "\n",
      "Batch 278/387 ━━━━━━━━━━━━━━━━━━━━ 14:54:29\n",
      "Accuracy: 0.9979 - Precision: 0.8986 - Recall: 0.8940 - Specificity: 0.9991 - F1: 0.8914 - Loss: 0.1211\n",
      "\n",
      "Batch 279/387 ━━━━━━━━━━━━━━━━━━━━ 14:55:46\n",
      "Accuracy: 0.9979 - Precision: 0.8972 - Recall: 0.8944 - Specificity: 0.9990 - F1: 0.8906 - Loss: 0.1220\n",
      "\n",
      "Batch 280/387 ━━━━━━━━━━━━━━━━━━━━ 14:57:05\n",
      "Accuracy: 0.9979 - Precision: 0.8972 - Recall: 0.8947 - Specificity: 0.9990 - F1: 0.8908 - Loss: 0.1218\n",
      "\n",
      "Batch 281/387 ━━━━━━━━━━━━━━━━━━━━ 14:58:32\n",
      "Accuracy: 0.9979 - Precision: 0.8975 - Recall: 0.8949 - Specificity: 0.9990 - F1: 0.8910 - Loss: 0.1216\n",
      "\n",
      "Batch 282/387 ━━━━━━━━━━━━━━━━━━━━ 14:59:50\n",
      "Accuracy: 0.9979 - Precision: 0.8976 - Recall: 0.8941 - Specificity: 0.9990 - F1: 0.8906 - Loss: 0.1220\n",
      "\n",
      "Batch 283/387 ━━━━━━━━━━━━━━━━━━━━ 15:01:06\n",
      "Accuracy: 0.9979 - Precision: 0.8979 - Recall: 0.8938 - Specificity: 0.9990 - F1: 0.8906 - Loss: 0.1221\n",
      "\n",
      "Batch 284/387 ━━━━━━━━━━━━━━━━━━━━ 15:02:41\n",
      "Accuracy: 0.9979 - Precision: 0.8980 - Recall: 0.8939 - Specificity: 0.9990 - F1: 0.8908 - Loss: 0.1219\n",
      "\n",
      "Batch 285/387 ━━━━━━━━━━━━━━━━━━━━ 15:04:03\n",
      "Accuracy: 0.9979 - Precision: 0.8975 - Recall: 0.8942 - Specificity: 0.9990 - F1: 0.8906 - Loss: 0.1221\n",
      "\n",
      "Batch 286/387 ━━━━━━━━━━━━━━━━━━━━ 15:05:32\n",
      "Accuracy: 0.9979 - Precision: 0.8975 - Recall: 0.8944 - Specificity: 0.9990 - F1: 0.8907 - Loss: 0.1220\n",
      "\n",
      "Batch 287/387 ━━━━━━━━━━━━━━━━━━━━ 15:06:55\n",
      "Accuracy: 0.9979 - Precision: 0.8976 - Recall: 0.8946 - Specificity: 0.9990 - F1: 0.8909 - Loss: 0.1218\n",
      "\n",
      "Batch 288/387 ━━━━━━━━━━━━━━━━━━━━ 15:08:29\n",
      "Accuracy: 0.9979 - Precision: 0.8975 - Recall: 0.8940 - Specificity: 0.9990 - F1: 0.8905 - Loss: 0.1222\n",
      "\n",
      "Batch 289/387 ━━━━━━━━━━━━━━━━━━━━ 15:09:52\n",
      "Accuracy: 0.9979 - Precision: 0.8976 - Recall: 0.8942 - Specificity: 0.9990 - F1: 0.8907 - Loss: 0.1221\n",
      "\n",
      "Batch 290/387 ━━━━━━━━━━━━━━━━━━━━ 15:11:27\n",
      "Accuracy: 0.9979 - Precision: 0.8974 - Recall: 0.8944 - Specificity: 0.9990 - F1: 0.8908 - Loss: 0.1220\n",
      "\n",
      "Batch 291/387 ━━━━━━━━━━━━━━━━━━━━ 15:12:53\n",
      "Accuracy: 0.9979 - Precision: 0.8974 - Recall: 0.8945 - Specificity: 0.9990 - F1: 0.8908 - Loss: 0.1219\n",
      "\n",
      "Batch 292/387 ━━━━━━━━━━━━━━━━━━━━ 15:14:19\n",
      "Accuracy: 0.9979 - Precision: 0.8972 - Recall: 0.8940 - Specificity: 0.9990 - F1: 0.8904 - Loss: 0.1223\n",
      "\n",
      "Batch 293/387 ━━━━━━━━━━━━━━━━━━━━ 15:15:42\n",
      "Accuracy: 0.9979 - Precision: 0.8966 - Recall: 0.8934 - Specificity: 0.9990 - F1: 0.8899 - Loss: 0.1229\n",
      "\n",
      "Batch 294/387 ━━━━━━━━━━━━━━━━━━━━ 15:16:57\n",
      "Accuracy: 0.9979 - Precision: 0.8969 - Recall: 0.8933 - Specificity: 0.9990 - F1: 0.8900 - Loss: 0.1229\n",
      "\n",
      "Batch 295/387 ━━━━━━━━━━━━━━━━━━━━ 15:18:21\n",
      "Accuracy: 0.9979 - Precision: 0.8965 - Recall: 0.8933 - Specificity: 0.9990 - F1: 0.8898 - Loss: 0.1231\n",
      "\n",
      "Batch 296/387 ━━━━━━━━━━━━━━━━━━━━ 15:19:48\n",
      "Accuracy: 0.9979 - Precision: 0.8966 - Recall: 0.8934 - Specificity: 0.9990 - F1: 0.8899 - Loss: 0.1230\n",
      "\n",
      "Batch 297/387 ━━━━━━━━━━━━━━━━━━━━ 15:21:09\n",
      "Accuracy: 0.9979 - Precision: 0.8967 - Recall: 0.8935 - Specificity: 0.9990 - F1: 0.8900 - Loss: 0.1228\n",
      "\n",
      "Batch 298/387 ━━━━━━━━━━━━━━━━━━━━ 15:22:46\n",
      "Accuracy: 0.9979 - Precision: 0.8964 - Recall: 0.8937 - Specificity: 0.9990 - F1: 0.8900 - Loss: 0.1229\n",
      "\n",
      "Batch 299/387 ━━━━━━━━━━━━━━━━━━━━ 15:24:25\n",
      "Accuracy: 0.9979 - Precision: 0.8966 - Recall: 0.8939 - Specificity: 0.9990 - F1: 0.8902 - Loss: 0.1226\n",
      "\n",
      "Batch 300/387 ━━━━━━━━━━━━━━━━━━━━ 15:26:12\n",
      "Accuracy: 0.9979 - Precision: 0.8963 - Recall: 0.8935 - Specificity: 0.9990 - F1: 0.8898 - Loss: 0.1230\n",
      "\n",
      "Batch 301/387 ━━━━━━━━━━━━━━━━━━━━ 15:27:41\n",
      "Accuracy: 0.9979 - Precision: 0.8965 - Recall: 0.8932 - Specificity: 0.9990 - F1: 0.8898 - Loss: 0.1230\n",
      "\n",
      "Batch 302/387 ━━━━━━━━━━━━━━━━━━━━ 15:29:07\n",
      "Accuracy: 0.9979 - Precision: 0.8966 - Recall: 0.8932 - Specificity: 0.9990 - F1: 0.8899 - Loss: 0.1230\n",
      "\n",
      "Batch 303/387 ━━━━━━━━━━━━━━━━━━━━ 15:30:30\n",
      "Accuracy: 0.9979 - Precision: 0.8965 - Recall: 0.8934 - Specificity: 0.9990 - F1: 0.8899 - Loss: 0.1229\n",
      "\n",
      "Batch 304/387 ━━━━━━━━━━━━━━━━━━━━ 15:31:45\n",
      "Accuracy: 0.9979 - Precision: 0.8966 - Recall: 0.8932 - Specificity: 0.9990 - F1: 0.8899 - Loss: 0.1230\n",
      "\n",
      "Batch 305/387 ━━━━━━━━━━━━━━━━━━━━ 15:33:17\n",
      "Accuracy: 0.9979 - Precision: 0.8969 - Recall: 0.8933 - Specificity: 0.9990 - F1: 0.8901 - Loss: 0.1228\n",
      "\n",
      "Batch 306/387 ━━━━━━━━━━━━━━━━━━━━ 15:34:36\n",
      "Accuracy: 0.9979 - Precision: 0.8969 - Recall: 0.8934 - Specificity: 0.9990 - F1: 0.8902 - Loss: 0.1227\n",
      "\n",
      "Batch 307/387 ━━━━━━━━━━━━━━━━━━━━ 15:35:55\n",
      "Accuracy: 0.9979 - Precision: 0.8971 - Recall: 0.8936 - Specificity: 0.9990 - F1: 0.8904 - Loss: 0.1225\n",
      "\n",
      "Batch 308/387 ━━━━━━━━━━━━━━━━━━━━ 15:37:14\n",
      "Accuracy: 0.9979 - Precision: 0.8972 - Recall: 0.8936 - Specificity: 0.9990 - F1: 0.8904 - Loss: 0.1224\n",
      "\n",
      "Batch 309/387 ━━━━━━━━━━━━━━━━━━━━ 15:38:32\n",
      "Accuracy: 0.9979 - Precision: 0.8969 - Recall: 0.8938 - Specificity: 0.9990 - F1: 0.8904 - Loss: 0.1224\n",
      "\n",
      "Batch 310/387 ━━━━━━━━━━━━━━━━━━━━ 15:39:58\n",
      "Accuracy: 0.9979 - Precision: 0.8972 - Recall: 0.8939 - Specificity: 0.9990 - F1: 0.8906 - Loss: 0.1222\n",
      "\n",
      "Batch 311/387 ━━━━━━━━━━━━━━━━━━━━ 15:41:25\n",
      "Accuracy: 0.9979 - Precision: 0.8974 - Recall: 0.8941 - Specificity: 0.9990 - F1: 0.8908 - Loss: 0.1220\n",
      "\n",
      "Batch 312/387 ━━━━━━━━━━━━━━━━━━━━ 15:42:42\n",
      "Accuracy: 0.9979 - Precision: 0.8969 - Recall: 0.8944 - Specificity: 0.9990 - F1: 0.8907 - Loss: 0.1221\n",
      "\n",
      "Batch 313/387 ━━━━━━━━━━━━━━━━━━━━ 15:44:11\n",
      "Accuracy: 0.9979 - Precision: 0.8969 - Recall: 0.8947 - Specificity: 0.9990 - F1: 0.8908 - Loss: 0.1220\n",
      "\n",
      "Batch 314/387 ━━━━━━━━━━━━━━━━━━━━ 15:45:43\n",
      "Accuracy: 0.9979 - Precision: 0.8970 - Recall: 0.8948 - Specificity: 0.9990 - F1: 0.8910 - Loss: 0.1218\n",
      "\n",
      "Batch 315/387 ━━━━━━━━━━━━━━━━━━━━ 15:47:36\n",
      "Accuracy: 0.9979 - Precision: 0.8972 - Recall: 0.8941 - Specificity: 0.9990 - F1: 0.8907 - Loss: 0.1221\n",
      "\n",
      "Batch 316/387 ━━━━━━━━━━━━━━━━━━━━ 16:12:05\n",
      "Accuracy: 0.9979 - Precision: 0.8974 - Recall: 0.8940 - Specificity: 0.9990 - F1: 0.8907 - Loss: 0.1220\n",
      "\n",
      "Batch 317/387 ━━━━━━━━━━━━━━━━━━━━ 16:13:41\n",
      "Accuracy: 0.9979 - Precision: 0.8969 - Recall: 0.8941 - Specificity: 0.9990 - F1: 0.8905 - Loss: 0.1222\n",
      "\n",
      "Batch 318/387 ━━━━━━━━━━━━━━━━━━━━ 16:15:19\n",
      "Accuracy: 0.9979 - Precision: 0.8970 - Recall: 0.8941 - Specificity: 0.9990 - F1: 0.8905 - Loss: 0.1222\n",
      "\n",
      "Batch 319/387 ━━━━━━━━━━━━━━━━━━━━ 16:16:49\n",
      "Accuracy: 0.9979 - Precision: 0.8963 - Recall: 0.8942 - Specificity: 0.9990 - F1: 0.8902 - Loss: 0.1226\n",
      "\n",
      "Batch 320/387 ━━━━━━━━━━━━━━━━━━━━ 16:18:18\n",
      "Accuracy: 0.9979 - Precision: 0.8964 - Recall: 0.8943 - Specificity: 0.9990 - F1: 0.8903 - Loss: 0.1225\n",
      "\n",
      "Batch 321/387 ━━━━━━━━━━━━━━━━━━━━ 16:19:46\n",
      "Accuracy: 0.9979 - Precision: 0.8966 - Recall: 0.8943 - Specificity: 0.9990 - F1: 0.8904 - Loss: 0.1224\n",
      "\n",
      "Batch 322/387 ━━━━━━━━━━━━━━━━━━━━ 16:21:16\n",
      "Accuracy: 0.9979 - Precision: 0.8968 - Recall: 0.8944 - Specificity: 0.9990 - F1: 0.8906 - Loss: 0.1222\n",
      "\n",
      "Batch 323/387 ━━━━━━━━━━━━━━━━━━━━ 16:22:43\n",
      "Accuracy: 0.9979 - Precision: 0.8971 - Recall: 0.8946 - Specificity: 0.9990 - F1: 0.8908 - Loss: 0.1220\n",
      "\n",
      "Batch 324/387 ━━━━━━━━━━━━━━━━━━━━ 16:24:18\n",
      "Accuracy: 0.9979 - Precision: 0.8973 - Recall: 0.8947 - Specificity: 0.9990 - F1: 0.8910 - Loss: 0.1218\n",
      "\n",
      "Batch 325/387 ━━━━━━━━━━━━━━━━━━━━ 16:25:57\n",
      "Accuracy: 0.9979 - Precision: 0.8975 - Recall: 0.8941 - Specificity: 0.9990 - F1: 0.8908 - Loss: 0.1221\n",
      "\n",
      "Batch 326/387 ━━━━━━━━━━━━━━━━━━━━ 16:27:30\n",
      "Accuracy: 0.9979 - Precision: 0.8977 - Recall: 0.8942 - Specificity: 0.9990 - F1: 0.8909 - Loss: 0.1219\n",
      "\n",
      "Batch 327/387 ━━━━━━━━━━━━━━━━━━━━ 16:29:07\n",
      "Accuracy: 0.9979 - Precision: 0.8978 - Recall: 0.8940 - Specificity: 0.9990 - F1: 0.8909 - Loss: 0.1219\n",
      "\n",
      "Batch 328/387 ━━━━━━━━━━━━━━━━━━━━ 16:31:18\n",
      "Accuracy: 0.9979 - Precision: 0.8976 - Recall: 0.8942 - Specificity: 0.9990 - F1: 0.8909 - Loss: 0.1219\n",
      "\n",
      "Batch 329/387 ━━━━━━━━━━━━━━━━━━━━ 16:33:27\n",
      "Accuracy: 0.9979 - Precision: 0.8971 - Recall: 0.8940 - Specificity: 0.9990 - F1: 0.8906 - Loss: 0.1223\n",
      "\n",
      "Batch 330/387 ━━━━━━━━━━━━━━━━━━━━ 16:35:13\n",
      "Accuracy: 0.9979 - Precision: 0.8969 - Recall: 0.8941 - Specificity: 0.9990 - F1: 0.8905 - Loss: 0.1224\n",
      "\n",
      "Batch 331/387 ━━━━━━━━━━━━━━━━━━━━ 16:36:57\n",
      "Accuracy: 0.9979 - Precision: 0.8971 - Recall: 0.8941 - Specificity: 0.9990 - F1: 0.8906 - Loss: 0.1222\n",
      "\n",
      "Batch 332/387 ━━━━━━━━━━━━━━━━━━━━ 16:38:33\n",
      "Accuracy: 0.9979 - Precision: 0.8972 - Recall: 0.8943 - Specificity: 0.9990 - F1: 0.8908 - Loss: 0.1221\n",
      "\n",
      "Batch 333/387 ━━━━━━━━━━━━━━━━━━━━ 16:40:08\n",
      "Accuracy: 0.9979 - Precision: 0.8972 - Recall: 0.8943 - Specificity: 0.9990 - F1: 0.8908 - Loss: 0.1221\n",
      "\n",
      "Batch 334/387 ━━━━━━━━━━━━━━━━━━━━ 16:41:34\n",
      "Accuracy: 0.9979 - Precision: 0.8973 - Recall: 0.8945 - Specificity: 0.9990 - F1: 0.8910 - Loss: 0.1219\n",
      "\n",
      "Batch 335/387 ━━━━━━━━━━━━━━━━━━━━ 16:42:59\n",
      "Accuracy: 0.9979 - Precision: 0.8975 - Recall: 0.8947 - Specificity: 0.9990 - F1: 0.8912 - Loss: 0.1217\n",
      "\n",
      "Batch 336/387 ━━━━━━━━━━━━━━━━━━━━ 16:44:22\n",
      "Accuracy: 0.9979 - Precision: 0.8976 - Recall: 0.8946 - Specificity: 0.9990 - F1: 0.8912 - Loss: 0.1216\n",
      "\n",
      "Batch 337/387 ━━━━━━━━━━━━━━━━━━━━ 16:45:57\n",
      "Accuracy: 0.9979 - Precision: 0.8977 - Recall: 0.8948 - Specificity: 0.9990 - F1: 0.8914 - Loss: 0.1215\n",
      "\n",
      "Batch 338/387 ━━━━━━━━━━━━━━━━━━━━ 16:47:28\n",
      "Accuracy: 0.9979 - Precision: 0.8976 - Recall: 0.8946 - Specificity: 0.9990 - F1: 0.8912 - Loss: 0.1216\n",
      "\n",
      "Batch 339/387 ━━━━━━━━━━━━━━━━━━━━ 16:49:02\n",
      "Accuracy: 0.9979 - Precision: 0.8978 - Recall: 0.8948 - Specificity: 0.9990 - F1: 0.8914 - Loss: 0.1214\n",
      "\n",
      "Batch 340/387 ━━━━━━━━━━━━━━━━━━━━ 16:50:39\n",
      "Accuracy: 0.9979 - Precision: 0.8978 - Recall: 0.8948 - Specificity: 0.9990 - F1: 0.8915 - Loss: 0.1213\n",
      "\n",
      "Batch 341/387 ━━━━━━━━━━━━━━━━━━━━ 16:52:04\n",
      "Accuracy: 0.9979 - Precision: 0.8980 - Recall: 0.8947 - Specificity: 0.9990 - F1: 0.8915 - Loss: 0.1213\n",
      "\n",
      "Batch 342/387 ━━━━━━━━━━━━━━━━━━━━ 16:53:34\n",
      "Accuracy: 0.9979 - Precision: 0.8981 - Recall: 0.8948 - Specificity: 0.9990 - F1: 0.8917 - Loss: 0.1212\n",
      "\n",
      "Batch 343/387 ━━━━━━━━━━━━━━━━━━━━ 16:55:00\n",
      "Accuracy: 0.9979 - Precision: 0.8976 - Recall: 0.8950 - Specificity: 0.9990 - F1: 0.8914 - Loss: 0.1214\n",
      "\n",
      "Batch 344/387 ━━━━━━━━━━━━━━━━━━━━ 16:56:28\n",
      "Accuracy: 0.9979 - Precision: 0.8976 - Recall: 0.8951 - Specificity: 0.9990 - F1: 0.8915 - Loss: 0.1213\n",
      "\n",
      "Batch 345/387 ━━━━━━━━━━━━━━━━━━━━ 16:57:51\n",
      "Accuracy: 0.9979 - Precision: 0.8978 - Recall: 0.8953 - Specificity: 0.9990 - F1: 0.8917 - Loss: 0.1210\n",
      "\n",
      "Batch 346/387 ━━━━━━━━━━━━━━━━━━━━ 16:59:10\n",
      "Accuracy: 0.9979 - Precision: 0.8970 - Recall: 0.8954 - Specificity: 0.9990 - F1: 0.8913 - Loss: 0.1215\n",
      "\n",
      "Batch 347/387 ━━━━━━━━━━━━━━━━━━━━ 17:00:40\n",
      "Accuracy: 0.9979 - Precision: 0.8968 - Recall: 0.8955 - Specificity: 0.9990 - F1: 0.8912 - Loss: 0.1216\n",
      "\n",
      "Batch 348/387 ━━━━━━━━━━━━━━━━━━━━ 17:01:58\n",
      "Accuracy: 0.9979 - Precision: 0.8969 - Recall: 0.8949 - Specificity: 0.9990 - F1: 0.8910 - Loss: 0.1219\n",
      "\n",
      "Batch 349/387 ━━━━━━━━━━━━━━━━━━━━ 17:03:19\n",
      "Accuracy: 0.9979 - Precision: 0.8971 - Recall: 0.8952 - Specificity: 0.9990 - F1: 0.8912 - Loss: 0.1216\n",
      "\n",
      "Batch 350/387 ━━━━━━━━━━━━━━━━━━━━ 17:04:39\n",
      "Accuracy: 0.9979 - Precision: 0.8972 - Recall: 0.8954 - Specificity: 0.9990 - F1: 0.8914 - Loss: 0.1214\n",
      "\n",
      "Batch 351/387 ━━━━━━━━━━━━━━━━━━━━ 17:06:04\n",
      "Accuracy: 0.9979 - Precision: 0.8960 - Recall: 0.8951 - Specificity: 0.9990 - F1: 0.8905 - Loss: 0.1223\n",
      "\n",
      "Batch 352/387 ━━━━━━━━━━━━━━━━━━━━ 17:07:33\n",
      "Accuracy: 0.9979 - Precision: 0.8950 - Recall: 0.8951 - Specificity: 0.9990 - F1: 0.8899 - Loss: 0.1229\n",
      "\n",
      "Batch 353/387 ━━━━━━━━━━━━━━━━━━━━ 17:08:52\n",
      "Accuracy: 0.9979 - Precision: 0.8952 - Recall: 0.8943 - Specificity: 0.9990 - F1: 0.8895 - Loss: 0.1233\n",
      "\n",
      "Batch 354/387 ━━━━━━━━━━━━━━━━━━━━ 17:10:06\n",
      "Accuracy: 0.9979 - Precision: 0.8954 - Recall: 0.8943 - Specificity: 0.9990 - F1: 0.8896 - Loss: 0.1232\n",
      "\n",
      "Batch 355/387 ━━━━━━━━━━━━━━━━━━━━ 17:11:36\n",
      "Accuracy: 0.9979 - Precision: 0.8957 - Recall: 0.8935 - Specificity: 0.9990 - F1: 0.8893 - Loss: 0.1236\n",
      "\n",
      "Batch 356/387 ━━━━━━━━━━━━━━━━━━━━ 17:13:00\n",
      "Accuracy: 0.9979 - Precision: 0.8959 - Recall: 0.8936 - Specificity: 0.9990 - F1: 0.8895 - Loss: 0.1235\n",
      "\n",
      "Batch 357/387 ━━━━━━━━━━━━━━━━━━━━ 17:14:31\n",
      "Accuracy: 0.9979 - Precision: 0.8961 - Recall: 0.8935 - Specificity: 0.9990 - F1: 0.8895 - Loss: 0.1234\n",
      "\n",
      "Batch 358/387 ━━━━━━━━━━━━━━━━━━━━ 17:16:14\n",
      "Accuracy: 0.9979 - Precision: 0.8963 - Recall: 0.8937 - Specificity: 0.9990 - F1: 0.8897 - Loss: 0.1232\n",
      "\n",
      "Batch 359/387 ━━━━━━━━━━━━━━━━━━━━ 17:17:54\n",
      "Accuracy: 0.9979 - Precision: 0.8965 - Recall: 0.8938 - Specificity: 0.9990 - F1: 0.8899 - Loss: 0.1230\n",
      "\n",
      "Batch 360/387 ━━━━━━━━━━━━━━━━━━━━ 17:19:29\n",
      "Accuracy: 0.9979 - Precision: 0.8967 - Recall: 0.8939 - Specificity: 0.9990 - F1: 0.8900 - Loss: 0.1229\n",
      "\n",
      "Batch 361/387 ━━━━━━━━━━━━━━━━━━━━ 17:21:01\n",
      "Accuracy: 0.9979 - Precision: 0.8969 - Recall: 0.8938 - Specificity: 0.9990 - F1: 0.8901 - Loss: 0.1228\n",
      "\n",
      "Batch 362/387 ━━━━━━━━━━━━━━━━━━━━ 17:22:30\n",
      "Accuracy: 0.9979 - Precision: 0.8971 - Recall: 0.8935 - Specificity: 0.9990 - F1: 0.8900 - Loss: 0.1228\n",
      "\n",
      "Batch 363/387 ━━━━━━━━━━━━━━━━━━━━ 17:24:05\n",
      "Accuracy: 0.9979 - Precision: 0.8969 - Recall: 0.8936 - Specificity: 0.9990 - F1: 0.8900 - Loss: 0.1229\n",
      "\n",
      "Batch 364/387 ━━━━━━━━━━━━━━━━━━━━ 17:25:33\n",
      "Accuracy: 0.9979 - Precision: 0.8970 - Recall: 0.8938 - Specificity: 0.9990 - F1: 0.8902 - Loss: 0.1227\n",
      "\n",
      "Batch 365/387 ━━━━━━━━━━━━━━━━━━━━ 17:26:55\n",
      "Accuracy: 0.9979 - Precision: 0.8972 - Recall: 0.8940 - Specificity: 0.9990 - F1: 0.8904 - Loss: 0.1225\n",
      "\n",
      "Batch 366/387 ━━━━━━━━━━━━━━━━━━━━ 17:28:17\n",
      "Accuracy: 0.9979 - Precision: 0.8971 - Recall: 0.8942 - Specificity: 0.9990 - F1: 0.8904 - Loss: 0.1224\n",
      "\n",
      "Batch 367/387 ━━━━━━━━━━━━━━━━━━━━ 17:29:42\n",
      "Accuracy: 0.9979 - Precision: 0.8972 - Recall: 0.8940 - Specificity: 0.9990 - F1: 0.8904 - Loss: 0.1225\n",
      "\n",
      "Batch 368/387 ━━━━━━━━━━━━━━━━━━━━ 17:31:33\n",
      "Accuracy: 0.9979 - Precision: 0.8973 - Recall: 0.8942 - Specificity: 0.9990 - F1: 0.8905 - Loss: 0.1223\n",
      "\n",
      "Batch 369/387 ━━━━━━━━━━━━━━━━━━━━ 17:33:14\n",
      "Accuracy: 0.9979 - Precision: 0.8973 - Recall: 0.8943 - Specificity: 0.9990 - F1: 0.8906 - Loss: 0.1222\n",
      "\n",
      "Batch 370/387 ━━━━━━━━━━━━━━━━━━━━ 17:35:01\n",
      "Accuracy: 0.9979 - Precision: 0.8973 - Recall: 0.8945 - Specificity: 0.9990 - F1: 0.8907 - Loss: 0.1221\n",
      "\n",
      "Batch 371/387 ━━━━━━━━━━━━━━━━━━━━ 17:36:55\n",
      "Accuracy: 0.9979 - Precision: 0.8969 - Recall: 0.8945 - Specificity: 0.9990 - F1: 0.8905 - Loss: 0.1223\n",
      "\n",
      "Batch 372/387 ━━━━━━━━━━━━━━━━━━━━ 17:38:42\n",
      "Accuracy: 0.9979 - Precision: 0.8968 - Recall: 0.8947 - Specificity: 0.9990 - F1: 0.8906 - Loss: 0.1222\n",
      "\n",
      "Batch 373/387 ━━━━━━━━━━━━━━━━━━━━ 17:40:12\n",
      "Accuracy: 0.9979 - Precision: 0.8969 - Recall: 0.8950 - Specificity: 0.9990 - F1: 0.8908 - Loss: 0.1220\n",
      "\n",
      "Batch 374/387 ━━━━━━━━━━━━━━━━━━━━ 17:41:49\n",
      "Accuracy: 0.9979 - Precision: 0.8970 - Recall: 0.8950 - Specificity: 0.9990 - F1: 0.8909 - Loss: 0.1219\n",
      "\n",
      "Batch 375/387 ━━━━━━━━━━━━━━━━━━━━ 17:43:16\n",
      "Accuracy: 0.9979 - Precision: 0.8971 - Recall: 0.8949 - Specificity: 0.9990 - F1: 0.8908 - Loss: 0.1219\n",
      "\n",
      "Batch 376/387 ━━━━━━━━━━━━━━━━━━━━ 17:44:50\n",
      "Accuracy: 0.9979 - Precision: 0.8971 - Recall: 0.8950 - Specificity: 0.9990 - F1: 0.8909 - Loss: 0.1219\n",
      "\n",
      "Batch 377/387 ━━━━━━━━━━━━━━━━━━━━ 17:46:09\n",
      "Accuracy: 0.9979 - Precision: 0.8972 - Recall: 0.8952 - Specificity: 0.9990 - F1: 0.8911 - Loss: 0.1217\n",
      "\n",
      "Batch 378/387 ━━━━━━━━━━━━━━━━━━━━ 17:47:31\n",
      "Accuracy: 0.9979 - Precision: 0.8974 - Recall: 0.8953 - Specificity: 0.9990 - F1: 0.8912 - Loss: 0.1215\n",
      "\n",
      "Batch 379/387 ━━━━━━━━━━━━━━━━━━━━ 17:49:01\n",
      "Accuracy: 0.9979 - Precision: 0.8974 - Recall: 0.8953 - Specificity: 0.9990 - F1: 0.8912 - Loss: 0.1215\n",
      "\n",
      "Batch 380/387 ━━━━━━━━━━━━━━━━━━━━ 17:50:34\n",
      "Accuracy: 0.9979 - Precision: 0.8972 - Recall: 0.8954 - Specificity: 0.9990 - F1: 0.8912 - Loss: 0.1215\n",
      "\n",
      "Batch 381/387 ━━━━━━━━━━━━━━━━━━━━ 17:51:50\n",
      "Accuracy: 0.9979 - Precision: 0.8974 - Recall: 0.8953 - Specificity: 0.9990 - F1: 0.8913 - Loss: 0.1215\n",
      "\n",
      "Batch 382/387 ━━━━━━━━━━━━━━━━━━━━ 17:53:13\n",
      "Accuracy: 0.9979 - Precision: 0.8976 - Recall: 0.8955 - Specificity: 0.9990 - F1: 0.8914 - Loss: 0.1213\n",
      "\n",
      "Batch 383/387 ━━━━━━━━━━━━━━━━━━━━ 17:54:48\n",
      "Accuracy: 0.9979 - Precision: 0.8978 - Recall: 0.8954 - Specificity: 0.9990 - F1: 0.8915 - Loss: 0.1212\n",
      "\n",
      "Batch 384/387 ━━━━━━━━━━━━━━━━━━━━ 17:56:09\n",
      "Accuracy: 0.9979 - Precision: 0.8980 - Recall: 0.8951 - Specificity: 0.9990 - F1: 0.8915 - Loss: 0.1213\n",
      "\n",
      "Batch 385/387 ━━━━━━━━━━━━━━━━━━━━ 17:57:39\n",
      "Accuracy: 0.9979 - Precision: 0.8978 - Recall: 0.8953 - Specificity: 0.9990 - F1: 0.8915 - Loss: 0.1213\n",
      "\n",
      "Batch 386/387 ━━━━━━━━━━━━━━━━━━━━ 17:59:03\n",
      "Accuracy: 0.9979 - Precision: 0.8980 - Recall: 0.8950 - Specificity: 0.9990 - F1: 0.8914 - Loss: 0.1213\n",
      "\n",
      "Batch 387/387 ━━━━━━━━━━━━━━━━━━━━ 18:00:19\n",
      "Accuracy: 0.9979 - Precision: 0.8981 - Recall: 0.8947 - Specificity: 0.9990 - F1: 0.8913 - Loss: 0.1214\n",
      "\n",
      "End of Epoch 16\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from scipy.ndimage import zoom, rotate\n",
    "import random\n",
    "\n",
    "# Paths to the dataset\n",
    "#image_dir = r'C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\Datasets\\ImageSegmentation\\3D\\Task01_BrainTumour\\imagesTr'\n",
    "#label_dir = r'C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\Datasets\\ImageSegmentation\\3D\\Task01_BrainTumour\\labelsTr'\n",
    "image_dir = r'F:\\Data\\3D\\Task01_BrainTumour\\imagesTr'\n",
    "label_dir = r'F:\\Data\\3D\\Task01_BrainTumour\\labelsTr'\n",
    "\n",
    "# Parameters\n",
    "batch_size = 1  # Reduced batch size to minimize memory load\n",
    "dim = (128, 128, 128)  # Target dimensions for resizing\n",
    "epochs = 50\n",
    "modalities = [\"FLAIR\", \"T1w\", \"t1gd\", \"T2w\"]\n",
    "\n",
    "# Load filenames and split into training and testing sets\n",
    "image_files = sorted(os.listdir(image_dir))\n",
    "label_files = sorted(os.listdir(label_dir))\n",
    "\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(image_files, label_files, test_size=0.2, random_state=42)\n",
    "\n",
    "# Data Generator Class with Data Augmentation\n",
    "class NiftiDataset(Sequence):\n",
    "    def __init__(self, image_files, label_files, image_dir, label_dir, batch_size=2, dim=(128, 128, 128), shuffle=True, augment=False):\n",
    "        self.image_files = image_files\n",
    "        self.label_files = label_files\n",
    "        self.image_dir = image_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.dim = dim\n",
    "        self.shuffle = shuffle\n",
    "        self.augment = augment\n",
    "        self.indexes = np.arange(len(self.image_files))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.image_files) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        # Pre-allocate arrays for images and masks\n",
    "        batch_images = np.zeros((self.batch_size, *self.dim, 4), dtype=np.float32)\n",
    "        batch_masks = np.zeros((self.batch_size, *self.dim, 1), dtype=np.float32)\n",
    "\n",
    "        for i, idx in enumerate(batch_indexes):\n",
    "            img_path = os.path.join(self.image_dir, self.image_files[idx])\n",
    "            mask_path = os.path.join(self.label_dir, self.label_files[idx])\n",
    "\n",
    "            img = nib.load(img_path).get_fdata()  # Load 4D data with modalities as channels\n",
    "            mask = nib.load(mask_path).get_fdata()\n",
    "\n",
    "            img_resized = self.preprocess_image(img)\n",
    "            mask_resized = self.preprocess_mask(mask)\n",
    "\n",
    "            if self.augment:\n",
    "                img_resized, mask_resized = self.augment_data(img_resized, mask_resized)\n",
    "\n",
    "            batch_images[i] = img_resized\n",
    "            batch_masks[i] = mask_resized[..., np.newaxis]  # Add channel dimension\n",
    "\n",
    "        return batch_images, batch_masks\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def preprocess_image(self, img):\n",
    "        img = (img - np.mean(img, axis=(0, 1, 2))) / (np.std(img, axis=(0, 1, 2)) + 1e-7)  # Normalize per modality\n",
    "        zoom_factors = [self.dim[i] / img.shape[i] for i in range(3)] + [1]  # Keep channels dimension unchanged\n",
    "        img_resized = zoom(img, zoom_factors, order=1)\n",
    "        return img_resized\n",
    "\n",
    "    def preprocess_mask(self, mask):\n",
    "        # Binarize the mask: Convert all non-zero labels to 1\n",
    "        mask = np.where(mask > 0, 1, 0)\n",
    "        zoom_factors = [self.dim[i] / mask.shape[i] for i in range(3)]\n",
    "        mask_resized = zoom(mask, zoom_factors, order=0)  # Use nearest-neighbor for binary masks\n",
    "        return mask_resized\n",
    "\n",
    "    def augment_data(self, image, mask):\n",
    "        # Randomly apply data augmentation\n",
    "        # Flip\n",
    "        if random.random() < 0.5:\n",
    "            axis = random.choice([0, 1, 2])\n",
    "            image = np.flip(image, axis=axis)\n",
    "            mask = np.flip(mask, axis=axis)\n",
    "        # Rotation\n",
    "        if random.random() < 0.5:\n",
    "            angle = random.uniform(-10, 10)\n",
    "            axes = random.choice([(0, 1), (0, 2), (1, 2)])\n",
    "            image = rotate(image, angle=angle, axes=axes, reshape=False, order=1)\n",
    "            mask = rotate(mask, angle=angle, axes=axes, reshape=False, order=0)\n",
    "        # Add more augmentations if needed\n",
    "        return image, mask\n",
    "\n",
    "# Define custom loss functions\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1e-7  # Smoothing constant to prevent division by zero\n",
    "    y_true_f = tf.reshape(y_true, [-1])\n",
    "    y_pred_f = tf.reshape(y_pred, [-1])\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "    denominator = tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f)\n",
    "    dice_coeff = (2. * intersection + smooth) / (denominator + smooth)\n",
    "    return 1 - dice_coeff\n",
    "\n",
    "def combined_loss(y_true, y_pred):\n",
    "    bce = tf.reduce_mean(tf.keras.losses.binary_crossentropy(y_true, y_pred))\n",
    "    d_loss = dice_loss(y_true, y_pred)\n",
    "    return bce + d_loss\n",
    "\n",
    "# Define TensorFlow-based Custom Metrics with Clipping\n",
    "def custom_precision(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(tf.round(y_pred), tf.float32)\n",
    "    tp = tf.reduce_sum(y_true * y_pred)\n",
    "    fp = tf.reduce_sum((1 - y_true) * y_pred)\n",
    "    precision = tp / (tp + fp + 1e-7)\n",
    "    precision = tf.clip_by_value(precision, 0, 1)  # Clip the precision to ensure it stays between 0 and 1\n",
    "    return precision\n",
    "\n",
    "def custom_recall(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(tf.round(y_pred), tf.float32)\n",
    "    tp = tf.reduce_sum(y_true * y_pred)\n",
    "    fn = tf.reduce_sum(y_true * (1 - y_pred))\n",
    "    recall = tp / (tp + fn + 1e-7)\n",
    "    recall = tf.clip_by_value(recall, 0, 1)  # Clip recall between 0 and 1\n",
    "    return recall\n",
    "\n",
    "def custom_f1(y_true, y_pred):\n",
    "    precision = custom_precision(y_true, y_pred)\n",
    "    recall = custom_recall(y_true, y_pred)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall + 1e-7)\n",
    "    f1 = tf.clip_by_value(f1, 0, 1)  # Clip F1 score between 0 and 1\n",
    "    return f1\n",
    "\n",
    "def custom_specificity(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(tf.round(y_pred), tf.float32)\n",
    "    tn = tf.reduce_sum((1 - y_true) * (1 - y_pred))\n",
    "    fp = tf.reduce_sum((1 - y_true) * y_pred)\n",
    "    specificity = tn / (tn + fp + 1e-7)\n",
    "    specificity = tf.clip_by_value(specificity, 0, 1)  # Clip specificity between 0 and 1\n",
    "    return specificity\n",
    "\n",
    "# Define convolutional block with residual connections\n",
    "def conv_block(inputs, filters, kernel_size=(3, 3, 3), padding='same', activation='relu'):\n",
    "    x = tf.keras.layers.Conv3D(filters, kernel_size, padding=padding)(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(activation)(x)\n",
    "    x = tf.keras.layers.Conv3D(filters, kernel_size, padding=padding)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    # Residual connection\n",
    "    shortcut = tf.keras.layers.Conv3D(filters, kernel_size=(1, 1, 1), padding='same')(inputs)\n",
    "    shortcut = tf.keras.layers.BatchNormalization()(shortcut)\n",
    "    x = tf.keras.layers.Add()([x, shortcut])\n",
    "    x = tf.keras.layers.Activation(activation)(x)\n",
    "    return x\n",
    "\n",
    "# Define 3D U-Net Model with Residual Connections\n",
    "def unet_3d(input_shape=(128, 128, 128, 4)):  # Adjust input_shape for 4 modalities\n",
    "    inputs = tf.keras.Input(input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    c1 = conv_block(inputs, 32)\n",
    "    p1 = tf.keras.layers.MaxPooling3D((2, 2, 2))(c1)\n",
    "\n",
    "    c2 = conv_block(p1, 64)\n",
    "    p2 = tf.keras.layers.MaxPooling3D((2, 2, 2))(c2)\n",
    "\n",
    "    c3 = conv_block(p2, 128)\n",
    "    p3 = tf.keras.layers.MaxPooling3D((2, 2, 2))(c3)\n",
    "\n",
    "    c4 = conv_block(p3, 256)\n",
    "\n",
    "    # Decoder\n",
    "    u5 = tf.keras.layers.UpSampling3D((2, 2, 2))(c4)\n",
    "    u5 = tf.keras.layers.Conv3D(128, (2, 2, 2), activation='relu', padding='same')(u5)\n",
    "    merge5 = tf.keras.layers.concatenate([c3, u5], axis=4)\n",
    "    c5 = conv_block(merge5, 128)\n",
    "\n",
    "    u6 = tf.keras.layers.UpSampling3D((2, 2, 2))(c5)\n",
    "    u6 = tf.keras.layers.Conv3D(64, (2, 2, 2), activation='relu', padding='same')(u6)\n",
    "    merge6 = tf.keras.layers.concatenate([c2, u6], axis=4)\n",
    "    c6 = conv_block(merge6, 64)\n",
    "\n",
    "    u7 = tf.keras.layers.UpSampling3D((2, 2, 2))(c6)\n",
    "    u7 = tf.keras.layers.Conv3D(32, (2, 2, 2), activation='relu', padding='same')(u7)\n",
    "    merge7 = tf.keras.layers.concatenate([c1, u7], axis=4)\n",
    "    c7 = conv_block(merge7, 32)\n",
    "\n",
    "    outputs = tf.keras.layers.Conv3D(1, (1, 1, 1), activation='sigmoid')(c7)\n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "# Custom callback to print more metrics at each batch and epoch\n",
    "class MetricsCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, total_batches):\n",
    "        super().__init__()\n",
    "        self.total_batches = total_batches\n",
    "        self.batch_counter = 1\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.batch_counter = 1  # Reset batch counter at the start of each epoch\n",
    "        print(f\"\\nEpoch {epoch + 1}/{self.params['epochs']}\")\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        logs = logs or {}\n",
    "        accuracy = logs.get('accuracy', 0)\n",
    "        loss = logs.get('loss', 0)\n",
    "        precision = logs.get('custom_precision', 0)\n",
    "        recall = logs.get('custom_recall', 0)\n",
    "        f1 = logs.get('custom_f1', 0)\n",
    "        specificity = logs.get('custom_specificity', 0)\n",
    "        current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        print(f\"Batch {self.batch_counter}/{self.total_batches} ━━━━━━━━━━━━━━━━━━━━ {current_time}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f} - Precision: {precision:.4f} - Recall: {recall:.4f} - Specificity: {specificity:.4f} - F1: {f1:.4f} - Loss: {loss:.4f}\\n\")\n",
    "        self.batch_counter += 1\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f\"End of Epoch {epoch+1}\")\n",
    "\n",
    "# Initialize Generators with Data Augmentation for Training\n",
    "train_gen = NiftiDataset(train_images, train_labels, image_dir, label_dir, batch_size=batch_size, dim=dim, augment=True)\n",
    "val_gen = NiftiDataset(val_images, val_labels, image_dir, label_dir, batch_size=batch_size, dim=dim, shuffle=False)\n",
    "\n",
    "# Define Model and Compile with Combined Loss Function\n",
    "model = unet_3d(input_shape=dim + (4,))  # Adjust input_shape to include 4 channels for modalities\n",
    "model.compile(optimizer='adam', loss=combined_loss,\n",
    "              metrics=['accuracy', custom_precision, custom_recall, custom_f1, custom_specificity])\n",
    "\n",
    "# Define Early Stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Initialize Metrics Callback\n",
    "steps_per_epoch = len(train_gen)\n",
    "metrics_callback = MetricsCallback(total_batches=steps_per_epoch)\n",
    "\n",
    "# Train Model with Data Augmentation and Modified Loss Function\n",
    "model.fit(train_gen, validation_data=val_gen, epochs=epochs, callbacks=[early_stopping, metrics_callback], verbose=0)\n",
    "\n",
    "# Visualization Function for Multi-Modal Data\n",
    "def visualize_predictions(images, true_masks, pred_masks, title):\n",
    "    slice_index = images.shape[2] // 2\n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    for i in range(4):  # Loop over modalities\n",
    "        plt.subplot(2, 3, i + 1)\n",
    "        plt.imshow(images[0][:, :, slice_index, i], cmap='gray')\n",
    "        plt.title(f'Modality: {modalities[i]}')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.subplot(2, 3, 5)\n",
    "    plt.imshow(true_masks[0][:, :, slice_index].squeeze(), cmap='jet', alpha=0.7)\n",
    "    plt.title('Ground Truth Mask')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2, 3, 6)\n",
    "    plt.imshow(pred_masks[0][:, :, slice_index].squeeze(), cmap='jet', alpha=0.7)\n",
    "    plt.title('Predicted Mask')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize Predictions for Test Set\n",
    "X_test_batch, y_test_batch = val_gen.__getitem__(0)  # Get first batch from validation set\n",
    "y_test_pred_batch = model.predict(X_test_batch)\n",
    "y_test_pred_batch_bin = (y_test_pred_batch > 0.5).astype(np.uint8)\n",
    "\n",
    "visualize_predictions(X_test_batch, y_test_batch, y_test_pred_batch_bin, \"Test Set Predictions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12641395-cdaa-4589-b4c3-da198f1eecbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e643312-968b-453e-af35-3ff6e47befb5",
   "metadata": {},
   "source": [
    "Runtime: 151.39 hours!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
